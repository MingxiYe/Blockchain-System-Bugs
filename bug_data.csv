source,title,url,bug_location,body,Functional Bug Symtoms,cwe_id,cwe_name,reasoning,state,root_cause,impact,id,number,created_at,closed_at,labels,error
avalanchego,Failed to Repair ProposerVM Height after C-Chain State Sync on Fuji,https://github.com/ava-labs/avalanchego/issues/3948,Storage,"Hitting this error after state syncing the C-Chain on Fuji:

```
[05-07|19:46:09.772] FATAL <C Chain> handler/handler.go:312 shutting down chain {""reason"": ""received an unexpected error"", ""error"": ""failed to notify VM that bootstrapping has started: failed to repair accepted chain height: proposervm height index (40288256) should never be lower than the inner height index (40297478) while processing sync message: get_accepted_state_summary_failed from NodeID-PT9g4vX1UAEE869Fed3kMFNR6Xjyx3RPb""}
```

After restart it fails a second time with:

```
[05-07|19:49:48.180] FATAL chains/manager.go:392 error creating required chain {""subnetID"": ""11111111111111111111111111111111LpoYY"", ""chainID"": ""yH8D7ThNJkxmtkuv2jgBa4P1Rn3Qpr4pPr7QYNfcdoS6k6HWp"", ""vmID"": ""mgj786NP7uDwBCcq6YwThhaN8FLyybkCa4zBWTQbNgmK6k9A6"", ""error"": ""error while creating new snowman vm failed to repair accepted chain by height: proposervm height index (40288256) should never be lower than the inner height index (40297478)""}
```

This appears to be hitting the same underlying error on two paths (`SetState` at the end of state sync and `Initialize` on restart).

The actual error occurs here: https://github.com/ava-labs/avalanchego/blob/a90944df3fc8a413e5cf14d7ba0c305899d47834/vms/proposervm/vm.go#L466

This indicates that the ProposerVM and Coreth end up breaking an invariant that the ProposerVM's last accepted height _must_ always be >= the inner VM's last accepted height.

Likely related to https://github.com/ava-labs/avalanchego/pull/3831",storage: storage corruption,CWE-682,Incorrect Calculation,"The bug report describes a fatal error where an invariant is violated: the `proposervm height index` is found to be lower than the `inner height index`. These heights are numerical values that represent the state of different virtual machines. The error occurs after a 'state sync' operation, which is a process to update the local node's state. The fact that these two height values are inconsistent implies that at least one of them was calculated incorrectly during the state sync process. This directly aligns with CWE-682, 'Incorrect Calculation', where the product performs a calculation that generates incorrect results (the inconsistent heights), leading to a critical failure (shutdown to prevent storage corruption). CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is not suitable because the system *does* check for this exceptional condition and correctly halts. The check itself is not the flaw; the underlying state is. CWE-20, 'Improper Input Validation', is less fitting because the issue is presented as a broken invariant between internal components, pointing to a flaw in internal state computation rather than a failure to validate external data.",closed,"The ProposerVM's last accepted height is incorrectly set to a value less than the inner VM's last accepted height, violating the invariant that it must always be greater than or equal.","This bug can lead to a chain shutdown and prevent the proper functioning of the C-Chain, resulting in potential service disruptions and inconsistencies in state management during synchronization.",3049236207,3948,"May 8, 2025 2:47 PM (GMT+8)","May 16, 2025 12:16 AM (GMT+8)",['bug'],
avalanchego,Unusual disk usage when bootstrapping from scratch with v1.11.6,https://github.com/ava-labs/avalanchego/issues/3060,Storage,"**Describe the bug**
I'm observing erratic disk usage while bootstrapping from scratch using the latest v1.11.6. The configuration file is provided below, and state-sync is enabled.

The last time I performed this operation, it completed in less than 48 hours. The attached screen captures show the disk usage differences between v1.11.5 and v1.11.6.

Notably, the configuration and server specifications are identical for both runs, with the only variable being the avalanchego version. The server specs are as follows:
- 16 vCPU cores
- 32GB RAM
- 400GiB SSD NVMe
- location: France

Please see the screen captures and configuration file below for further details.

**To Reproduce**
Start a new instance with an empty database with the following C-Chain configuration:
```json
{
    ""state-sync-enabled"": true
}
```

**Expected behavior**

Reduced synchronization time and, more importantly, lower disk usage. As shown in the screenshot, there was a spike exceeding 80%.
This issue might be related to a Core-ETH bug that I've already reported. Here is the fix: https://github.com/ava-labs/coreth/pull/565

**Screenshots**
Here is a screenshot of the disk usage from a bootstrap I performed two weeks ago using v1.11.5:
![avalanchego-v1 11 5](https://github.com/ava-labs/avalanchego/assets/135046224/425c6fe9-f5fe-42a4-8ebf-84f4eebf98b2)

Here is a screenshot of the disk usage from the current bootstrap with the v1.11.6:
![avalanchego-v1 11 6](https://github.com/ava-labs/avalanchego/assets/135046224/a22a77f1-9300-479a-94d9-254aac121e2b)

**Logs**
Please find attached the log file.

**Metrics**
Please find attached the metrics.log

**Operating System**
Ubuntu 22.04 LTS

**To best protect the Avalanche community security bugs should be reported in accordance to our [Security Policy](../security/policy)**
[metrics.log](https://github.com/ava-labs/avalanchego/files/15501523/metrics.log)
",general: general performance degradation,CWE-459,Incomplete Cleanup,"The bug report describes an issue of 'unusual disk usage' and a 'spike exceeding 80%' during a bootstrapping process. The user explicitly links to a pull request for a fix titled 'fix: Prune expired trie nodes during state sync'. This title strongly indicates that the problem stems from a failure to remove data that is no longer needed ('expired trie nodes') during the operation. This directly aligns with the definition of CWE-459: 'Incomplete Cleanup', which states that 'The product does not properly clean up and remove temporary or supporting resources after they have been used.' The expired nodes are supporting resources that are not being cleaned up, leading to excessive disk consumption. 

CWE-400, 'Uncontrolled Resource Consumption', is a broader category that describes the symptom (high disk usage) but not the specific cause. CWE-459 is more precise because it identifies the root cause as a failure in the cleanup process. 

CWE-404, 'Improper Resource Shutdown or Release', is less applicable as it typically refers to resources like file handles or network connections, not the persistent data files that are accumulating on the disk due to a lack of cleanup.",closed,"The issue appears to stem from an inefficient resource management during the bootstrapping process in version v1.11.6, leading to unexpected spikes in disk usage.","The erratic disk usage can lead to resource exhaustion, potentially affecting the performance and reliability of the node, resulting in longer synchronization times and increased operational costs.",2325862668,3060,"May 30, 2024 2:47 PM (GMT+8)","May 31, 2024 11:25 PM (GMT+8)","['bug', 'storage']",
avalanchego,API returns wrong control keys data after subnet ownership transfer,https://github.com/ava-labs/avalanchego/issues/3012,API,"**Describe the bug**
When subnet ownership has been transferred over, `platform.getSubnets()` API call shows the old data unless selecting for the subent specifically using the `ids` param.

**To Reproduce**
Curl-ing with a payload of:
```json
{
    ""jsonrpc"": ""2.0"",
    ""method"": ""platform.getSubnets"",
    ""params"": {},
    ""id"": 1
}
```
gives the list of all the subnets, among others it has:
```json
            {
                ""id"": ""HDHyjxQi3fnMDmuEGZzEx33rbGe6Yz1dz2WGgEit6jEuTbxdj"",
                ""controlKeys"": [
                    ""P-fuji1ywzvrftfqexh5g6qa9zyrytj6pqdfetza2hqln""
                ],
                ""threshold"": ""1""
            },
```
But calling with
```json
{
    ""jsonrpc"": ""2.0"",
    ""method"": ""platform.getSubnets"",
    ""params"": {""ids"":[""HDHyjxQi3fnMDmuEGZzEx33rbGe6Yz1dz2WGgEit6jEuTbxdj""]},
    ""id"": 1
}
```
returns the correct control key:
```json
            {
                ""id"": ""HDHyjxQi3fnMDmuEGZzEx33rbGe6Yz1dz2WGgEit6jEuTbxdj"",
                ""controlKeys"": [
                    ""P-fuji1mlhaxu92c5p57ce56trsc7eha6cflh20cfy4gn""
                ],
                ""threshold"": ""1""
            }
```
**Expected behavior**
The API call should return the correct data in both cases.

**Operating System**
Node running on Ubuntu. Version info:
```json
{
    ""jsonrpc"": ""2.0"",
    ""result"": {
        ""version"": ""avalanchego/1.11.4"",
        ""databaseVersion"": ""v1.4.5"",
        ""rpcProtocolVersion"": ""35"",
        ""gitCommit"": ""e8904ae11aa144ae601bb9795682d11c3fb178ee"",
        ""vmVersions"": {
            ""avm"": ""v1.11.4"",
            ""evm"": ""v0.13.2"",
            ""platform"": ""v1.11.4""
        }
    },
    ""id"": 1
}
```
",api: incorrect api output,CWE-672,Operation on a Resource after Expiration or Release,"The bug report describes a scenario where an API endpoint, `platform.getSubnets`, returns stale data after a state change (subnet ownership transfer). Specifically, a general query returns the old `controlKeys`, while a more specific query returns the correct, new `controlKeys`. This indicates the system is using an outdated representation of the subnet's state. This directly maps to CWE-672: Operation on a Resource after Expiration or Release. The 'resource' is the subnet's ownership data (the `controlKeys`). After the transfer, the old data is 'expired'. The API call that returns this old data is performing an 'operation on a resource after expiration'.

CWE-459 (Incomplete Cleanup) is a possible cause, as the stale data might exist due to a failure to invalidate a cache (a form of incomplete cleanup). However, CWE-672 describes the direct consequence and the nature of the bug itself—the *use* of the expired data—which is what is reported. 

CWE-662 (Improper Synchronization) is less suitable because the bug report describes a consistent failure for a specific API call path, not the intermittent or unpredictable behavior characteristic of a race condition or synchronization issue.",closed,"The API does not properly update or validate the state of the subnet ownership transfer, leading to stale data being returned for the control keys until a specific subnet ID is queried.","Users may receive outdated or incorrect control keys information, potentially leading to unauthorized access or management issues regarding the subnets, affecting overall trust and reliability in the API.",2290044968,3012,"May 10, 2024 4:29 PM (GMT+8)","May 30, 2024 1:35 AM (GMT+8)",['bug'],
avalanchego,RPC call: the method debug_traceBlockByNumber does not exist/is not available,https://github.com/ava-labs/avalanchego/issues/2939,API,"**Describe the bug**
Editing the config file of the chain appears to have no effect.

In this case, setting the value of `eth-apis` to include `debug-tracer` does nothing.

Here is the file configs/chains/ourChainName/config.json:

```
{
    ""eth-apis"": [
        ""eth"",
        ""eth-filter"",
        ""net"",
        ""web3"",
        ""internal-eth"",
        ""internal-blockchain"",
        ""internal-transaction"",
        ""debug-tracer""
    ],
    ""http-host"": """",
    ""http-port"": 9123,
    ""network-id"": ""fuji"",
    ""public-ip"": ""ommited"",
    ""staking-port"": 9122,
    ""state-sync-enabled"": true,
    ""track-subnets"": ""ommited""
}
```

Here is an example, when running:
```
curl http://127.0.0.1:9123/ext/bc/23SUgLgnzQcai7ceCSnKcWQieQwkUsUpM8HrfSVG4Mk5tof8Tp/rpc \
  -X POST \
  -H ""Content-Type: application/json"" \
  --data '{""method"":""debug_traceTransaction"",""params"":[""0x154bbe502added59dd0dfc4198fe584a85abdfcc7a0c842aa43b9b75cb62b154"", {}],""id"":1,""jsonrpc"":""2.0""}'
```
outputs, on any node (all of them have debug-tracer on the config):
```
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32601,""message"":""the method debug_traceTransaction does not exist/is not available""}}
```

another example:
```
curl http://127.0.0.1:9123/ext/bc/23SUgLgnzQcai7ceCSnKcWQieQwkUsUpM8HrfSVG4Mk5tof8Tp/rpc \
  -X POST \
  -H ""Content-Type: application/json"" \
  --data '{""method"":""debug_traceBlockByNumber"",""params"":[""0xc"", {}],""id"":1,""jsonrpc"":""2.0""}'
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32601,""message"":""the method debug_traceBlockByNumber does not exist/is not available""}}
```

Another piece of information is:

I removed the API `internal-blockchain` from the config and restarted the node.

Then I called the method `eth_getBlockByNumber` of this API:
`curl http :// 127 . 0 . 0 . 1:9123/ext/bc/23SUgLgnzQcai7ceCSnKcWQieQwkUsUpM8HrfSVG4Mk5tof8Tp/rpc   -X POST   -H ""Content-Type: application/json""   --data '{""method"":""eth_getBlockByNumber"",""params"":[""0xc"",false],""id"":1,""jsonrpc"":""2.0""}'` 

And it gave me an answer. But it was not supposed to give me an answer: it was supposed to say the method `eth_getBlockByNumber` was not availalbe because I disabled its API.

So it seems that:
1. there is an issue with the config file
2. the value is not being taken
3. the value is being overwritten


**Additional context**

    OS: ubuntu
    Version avalanchego/1.11.3",api: api unavailability,CWE-547,Use of Hard-coded,"The bug report describes a situation where the application's configuration file is being ignored. The user attempts to enable a 'debug-tracer' API and disable an 'internal-blockchain' API by editing the `eth-apis` list in a JSON configuration file. In both cases, the changes have no effect. The application behaves as if a default or different configuration is active, making the debug API unavailable and keeping the internal API available. This strongly suggests that the list of enabled APIs, a security-relevant setting, is not being read from the configuration file but is instead using a hard-coded value. This aligns directly with CWE-547, which describes the use of hard-coded constants for security-critical values, preventing them from being changed as intended by the user or administrator. CWE-755 is less appropriate because the core issue is not the handling of an exceptional condition (like an error during an operation). The error message 'the method does not exist/is not available' is a symptom of the underlying configuration problem, not a failure in exception handling logic.",closed,"The configuration settings for the RPC API are not being properly applied, leading to methods that should be disabled remaining available.","This bug can lead to unauthorized access to API methods, exposing sensitive functionalities that should be restricted, potentially allowing malicious users to exploit the system.",2240710008,2939,"April 12, 2024 6:40 PM (GMT+8)","April 14, 2024 1:14 AM (GMT+8)",['bug'],
avalanchego,FATAL chains/manager.go:350 error creating required chain,https://github.com/ava-labs/avalanchego/issues/2621,Consensus,"Hi... I set up my validator. I believe it went through boostrapping ok. 

My set up is an AWS Ubuntu VM. 
I'm running avalanche/1.10.15 [database=v1.4.5, rpcchainvm=30, commit=20f3580b4912f29adc602ad883e84897f0965cc1, go=1.21.3]

When I type in avalanchego i receive this error: 
FATAL chains/manager.go:350 error creating required chain
""error"": ""error while creating new snowman vm failed to create atomic backend: duplicated operation on provided value""",general: initialization failure,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a `FATAL` error that occurs during the application's startup sequence (`error creating required chain`). The specific error, `duplicated operation on provided value`, represents an unexpected state that the program encounters. The application's response is to terminate completely, as indicated by the `FATAL` log level and the `initialization failure` symptom. This is a direct example of failing to handle an exceptional condition. CWE-703, 'Improper Check or Handling of Exceptional Conditions', perfectly describes this scenario where the software does not properly handle a rare or unexpected state, leading to a crash. CWE-662, 'Improper Synchronization', could be the underlying root cause of the 'duplicated operation' error, but the bug report's most prominent and certain evidence is the failure to handle the resulting exception, not the synchronization issue itself. CWE-404, 'Improper Resource Shutdown or Release', is not applicable as the error occurs during resource creation and initialization, not during shutdown or release.",closed,"The error indicates that there is an issue with creating a new chain due to a duplicated operation on a provided value, which suggests that a value might be reused improperly in the context of chain creation.","This bug can prevent the validator from successfully starting and participating in the network, leading to downtime and potential loss of rewards for the validator. It may also affect the overall network stability if a significant number of validators encounter this issue.",2086813574,2621,"January 17, 2024 7:12 PM (GMT+8)","January 19, 2024 5:42 AM (GMT+8)",['bug'],
op-geth,Interop ingress filter should assign the pending timestamp to exec descriptors,https://github.com/ethereum-optimism/op-geth/issues/603,Consensus,"The ingress filter currently assigns the latest timestamp to exec descriptors:

https://github.com/ethereum-optimism/op-geth/blob/e605d07bde55b02f9e0309c330fb87500d80d06f/core/txpool/ingress_filters.go#L48

https://github.com/ethereum-optimism/op-geth/blob/e605d07bde55b02f9e0309c330fb87500d80d06f/eth/interop.go#L20-L31

This means executing messages are unnecessarily delayed by one block when the supervisor uses a stringent [access list policy](https://specs.optimism.io/interop/supervisor.html#access-list-checks), as in the [reference implementation](https://github.com/ethereum-optimism/optimism/blob/23c1fef1f0fe6b626c987eecbfa91fd5e0b66fb0/op-supervisor/supervisor/types/types.go#L344-L346).

Assigning the pending timestamp instead of the unsafe timestamp should fix the issue.",consensus: consensus inefficiency,CWE-682,Incorrect Calculation,"The bug report describes an issue where an incorrect timestamp (`latest` instead of `pending`) is assigned to execution descriptors. This incorrect value leads to an unintended consequence: an unnecessary one-block delay in message execution, which is termed a 'consensus inefficiency'. This directly aligns with CWE-682 'Incorrect Calculation', which states 'The product performs a calculation that generates incorrect or unintended results that are later used in security-critical decisions or resource management.' In this case, the 'incorrect calculation' is the selection of the wrong timestamp. This result is then used in a security-critical decision (the access list policy check, part of the consensus mechanism), leading to the unintended outcome (the delay). CWE-693 'Protection Mechanism Failure' is less accurate because the issue is not a failure of the access list policy itself, but rather incorrect data being fed into it. The problem is an inefficiency, not a failure to defend against a directed attack. CWE-841 'Improper Enforcement of Behavioral Workflow' is also incorrect as the bug is not about the sequence of operations being wrong, but about an incorrect data value being used within one of the steps.",closed,"The ingress filter incorrectly assigns the latest timestamp to execution descriptors instead of the pending timestamp, causing delays in executing messages due to stringent access list checks.","This bug can lead to unnecessary delays in message execution, adversely affecting the performance and responsiveness of the system, especially under stringent access control conditions.",3057340949,603,"May 12, 2025 3:21 PM (GMT+8)","June 3, 2025 9:55 PM (GMT+8)","['bug', 'H-interop']",
op-geth,eth_feeHistory is broken with v1.101503.0,https://github.com/ethereum-optimism/op-geth/issues/542,API,"#### System information

v1.101503.0

tried this payload
```json
{""jsonrpc"":""2.0"",""id"":1,""method"":""eth_feeHistory"",""params"":[10,""latest"",[25,75]]}
```

getting
```json
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32603,""message"":""json: unsupported value: NaN""}}
```",api: api unavailability,CWE-755,Improper Handling of Exceptional Conditions,"The bug report indicates that a specific API call to `eth_feeHistory` results in an error: `""json: unsupported value: NaN""`. This error message is key. It shows that during the execution of the API method, a calculation resulted in a `NaN` (Not a Number) value. This `NaN` is an exceptional condition. The program then attempted to serialize this `NaN` value into a JSON response, which is not supported by the JSON standard, causing the serializer to fail and return an internal error. 

- **CWE-20 (Improper Input Validation)** is not the best fit. The input parameters `[10, ""latest"", [25, 75]]` appear to be syntactically and semantically valid for the `eth_feeHistory` method. The issue is not that the input is malformed or invalid, but rather that the internal processing of this valid input leads to an exceptional state.

- **CWE-754 (Improper Check for Unusual or Exceptional Conditions)** is a plausible candidate, as the code likely did not check if a calculation resulted in `NaN`. However, this is the root cause, not the most direct description of the failure mode.

- **CWE-755 (Improper Handling of Exceptional Conditions)** is the most accurate choice. The system successfully generated the exceptional condition (`NaN`) but then failed to handle it gracefully. Instead of catching the `NaN` and returning a more meaningful error or a default value, the program passed the unsupported value to the JSON serializer, which then crashed. This is a direct example of improperly handling an exceptional condition that has already occurred. The bug report's evidence points directly to the failure in handling, making CWE-755 the most precise classification.",closed,"The API method `eth_feeHistory` is returning an error due to an unsupported value (NaN) in the response, which suggests that there is an issue with the calculation or representation of fee history data.","The bug prevents users from retrieving the fee history, which can hinder their ability to make informed decisions about transaction fees, potentially leading to inefficient transaction processing.",2915554136,542,"March 13, 2025 1:36 AM (GMT+8)","March 13, 2025 8:00 PM (GMT+8)",['bug'],
nethermind,GetStorageRange returns both empty arrays when no slots are found,https://github.com/NethermindEth/nethermind/issues/8537,Storage,"**Description**
GetStorageRange returns both empty arrays when no slots are found which is a typical return for a missing root hash. Snap client code cannot interpret that there are not further slots for an account.

**Expected behavior**
In a case where no storage slots are found according to the request, the response should contains an empty arrays for slots and a proof for absence of the key.",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report describes a situation where an API (`GetStorageRange`) returns the same value (two empty arrays) for two different underlying states: 'no storage slots found' and 'a missing root hash'. This ambiguity causes the client consuming the API to misinterpret the state, as it 'cannot interpret that there are not further slots for an account'. This directly aligns with the definition of CWE-436, 'Interpretation Conflict', where one product (the client) performs incorrect actions based on its perception of another product's (the server's) state due to a difference in how a value is handled or interpreted. CWE-391, 'Unchecked Error Condition', is unsuitable because the issue is not that an error is ignored, but that a returned value is ambiguous. CWE-755, 'Improper Handling of Exceptional Conditions', is less precise because the core problem is not just the handling of a condition, but the specific outcome of that handling: an ambiguous representation that leads to a conflict in interpretation between the server and the client.",closed,"The GetStorageRange function does not differentiate between a missing root hash and a successful request with no storage slots, leading to ambiguous responses.","This can cause confusion in the Snap client code, making it unable to correctly interpret the absence of storage slots, which may lead to incorrect application behavior or failure to process user requests properly.",3005095577,8537,"April 18, 2025 2:40 PM (GMT+8)","May 29, 2025 3:43 PM (GMT+8)",['bug'],
nethermind,Nethermind doesn't always the right return code upon some processing errors in the engine API,https://github.com/NethermindEth/nethermind/issues/8479,API,"**Description**

A Nethermind that gets an out-of-memory issue while processing a block in the engine API, can under some circumstances return the error code `INVALID` back to the beacon node, without having fully processed the block. As a result the beacon node will think the block is indeed invalid and start building on the parent slot instead: this leads to a fork.

I believe the issue is here in the code in PayloadStatusV1 (NewPayloadHandler.cs):

```
        if (!request.TryGetBlock(out Block? block, _poSSwitcher.FinalTotalDifficulty))
        {
            if (_logger.IsWarn) _logger.Warn($""New Block Request Invalid: {request}."");
            return NewPayloadV1Result.Invalid(null, $""Block {request} could not be parsed as a block"");
        }
```

Under these circumstances, it should likely return:

```
-32603 | Internal error | Internal JSON-RPC error.
-32000 | Server error | Generic client error while processing request.
```

From https://github.com/ethereum/execution-apis/blob/main/src/engine/common.md ; I didn't check other possible errors but there can be more similar issues in the codebase.

**Additional context**

This was encountered on Sepolia and led the validators behind the affected node to be on a fork for some time. In a large-scale memory/processing event like the inactivity leak that happened once in mainnet, this could actually stuck the mainnet chain as Nethermind has > 33% market shares.

**Logs**

Beacon:

```
2025-04-05 06:01:34.372 INFO  - Retrying execution of block ebb3fe9c5fc6e5cbe00c00a36582261008e0c1472b10433476a7185f0aae7646 (7341607)
2025-04-05 06:01:39.068 INFO  -  Execution Client is responding to requests again after a previous failure 
2025-04-05 06:01:39.071 WARN  - Payload for child of block root 0xdf035ea5dbe9975298e6e3bfa692100d868dc47ffcea88fff9775e8febd5abe4 marked as invalid by Execution Client
```

Exec:

```
05 Apr 06:01:29 | Received New Block:  8054232 (0xca12a7...a82cf3)      | limit    35,964,743 👆 | Extra Data: ؃ geth go1.23.2 linux
05 Apr 06:01:36 | Processing queue wasn't empty added to queue New Block:  8054232 (0xca12a7...a82cf3).
05 Apr 06:01:39 | New Block Request Invalid: 8054232 (0xca12a7...a82cf3).
05 Apr 06:01:41 | Encountered exception System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.
   at System.GC.AllocateNewArray(IntPtr typeHandle, Int32 length, GC_ALLOC_FLAGS flags)
   at System.Buffers.SharedArrayPool`1.Rent(Int32 minimumLength)
   at Nethermind.Evm.EvmPooledMemory.UpdateSize(UInt64 length, Boolean rentIfNeeded) in /src/Nethermind/Nethermind.Evm/EvmPooledMemory.cs:line 351
   at Nethermind.Evm.EvmPooledMemory.Save(UInt256& location, ZeroPaddedSpan& value) in /src/Nethermind/Nethermind.Evm/EvmPooledMemory.cs:line 140
   at Nethermind.Evm.VirtualMachine`1.ExecuteCode[TTracingInstructions,TTracingRefunds,TTracingStorage](EvmState vmState, EvmStack`1& stack, Int64 gasAvailable, IReleaseSpec spec) in /src/Nethermind/Nethermind.Evm/VirtualMachine.cs:line 1219
[...]
```

Thanks to folks on the Sepolia TG and Enrico Del Fante for helping with investigations.",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a scenario where the system encounters an `OutOfMemoryException` while processing a block. This is an exceptional condition. The system's response to this exception is incorrect; it returns an `INVALID` error code instead of an internal server error code. This misclassification of the error leads to severe consequences, namely a blockchain fork. 

- **CWE-400 (Uncontrolled Resource Consumption)** is a plausible root cause for the `OutOfMemoryException` itself, but the bug report's focus is not on why the memory was exhausted, but on how the application behaved *after* the exception occurred. The weakness described is in the error handling logic, not the resource management.

- **CWE-391 (Unchecked Error Condition)** is incorrect because the error condition is not ignored. The code does check for a failure (the `if (!request.TryGetBlock(...))` block) but then handles it improperly. The error is checked, but the subsequent action is wrong.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions)** is the most accurate description. An `OutOfMemoryException` is a classic exceptional condition. The software does not handle this specific exception correctly, leading it to return a misleading error status. This directly aligns with the CWE's definition of not properly handling exceptional conditions that occur during operation.",closed,"The engine API does not handle out-of-memory errors properly, leading it to return an incorrect response code of `INVALID` instead of an appropriate error code.","This can cause the beacon node to mistakenly treat a block as invalid, resulting in forks in the blockchain, which can severely disrupt the network, especially if a significant portion of nodes are affected.",2977040419,8479,"April 7, 2025 2:21 PM (GMT+8)","April 10, 2025 11:17 PM (GMT+8)","['bug', '[Pri] High']",
nethermind,No space left on device: Gracefully handle internal exceptions,https://github.com/NethermindEth/nethermind/issues/8384,API,"On ""No space left on device"" error, the node reported the block as invalid, which was sent to the CL. We should avoid propagating El's internal errors to CL.

Stacktrace:

```
Processing loop threw an exception. Block: 7923793 (0x94b38e...364d54), Exception: RocksDbSharp.RocksDbException: IO error: No space left on device: While appending to file: /data/execution/nethermind_db/sepolia/badBlocks/000008.log: No space left on device
   at Nethermind.Db.Rocks.DbOnTheRocks.SetWithColumnFamily(ReadOnlySpan`1 key, ColumnFamilyHandle cf, ReadOnlySpan`1 value, WriteFlags flags) in /src/Nethermind/Nethermind.Db.Rocks/DbOnTheRocks.cs:line 719
   at Nethermind.Core.KeyValueStoreExtensions.Set(IWriteOnlyKeyValueStore db, Int64 blockNumber, Hash256 key, ReadOnlySpan`1 value, WriteFlags writeFlags) in /src/Nethermind/Nethermind.Core/KeyValueStoreExtensions.cs:line 120
   at Nethermind.Blockchain.Blocks.BadBlockStore.Insert(Block block, WriteFlags writeFlags) in /src/Nethermind/Nethermind.Blockchain/Blocks/BadBlockStore.cs:line 26
   at Nethermind.Blockchain.BlockTree.DeleteInvalidBlock(Block invalidBlock) in /src/Nethermind/Nethermind.Blockchain/BlockTree.cs:line 688
   at Nethermind.Consensus.Processing.BlockchainProcessor.<>c__DisplayClass56_0.<ProcessBranch>g__DeleteInvalidBlocks|0(ProcessingBranch& processingBranch, Hash256 invalidBlockHash) in /src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 460
   at Nethermind.Consensus.Processing.BlockchainProcessor.ProcessBranch(ProcessingBranch& processingBranch, ProcessingOptions options, IBlockTracer tracer, String& error) in /src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 519
   at Nethermind.Consensus.Processing.BlockchainProcessor.Process(Block suggestedBlock, ProcessingOptions options, IBlockTracer tracer, String& error) in /src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 366
   at Nethermind.Consensus.Processing.BlockchainProcessor.RunProcessingLoop() in /src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 286
17 Mar 2025 23:05:14.358
 Corrupted DB detected on path /data/execution/nethermind_db/sepolia/badBlocks. Please restart Nethermind to attempt repair.
```",api: incorrect api output,CWE-755,Improper Handling of Exceptional Conditions,"The bug report details how the application behaves when it encounters a 'No space left on device' error. This is an exceptional condition. The stack trace shows a `RocksDbException` being thrown, which is not handled gracefully. Instead of managing this internal error, the application propagates it in a way that leads to incorrect logic (reporting a block as invalid) and a potentially corrupted state. The bug's title, 'Gracefully handle internal exceptions', and the description, 'We should avoid propagating El's internal errors to CL', directly point to a failure in exception handling. 

- CWE-20 is incorrect because the issue is not related to validating input data.
- CWE-400 describes the condition that triggers the error (resource exhaustion) but not the software flaw itself. The flaw is the program's *reaction* to the lack of resources, not the consumption of the resources.
- CWE-755 perfectly describes the situation: the product encounters an exceptional condition (disk full) and handles it incorrectly, leading to downstream logical errors. Therefore, it is the most accurate classification.",closed,"The node fails to gracefully handle the 'No space left on device' error when attempting to write to the database, leading to the propagation of internal exceptions to the consensus layer.","This bug can cause the node to incorrectly mark blocks as invalid, disrupt the block processing loop, and potentially lead to corruption of the database, which may require a restart to repair.",2928148988,8384,"March 18, 2025 11:20 AM (GMT+8)","April 10, 2025 11:17 PM (GMT+8)","['bug', '[Pri] High']",
nethermind,eth_getRawTransactionByHash wrong TX encoding,https://github.com/NethermindEth/nethermind/issues/8256,API,"**Description**

I _think_ there is a bug in the implementation of the `eth_getRawTransactionByHash` RPC call.
The reason I think this is because when this is called from [rbuilder](https://github.com/flashbots/rbuilder/blob/6cdb89c06636dca8bedd7b24a12a0d6e6edcc3e5/crates/rbuilder/src/primitives/mod.rs#L611), TX cannot be parsed and errors with `Failed to decode transaction, error: unexpected string`

**Steps to Reproduce**
In order to replicate the behavior, please provide a detailed list of steps:
1. This is output of one of the transactions: `b8b702f8b40183adcb6a84773594008517bfac7c008303291894a0b86991c6218b36c1d19d4a2e9eb0ce3606eb4880b844a9059cbb0000000000000000000000003c5fd3564bbaec0fc9383b5c13a6eb20926a800000000000000000000000000000000000000000000000000000000000015752a0c080a058a58bd8771dea6375c0ad0420c5321a2e15de402044f67874ddccfefa091ee6a06cea78cba171430e4a3d051381301516105ded783fb1a156a2944666ec3facbb`
2. I went to [this website](https://rawtxdecode.in/), tried to decode TX from above and also got an error (like in `rbuilder`), that's why I think the issue is on our side
3. Error: _Failed to parse raw transaction hex: Unable to cast object of type 'Nethereum.RLP.RLPItem' to type 'Nethereum.RLP.RLPCollection'_.

**Expected behaviour**
The TX shoul've been parsed,  this is that very same TX: [link](https://etherscan.io/tx/0x5fbc9b1132c3d568f9b5e805981162c75d50ee9c99ab72ad100a3a6e4e4103e3)


**Additional context**
As far as I can tell, this only happens with EIP-2718 Typed TXs, the Legacy ones are OK. 
Here is the output of Legacy TX:
```
f9014b8218e184504a4cba831e84809468b3465833fb72a70ecdf485e0e4c7bd8665fc4580b8e404e45aaf000000000000000000000000bdf43ecadc5cef51b7d1772f722e40596bc1788b000000000000000000000000a0b86991c6218b36c1d19d4a2e9eb0ce3606eb480000000000000000000000000000000000000000000000000000000000000bb8000000000000000000000000a9ab8d5b5aab8e3215c6d0a5dcbce123299f1e7b000000000000000000000000000000000000000000000518d4f6fa3446ce000000000000000000000000000000000000000000000000000000000001949c3941000000000000000000000000000000000000000000000000000000000000000026a0fafdafb3c614c7feb1accecead542acf28efa69673276d6e2435d09bc389d657a01e8130c326f08f1707aa8973a87cc72edc857f5c956bccb70d30a1ea4b665c43
```
This doesn't error on `rbuilder` and it is also successfully parsed by [this site](https://rawtxdecode.in/). 

I have tried playing with different `RlpBehaviors` but that didn't help :)
To parse the TX `rbuilder` uses `alloy-rs` here is how [they parse this ](https://github.com/alloy-rs/alloy/blob/88fc40338270756cc1f468319eda642cf01eb153/crates/consensus/src/transaction/pooled.rs#L338).

**rbuilder repro steps**
1. `rbuilder` connects to NMC via WS/IPC and subscribes to mainnet pending transactions (`eth_subscribe/newPendingTransactions`)
2. When new TX hash is received by `rbuilder` it calls `eth_getRawTransactionByHash` 
3. After receiving raw TX (bytes), `rbuilder` will fail to decode these bytes: [here](https://github.com/flashbots/rbuilder/blob/70e396298cb4961b863c093be603fdfbbd4f7e1e/crates/rbuilder/src/primitives/mod.rs#L619) 
",api: incorrect api output,CWE-116,Improper Encoding or Escaping of Output,"The bug report details an issue where the `eth_getRawTransactionByHash` RPC call produces an incorrectly formatted byte string for a specific type of transaction (EIP-2718). This output is intended for consumption by another component (`rbuilder`), which fails to parse it. The core problem is that the data is not encoded according to the specification, causing downstream failures. This aligns perfectly with the definition of CWE-116, which states, 'The product prepares a structured message for communication with another component, but encoding or escaping of the data is either missing or done incorrectly. As a result, the intended structure of the message is not preserved.' The Nethermind node is the product, the raw transaction is the structured message, and the encoding is incorrect. CWE-704, 'Incorrect Type Conversion or Cast', describes a symptom seen in the client ('Unable to cast object...') rather than the root cause in the server, which is the improper encoding. CWE-436, 'Interpretation Conflict', is less accurate because the problem is not a differing interpretation of a valid message but the generation of a malformed message that violates the agreed-upon standard.",closed,"The implementation of the `eth_getRawTransactionByHash` RPC call does not correctly handle EIP-2718 Typed Transactions, resulting in decoding failures when retrieving the transaction data.","This bug can lead to failures in transaction processing for EIP-2718 Typed Transactions, which may affect applications relying on accurate transaction data retrieval, potentially causing transaction errors or mismanagement in systems like `rbuilder`.",2874804543,8256,"February 24, 2025 12:27 PM (GMT+8)","March 7, 2025 9:37 PM (GMT+8)","['bug', 'rpc']",
nethermind,Pectra from genesis in Kurtosis devnet,https://github.com/NethermindEth/nethermind/issues/8223,Execution,"[genesis (2).json](https://github.com/user-attachments/files/18849514/genesis.2.json)


```
18 Feb 14:05:45 | Processed block 0 (0x5cd018...da40df) is invalid:
  18 Feb 14:05:45 | - hash: expected 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961, got 0x5cd018ddc42848afb122fa54cc4d3a5c0c40c42d23cbacf12ac28209b7da40df
  18 Feb 14:05:45 | - state root: expected 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc, got 0x4f45c30603679bb3d3d65c537b7782b65ab2b24c7d353c4259a1ba4773f24818
  18 Feb 14:05:45 | - block extra data : , UTF8:
  18 Feb 14:05:45 | Rejected invalid block 0 (0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961),  ExtraData: , reason: invalid block after processing
  18 Feb 14:05:45 | Encountered exception Nethermind.Blockchain.InvalidBlockException: InvalidStateRoot: State root in header does not match. Expected 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc, got 0x4f45c30603679bb3d3d65c537b7782b65ab2b24c7d353c4259a1ba4773f24818
     at Nethermind.Consensus.Processing.BlockProcessor.ValidateProcessedBlock(Block suggestedBlock, ProcessingOptions options, Block block, TxReceipt[] receipts) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 302
     at Nethermind.Consensus.Processing.BlockProcessor.ProcessOne(Block suggestedBlock, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 287
     at Nethermind.Consensus.Processing.BlockProcessor.Process(Hash256 newBranchStateRoot, List`1 suggestedBlocks, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 148 while processing blocks.
  18 Feb 14:05:45 | Issue processing block Hash: 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961
  Number: 0
  Parent: 0x0000000000000000000000000000000000000000000000000000000000000000
  Beneficiary: 0x0000000000000000000000000000000000000000
  Gas Limit: 100000000
  Gas Used: 0
  Timestamp: 1739887562
  Extra Data:
  Difficulty: 0
  Mix Hash: 0x0000000000000000000000000000000000000000000000000000000000000000
  Nonce: 4660
  Uncles Hash: 0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347
  Tx Root: 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421
  Receipts Root: 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421
  State Root: 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc
  BaseFeePerGas: 1000000000
  WithdrawalsRoot: 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421
  ParentBeaconBlockRoot: 0x0000000000000000000000000000000000000000000000000000000000000000
  BlobGasUsed: 0
  ExcessBlobGas: 0
  IsPostMerge: False
  TotalDifficulty: 0
  RequestsHash: 0xe3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
   Nethermind.Blockchain.InvalidBlockException: InvalidStateRoot: State root in header does not match. Expected 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc, got 0x4f45c30603679bb3d3d65c537b7782b65ab2b24c7d353c4259a1ba4773f24818
     at Nethermind.Consensus.Processing.BlockProcessor.ValidateProcessedBlock(Block suggestedBlock, ProcessingOptions options, Block block, TxReceipt[] receipts) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 302
     at Nethermind.Consensus.Processing.BlockProcessor.ProcessOne(Block suggestedBlock, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 287
     at Nethermind.Consensus.Processing.BlockProcessor.Process(Hash256 newBranchStateRoot, List`1 suggestedBlocks, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 148
     at Nethermind.Consensus.Processing.BlockchainProcessor.ProcessBranch(ProcessingBranch& processingBranch, ProcessingOptions options, IBlockTracer tracer, String& error) in /src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 472
  18 Feb 14:05:45 | Created a RLP dump of invalid block 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961 in file /tmp/block_0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961.rlp
  18 Feb 14:05:45 | Processed block 0 (0x5cd018...da40df) is invalid:
  18 Feb 14:05:45 | - hash: expected 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961, got 0x5cd018ddc42848afb122fa54cc4d3a5c0c40c42d23cbacf12ac28209b7da40df
  18 Feb 14:05:45 | - state root: expected 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc, got 0x4f45c30603679bb3d3d65c537b7782b65ab2b24c7d353c4259a1ba4773f24818
  18 Feb 14:05:45 | - block extra data : , UTF8:
  18 Feb 14:05:45 | Rejected invalid block 0 (0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961),  ExtraData: , reason: invalid block after processing
  18 Feb 14:05:45 | Encountered exception Nethermind.Blockchain.InvalidBlockException: InvalidStateRoot: State root in header does not match. Expected 0x4ecd824c979f3956561f3b2c90fabe1c283a333f9e7e17ab3f44e331c526e5bc, got 0x4f45c30603679bb3d3d65c537b7782b65ab2b24c7d353c4259a1ba4773f24818
     at Nethermind.Consensus.Processing.BlockProcessor.ValidateProcessedBlock(Block suggestedBlock, ProcessingOptions options, Block block, TxReceipt[] receipts) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 302
     at Nethermind.Consensus.Processing.BlockProcessor.ProcessOne(Block suggestedBlock, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 287
     at Nethermind.Consensus.Processing.BlockProcessor.Process(Hash256 newBranchStateRoot, List`1 suggestedBlocks, ProcessingOptions options, IBlockTracer blockTracer) in /src/Nethermind/Nethermind.Consensus/Processing/BlockProcessor.cs:line 148 while processing blocks.
  18 Feb 14:05:45 | Created a Receipts trace of invalid block 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961 in file /tmp/receipts_0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961.txt
  18 Feb 14:05:45 | Deleting invalid block 0xd45ee46a462f2bb6ac78ed3024b974713bca771e5664b5d7fbc51a14a2294961 at level 0
  18 Feb 14:06:25 | Step LoadGenesisBlock         failed after 40,111ms System.TimeoutException: Genesis block was not processed after 40 seconds. If you are running custom chain with very big genesis file consider increasing BlocksConfig.GenesisTimeoutMs.
     at Nethermind.Init.Steps.LoadGenesisBlock.Load(IWorldState worldState) in /src/Nethermind/Nethermind.Init/Steps/LoadGenesisBlock.cs:line 89
     at Nethermind.Init.Steps.LoadGenesisBlock.Execute(CancellationToken _) in /src/Nethermind/Nethermind.Init/Steps/LoadGenesisBlock.cs:line 47
     at Nethermind.Init.Steps.EthereumStepsManager.ExecuteStep(IStep step, StepInfo stepInfo, CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 153
     at Nethermind.Init.Steps.EthereumStepsManager.ReviewFailedAndThrow() in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 210
     at Nethermind.Init.Steps.EthereumStepsManager.InitializeAll(CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 95
     at Nethermind.Runner.Ethereum.EthereumRunner.Start(CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Runner/Ethereum/EthereumRunner.cs:line 30
     at Program.<>c__DisplayClass0_0.<<<Main>$>g__RunAsync|2>d.MoveNext() in /src/Nethermind/Nethermind.Runner/Program.cs:line 208
  18 Feb 14:06:25 | A critical error has occurred System.TimeoutException: Genesis block was not processed after 40 seconds. If you are running custom chain with very big genesis file consider increasing BlocksConfig.GenesisTimeoutMs.
     at Nethermind.Init.Steps.LoadGenesisBlock.Load(IWorldState worldState) in /src/Nethermind/Nethermind.Init/Steps/LoadGenesisBlock.cs:line 89
     at Nethermind.Init.Steps.LoadGenesisBlock.Execute(CancellationToken _) in /src/Nethermind/Nethermind.Init/Steps/LoadGenesisBlock.cs:line 47
     at Nethermind.Init.Steps.EthereumStepsManager.ExecuteStep(IStep step, StepInfo stepInfo, CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 153
     at Nethermind.Init.Steps.EthereumStepsManager.ReviewFailedAndThrow() in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 210
     at Nethermind.Init.Steps.EthereumStepsManager.InitializeAll(CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Init/Steps/EthereumStepsManager.cs:line 95
     at Nethermind.Runner.Ethereum.EthereumRunner.Start(CancellationToken cancellationToken) in /src/Nethermind/Nethermind.Runner/Ethereum/EthereumRunner.cs:line 30
     at Program.<>c__DisplayClass0_0.<<<Main>$>g__RunAsync|2>d.MoveNext() in /src/Nethermind/Nethermind.Runner/Program.cs:line 208
  18 Feb 14:06:25 | Nethermind is shutting down... Please wait until all activities are stopped.
```",general: initialization failure,CWE-436,Interpretation Conflict,"The bug report details a failure during the processing of a genesis block. The core of the issue is captured in the error message: `InvalidStateRoot: State root in header does not match. Expected 0x4ecd..., got 0x4f45...`. This indicates that the software (Nethermind, which can be considered Product A) processed the initial state allocations from the genesis file and calculated a state root hash. This calculated hash differs from the state root hash provided within the genesis file itself, which was likely generated by another tool or process (Product B). This discrepancy arises because the two products interpret the rules for calculating the state root from the genesis data differently. This is the exact scenario described by CWE-436.

- **CWE-436 (Interpretation Conflict)** is the best fit because it directly addresses the situation where two systems handle the same input differently, leading to an inconsistent state. The mismatched state root is a direct symptom of this conflict.

- **CWE-20 (Improper Input Validation)** is less suitable. The software *is* validating the input; the check that compares the calculated state root to the one in the header is a form of validation. This validation is working correctly, as it successfully identifies the inconsistency and rejects the block. The root cause is not a flaw in the validation logic itself, but the inconsistent nature of the input due to differing interpretations.

- **CWE-693 (Protection Mechanism Failure)** is incorrect. The state root validation is a critical protection mechanism to ensure the integrity of the blockchain. The logs show this mechanism is working as intended—it detected an invalid state and prevented the system from proceeding. There is no failure of the protection mechanism; rather, it has been successfully triggered.",closed,"The consensus mechanism failed to validate the state root of the processed block against the expected value, leading to the rejection of the block as invalid.","This bug can prevent the blockchain from processing valid transactions and blocks, leading to a halt in network operations, potential loss of data integrity, and a failure to reach consensus among nodes.",2861063361,8223,"February 18, 2025 5:02 PM (GMT+8)","March 17, 2025 7:45 PM (GMT+8)",['bug'],
nethermind,Consensus client missing capabilities V2 and V1,https://github.com/NethermindEth/nethermind/issues/8124,API,"` Consensus client missing capabilities: engine_newPayloadV2, engine_getPayloadV1, engine_getPayloadV2, engine_forkchoiceUpdatedV2, engine_forkchoiceUpdatedV1, engine_newPayloadV1
`

It looks like Teku removed support for V2 and V1, which makes sense. However, Nethermind will still print a warning. We should ensure that the warning only applies to the latest version.







",api: api unavailability,CWE-436,Interpretation Conflict,"The bug report describes an issue where one software component, Nethermind (Product A), interacts with another, Teku (Product B). Teku has changed its behavior by removing support for older API versions (V1, V2). Nethermind, however, still expects these older versions to be available and logs a warning when they are not. This is a classic example of an Interpretation Conflict. Nethermind performs an incorrect action (logging an unnecessary warning) based on its outdated perception of Teku's state (its available capabilities). 

CWE-20 (Improper Input Validation) is less suitable because the problem is not that Nethermind fails to validate the data received from Teku (the list of capabilities). The data is received correctly; the flaw is in the logic that interprets what that data means. 

CWE-755 (Improper Handling of Exceptional Conditions) is also not the best fit. An updated client deprecating old API versions is a normal, expected state, not an 'exceptional condition' like an error or crash. The bug is in how Nethermind interprets this normal state, not in its failure to handle a true exception.",closed,The consensus client has removed support for specific capabilities (V1 and V2) without appropriately managing backward compatibility or warning mechanisms for older versions.,"This bug could lead to confusion or improper functioning of clients that still rely on V1 and V2 capabilities, potentially causing issues in transaction validation and consensus process, which can affect the overall blockchain integrity and performance.",2818145067,8124,"January 29, 2025 12:57 PM (GMT+8)","February 5, 2025 3:25 AM (GMT+8)","['bug', '[Pri] Medium']",
nethermind,'Invalid Params' Error on Nethermind for Type-3 Transactions,https://github.com/NethermindEth/nethermind/issues/7987,API,"**Description**

After the Cancun upgrade, Ethereum introduced Type-3 transactions, which can store “blob” data with significantly reduced gas costs. While eth_estimateGas should return the correct gas usage for a Type-3 transaction, it currently returns {'code': -32602, 'message': 'Invalid params'}.

**Steps to Reproduce**

To reproduce this issue, follow these steps:
1. Run a testnet or use an existing mainnet node provided by `Nethermind`.
2. Execute the script in the appendix with the appropriate environment configuration (i.e., `TESTNET_RPC_URL=<your-nethermind-node-rpc-url> python3 estimate.py`).
3. Observe that the script returns `{'code': -32602, 'message': 'Invalid params'}`.

**Actual behavior**

The error returned is {'code': -32602, 'message': 'Invalid params'}. After reviewing the following code:
https://github.com/NethermindEth/nethermind/blob/1a1e6025c3c23fca13d830d188c1f2207b06b6be/src/Nethermind/Nethermind.JsonRpc/JsonRpcService.cs#L154-L162
I suspect that the RPC module does not yet support Type-3 transactions, as suggested by [this snippet](https://github.com/NethermindEth/nethermind/blob/1a1e6025c3c23fca13d830d188c1f2207b06b6be/src/Nethermind/Nethermind.JsonRpc/Modules/Eth/SimulateTxExecutor.cs#L71-L90).

**Expected behavior**

Switching the `TESTNET_RPC_URL` to a endpoint of `geth`, `reth`, `besu`, or `erigon` allows the script to successfully return the estimated gas.

**Desktop (please complete the following information):**
Please provide the following information regarding your setup:
 - Operating System: Linux
 - Version: v1.30.1
 - Installation Method: Using Kurtosis to run testnet
 - Consensus Client: Lighthouse

**Appendix**

The python script (i.e., `estimate.py` used for poc):
```
#!/usr/bin/env python3

import os
import hashlib
import json
import traceback
from web3 import Web3, HTTPProvider
from eth_account import Account

def generate_demo_blob(blob_index: int, size_kb: int = 128) -> bytes:
    """"""
    Generates a demo blob of specified size filled with deterministic data for consistency.
    
    Args:
        blob_index (int): Index of the blob for pattern variation.
        size_kb (int): Size of the blob in kilobytes (default is 128 KB).
        
    Returns:
        bytes: Generated blob data.
    """"""
    # Each blob is size_kb KB
    pattern = (f""Blob{blob_index}Data"").encode()
    blob_size = size_kb * 1024  # Convert KB to bytes
    blob = (pattern * (blob_size // len(pattern) + 1))[:blob_size]
    return blob

def compute_blob_hash(blob, version=1):
    sha256_hash = hashlib.sha256(blob).digest()
    versioned_hash = bytes([0x01]) + sha256_hash[1:]
    return '0x' + versioned_hash.hex()

def to_hex(value):
    """"""
    Converts an integer value to a hex string with '0x' prefix.
    
    Args:
        value (int): The integer value to convert.
        
    Returns:
        str: Hexadecimal string representation with '0x' prefix.
    """"""
    return hex(value)

def main():
    # Initialize Web3
    rpc_url = os.getenv(""TESTNET_RPC_URL"")
    if not rpc_url:
        raise EnvironmentError(""TESTNET_RPC_URL environment variable not set."")
    w3 = Web3(HTTPProvider(rpc_url))
    assert w3.is_connected(), ""Web3 provider is not connected.""

    # Load account from private key
    private_key = os.getenv(""PRIVATE_KEY"", ""0xbf3beef3bd999ba9f2451e06936f0423cd62b815c9233dd3bc90f7e02a1e8673"")
    account = Account.from_key(private_key)

    # Get the nonce for the account
    nonce = w3.eth.get_transaction_count(account.address)

    # Number of blobs to include (1 blob of 128 KB)
    num_blobs = 1
    blob_size_kb = 128  # 128 KB per blob

    # Generate demo blobs and their hashes
    blobs = []
    blob_versioned_hashes = []
    for i in range(num_blobs):
        blob = generate_demo_blob(i, size_kb=blob_size_kb)
        blobs.append('0x' + blob.hex())  # Blob as hex string with '0x' prefix
        blob_hash = compute_blob_hash(blob)
        blob_versioned_hashes.append(blob_hash)

    # Validate blob sizes
    for idx, blob in enumerate(blobs):
        blob_bytes = bytes.fromhex(blob[2:])  # Remove '0x' prefix
        expected_size = blob_size_kb * 1024
        actual_size = len(blob_bytes)
        assert actual_size == expected_size, f""Blob {idx + 1} size is incorrect: {actual_size} bytes, expected {expected_size} bytes.""

    # Validate blob hashes sizes
    for idx, hash_str in enumerate(blob_versioned_hashes):
        hash_hex = hash_str[2:]  # Remove '0x' prefix
        assert len(hash_hex) == 64, f""Blob {idx + 1} hash length is incorrect: {len(hash_hex)} characters, expected 64 characters.""

    # Construct the Type-3 transaction with hexadecimal fields
    tx = {
        ""type"": 3,  # Type-3 Transaction
        ""chainId"": to_hex(w3.eth.chain_id),
        ""nonce"": to_hex(nonce),
        ""from"": account.address,  # Optional when signing
        ""to"": ""0x0000000000000000000000000000000000000000"",
        ""value"": to_hex(0),
        ""maxPriorityFeePerGas"": to_hex(w3.to_wei(""2"", ""gwei"")),
        ""maxFeePerGas"": to_hex(w3.to_wei(""30"", ""gwei"")),
        ""maxFeePerBlobGas"": to_hex(w3.to_wei(""100"", ""gwei"")),
        ""gas"": to_hex(1500000),
        ""data"": ""0x"",
        ""blobVersionedHashes"": blob_versioned_hashes,  # List containing one 32-byte hash
        ""blobs"": blobs,  # List containing one 128 KB blob as hex string
    }

    # Estimate Gas
    try:
        estimated_gas = w3.eth.estimate_gas(tx)
        print(f""Estimated Gas: {estimated_gas}"")
    except Exception as e:
        print(""Error estimating gas:"", e)
        traceback.print_exc()

if __name__ == ""__main__"":
    main()
```",api: api unavailability,CWE-20,Improper Input Validation,"The bug report details a scenario where the Nethermind Ethereum client's `eth_estimateGas` RPC method rejects a valid, newly introduced Type-3 transaction with an 'Invalid params' error. This directly aligns with the definition of CWE-20, 'Improper Input Validation'. The system receives an input (the Type-3 transaction object) that is valid according to the protocol specification (as proven by its acceptance by other clients like `geth`), but the validation logic within Nethermind incorrectly identifies it as invalid because it has not been updated to support this new transaction type. The error message itself points to a failure in parameter validation.

CWE-436, 'Interpretation Conflict', is less accurate. While Nethermind's behavior differs from other clients, the root cause is not a misinterpretation of another product's state. It's a failure of Nethermind's own implementation to adhere to a common, updated protocol standard. The other clients are used as a benchmark to prove the input's validity, not as part of a stateful interaction that is being misinterpreted.

CWE-1059, 'Insufficient Technical Documentation', is not applicable as the problem is a functional code defect, not an issue with the product's documentation.",closed,"The RPC module in Nethermind does not support Type-3 transactions introduced after the Cancun upgrade, leading to an 'Invalid params' error when attempting to estimate gas for such transactions.","This bug prevents users from accurately estimating gas costs for Type-3 transactions, which could hinder the adoption of this new transaction type and impact developers relying on accurate gas estimations for their applications.",2764715246,7987,"December 31, 2024 11:00 PM (GMT+8)","January 24, 2025 1:20 AM (GMT+8)","['bug', 'rpc', '[Pri] High']",
nethermind,Setting empty --Blocks.ExtraData broken by v1.30.0,https://github.com/NethermindEth/nethermind/issues/7956,Others,"**Description**
It seems setting empty --Blocks.ExtraData is no longer possible since v1.30.0.

**Steps to Reproduce**
Run Nethermind with `--Blocks.ExtraData=`

**Actual behavior**
Nethermind complains: `Required argument missing for option: '--Blocks.ExtraData'.`

**Expected behavior**
Empty `--Blocks.ExtraData` is used.

**Additional context**
See https://github.com/NethermindEth/nethermind/issues/4952

Historically setting empty extra data has been possible via environment variable. Then only CLI argument. Now it seems there is no way to do it.
",general: initialization failure,CWE-20,Improper Input Validation,"The bug report describes a regression where the application's command-line parser no longer accepts an empty string for the `--Blocks.ExtraData` argument. It incorrectly flags this as a missing argument, causing an initialization failure. This is a classic input validation problem.

1.  **CWE-1389 (Incorrect Parsing of Numbers with Different Radices)** is incorrect. The bug is about handling an empty string argument, not parsing a number with a specific base like decimal or hexadecimal.

2.  **CWE-754 (Improper Check for Unusual or Exceptional Conditions)** is a less accurate fit. While an empty argument might be considered a special or 'unusual' case, the problem is not a failure to check for this condition. Instead, a check is performed, but it incorrectly validates the input, classifying a valid empty string as an invalid missing argument. The core issue is the validation logic itself.

3.  **CWE-20 (Improper Input Validation)** is the most accurate fit. The official description states, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' In this case, the command-line parser incorrectly validates the input for `--Blocks.ExtraData`, failing to recognize an explicitly provided empty string as a valid value. This incorrect validation directly causes the reported failure.",closed,"The code handling the '--Blocks.ExtraData' option does not accept an empty value, which is a change in behavior introduced in version 1.30.0, breaking backward compatibility.","This bug prevents users from setting empty extra data, which may disrupt workflows that depend on this functionality and could lead to issues in transaction processing or block creation.",2754389462,7956,"December 21, 2024 10:36 PM (GMT+8)","January 7, 2025 9:01 PM (GMT+8)",['bug'],
nethermind,"Nethermind includes extraneous `0x` values in `eth_getProof` responses, breaking cryptographic consistency.",https://github.com/NethermindEth/nethermind/issues/7759,API,"**Description**
`eth_getProof` includes erroneous `0x` values that don't make sense

**Steps to Reproduce**
Calling this `eth_getProof` request on Nethermind:
```
curl <Nethermind node URL>  \
  -X POST \
  -H ""Content-Type: application/json"" \
  --data '{""method"":""eth_getProof"",""params"":[""0x3a10dc1a145da500d5fba38b9ec49c8ff11a981f"",[""0x0000000000000000000000000000000000000000000000000000000000000003"",""0x0000000000000000000000000000000000000000000000000000000000000004"",""0x0ddc93f0dfd4cec69030b20fc3c9037ae4a8a3151a4c66b05fa74272b3a48df8"", ""0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc"",""0x90375f0b936c9e37c8e89c250b2c970b724107b72ed642aa819ba7b257516d30"",""0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103"",""0xfd21a1ac9a14dff647460ce8ad2ccecb794a59a4cfbb8678b1f9900a6a99551f"",""0xfd21a1ac9a14dff647460ce8ad2ccecb794a59a4cfbb8678b1f9900a6a995520"",""0xfd21a1ac9a14dff647460ce8ad2ccecb794a59a4cfbb8678b1f9900a6a995521"",""0xfd21a1ac9a14dff647460ce8ad2ccecb794a59a4cfbb8678b1f9900a6a995523""],""0x143212F""],""id"":1,""jsonrpc"":""2.0""}' |jq
 ```

**Actual behavior**
The proof nodes array includes multiple `0x` entries, representing empty nodes. These extra empty nodes imply an unnecessary parent-child relationship between empty nodes, which breaks the cryptographic consistency expected in exclusion proofs.

**Expected behavior**
The proof nodes array should exclude redundant 0x entries in exclusion proofs, only including relevant nodes that provide a cryptographically verifiable path. Correct exclusion proofs from other clients do not include these extra empty nodes.

**Screenshots**
<img width=""770"" alt=""image"" src=""https://github.com/user-attachments/assets/4b5647b9-04f9-439b-a7c4-25fa58c91c18"">

**Desktop (please complete the following information):**
 - Operating System: Ubuntu 24.04
 - Version: `Nethermind/v1.29.1`

 - Installation Method:Github release
 - Consensus Client: Lighthouse
 
 
",api: incorrect api output,CWE-358,Improperly Implemented Security Check for Standard,"The bug report describes an issue where the `eth_getProof` API method in the Nethermind client generates a response with extraneous data (`0x` values). This makes the resulting Merkle proof cryptographically inconsistent and unusable for its intended security purpose (verifying the exclusion of data). The `eth_getProof` method is part of the standardized Ethereum JSON-RPC API, and the generation of Merkle proofs is a standardized cryptographic technique. The bug is a direct result of Nethermind's failure to correctly implement this standard.

Let's evaluate the provided CWEs:
- **CWE-1302 (Missing Source Identifier in Entity Transactions on a System-On-Chip (SOC))**: This is irrelevant. The bug is related to a software API for a blockchain client, not hardware-level transactions on a System-on-Chip.
- **CWE-682 (Incorrect Calculation)**: This is a plausible but general description. The generation of the proof is a form of calculation, and the result is incorrect. However, this CWE does not capture the specific context of the failure.
- **CWE-358 (Improperly Implemented Security Check for Standard)**: This is the most accurate description. The bug is an incorrect implementation of a security-relevant technique (Merkle proof generation) that is part of a standardized protocol (Ethereum JSON-RPC API). The report explicitly states the output breaks ""cryptographic consistency expected in exclusion proofs,"" directly pointing to a failure in correctly implementing the standard for this security feature. The root cause is not just a generic calculation error, but a specific failure to adhere to the standard for a security-critical protocol.

Therefore, CWE-358 is the best fit because it precisely identifies the weakness as an incorrect implementation of a standardized, security-relevant protocol.",closed,"The `eth_getProof` implementation in Nethermind erroneously includes extraneous `0x` values in the proof nodes array, which represent empty nodes and lead to incorrect parent-child relationships.","The presence of these extraneous `0x` values breaks the cryptographic consistency of exclusion proofs, potentially leading to vulnerabilities in the verification of proofs and affecting the integrity of the data returned by the API.",2658989948,7759,"November 14, 2024 2:32 PM (GMT+8)","November 20, 2024 9:22 PM (GMT+8)","['bug', 'rpc']",
nethermind,`logIndex` changes after block becomes `safe`,https://github.com/NethermindEth/nethermind/issues/7751,Others,"On Nethermind 1.27.0 (and Sepolia chain) we discovered the following behaviour: `eth_getFilterChanges` returns incorrect `logIndex` for logs in unfinalized blocks. After block is finalized, the `logIndex` becomes correct. We don't see the same on Erigon.

For example, I caught that for [this transaction](https://eth-sepolia.blockscout.com/tx/0xb7f1fe65f346fb79515153c0f080fc2bb62cf8a1e33fcf0366ca0b6c83d3b8af) and a log with topic `0xb3813568d9991fc951961fcb4c784893574240a28925604d09fc577c55bb7c32 ` the output was as follows:

```
  ""address"" => ""0x65ea1489741a5d72ffdd8e6485b216bbdcc15af3"",
  ""blockHash"" => ""0xa262b5b296c8fd026516a815a0070096e4285535199af1349f695d47ee24fec4"",
  ""blockNumber"" => ""0x6bbf94"",
  ""data"" => ""0x0000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000020d00000000000000000000000000000000000000000000000000038d7ea4c6800000000000000000000000000000000000000000000000000000038d7ea4c680000000000000077f2e00d764ad0b0001000000000000000000000000000000000000000000000000000000113fa70000000000000000000000005f5a404a5edabcdd80db05e8e54a78c9ebf000c2000000000000000000000000420000000000000000000000000000000000001000000000000000000000000000000000000000000000000000038d7ea4c680000000000000000000000000000000000000000000000000000000000000030d4000000000000000000000000000000000000000000000000000000000000000c000000000000000000000000000000000000000000000000000000000000000c41635f5fd000000000000000000000000ecb06f2cc720626619821efee4bda42898b39c42000000000000000000000000ecb06f2cc720626619821efee4bda42898b39c4200000000000000000000000000000000000000000000000000038d7ea4c680000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000b73757065726272696467650000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
  ""logIndex"" => ""0xbc85a"",
  ""removed"" => false,
  ""topics"" => [""0xb3813568d9991fc951961fcb4c784893574240a28925604d09fc577c55bb7c32"", ""0x0000000000000000000000001295245d202724dc28a2b688952cb56c882c3380"", ""0x0000000000000000000000004200000000000000000000000000000000000007"", ""0x0000000000000000000000000000000000000000000000000000000000000000""],
  ""transactionHash"" => ""0xb7f1fe65f346fb79515153c0f080fc2bb62cf8a1e33fcf0366ca0b6c83d3b8af"",
  ""transactionIndex"" => ""0x49"",
  ""transactionLogIndex"" => ""0x2""
```

After block is finalized, `eth_getLogs` returned another (correct) value:

```
  ""address"" => ""0x65ea1489741a5d72ffdd8e6485b216bbdcc15af3"",
  ""blockHash"" => ""0xa262b5b296c8fd026516a815a0070096e4285535199af1349f695d47ee24fec4"",
  ""blockNumber"" => ""0x6bbf94"",
  ""data"" => ""0x0000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000020d00000000000000000000000000000000000000000000000000038d7ea4c6800000000000000000000000000000000000000000000000000000038d7ea4c680000000000000077f2e00d764ad0b0001000000000000000000000000000000000000000000000000000000113fa70000000000000000000000005f5a404a5edabcdd80db05e8e54a78c9ebf000c2000000000000000000000000420000000000000000000000000000000000001000000000000000000000000000000000000000000000000000038d7ea4c680000000000000000000000000000000000000000000000000000000000000030d4000000000000000000000000000000000000000000000000000000000000000c000000000000000000000000000000000000000000000000000000000000000c41635f5fd000000000000000000000000ecb06f2cc720626619821efee4bda42898b39c42000000000000000000000000ecb06f2cc720626619821efee4bda42898b39c4200000000000000000000000000000000000000000000000000038d7ea4c680000000000000000000000000000000000000000000000000000000000000000080000000000000000000000000000000000000000000000000000000000000000b73757065726272696467650000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
  ""logIndex"" => ""0x6e"",
  ""removed"" => false,
  ""topics"" => [""0xb3813568d9991fc951961fcb4c784893574240a28925604d09fc577c55bb7c32"", ""0x0000000000000000000000001295245d202724dc28a2b688952cb56c882c3380"", ""0x0000000000000000000000004200000000000000000000000000000000000007"", ""0x0000000000000000000000000000000000000000000000000000000000000000""],
  ""transactionHash"" => ""0xb7f1fe65f346fb79515153c0f080fc2bb62cf8a1e33fcf0366ca0b6c83d3b8af"",
  ""transactionIndex"" => ""0x49"",
  ""transactionLogIndex"" => ""0x2""
```",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report details an issue where the `logIndex` value returned by an API call is incorrect for unfinalized blocks and is only corrected after the block is finalized. This points to a flaw in the system's internal logic for determining the `logIndex` under a specific state (unfinalized). This directly matches the definition of CWE-682, 'Incorrect Calculation,' as the system is performing a calculation or process that generates an incorrect result. CWE-20, 'Improper Input Validation,' is not applicable because the issue is not with the input provided to the API but with the output generated by the system's internal processing. CWE-457, 'Use of Uninitialized Variable,' is a possible but less precise explanation; the report describes a consistently incorrect value that is later corrected, which is more indicative of a flawed calculation logic rather than the typically unpredictable behavior resulting from an uninitialized variable. Therefore, CWE-682 is the most accurate and direct classification based on the provided information.",closed,"The `logIndex` for logs in unfinalized blocks is incorrectly calculated or retrieved, leading to inconsistencies until the block is finalized.","This bug can lead to incorrect log indexing in unfinalized blocks, causing clients to return invalid or misleading log data, which can affect applications relying on accurate blockchain event data.",2652144447,7751,"November 12, 2024 1:08 PM (GMT+8)","December 3, 2024 8:24 PM (GMT+8)","['bug', 'rpc']",
nethermind,GetBlobsV1 with Teku,https://github.com/NethermindEth/nethermind/issues/7574,API,"rocketpool_eth2          | 2024-10-08 10:57:21.860 WARN  - Local EL blobs lookup failed: CompletionException: tech.pegasys.teku.ethereum.executionclient.response.InvalidRemoteResponseException: Invalid remote response from the execution client: Cannot deserialize value of type `java.util.ArrayList<tech.pegasys.teku.ethereum.executionclient.schema.BlobAndProofV1>` from Object value (token `JsonToken.START_OBJECT`)
rocketpool_eth2          |  at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 27] (through reference chain: tech.pegasys.teku.ethereum.executionclient.web3j.Web3JExecutionEngineClient$GetBlobsVersionV1Web3jResponse[""result""])

Details: https://discordapp.com/channels/629004402170134531/629004402170134537/1293170041256280138",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report describes a failure where a Teku client cannot parse a response from a Nethermind client. Specifically, Teku expects a JSON array (`java.util.ArrayList`) but receives a JSON object (`JsonToken.START_OBJECT`). This is a classic interoperability problem between two different software products that are supposed to communicate over a defined API. 

Let's analyze the options:
- CWE-1389 (Incorrect Parsing of Numbers with Different Radices) is not applicable. The issue is a structural mismatch in a JSON response (array vs. object), not an incorrect interpretation of a number's base.
- CWE-703 (Improper Check or Handling of Exceptional Conditions) is plausible because a deserialization error is an exceptional condition. However, it is too generic. The root cause is not simply a failure to handle an exception, but the specific reason *why* the exception occurred: the data format from the remote client was not what was expected.
- CWE-436 (Interpretation Conflict) is the most accurate fit. The official description states, 'Product A handles inputs or steps differently than Product B, which causes A to perform incorrect actions based on its perception of B's state.' In this case, Product A (Teku) and Product B (Nethermind) have different interpretations of the `GetBlobsV1` API response format. This conflict in interpretation directly causes the failure in Teku. The log message 'Invalid remote response from the execution client' explicitly points to a problem originating from the interaction between two separate systems.",closed,The execution client is unable to deserialize a JSON response into the expected Java object type due to an invalid format of the response received from the remote execution client.,"This bug can lead to failures in processing blobs, resulting in issues with transaction execution and potentially disrupting the overall functionality of the Ethereum network, especially in contexts relying on blob data.",2572948814,7574,"October 8, 2024 11:40 AM (GMT+8)","October 24, 2024 9:07 PM (GMT+8)",['bug'],
nethermind,Can't trace Genesis block,https://github.com/NethermindEth/nethermind/issues/7195,API,"On Chiado, we can't trace genesis block:

curl -X POST -H ""Content-Type: application/json"" --data '{""method"": ""debug_traceBlock"", ""params"": [""0x0""], ""id"": 1, ""jsonrpc"": ""2.0""}'

```
{
   ""error"" : {
      ""code"" : -32603,
      ""data"" : ""System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\n ---> Nethermind.Serialization.Rlp.RlpException: Expected a sequence prefix to be in the range of <192, 255> and got 0 at position 1 in the message of length 1 starting with 00\n   at Nethermind.Serialization.Rlp.RlpStream.ReadSequenceLength() in /_/src/Nethermind/Nethermind.Serialization.Rlp/RlpStream.cs:line 743\n   at Nethermind.Serialization.Rlp.BlockDecoder.Decode(RlpStream rlpStream, RlpBehaviors rlpBehaviors) in /_/src/Nethermind/Nethermind.Serialization.Rlp/BlockDecoder.cs:line 30\n   at Nethermind.Serialization.Rlp.Rlp.Decode[T](RlpStream rlpStream, RlpBehaviors rlpBehaviors) in /_/src/Nethermind/Nethermind.Serialization.Rlp/Rlp.cs:line 229\n   at Nethermind.Serialization.Rlp.Rlp.Decode[T](Rlp oldRlp, RlpBehaviors rlpBehaviors) in /_/src/Nethermind/Nethermind.Serialization.Rlp/Rlp.cs:line 121\n   at Nethermind.Consensus.Tracing.GethStyleTracer.GetBlockToTrace(Rlp blockRlp) in /_/src/Nethermind/Nethermind.Consensus/Tracing/GethStyleTracer.cs:line 223\n   at Nethermind.Consensus.Tracing.GethStyleTracer.TraceBlock(Rlp blockRlp, GethTraceOptions options, CancellationToken cancellationToken) in /_/src/Nethermind/Nethermind.Consensus/Tracing/GethStyleTracer.cs:line 144\n   at Nethermind.JsonRpc.Modules.DebugModule.DebugRpcModule.debug_traceBlock(Byte[] blockRlp, GethTraceOptions options) in /_/src/Nethermind/Nethermind.JsonRpc/Modules/DebugModule/DebugRpcModule.cs:line 162\n   at InvokeStub_IDebugRpcModule.debug_traceBlock(Object, Span`1)\n   at System.Reflection.MethodBaseInvoker.InvokeWithFewArgs(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\n   --- End of inner exception stack trace ---\n   at System.Reflection.MethodBaseInvoker.InvokeWithFewArgs(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\n   at Nethermind.JsonRpc.JsonRpcService.ExecuteAsync(JsonRpcRequest request, String methodName, ResolvedMethodInfo method, JsonRpcContext context) in /_/src/Nethermind/Nethermind.JsonRpc/JsonRpcService.cs:line 169"",
      ""message"" : ""Internal error""
   },
   ""id"" : 1,
   ""jsonrpc"" : ""2.0""
}
```",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report shows that an API call to trace the genesis block (`0x0`) results in an unhandled exception (`RlpException`) which propagates up to the user as a generic 'Internal error' with a full stack trace. This is a classic case of an exceptional condition not being handled correctly.

1.  **Analysis of CWE-20 (Improper Input Validation):** This CWE is less suitable. The input `""0x0""` is a syntactically valid block identifier. The problem is not that the input is malformed, but that it represents a special case (the genesis block) that the application's logic cannot process correctly. This makes it an exceptional condition rather than invalid input.

2.  **Analysis of CWE-754 (Improper Check for Unusual or Exceptional Conditions):** This is a plausible candidate. The root cause of the `RlpException` is likely a missing check to see if the requested block is the genesis block, which may require a different processing path. The failure to perform this check leads to the error.

3.  **Analysis of CWE-703 (Improper Check or Handling of Exceptional Conditions):** This is the most accurate choice. The bug report's primary evidence is the stack trace and the generic 'Internal error'. This demonstrates that when the `RlpException` occurred, the application did not 'properly anticipate or handle' it. Instead of catching the specific exception and returning a user-friendly error (e.g., 'Genesis block tracing is not supported'), the system allowed the exception to bubble up, resulting in a poor failure state and leaking internal implementation details. The failure to *handle* the exception is the most direct and impactful problem shown in the report.

**Conclusion:** While the bug involves a missing check (related to CWE-754), the most prominent and accurate classification based on the provided evidence (unhandled exception, stack trace) is the failure to handle the resulting exceptional condition, which is precisely described by CWE-703.",closed,"The API call to trace the genesis block is failing due to an expectation of a specific RLP (Recursive Length Prefix) encoding format that is not being met, indicating that the genesis block is either not being properly serialized or not accessible as expected.","This bug prevents users from tracing the genesis block, which can hinder debugging and analysis processes on the Chiado network, potentially affecting developers and users who rely on tracing for transaction verification and network diagnostics.",2362328817,7195,"June 19, 2024 12:59 PM (GMT+8)","June 25, 2024 11:04 PM (GMT+8)","['bug', 'rpc']",
nethermind,Goerli node - Failed to notify peer about transactions.,https://github.com/NethermindEth/nethermind/issues/6783,Network,"```
System.ObjectDisposedException: Cannot access a disposed object.
Object name: 'ArrayPoolList'.
   at Nethermind.Core.Collections.ArrayPoolList`1.<GuardDispose>g__ThrowObjectDisposed|9_0() in /_/src/Nethermind/Nethermind.Core/Collections/ArrayPoolList.cs:line 51
   at Nethermind.Core.Collections.ArrayPoolList`1.GuardResize(Int32 itemsToAdd) in /_/src/Nethermind/Nethermind.Core/Collections/ArrayPoolList.cs:line 154
   at Nethermind.Core.Collections.ArrayPoolList`1.Add(T item) in /_/src/Nethermind/Nethermind.Core/Collections/ArrayPoolList.cs:line 59
   at Nethermind.Network.P2P.Subprotocols.Eth.V65.Eth65ProtocolHandler.SendNewTransactionsCore(IEnumerable`1 txs, Boolean sendFullTx) in /_/src/Nethermind/Nethermind.Network/P2P/Subprotocols/Eth/V65/Eth65ProtocolHandler.cs:line 183
   at Nethermind.TxPool.TxBroadcaster.Notify(ITxPoolPeer peer, IEnumerable`1 txs, Boolean sendFullTx) in /_/src/Nethermind/Nethermind.TxPool/TxBroadcaster.cs:line 313
```",network: p2p protocol error,CWE-672,Operation on a Resource after Expiration or Release,"The bug report shows a `System.ObjectDisposedException` with the message 'Cannot access a disposed object. Object name: 'ArrayPoolList''. The stack trace indicates that the application attempts to call the `Add` method on an `ArrayPoolList` object. This exception is thrown specifically when an operation is performed on an object that has already had its resources released via the `Dispose` method. This scenario directly matches the definition of CWE-672, 'Operation on a Resource after Expiration or Release', where the 'resource' is the `ArrayPoolList` object and the 'operation' is the attempt to add an item to it after it has been 'released' (disposed).

CWE-416, 'Use After Free', is closely related but is more specific to errors in manually managed memory (like C/C++), where a pointer to freed memory is used. In a managed environment like C#/.NET, CWE-672 is the more general and accurate classification for using an object after it has been logically disposed, which is the case here.

CWE-362, 'Race Condition', could be the underlying root cause that leads to this state (e.g., one thread disposes the object while another is about to use it), but the immediate and observable weakness demonstrated by the exception is the operation on the already-released resource. Therefore, CWE-672 is the most precise description of the fault itself.",closed,"The error occurs due to an attempt to access a disposed object, specifically an instance of 'ArrayPoolList', which indicates that the object has been cleaned up and is no longer available for use.","This bug could lead to failures in notifying peers about new transactions, which can disrupt the transaction broadcasting process in the network, potentially resulting in lost transactions or delays in processing.",2156299038,6783,"February 27, 2024 11:02 AM (GMT+8)","February 27, 2024 9:11 PM (GMT+8)",['bug'],
nethermind,ReceiptsSyncDispatcher throwing object disposed exceptions after finish of OldBodies,https://github.com/NethermindEth/nethermind/issues/6777,Network,"SyncDispatcher throwing object disposed exceptions after finish of OldBodies

**Logs**

```
24 Feb 05:29:05 | Old Bodies   18,794,150 / 19,291,169 ( 97.42 %) | queue   496,187 | current           26 Blk/s | total        2,216 Blk/s
24 Feb 05:29:10 | Old Bodies   18,794,150 / 19,291,169 ( 97.42 %) | queue   496,891 | current            0 Blk/s | total        2,215 Blk/s
24 Feb 05:29:11 | Received New Block:  19295361 (0x574d57...0d9bf7)
24 Feb 05:29:11 | Processed            19295361     |    190.23 ms  |  slot     12,147 ms |⛽ Gas gwei: 24.27 .. 24.27 (26.13) .. 70.00
24 Feb 05:29:11 | - Block              13.74 MGas   |    170    txs |  calls    554 ( 43) | sload   1,479 | sstore    466 | create   0
24 Feb 05:29:11 | - Block throughput   72.22 MGas/s |    893.67 t/s |          5.26 Blk/s | recv        0 | proc        0
24 Feb 05:29:11 | Received ForkChoice: 19295361 (0x574d57...0d9bf7), Safe: 19295333 (0xcfa0b7...b1863b), Finalized: 19295269 (0x31e956...8d306d)
24 Feb 05:29:11 | Synced Chain Head to 19295361 (0x574d57...0d9bf7)
24 Feb 05:29:14 | Changing state WaitingForBlock, FastBodies to WaitingForBlock, FastReceipts at processed: 19295361 | state: 19295361 | block: 19295361 | header: 19295361 | target block: 19295360 | peer block: 19295360
24 Feb 05:29:14 | Changed pivot in receipts sync. Now using pivot 19291169 and barrier 1
24 Feb 05:29:15 | SyncDispatcher<BodiesSyncBatch> has finished work.
24 Feb 05:29:15 | Fast blocks bodies task completed.
24 Feb 05:29:15 | Sync mode changed from WaitingForBlock, FastBodies to WaitingForBlock, FastReceipts
24 Feb 05:29:15 | Failure when executing request System.ObjectDisposedException: Cannot access a disposed object.
Object name: 'ArrayPoolList'.
   at Nethermind.Core.Collections.ArrayPoolList`1.<GuardDispose>g__ThrowObjectDisposed|9_0() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 51
   at Nethermind.Core.Collections.ArrayPoolList`1.get_Count() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 110
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.<>c__DisplayClass5_0`2.<<Run>b__0>d.MoveNext()
--- End of stack trace from previous location ---
   at Nethermind.Core.AdaptiveRequestSizer.Run[TResponse](Func`2 func)
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.Run[TResponse,TRequest](IReadOnlyList`1 request, Func`2 func)
   at Nethermind.Network.P2P.Subprotocols.Eth.V63.Eth63ProtocolHandler.GetReceipts(IReadOnlyList`1 blockHashes, CancellationToken token) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Network\P2P\Subprotocols\Eth\V63\Eth63ProtocolHandler.cs:line 156
   at Nethermind.Synchronization.FastBlocks.ReceiptsSyncDispatcher.Dispatch(PeerInfo peerInfo, ReceiptsSyncBatch batch, CancellationToken cancellationToken) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\FastBlocks\ReceiptsSyncDownloader.cs:line 42
   at Nethermind.Synchronization.ParallelSync.SyncDispatcher`1.DoDispatch(CancellationToken cancellationToken, PeerInfo allocatedPeer, T request, SyncPeerAllocation allocation) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\ParallelSync\SyncDispatcher.cs:line 139
24 Feb 05:29:15 | Failure when executing request System.ObjectDisposedException: Cannot access a disposed object.
Object name: 'ArrayPoolList'.
   at Nethermind.Core.Collections.ArrayPoolList`1.<GuardDispose>g__ThrowObjectDisposed|9_0() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 51
   at Nethermind.Core.Collections.ArrayPoolList`1.get_Count() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 110
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.<>c__DisplayClass5_0`2.<<Run>b__0>d.MoveNext()
--- End of stack trace from previous location ---
   at Nethermind.Core.AdaptiveRequestSizer.Run[TResponse](Func`2 func)
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.Run[TResponse,TRequest](IReadOnlyList`1 request, Func`2 func)
   at Nethermind.Network.P2P.Subprotocols.Eth.V63.Eth63ProtocolHandler.GetReceipts(IReadOnlyList`1 blockHashes, CancellationToken token) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Network\P2P\Subprotocols\Eth\V63\Eth63ProtocolHandler.cs:line 156
   at Nethermind.Synchronization.FastBlocks.ReceiptsSyncDispatcher.Dispatch(PeerInfo peerInfo, ReceiptsSyncBatch batch, CancellationToken cancellationToken) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\FastBlocks\ReceiptsSyncDownloader.cs:line 42
   at Nethermind.Synchronization.ParallelSync.SyncDispatcher`1.DoDispatch(CancellationToken cancellationToken, PeerInfo allocatedPeer, T request, SyncPeerAllocation allocation) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\ParallelSync\SyncDispatcher.cs:line 139
24 Feb 05:29:15 | Failure when executing request System.ObjectDisposedException: Cannot access a disposed object.
Object name: 'ArrayPoolList'.
   at Nethermind.Core.Collections.ArrayPoolList`1.<GuardDispose>g__ThrowObjectDisposed|9_0() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 51
   at Nethermind.Core.Collections.ArrayPoolList`1.get_Count() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 110
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.<>c__DisplayClass5_0`2.<<Run>b__0>d.MoveNext()
--- End of stack trace from previous location ---
   at Nethermind.Core.AdaptiveRequestSizer.Run[TResponse](Func`2 func)
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.Run[TResponse,TRequest](IReadOnlyList`1 request, Func`2 func)
   at Nethermind.Network.P2P.Subprotocols.Eth.V63.Eth63ProtocolHandler.GetReceipts(IReadOnlyList`1 blockHashes, CancellationToken token) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Network\P2P\Subprotocols\Eth\V63\Eth63ProtocolHandler.cs:line 156
   at Nethermind.Synchronization.FastBlocks.ReceiptsSyncDispatcher.Dispatch(PeerInfo peerInfo, ReceiptsSyncBatch batch, CancellationToken cancellationToken) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\FastBlocks\ReceiptsSyncDownloader.cs:line 42
   at Nethermind.Synchronization.ParallelSync.SyncDispatcher`1.DoDispatch(CancellationToken cancellationToken, PeerInfo allocatedPeer, T request, SyncPeerAllocation allocation) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\ParallelSync\SyncDispatcher.cs:line 139
24 Feb 05:29:15 | Failure when executing request System.ObjectDisposedException: Cannot access a disposed object.
Object name: 'ArrayPoolList'.
   at Nethermind.Core.Collections.ArrayPoolList`1.<GuardDispose>g__ThrowObjectDisposed|9_0() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 51
   at Nethermind.Core.Collections.ArrayPoolList`1.get_Count() in D:\GitHub\nethermind\src\Nethermind\Nethermind.Core\Collections\ArrayPoolList.cs:line 110
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.<>c__DisplayClass5_0`2.<<Run>b__0>d.MoveNext()
--- End of stack trace from previous location ---
   at Nethermind.Core.AdaptiveRequestSizer.Run[TResponse](Func`2 func)
   at Nethermind.Core.LatencyAndMessageSizeBasedRequestSizer.Run[TResponse,TRequest](IReadOnlyList`1 request, Func`2 func)
   at Nethermind.Network.P2P.Subprotocols.Eth.V63.Eth63ProtocolHandler.GetReceipts(IReadOnlyList`1 blockHashes, CancellationToken token) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Network\P2P\Subprotocols\Eth\V63\Eth63ProtocolHandler.cs:line 156
   at Nethermind.Synchronization.FastBlocks.ReceiptsSyncDispatcher.Dispatch(PeerInfo peerInfo, ReceiptsSyncBatch batch, CancellationToken cancellationToken) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\FastBlocks\ReceiptsSyncDownloader.cs:line 42
   at Nethermind.Synchronization.ParallelSync.SyncDispatcher`1.DoDispatch(CancellationToken cancellationToken, PeerInfo allocatedPeer, T request, SyncPeerAllocation allocation) in D:\GitHub\nethermind\src\Nethermind\Nethermind.Synchronization\ParallelSync\SyncDispatcher.cs:line 139
```
",network: p2p protocol error,CWE-672,Operation on a Resource after Expiration or Release,"The bug report's primary evidence is the repeated `System.ObjectDisposedException` with the message `Cannot access a disposed object. Object name: 'ArrayPoolList'`. This log entry explicitly states that an operation (accessing the `.Count` property) was attempted on a resource (the `ArrayPoolList` object) after it had been released (disposed). This directly maps to the definition of CWE-672: 'The product uses, accesses, or otherwise operates on a resource after that resource has been expired, released, or revoked.'

CWE-416 ('Use After Free') is less appropriate because it is a more specific type of CWE-672 that typically refers to vulnerabilities in languages with manual memory management like C/C++. The bug occurs in C# code, where 'disposing' an object is the managed equivalent, making the more general CWE-672 a better fit.

CWE-362 ('Race Condition') describes the likely root cause of the issue – one process disposes the object while another concurrent process still intends to use it. However, CWE-672 describes the direct, observable fault that results from the race condition. Since the evidence (the exception) is a direct instance of an operation on a released resource, CWE-672 is the most precise and accurate classification of the weakness itself.",closed,"The SyncDispatcher is attempting to access an object (ArrayPoolList) that has already been disposed, leading to ObjectDisposedExceptions.","This bug could disrupt the synchronization process of receipts, potentially causing delays in block processing and affecting overall network performance.",2152127559,6777,"February 24, 2024 5:34 AM (GMT+8)","March 4, 2024 9:51 PM (GMT+8)",['bug'],
nethermind,"[BUG] dont charge `(contract_address, 0, CODE_KECCAK_LEAF_KEY)` when a contract creation is initialized",https://github.com/NethermindEth/nethermind/issues/6758,Execution,,evm: incorrect gas calculation,CWE-682,Incorrect Calculation,"The bug report's title and functional symptoms explicitly point to an 'incorrect gas calculation'. The bug involves not charging for a specific operation during contract creation initialization. In the context of the Ethereum Virtual Machine (EVM), gas is a critical resource, and its calculation is a form of resource management. CWE-682, 'Incorrect Calculation', is defined as a calculation that produces incorrect results which are then used in resource management. This directly maps to the described bug. CWE-670, 'Always-Incorrect Control Flow Implementation', is less suitable because the core issue identified is the result of the calculation (the gas cost), not necessarily a flaw in the program's logical path. While a control flow error might be the underlying cause, the most direct and accurate description of the weakness presented in the report is the incorrect calculation itself.",closed,"The system does not properly manage the charging mechanism for contract creation, specifically when it comes to the execution of certain operations involving contract addresses and associated keys.","This bug may lead to unintended contract creation without charging the appropriate fees, which could result in financial losses for the network or abuse of the contract creation process.",2148258316,6758,"February 22, 2024 5:50 AM (GMT+8)","March 21, 2024 3:43 PM (GMT+8)","['bug', 'verkle']",
nethermind,Attempted to process a blockchain without having starting state,https://github.com/NethermindEth/nethermind/issues/6670,Storage,"**Description**
Block processing or recovery after restart leads to broken state, restart helped at least in one case.

**Steps to Reproduce**
Run the node/restart it

**Actual behavior**
Node stucks reporting ""Exception: System.InvalidOperationException: Attempted to process a blockchain without having starting state""

**Expected behavior**
Startup recovery and block processing is OK

**Desktop (please complete the following information):**
Please provide the following information regarding your setup:
 - Operating System: Linux x64
 - Version: 1.25.3
 - Installation Method: docker
 - Consensus Client: lighthouse, nimbus

**Additional context**
Please provide any additional context about the problem.

**Logs**

```
nethermind-lh_1        | 04 Feb 00:02:56 | Processed    10480679... 10480680 |  1,167.85 ms  |  slot      1,172 ms | Gas gwei: 0.00 .. 0.00 (0.31) .. 5.00 
nethermind-lh_1        | 04 Feb 00:02:56 | - Blocks 2            3.34 MGas   |     72    txs |  calls    102 (  4) | sload     456 | sstore    128 | create   0 
nethermind-lh_1        | 04 Feb 00:02:56 | - Block throughput    2.86 MGas/s |     61.65 t/s |          1.71 Blk/s | recv        0 | proc       88 
nethermind-lh_1        | 04 Feb 00:02:57 | Processed            10480681     |  1,412.70 ms  |  slot      1,416 ms | Gas gwei: 0.00 .. 0.00 (0.29) .. 18.00 
nethermind-lh_1        | 04 Feb 00:02:57 | - Block               5.04 MGas   |    158    txs |  calls     94 (  2) | sload     317 | sstore     87 | create   0 
nethermind-lh_1        | 04 Feb 00:02:57 | - Block throughput    3.57 MGas/s |    111.84 t/s |          0.71 Blk/s | recv        0 | proc       87 
nethermind-lh_1        | 04 Feb 00:02:59 | Processed            10480682     |  1,558.34 ms  |  slot      1,560 ms | Gas gwei: 0.00 .. 0.00 (0.13) .. 6.00 
nethermind-lh_1        | 04 Feb 00:02:59 | - Block               7.23 MGas   |    183    txs |  calls    216 (  2) | sload     847 | sstore    181 | create   0 
nethermind-lh_1        | 04 Feb 00:02:59 | - Block throughput    4.64 MGas/s |    117.43 t/s |          0.64 Blk/s | recv        0 | proc       86 
nethermind-lh_1        | 04 Feb 00:03:01 | Processed            10480683     |  2,346.91 ms  |  slot      2,348 ms | Gas gwei: 0.00 .. 0.00 (0.07) .. 6.00 
nethermind-lh_1        | 04 Feb 00:03:01 | - Block               9.70 MGas   |    321    txs |  calls     81 (  3) | sload     315 | sstore    109 | create   0 
nethermind-lh_1        | 04 Feb 00:03:01 | - Block throughput    4.13 MGas/s |    136.78 t/s |          0.43 Blk/s | recv        0 | proc       85 
nethermind-lh_1        | 04 Feb 00:03:01 | Received new block:  10480769 (0x3dfba8...22f76e) 
nethermind-lh_1        | 04 Feb 00:03:01 | Processing loop threw an exception. Block: 10480685 (0xdfb77c...a6e7cd), Exception: System.InvalidOperationException: Attempted to process a blockchain without having starting state
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.PrepareBlocksToProcess(Block suggestedBlock, ProcessingOptions options, ProcessingBranch processingBranch) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 576
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.Process(Block suggestedBlock, ProcessingOptions options, IBlockTracer tracer) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 384
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.RunProcessingLoop() in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 317 
nethermind-lh_1        | 04 Feb 00:03:01 | Processing loop threw an exception. Block: 10480686 (0xba4ff6...8c2c7e), Exception: System.InvalidOperationException: Attempted to process a blockchain without having starting state
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.PrepareBlocksToProcess(Block suggestedBlock, ProcessingOptions options, ProcessingBranch processingBranch) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 576
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.Process(Block suggestedBlock, ProcessingOptions options, IBlockTracer tracer) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 384
nethermind-lh_1        |    at Nethermind.Consensus.Processing.BlockchainProcessor.RunProcessingLoop() in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 317
```

another case after restart
```
execution-1  | 05 Feb 10:56:52 | Rerunning block after reorg or pruning: 810888 (0x6ec590...f2c637) 
execution-1  | 05 Feb 10:56:52 | Rerunning block after reorg or pruning: 810889 (0x353973...e6c062) 
execution-1  | 05 Feb 10:56:52 | Rerunning block after reorg or pruning: 810890 (0xb42948...1cd3fc) 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810891 (0x2b9e28...e4d4d2) 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810892 (0xc6b947...4e7d53) 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810893 (0xad0ad5...4300de) 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810894 (0x05aa2f...0b66b7) 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810895 (0x2b941d...07a912) 
execution-1  | 05 Feb 10:56:53 | Processed      810886...   810895 |  1,051.79 ms  |  slot      1,053 ms | Gas gwei: 1.12 .. [97m1.12[37m (1.65) .. 3.00 
execution-1  | 05 Feb 10:56:53 | - Blocks 10         144.39[37m MGas   |    186    txs |  calls  5,089[37m [37m( 17)[37m | sload  12,747 | sstore  7,275[37m | create 1,307[37m[37m(-1,006)[37m 
execution-1  | 05 Feb 10:56:53 | - Block throughput  137.28 MGas/s |    176.84 t/s |          9.51 Blk/s | recv    5,966 | proc    2,000 
execution-1  | 05 Feb 10:56:53 | Rerunning block after reorg or pruning: 810896 (0x673fc3...06478b) 
execution-1  | 05 Feb 10:56:53 | Processing loop threw an exception. Block: 810898 (0xd20dc7...cdc856), Exception: System.InvalidOperationException: Attempted to process a blockchain without having starting state
execution-1  |    at Nethermind.Consensus.Processing.BlockchainProcessor.PrepareBlocksToProcess(Block suggestedBlock, ProcessingOptions options, ProcessingBranch processingBranch) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 576
execution-1  |    at Nethermind.Consensus.Processing.BlockchainProcessor.Process(Block suggestedBlock, ProcessingOptions options, IBlockTracer tracer) in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 384
execution-1  |    at Nethermind.Consensus.Processing.BlockchainProcessor.RunProcessingLoop() in /_/src/Nethermind/Nethermind.Consensus/Processing/BlockchainProcessor.cs:line 317 
```
",general: initialization failure,CWE-665,Improper Initialization,"The bug report explicitly states that the software throws a `System.InvalidOperationException` with the message 'Attempted to process a blockchain without having starting state'. This occurs during block processing, particularly after a restart or during a reorg recovery. This directly aligns with the definition of CWE-665, 'Improper Initialization', which describes a product not initializing or incorrectly initializing a resource, leaving it in an unexpected state. The 'starting state' is the resource that is not properly initialized before being accessed by the blockchain processor.

CWE-362 ('Race Condition') is a less suitable choice. While a race condition could be the underlying cause of the initialization failure, the bug report's primary evidence is the resulting state (uninitialized) rather than direct evidence of a timing window or concurrent access conflict. CWE-665 describes the immediate, observable problem more accurately.

CWE-459 ('Incomplete Cleanup') is incorrect because the problem is not about failing to remove resources after use, but rather about failing to set up a required state before use.",closed,"The node is attempting to process blocks without having a valid starting state, which indicates a failure in the state initialization or recovery process after a restart.","This bug can lead to the node being stuck and unable to process further blocks, resulting in a halted consensus mechanism and preventing the node from participating in the network. This could affect the overall performance and reliability of the blockchain.",2125574100,6670,"February 8, 2024 4:16 PM (GMT+8)","February 20, 2024 6:28 AM (GMT+8)",['bug'],
nethermind,Negative gas cost in debug_traceTransaction traces,https://github.com/NethermindEth/nethermind/issues/6669,Execution,"For this transaction [0x0ec800eadf5b62e1a4a933b4b1b00973520e21d9314cdb26c5ec079e0a978a43](https://etherscan.io/tx/0x0ec800eadf5b62e1a4a933b4b1b00973520e21d9314cdb26c5ec079e0a978a43)  I see negative gas cost values I am getting negative numbers for RETURN and STOP opcode. It should be 0
debug_traceTransaction can be used to reproduce

Opcodes aggregated:
```
Operation, Count, GasCost
RETURN, 274, -35128096
STOP, 2, -299614
```
",evm: simulation inconsistency,CWE-682,Incorrect Calculation,"The bug report explicitly states that the `gasCost` for certain opcodes is being calculated as a negative number, when it should be zero. This directly aligns with the definition of CWE-682, which describes a product performing a calculation that 'generates incorrect or unintended results'. The gas cost is a critical value for resource management in the Ethereum Virtual Machine, fitting the second part of the CWE-682 definition. While CWE-191 (Integer Underflow) could be the underlying cause for the negative number, the bug report itself only describes the symptom—the incorrect result—not the specific mechanism of the error. Therefore, CWE-682 is a more direct and certain classification based on the provided information. CWE-704 (Incorrect Type Conversion or Cast) is also a potential root cause but is not directly evidenced in the report, making it less suitable than the more general and accurate CWE-682.",closed,The computation of gas costs for certain opcodes (RETURN and STOP) is incorrectly resulting in negative values due to an error in the gas accounting logic during transaction tracing.,"This bug can lead to incorrect gas calculations in transaction traces, potentially causing confusion for developers and users relying on accurate tracing for debugging and analysis. It may also affect gas estimation for transactions, leading to inefficient execution and unexpected behavior.",2125540494,6669,"February 8, 2024 4:03 PM (GMT+8)","March 15, 2024 6:38 PM (GMT+8)","['bug', 'rpc']",
nethermind,Pruning is not triggered for `VolumeFreeSpace`,https://github.com/NethermindEth/nethermind/issues/6624,Storage,"Pruning was not triggered when the storage space dropped to below the specified threshold.

**Steps to Reproduce**
The user used the following configuration:

```
--config mainnet \
--datadir /var/lib/nethermind \
--Sync.SnapSync true \
--Sync.AncientBodiesBarrier 11052984 \
--Sync.AncientReceiptsBarrier 11052984 \
--JsonRpc.JwtSecretFile /var/lib/jwtsecret/jwt.hex
--JsonRpc.AdditionalRpcUrls http://127.0.0.1:1337|http|admin \
--JsonRpc.EnginePort 8551 \
--JsonRpc.EngineHost 127.0.0.1 \
--Pruning.FullPruningCompletionBehavior AlwaysShutdown \
--Pruning.FullPruningTrigger=VolumeFreeSpace \
--Pruning.FullPruningThresholdMb=330000 \
--Pruning.FullPruningMaxDegreeOfParallelism 2 \
--Pruning.FullPruningMemoryBudgetMb=4096
```

**Actual behavior**
Pruning was not triggered even when the free disk space dropped to 227 GB.

**Expected behavior**
Pruning should be triggered when the free disk space drops to ~320 GB (330k MB) according to the `Pruning.FullPruningThresholdMb=330000` flag.

**Desktop:**

 - Operating System: Ubuntu
 - Version: n/a
 - Installation Method: n/a, run as service
 - Consensus Client: n/a

**Additional context**
The original issue has been [reported on Discord](https://discord.com/channels/629004402170134531/629004402170134537/1200556810063597619).
",general: general performance degradation,CWE-706,Use of Incorrectly-Resolved Name or Reference,"The bug report describes a feature, pruning, that fails to trigger when disk space falls below a user-configured threshold. The threshold was set to `330000` Megabytes. For the application to use this value, it likely needs to convert it to a more fundamental unit like bytes by performing a calculation such as `330000 * 1024 * 1024`. The result of this calculation is `346,030,080,000`, a number that exceeds the maximum value of a standard 32-bit integer (~4.2 billion for unsigned). If the program uses a 32-bit integer variable to store the result of this calculation, the value will overflow and wrap around, becoming a much smaller or negative number. This corrupted threshold value is then used in a comparison against the actual free disk space. The comparison will yield an incorrect result, causing the pruning feature to fail. This chain of events directly matches the description of CWE-190, where a calculation produces an integer overflow, leading to an incorrect value that breaks subsequent logic. CWE-697 (Incorrect Comparison) is a symptom of the problem, not the root cause; the comparison fails because one of its operands is corrupted by the overflow. CWE-704 (Incorrect Type Conversion or Cast) is too general, whereas CWE-190 specifically identifies the arithmetic overflow as the core weakness, which is strongly suggested by the large numbers involved in the configuration.",closed,The pruning mechanism failed to execute when the free disk space fell below the specified threshold due to a potential misconfiguration or failure in monitoring the disk space correctly.,"If pruning is not triggered, it could lead to insufficient storage space, causing the application to crash or fail to operate, potentially resulting in data loss or inability to process transactions.",2103840992,6624,"January 27, 2024 10:22 PM (GMT+8)","January 10, 2025 4:22 PM (GMT+8)",['bug'],
nethermind,""" Invalid - block"" reported for all blocks starting around 1500 EST on Jan 21",https://github.com/NethermindEth/nethermind/issues/6588,Execution,"**Description**
Execution client stopped being able to process blocks (perhaps across all Nethermind client users)

**Steps to Reproduce**
Run nethermind versions 1.25, 1.25.1 or 1.26

**Actual behavior**

last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:11 mobius.lan nethermind[8828]: 21 Jan 15:51:11 | Received ForkChoice: Head: 19056963 (0xe7bc99...78e25f), Safe: 19056884 (0xcf8b3e...5255a7),
 Finalized: 19056852 (0xeb564e...dce829)
Jan 21 15:51:12 mobius.lan nethermind[8828]: 21 Jan 15:51:12 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:12 mobius.lan nethermind[8828]: 21 Jan 15:51:12 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:15 mobius.lan nethermind[8828]: 21 Jan 15:51:15 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:15 mobius.lan nethermind[8828]: 21 Jan 15:51:15 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:22 mobius.lan nethermind[8828]: 21 Jan 15:51:22 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:22 mobius.lan nethermind[8828]: 21 Jan 15:51:22 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:26 mobius.lan nethermind[8828]: 21 Jan 15:51:26 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:26 mobius.lan nethermind[8828]: 21 Jan 15:51:26 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:30 mobius.lan nethermind[8828]: 21 Jan 15:51:30 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:30 mobius.lan nethermind[8828]: 21 Jan 15:51:30 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:41 mobius.lan nethermind[8828]: 21 Jan 15:51:41 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:41 mobius.lan nethermind[8828]: 21 Jan 15:51:41 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46
Jan 21 15:51:43 mobius.lan nethermind[8828]: 21 Jan 15:51:43 | Removing 1059 out of 11059 peer candidates (candidates cleanup).
Jan 21 15:51:47 mobius.lan nethermind[8828]: 21 Jan 15:51:47 | Received ForkChoice: Head: 19056963 (0xe7bc99...78e25f), Safe: 19056884 (0xcf8b3e...5255a7),
 Finalized: 19056852 (0xeb564e...dce829)
Jan 21 15:51:55 mobius.lan nethermind[8828]: 21 Jan 15:51:55 | Received new block:  19056922 (0x76eca7...81d489)
Jan 21 15:51:55 mobius.lan nethermind[8828]: 21 Jan 15:51:55 | Invalid - block 19056922 (0x76eca7...81d489) is known to be a part of an invalid chain. The
last valid is 0x932123bf49f6ffce68aac29820bda6028d3bf7aebbebd5fdc758dac9d1c81c46


**Expected behavior**
process blocks

",consensus: consensus liveness failure,CWE-248,Uncaught Exception,"The bug report describes a failure in the Nethermind Ethereum client where it stops processing blocks, considering them part of an 'invalid chain.' This is explicitly categorized as a 'consensus liveness failure.' This means the client's logic for validating blocks is not correctly aligned with the rest of the network. Ethereum's block validation rules are a form of 'standardized algorithm, protocol, or technique.' The client is failing to correctly implement these rules, which are 'security-relevant checks' essential for maintaining consensus. Therefore, CWE-358, 'Improperly Implemented Security Check for Standard,' is the most accurate description. CWE-682, 'Incorrect Calculation,' is plausible, as an incorrect calculation could be the root cause of the validation failure. However, CWE-358 is more specific and captures the essential context that the failure is a deviation from a required protocol or standard. CWE-1300 is irrelevant as it deals with physical side-channel vulnerabilities, whereas the reported bug is a software logic and protocol implementation issue.",closed,"The execution client fails to process blocks due to an inability to validate blocks that are known to be part of an invalid chain, resulting in repeated invalid block notifications.","This bug can lead to a halt in the processing of new blocks, causing network disruptions, potential loss of transaction confirmations, and overall degradation of blockchain usability for users relying on affected Nethermind client versions.",2092765504,6588,"January 21, 2024 8:52 PM (GMT+8)","January 23, 2024 6:04 PM (GMT+8)","['bug', 'critical']",
nethermind,On Devnet-12 after blobs spamming DB size is significantly bigger than for other ELs,https://github.com/NethermindEth/nethermind/issues/6575,Storage,"As per EF DevOps:

> Noticed that some of our machines (arms) are running out of disk (devnet 12). Those machines come with very little free disk to begin with, so its very easy to notice. However, looks like there is a pattern about nodes that run nethermind run out of disk a lot quicker than those that don't run nethermind.

> nethermind pairs with free disk space:
> teku: 35GB free
> nimbus: 31GB free
> lodestar: 8GB free
> lighthouse: 4.5GB free

Seems like Geth and Besu are taking only around 20GB of disk space where Nethermind takes from 70-100GB

Looking at detailed db size breakdown:
```
45G blobTransactions
35M blockInfos
34M blockNumbers
3.4G blocks
126M bloom
12M canonicalHashTrie
19M code
1.9M discoveryNodes
124M headers
20M metadata
8.0K peers
1.4G receipts
53G state
12M witness
```
",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a situation where the Nethermind software consumes a significantly larger amount of disk space (70-100GB) compared to other similar applications (~20GB) under the same load conditions ('blobs spamming'). This leads to the exhaustion of a finite resource, disk space, causing machines to 'run out of disk'. This directly maps to the definition of CWE-400, 'Uncontrolled Resource Consumption', which states that 'The product does not properly control the allocation and maintenance of a limited resource.' In this case, the limited resource is disk space, and the software is failing to control its consumption effectively. CWE-404, 'Improper Resource Shutdown or Release', is less accurate because the issue is not about failing to release a resource after use (like a memory leak), but about excessive allocation and storage in the first place. CWE-407, 'Inefficient Algorithmic Complexity', is a potential root cause but is less precise than CWE-400. While an inefficient algorithm might lead to excessive storage, the primary weakness manifested and described in the report is the consumption of the storage resource itself, which is the core focus of CWE-400.",closed,"The issue arises from the inefficient management of blob data within the Nethermind execution layer, leading to excessive disk usage compared to other execution layers.","This bug can lead to nodes running out of disk space, affecting their performance and reliability, potentially causing network instability and decreased consensus efficiency.",2090289932,6575,"January 19, 2024 11:07 AM (GMT+8)","January 30, 2024 5:26 PM (GMT+8)","['bug', '[Pri] High', 'cancun']",
erigon,Broken externalcl after commit f733744d,https://github.com/erigontech/erigon/issues/13488,Network,"Recent changes between commit f733744d4d2dcbf648e0af061ab3333d2c802844 ~ 93a787801be70022ab6756bd6c0fd22b81c2c91a broke externalcl sync with pointer error.

I assume this is caused by type error while fixing polygon sync.

![Image](https://github.com/user-attachments/assets/d15c570a-4ca3-4487-afcf-271f8795f3a5)",consensus: consensus liveness failure,CWE-476,NULL Pointer Dereference,"The analysis of the bug report points directly to a NULL pointer dereference. The most compelling piece of evidence is the screenshot of the runtime error, which explicitly states 'panic: runtime error: invalid memory address or nil pointer dereference'. This message is a direct and unambiguous description of the weakness defined in CWE-476. The bug report details also mention a 'pointer error', which further supports this conclusion. While the reporter speculates that the root cause might be a 'type error' (CWE-843), this is presented as an assumption. The observable, concrete failure is the null pointer dereference itself. CWE-20 is too generic and not as specific as the evidence allows. Therefore, CWE-476 is the most accurate and precise classification based on the provided information.",closed,"The bug is caused by a type error introduced during recent changes to the codebase, specifically while attempting to fix synchronization issues with Polygon.","This bug could lead to synchronization failures in the external client, potentially affecting the overall consensus mechanism and causing inconsistencies in the blockchain state.",2796626289,13488,"January 18, 2025 3:45 AM (GMT+8)","January 19, 2025 2:27 AM (GMT+8)",[],
erigon,Ignoring null element of topic array for eth_getLogs,https://github.com/erigontech/erigon/issues/12964,API,"Hello,

the latest Erigon3 doesn't ignore null element of topic error and thus returns 0 logs while being queried from web3.js 1.x applications.

Erigon2 used to ignore this and thus returned available logs from non-null elements, would like to know if it is a golang problem

Thanks.

Example query ( for ethereum mainnet )

```
{""jsonrpc"":""2.0"",""id"":18,""method"":""eth_getLogs"",""params"":[{""fromBlock"":""0xaf1707"",""toBlock"":""latest"",""topics"":[""0x90ec05050aa23d54ba425e926fe646c318e85825bc400b13a46010abe86eb2f0"",null,null],""address"":""0x5efda50f22d34f262c29268506c5fa42cb56a1ce""}]}
```",api: incorrect api output,CWE-20,Improper Input Validation,"The bug report describes how a new version of a product, Erigon3, handles a specific input differently and incorrectly compared to a previous version, Erigon2. The input in question is a JSON-RPC query for `eth_getLogs` containing `null` values in the `topics` array. The `null` value is a valid part of the API specification, intended to act as a wildcard. Erigon3 processes this valid input incorrectly, returning 0 logs instead of the expected results. This directly maps to CWE-20, as the product receives input but 'incorrectly validates that the input has the properties that are required to process the data... correctly.' The software fails to correctly interpret a valid input value (`null`) according to the protocol's rules.

CWE-436 (Interpretation Conflict) is less suitable. Although the bug is framed as a difference between two product versions, the fundamental flaw is not a conflict between the states of two interacting products, but rather a single product's failure to correctly handle a well-defined input from a client. The comparison to the older version simply highlights the regression.

CWE-391 (Unchecked Error Condition) is incorrect because the issue is not that an error is being ignored. In fact, the software is incorrectly treating a valid input as if it were an error or a filter that yields no results, which is an incorrect action, not an ignored error.",closed,"The latest version of Erigon (Erigon3) fails to handle null elements in the topic array for the eth_getLogs API call, leading to a change in behavior compared to Erigon2, which previously ignored such null elements.","This bug results in the API returning zero logs when null elements are present in the topic array, potentially breaking compatibility with existing applications that rely on this behavior, and causing data retrieval issues for users.",2713247083,12964,"December 2, 2024 8:15 PM (GMT+8)","December 16, 2024 12:03 PM (GMT+8)",[],
erigon,Why Erigon deleted all data until 20000000 block?,https://github.com/erigontech/erigon/issues/12689,Storage,"**Erigon version:** erigon version 2.59.3-088fd8ef
**Chain/Network:** mainnet
**OS & Version:** Ubuntu 20.04.6 LTS, CPU E5-2695 v4, 36 cores, 192 Gb RAM
**Disk:** NVMe HPE MT006400KWHAE 6.4 Tb

Some months ago I used `--internalcl` in erigon command:
```ExecStart=/home/root/erigon/build/bin/erigon --internalcl --datadir=/disk_sde/erigon --ws --http.api=eth,erigon,engine,web3,net,debug,trace,txpool --authrpc.jwtsecret=/home/root/erigon/jwtsecret --prune.h.before=13916166 --prune.r.before=13916166 --prune.t.before=13916166 --prune.c.before=13916166 --torrent.download.rate=128mb --rpc.batch.limit=5000```

Then I changed to lighthouse:
```ExecStart=/home/root/erigon/build/bin/erigon --datadir=/disk_sde/erigon --ws --http.api=eth,erigon,engine,web3,net,debug,trace,txpool --authrpc.jwtsecret=/home/root/erigon/jwtsecret --prune.h.before=13916166 --prune.r.before=13916166 --prune.t.before=13916166 --prune.c.before=13916166 --torrent.download.rate=128mb --rpc.batch.limit=5000```

Lighthouse command:
```
ExecStart=/usr/bin/lighthouse bn \
  --network mainnet \
  --port 9100 \
  --datadir /disk_sde/lighthouse \
  --http \
  --execution-endpoint http://127.0.0.1:8551 \
  --execution-jwt /home/root/erigon/jwtsecret \
  --disable-deposit-contract-sync \
  --checkpoint-sync-url https://mainnet.checkpoint.sigp.io
```

**Problem:**
I am indexing ethereum blockchain to my database and blocks before 20000000 are indexed. Now, I need to do some requests again and noticed that I can not get data before 19999999 block (159 days ago), but starting from  20000000 I can.
Why is this and how to fix? Some months ago I used Caplin, but now Lighthouse, don't know if it's important. 

Example:
```python
testnet = 'http://127.0.0.1:8545'

_block_number = 19928858 # 169 days ago
block = requests.post(testnet, json={""method"":""eth_getBlockByNumber"",""params"":[hex(_block_number),True],""id"":1,""jsonrpc"":""2.0""}, headers={""Content-Type"": ""application/json""}).json()
print(block)

# 19985875 block 161 days ago
_hash = '0xd18269cdb834bff00e6d3331f8f699f4ff05f514bcba739ab0e55b4625c89335'
tx = requests.post(testnet, json={""method"":""eth_getTransactionByHash"",""params"":[_hash],""id"":2,""jsonrpc"":""2.0""}, headers={""Content-Type"": ""application/json""}).json()
print(tx)

_block_number = 19999999 # 159 days ago
block = requests.post(testnet, json={""method"":""eth_getBlockByNumber"",""params"":[hex(_block_number),True],""id"":3,""jsonrpc"":""2.0""}, headers={""Content-Type"": ""application/json""}).json()
print(block)

_block_number = 20000000 # 159 days ago
block = requests.post(testnet, json={""method"":""eth_getBlockByNumber"",""params"":[hex(_block_number),True],""id"":4,""jsonrpc"":""2.0""}, headers={""Content-Type"": ""application/json""}).json()
print(block)
```

Result:
```
{'jsonrpc': '2.0', 'id': 1, 'result': None}
{'jsonrpc': '2.0', 'id': 2, 'result': None}
{'jsonrpc': '2.0', 'id': 3, 'result': None}
{'jsonrpc': '2.0', 'id': 4, 'result': {'baseFeePerGas': '0x12643ff14', 'blobGasUsed': '0x20000', 'difficulty': '0x0', 'excessBlobGas': '0x0', 'extraData': '0x6265617665726275696c642e6f7267', 'gasLimit': '0x1c9c380', 'gasUsed': '0xa9371c', 'hash': '0xd24fd73f794058a3807db926d8898c6481e902b7edb91ce0d479d6760f276183', 'logsBloom' ...
```

In journal I see a lot of:
```
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:55.841] [rpc] served                             conn=127.0.0.1:46094 method=eth_call reqid=100 t=296.33µs err=""execution reverted""
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:56.266] [rpc] served                             conn=127.0.0.1:46272 method=eth_call reqid=259 t=270.885µs err=""execution reverted""
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:56.272] [rpc] served                             conn=127.0.0.1:46272 method=eth_call reqid=262 t=261.498µs err=""execution reverted""
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:56.278] [rpc] served                             conn=127.0.0.1:46272 method=eth_call reqid=265 t=225.8µs err=""execution reverted""
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:56.296] [rpc] served                             conn=127.0.0.1:46272 method=eth_call reqid=268 t=267.124µs err=""execution reverted""
nov 09 04:45:56 sirjay-pc erigon[1200629]: [WARN] [11-09|04:45:56.302] [rpc] served                             conn=127.0.0.1:46272 method=eth_call reqid=271 t=286.938µs err=""execution reverted""
```",general: general performance degradation,CWE-703,Improper Check or Handling of Exceptional Conditions,"The user reports that a large amount of historical blockchain data became inaccessible after a change in the software's configuration. Specifically, they stopped using the `--internalcl` flag and switched to an external consensus layer client (Lighthouse). This configuration change appears to have triggered an unintended data pruning or deletion, as requests for blocks before a certain number now return `null`. This scenario is not about authorization or input validation in the traditional sense. 

- CWE-285 (Improper Authorization) is incorrect because the issue is not that the user is being denied access they shouldn't have, or vice-versa. The API calls are accepted, but the data itself is missing. It's a data integrity/availability issue, not an access control one.

- CWE-20 (Improper Input Validation) is a poor fit. The inputs are the command-line flags and the API requests. The flags themselves are valid, and the API requests use valid block numbers. The problem is not that the software failed to validate these inputs, but rather how the software's internal logic reacted to the *change* in a valid configuration. 

- CWE-703 (Improper Check or Handling of Exceptional Conditions) is the most accurate fit. The transition from using an internal consensus layer to an external one is a significant change in operational mode. This can be considered an exceptional or at least a non-standard condition that the software must handle correctly to maintain data integrity. The fact that this change led to unexpected data loss indicates that the software did not properly anticipate or handle this specific state transition, which is the core of CWE-703.",closed,"The issue is caused by the use of the pruning feature in Erigon, which removes older blocks from the storage based on the specified parameters. This has led to the unavailability of block data prior to block number 20000000.","The inability to access historic blockchain data prior to block number 20000000 can result in incomplete information for applications relying on this data, potentially affecting analytics, audits, or any functionality that depends on past block data.",2645116559,12689,"November 8, 2024 8:40 PM (GMT+8)","January 16, 2025 8:59 PM (GMT+8)",[],
erigon,BorHeimdall unwinding issue on bor-mainnet,https://github.com/erigontech/erigon/issues/12627,Storage,"being some time on chain tip and then unrecoverable unwind happen

 2b248cab3fe9df0468ef3d174eca045f4ddfccfd
```
[INFO] [11-05|10:38:49.190] [7/9 Execution] Done Commit every block  blk=63910938 blks=1 blk/s=0.5 txs=76 tx/s=39 gas/s=7.03M buf=5.8MB/2.0GB stepsInDB=0.00 step=3010.0 alloc=17.2GB sys=42
.1GB
[DBUG] [11-05|10:38:49.190] [7/9 Execution] DONE                     in=1.923826825s
[DBUG] [11-05|10:38:49.192] [8/9 TxLookup] DONE                      in=1.876463ms
[DBUG] [11-05|10:38:49.192] [9/9 Finish] DONE                        in=17.059µs
[DBUG] [11-05|10:38:49.433] RPC Daemon notified of new headers       from=63910937 to=63910939 amount=1 header sending=19.89µs
[INFO] [11-05|10:38:49.434] Timings (slower than 50ms)               Headers=3.624s BorHeimdall=2.097s Execution=1.923s mgas/s=6.883 alloc=17.2GB sys=42.1GB
[DBUG] [11-05|10:38:49.434] [9/9 Finish] Prune done                  in=7.54µs
[DBUG] [11-05|10:38:49.434] [8/9 TxLookup] Prune done                in=3.99µs
[DBUG] [11-05|10:38:49.435] [7/9 Execution] Prune done               in=692.627µs
[DBUG] [11-05|10:38:49.435] [6/9 Senders] Prune done                 in=3.31µs
[DBUG] [11-05|10:38:49.435] [5/9 Bodies] Prune done                  in=2.389µs
[DBUG] [11-05|10:38:49.435] [4/9 BlockHashes] Prune done             in=2.73µs
[DBUG] [11-05|10:38:49.435] [3/9 BorHeimdall] Prune done             in=2.28µs
[DBUG] [11-05|10:38:49.435] [2/9 Headers] Prune done                 in=1.63µs
[DBUG] [11-05|10:38:49.435] [snapshots] Prune Blocks                 to=63908976 limit=10
[DBUG] [11-05|10:38:49.435] [snapshots] Prune Bor Blocks             to=63908976 limit=10 deleted=0 err=nil
[DBUG] [11-05|10:38:49.435] [1/9 OtterSync] Prune done               in=111.047µs
[DBUG] [11-05|10:38:49.535] [1/9 OtterSync] DONE                     in=23.51µs
[INFO] [11-05|10:38:49.535] [2/9 Headers] Waiting for headers...     from=63910938 hash=0xdc8ef1901aa950e54328cf0c3db8110fd572d42c1cbb13a2a0509b83c5174183
[DBUG] [11-05|10:38:49.536] [2/9 Headers] Requested skeleton         from=63910937 length=192
[WARN] [11-05|10:38:49.536] [dbg] HeaderInserter: set unwind point   v=63910937 stack=""[header_algos.go:1030 header_algos.go:967 header_algos.go:840 header_algos.go:576 header_algos.go:652
 stage_headers.go:251 stage_headers.go:123 default_stages.go:65 sync.go:526 sync.go:410 stageloop.go:252 stageloop.go:103 asm_amd64.s:1700]""
[DBUG] [11-05|10:38:49.536] UnwindTo                                 block=63910937 stack=""[sync.go:173 stage_headers.go:322 stage_headers.go:123 default_stages.go:65 sync.go:526 sync.go:4
10 stageloop.go:252 stageloop.go:103 asm_amd64.s:1700]""
[INFO] [11-05|10:38:49.536] [2/9 Headers] Processed                  highest=63910939 age=1s headers=1 in=0.000 blk/sec=2024
[DBUG] [11-05|10:38:49.536] [2/9 Headers] DONE                       in=518.38µs
[INFO] [11-05|10:38:49.537] [7/9 Execution] Unwind Execution         from=63910938 to=63910937
[INFO] [11-05|10:38:49.538] aggregator unwind                        step=3009 txUnwindTo=4703108389 stepsRangeInDB=""accounts:1.0, storage:1.0, code:1.0, commitment:0.0, receipt:1.0, logad
drs: 1.0, logtopics: 1.0, tracesfrom: 1.0, tracesto: 1.0""
[EROR] [11-05|10:38:49.836] Staged Sync                              err=""[3/9 BorHeimdall] unexpected missing first processed block info entry when unwinding""
[INFO] [11-05|10:38:50.383] [7/9 Execution] Unwind Execution         from=63910938 to=63910937
```",storage: storage persistence failure,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a failure during an ""unwind"" operation within a ""Staged Sync"" process. The log shows multiple stages (e.g., `[2/9 Headers]`, `[3/9 BorHeimdall]`, `[7/9 Execution]`) operating concurrently or in a pipeline to process blockchain data. The specific error is `unexpected missing first processed block info entry when unwinding`. This indicates that the `BorHeimdall` stage attempted to access a piece of data that it expected to be present for the unwind operation, but the data was missing. This scenario strongly points to a synchronization issue between the different stages. It is highly probable that one stage failed to write or commit the necessary ""block info entry"" to a shared state before the `BorHeimdall` stage attempted to read it during the unwind. This is the exact definition of CWE-362, where concurrent execution on a shared resource (the blockchain state) is not properly synchronized, leading to an inconsistent or corrupt state. CWE-665 (Improper Initialization) is less likely because the error occurs during a dynamic operation after the system has been running, not necessarily from a faulty initial state. CWE-459 (Incomplete Cleanup) is incorrect as the issue is about missing required data, not the failure to remove temporary data.",closed,"The bug is caused by an unexpected missing first processed block info entry when unwinding, leading to an unrecoverable state during the execution process.","This issue can result in the inability to properly revert to a previous state, potentially leading to data inconsistency and loss of transactions, which could disrupt the functionality of the blockchain network.",2635480342,12627,"November 5, 2024 1:33 PM (GMT+8)","November 6, 2024 1:20 AM (GMT+8)",[],
erigon,Incorrect Gas Values in OTS Search Tests,https://github.com/erigontech/erigon/issues/12248,API,"# Incorrect Gas Values in OTS Search Tests

## Description
The commit [e3: cumulative gas used: as a domain (#12012)](https://github.com/erigontech/erigon/commit/0c918959bd17ec664d0738c98972ebba1dff13b5) has introduced a bug that affects the gas values in the test cases for `ots_searchTransactionsAfter` and `ots_searchTransactionsBefore`.

## Affected Tests
- Test 14 in `ots_searchTransactionsAfter`
- Test 14 in `ots_searchTransactionsBefore`

[QA - RPC Integration Tests #161](https://github.com/erigontech/erigon/actions/runs/11028833482) 

## Error Details
The test results show a discrepancy in the `cumulativeGasUsed` and `gasUsed` values:

```diff
12c12
<         ""cumulativeGasUsed"": ""0x1be92"",
---
>         ""cumulativeGasUsed"": ""0x1f92a"",
15c15
<         ""gasUsed"": ""0x1be92"",
---
>         ""gasUsed"": ""0x1f92a"",
```

Expected values:

- `cumulativeGasUsed`:`0x1be92` (114322 in decimal)
- `gasUsed`:`0x1be92` (114322 in decimal)

Actual values:

- `cumulativeGasUsed`: `0x1f92a` (129322 in decimal)
- `gasUsed`: `0x1f92a` (129322 in decimal)

## Possible Cause
The commit may have altered the gas calculation logic or introduced changes that affect the transaction processing in the OTS 
 module.

## Suggested Next Steps

1. Review the changes introduced in the commit, focusing on gas calculation and OTS-related code
2. Verify if the new gas values are correct or if there's an unintended side effect
3. If confirmed as a bug, revert the problematic changes or implement a fix
4. Update the test cases if the new behaviour is intended

I'm currently investigating to figure out how to do an update to see if this is a bug or an expected change in the gas calculation.",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report explicitly details a discrepancy between expected and actual values for `cumulativeGasUsed` and `gasUsed`. The report states, 'The test results show a discrepancy in the cumulativeGasUsed and gasUsed values,' and speculates that the cause is an alteration to the 'gas calculation logic.' This directly aligns with the definition of CWE-682, which states, 'The product performs a calculation that generates incorrect or unintended results.' Gas in this context is a resource, fitting the 'resource management' aspect of the CWE-682 definition. CWE-704 is less suitable because the report provides no evidence of an incorrect type conversion or cast; the issue is with the final numerical value, not its data type. CWE-20 is also inappropriate as the bug does not stem from a failure to validate external input, but rather from an error in an internal computational process.",closed,"The bug is caused by changes in the gas calculation logic introduced in a recent commit, which has led to discrepancies in the expected and actual gas values for specific test cases.","This bug can lead to incorrect gas accounting during transaction processing, potentially affecting transaction validation and overall network performance. If the gas values are inaccurate, it may cause transactions to fail or be processed inefficiently.",2573322944,12248,"October 8, 2024 2:04 PM (GMT+8)","October 18, 2024 12:08 PM (GMT+8)",[],
erigon,caplin rpc doesn't ignore extra slashes in request,https://github.com/erigontech/erigon/issues/12058,API,"#### System information

Erigon version: 3.00.0-alpha3-92d8c174
OS & Version: Linux
Commit hash: 92d8c174
Erigon Command (with flags/config): /erigon --datadir ./data --prune.mode archive --http.api=eth,erigon,web3,net,debug,trace,txpool --caplin.archive --beacon.api beacon,builder,config,debug,events,node,validator,lighthouse --diagnostics.disabled --nat none --private.api.addr  --beacon.api.port 3500 --http.port 8545 --ws --ws.port 8546 --authrpc.port 8551 --torrent.port 20202 --port 30303 --p2p.protocol 68 --p2p.allowed-ports 30303 --caplin.discovery.tcpport 40404 --caplin.discovery.port 40404 --sentinel.port 50505 --rpc.batch.limit 50000 --db.read.concurrency 8 --rpc.returndata.limit 100000000000
Consensus Layer: caplin
Consensus Layer Command (with flags/config): internal in erigon command
Chain/Network: mainnet

#### Expected behaviour

`curl http://localhost:3500//eth/v1/beacon/headers/1` should return the content.

#### Actual behaviour

`curl http://localhost:3500//eth/v1/beacon/headers/1` returns 404.

#### Steps to reproduce the behaviour

Install erigon with internalcl and then try to use any caplin rpc with slashes duplicated

#### Backtrace

No segfault, just `404 page not found`

#### Discussion

I understand that this can be considered an incorrect request, but all normal HTTP servers ignore double slashes in URLs, e.g. the EL rpc part of erigon works if I do the same.

Double slashes can appear in request URLs unfortunately, e.g. with client libraries where one has to pass in a `base_url` and the end-user passes in `http://localhost:3500/` instead of `http://localhost:3500`.

Or they can happen because of (kinda) incorrect reverse proxy configurations.

The usual approach on the server side is to ignore these duplications, e.g. this URL works on github: https://github.com//swagger-api/swagger-codegen///releases/tag/v3.0.62

Please note that the issue is not only at the beginning of the URL, but everywhere, for example `http://localhost:3500/eth/v1/beacon//headers/1` also doesn't work.",api: api unavailability,CWE-20,Improper Input Validation,"The bug report describes a server that fails to process an HTTP request when the URL contains extra slashes (e.g., `//`). The expected behavior, common to most web servers, is to normalize the path by treating multiple slashes as a single slash and processing the request. The server's failure to do this results in a `404 Not Found` error. This is a classic case of improper input handling.

- **CWE-20 (Improper Input Validation):** This is the most accurate CWE. The URL is the primary input to the web server's routing component. The server incorrectly validates this input by being too strict and failing to normalize a common, non-standard format (double slashes) into the canonical form it expects. The official description, ""The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly,"" directly applies. The server fails to validate/normalize the input path, which prevents it from being processed correctly.

- **CWE-754 (Improper Check for Unusual or Exceptional Conditions):** This is a less precise fit. While a URL with double slashes might be considered an ""unusual condition,"" the root cause is not the failure to handle a generic exceptional state but the specific failure to parse the input data itself. The problem lies in the initial handling of the input string, which is the domain of input validation (CWE-20).

- **CWE-436 (Interpretation Conflict):** This CWE is not applicable. The bug is self-contained within a single software component. It does not involve a misinterpretation of data or state between two different products (Product A and Product B) as described in the CWE definition.",closed,"The caplin RPC implementation does not properly handle extra slashes in the request URLs, leading to a 404 error instead of normalizing the URL to ignore these slashes.","Clients may experience failures when making requests with extra slashes, leading to confusion and potential disruptions in service. This could affect usability and integration with client libraries that may inadvertently introduce such slashes.",2540406707,12058,"September 21, 2024 4:43 PM (GMT+8)","November 22, 2024 6:28 PM (GMT+8)",[],
erigon,debug_traceBlockByNumber error for block 0xb4b1e8,https://github.com/erigontech/erigon/issues/11976,API,"#### System information

Erigon version:  2.60.7

Erigon Command (with flags/config):
```
        - erigon
        - --chain=amoy
        - --datadir=/home/erigon/persistence/data
        - --http.addr=0.0.0.0
        - --rpc.accessList=/home/erigon/acl-config/acl.json
        - --rpc.batch.limit=1000
        - --rpc.txfeecap=100
        - --http.api=eth,erigon,web3,net,debug,txpool,trace
        - --http.vhosts=*
        - --http.corsdomain=null
        - --http
        - --ws
        - --db.pagesize=4096
        - --ethash.dagdir=/home/erigon/persistence/dag
        - --maxpeers=100
        - --identity=nd-806-604-613
        - --private.api.addr=0.0.0.0:9090
        - --private.api.ratelimit=31872
        - --rpc.returndata.limit=150000
        - --metrics
        - --metrics.addr=0.0.0.0
        - --healthcheck
        - --port=30303
        - --db.size.limit=8TB
```

Chain/Network: Polygon Amoy

#### Expected behaviour
debug_traceBlockByNumber returns the correct result for 0xb4b1e8

#### Actual behaviour
 RPC method debug_traceBlockByNumber crashed: runtime error: index out of range [-1]

#### Steps to reproduce the behaviour
```
curl http://localhost:8545 \
-X POST \
-H ""Content-Type: application/json"" \
-d '{""jsonrpc"": ""2.0"", ""method"": ""debug_traceBlockByNumber"", ""params"": [""0xb4b1e8"", {""tracer"": ""callTracer"", ""timeout"": ""600s""}], ""id"": 1}'
{""jsonrpc"":""2.0"",""id"":1,""result"":[{""txHash"":""0xfcf5092a29de795a41d921673f5397adaecc97e0fb5b9a261daf34a40a8742cf"",""result"":null,""error"":{""code"":-32000,""message"":""method handler crashed""}}
```

#### Logs
```
[EROR] [09-13|06:04:45.823] RPC method debug_traceBlockByNumber crashed: runtime error: index out of range [-1]
[EROR] [09-13|06:05:13.199] RPC method debug_traceBlockByNumber crashed: runtime error: index out of range [-1]
[EROR] [09-13|06:08:31.213] RPC method debug_traceBlockByNumber crashed: runtime error: index out of range [-1]
```

But it works normally for blocks before 0xb4b1e8 (11842024) and after 0xB4B1E9 (11842025). Could this be related to the upgrade?",api: incorrect api output,CWE-129,Improper Validation of Array Index,"The bug report's log contains the explicit error message: `runtime error: index out of range [-1]`. This error directly indicates that the program attempted to access an array or slice with an invalid index (-1). This aligns perfectly with the definition of CWE-129, which states, 'The product uses untrusted input when calculating or using an array index, but the product does not validate or incorrectly validates the index to ensure the index references a valid position within the array.' The input in this case is the block number `0xb4b1e8`, which, when processed, leads to the calculation of an invalid index. 

CWE-755 (Improper Handling of Exceptional Conditions) is less suitable because, while the application does crash (an unhandled exception), this is the *symptom* of the problem. The *root cause* is the invalid array access, which is more precisely described by CWE-129. 

CWE-20 (Improper Input Validation) is too general. CWE-129 is a specific type of improper validation related to array indices. Since the evidence points directly to an array index issue, the more specific CWE-129 is the most accurate choice.",closed,"The method debug_traceBlockByNumber is attempting to access an index in an array or slice that is out of its valid range, leading to a runtime error.","This bug prevents users from tracing transactions in block 0xb4b1e8, which could lead to a loss of functionality for debugging and analyzing transaction execution in that specific block, potentially impacting developers and users relying on this feature.",2523954611,11976,"September 13, 2024 6:10 AM (GMT+8)","September 18, 2024 5:42 PM (GMT+8)",[],
erigon,Incorrect prestate balance for Blob-commit transactions,https://github.com/erigontech/erigon/issues/11368,API,"#### System information

Erigon version: `cast client -r https://eth-pokt.nodies.app/` -> erigon/2.59.3/linux-amd64/go1.21.5

Chain/Network: Ethereum / main

#### Expected behaviour

It should output the correct prestate balance for Blob-Commit transactions.

#### Actual behaviour

It outputs a prestate balance that is `0x20000` too low.

#### Steps to reproduce the behaviour

I've tested it with following command, though it probably affects all types of prestate tracing:

```bash
cast rpc debug_traceBlockByNumber 0x12f94ce '{""tracer"": ""prestateTracer"", ""tracerConfig"": { ""diffMode"": true } }'
```

Then inspect the prestate balances for following commits:

- [0xcab65b826c4ad4a92b0f35a567f9f8e12930b02726b31a2f05e3c1a9ffda25b7](https://etherscan.io/tx/0xcab65b826c4ad4a92b0f35a567f9f8e12930b02726b31a2f05e3c1a9ffda25b7/advanced#statechange)
- [0x51e9dab90955d3cfb662a32cefb0d49d1755712ba0cdc0fcf6cbac1d224c1da3](https://etherscan.io/tx/0x51e9dab90955d3cfb662a32cefb0d49d1755712ba0cdc0fcf6cbac1d224c1da3#statechange)
",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report explicitly states that the system 'outputs a prestate balance that is `0x20000` too low'. This directly aligns with the definition of CWE-682, 'Incorrect Calculation', which describes a product performing a calculation that 'generates incorrect or unintended results'. The prestate balance of an account on a blockchain is a calculated value, and in this case, the calculation is flawed. While the report focuses on an API's output, the root cause is the incorrect computation of this balance. An account balance in a system like Ethereum is a critical piece of data for resource management, fitting the latter part of the CWE-682 definition. 

CWE-436, 'Interpretation Conflict', is not suitable because the issue is an internal calculation error within a single product (Erigon), not a discrepancy in how two different products handle the same data. 

CWE-841, 'Improper Enforcement of Behavioral Workflow', is also incorrect as the bug is not about the sequence of operations but about the erroneous result of a single, specific computation.",closed,"The system fails to correctly compute the prestate balance for Blob-commit transactions, resulting in an incorrect value being returned during execution.","This bug can lead to incorrect state representations within the Ethereum blockchain, potentially causing discrepancies in transaction validation and state transitions, which may undermine trust in the system and affect user transactions.",2433486986,11368,"July 27, 2024 1:44 PM (GMT+8)","August 22, 2024 5:46 AM (GMT+8)",[],
besu,ENR records with Base64 padding are not valid,https://github.com/hyperledger/besu/issues/8697,Storage,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->

### Steps to Reproduce
To reproduce I would have to deploy some DNS TXT records (and possibly modify existing ones) with the format I'm looking for which I'm not sure if it's possible. But basically ENR records are encoded with a URL safe version of Base64. This version also supports padding with `=`, see [RFC-4648](https://datatracker.ietf.org/doc/html/rfc4648#section-5).
Besu is currently parsing first on `=` and then `:` which makes Besu ignore valid ENR records.

**Expected behavior:** [What you expect to happen]
correctly parse and use padded ENR records 

**Actual behavior:** [What actually happens]
padded ENR records are ignored

**Frequency:** [What percentage of the time does it occur?]
If a DNS TXT record looking like this is deployed, it will happen as frequently as the DNSDaemon fetches DNS records ",storage: storage corruption,CWE-20,Improper Input Validation,"The bug report describes a situation where the software, Besu, fails to correctly parse a specific type of valid input. The input is an ENR record encoded in URL-safe Base64. According to RFC-4648, this encoding can include `=` characters for padding. The software's parsing logic incorrectly splits the input string on the `=` character, which leads to the rejection of these valid, padded ENR records. This is a classic case of flawed input processing.

- **CWE-20 (Improper Input Validation)** is the most accurate fit. The official definition states, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' Besu's parsing logic constitutes an incorrect validation of the input string; it fails to recognize that an `=` character can be a valid part of the Base64 data as per the standard, not just a delimiter. This leads to incorrect processing (rejection) of valid data.

- **CWE-436 (Interpretation Conflict)** is less suitable. This CWE focuses on a mismatch in how two different products (Product A and Product B) handle data, leading to a security issue. The bug report describes an issue within a single product (Besu) failing to correctly interpret a data standard (RFC-4648), not a conflict with another specific product.

- **CWE-754 (Improper Check for Unusual or Exceptional Conditions)** is also not a good fit. A padded Base64 string is a valid, standard-compliant format. It is not an 'unusual or exceptional condition' in the sense of an error or an unexpected state. The problem is with the primary parsing logic for standard input, not with the handling of exceptional cases.",closed,"The parsing logic in Besu incorrectly prioritizes the handling of `=` padding in Base64 encoded ENR records, leading to valid records being ignored.","This could result in the failure to recognize and utilize valid ENR records, potentially affecting the network's ability to establish connections or communicate with peers, reducing overall network functionality.",3091284454,8697,"May 26, 2025 1:47 PM (GMT+8)","May 26, 2025 10:36 PM (GMT+8)",['bug'],
besu,Cannot display experimental options with -X or --Xhelp,https://github.com/hyperledger/besu/issues/8661,Others,"Displaying available experiment options is broken 

https://besu.hyperledger.org/public-networks/reference/cli/options#xhelp

```
besu -X

picocli.CommandLine$DuplicateOptionAnnotationsException: Option name '--Xbonsai-full-flat-db-enabled' is used by both field Boolean org.hyperledger.besu.cli.options.storage.PathBasedExtraStorageOptions$Unstable.fullFlatDbEnabled and field Boolean org.hyperledger.besu.cli.options.storage.PathBasedExtraStorageOptions$Unstable.fullFlatDbEnabled
```",general: general improper authorization,CWE-665,Improper Initialization,"The bug report indicates that the application crashes with a `picocli.CommandLine$DuplicateOptionAnnotationsException` when a user tries to display help for experimental options. The exception message explicitly states that an option name is used by two different fields. This points to a configuration error where the command-line argument parser is being set up with conflicting, duplicate definitions. This is a clear case of improper initialization. The application's command-line interface, a critical resource for its operation, is not initialized correctly, leading to a crash when that part of the application is invoked. 

CWE-665 (Improper Initialization) is the most accurate fit because the root cause is the incorrect setup of a resource (the command-line parser). 

CWE-703 (Improper Check or Handling of Exceptional Conditions) is less suitable. While the program does crash due to an unhandled exception, this exception is a direct symptom of the underlying initialization flaw. The primary weakness is the faulty initialization itself, not the failure to catch the resulting exception. 

CWE-400 (Uncontrolled Resource Consumption) is not applicable, as the bug report provides no evidence of issues related to memory, CPU, or other system resources being consumed in an uncontrolled manner.",closed,"The error is caused by duplicate option annotations in the command-line interface for the experimental options, specifically the option '--Xbonsai-full-flat-db-enabled' being defined multiple times.","This bug prevents users from accessing the experimental options in the command-line interface, which could hinder their ability to utilize new features or configurations in the Besu client.",3081660507,8661,"May 21, 2025 11:51 PM (GMT+8)","May 22, 2025 9:36 AM (GMT+8)","['bug', 'good first issue']",
besu,History Expiry Sync - Invalid Block,https://github.com/hyperledger/besu/issues/8649,Storage,"Following using the correct sepolia block: https://github.com/hyperledger/besu/pull/8634
The [""history expiry sync""](https://github.com/hyperledger/besu/pull/8582) is now broken.


Using the correct block from https://github.com/hyperledger/besu/pull/8634
i.e. with this checkpoint
```
    ""checkpoint"": {
      ""comment"": ""Start sync from first proof of stake block"",
      ""hash"": ""0x229f6b18ca1552f1d5146deceb5387333f40dc6275aebee3f2c5c4ece07d02db"",
      ""number"": 1450409,
      ""totalDifficulty"": ""0x3c656d23029ab0""
    }
```

When we start a sepolia sync with the pre-merge-headers flag:
`$BESU --data-path=/tmp/besu --network=sepolia --sync-mode=SNAP --Xsnapsync-synchronizer-pre-merge-headers-only-enabled=true`

We get this error upon completing the pre-merge header import and switching to the full block import:
```
2025-05-16 08:21:35.950+10:00 | EthScheduler-Services-40 (savePreMergeHeadersStep) | INFO  | SavePreMergeHeadersStep | Pre-merge headers import completed at block 1450408 (0xd07cce9785d39c0dd2409b7d8e69d6bff26a69a0fa5308ac781c63ffe2a37bc1)
2025-05-16 08:21:36.529+10:00 | EthScheduler-Services-43 (importBlock) | INFO  | CalculatedDifficultyValidationRule | Invalid block header: difficulty 0 does not equal expected difficulty 161684159667
2025-05-16 08:21:36.544+10:00 | EthScheduler-Services-43 (importBlock) | INFO  | Pipeline | Unexpected exception in pipeline. Aborting.
Throwable summary: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block 1450409 (0x229f6b18ca1552f1d5146deceb5387333f40dc6275aebee3f2c5c4ece07d02db)
	at: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException.fromInvalidBlock(InvalidBlockException.java:36)
2025-05-16 08:21:36.546+10:00 | EthScheduler-Services-43 (importBlock) | WARN  | PipelineChainDownloader | Invalid block detected (BREACH_OF_PROTOCOL). Disconnecting from sync target. Failed to import block: Invalid block 1450409 (0x229f6b18ca1552f1d5146deceb5387333f40dc6275aebee3f2c5c4ece07d02db)
2025-05-16 08:21:36.549+10:00 | EthScheduler-Services-43 (importBlock) | WARN  | PipelineChainDownloader | Chain download failed. Restarting after short delay.
java.util.concurrent.CompletionException: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block 1450409 (0x229f6b18ca1552f1d5146deceb5387333f40dc6275aebee3f2c5c4ece07d02db)
	at java.base/java.util.concurrent.CompletableFuture.encodeRelay(CompletableFuture.java:368)
	at java.base/java.util.concurrent.CompletableFuture.completeRelay(CompletableFuture.java:377)
	at java.base/java.util.concurrent.CompletableFuture$UniRelay.tryFire(CompletableFuture.java:1097)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
	at org.hyperledger.besu.services.pipeline.Pipeline.abort(Pipeline.java:220)
	at org.hyperledger.besu.services.pipeline.Pipeline.lambda$runWithErrorHandling$3(Pipeline.java:199)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block 1450409 (0x229f6b18ca1552f1d5146deceb5387333f40dc6275aebee3f2c5c4ece07d02db)
	at org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException.fromInvalidBlock(InvalidBlockException.java:36)
	at org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException.fromInvalidBlock(InvalidBlockException.java:30)
	at org.hyperledger.besu.ethereum.eth.sync.fastsync.ImportBlocksStep.accept(ImportBlocksStep.java:82)
	at org.hyperledger.besu.ethereum.eth.sync.fastsync.ImportBlocksStep.accept(ImportBlocksStep.java:40)
	at org.hyperledger.besu.services.pipeline.CompleterStage.run(CompleterStage.java:37)
	at org.hyperledger.besu.services.pipeline.Pipeline.lambda$runWithErrorHandling$3(Pipeline.java:183)
	... 5 more
```

Full log: [sepolia-pre-merge-headers-only-enabled.log](https://github.com/user-attachments/files/20319952/sepolia-pre-merge-headers-only-enabled.log)

Restarting the node allows us to continue!

---

This is what a successful sync looks like, when using the block from https://blog.ethereum.org/2022/08/03/sepolia-post-merge-upgrade
i.e. using this checkpoint
```
    ""checkpoint"": {
      ""hash"": ""0x36fb89fba5b7857cf0ca78b5a9625b4043ff4555dfce9b7bcdcdd758a11eb946"",
      ""number"": 1735371,
      ""totalDifficulty"": ""0x3c656d23029ab0""
    }
```

```
2025-05-20 08:36:27.836+10:00 | EthScheduler-Services-40 (savePreMergeHeadersStep) | INFO  | SavePreMergeHeadersStep | Pre-merge headers import completed at block 1735370 (0x54a798ca96ac940bc30d9d3101157bec402a6c9a1e422f4a8a9de43d6f9bda89)
2025-05-20 08:36:28.081+10:00 | EthScheduler-Services-43 (importBlock) | INFO  | BlockPropagationManager | Block propagation was running, then ttd reached
2025-05-20 08:36:28.649+10:00 | EthScheduler-Services-43 (importBlock) | INFO  | ImportBlocksStep | Block import progress: 1735400 of 8359714 (20%), Peer count: 7
```

---

Any block below 1735371 and above 1450409 (the first PoS block) also breaks.

e.g. the parent of 1735371:

```
    ""checkpoint"": {
      ""hash"": ""0x54a798ca96ac940bc30d9d3101157bec402a6c9a1e422f4a8a9de43d6f9bda89"",
      ""number"": 1735370,
      ""totalDifficulty"": ""0x3c656d23029ab0""
    }
```

---

> difficulty 0 does not equal expected difficulty 161684159667

^ This is the first PoS block, but an interesting observation is that if you try to sync using a block in the ""broken range"", e.g. first PoS block + 1 then you always get this value for difficulty:
> Invalid block header: difficulty 0 does not equal expected difficulty 131072

where 131072 = 0x20000 which is the difficulty set in the sepolia genesis: https://github.com/hyperledger/besu/blob/8e5b1f100a0641c5449f4cbd8acbeb92650c30f2/config/src/main/resources/sepolia.json#L69",storage: storage corruption,CWE-665,Improper Initialization,"The bug report describes a failure that occurs when the Besu client transitions from one synchronization phase ('pre-merge headers import') to another ('full block import'). The specific error, `Invalid block header: difficulty 0 does not equal expected difficulty...`, indicates that a critical value used for block validation is incorrect at the moment of transition. The report further observes that for certain blocks, the system expects a difficulty value from the genesis block, which is clearly incorrect for a block much later in the chain. This points to a failure in correctly setting up the state for the second phase of the operation. This directly aligns with the definition of CWE-665, where a resource (in this case, the synchronization state, including the expected difficulty) is incorrectly initialized, leading to an unexpected state and subsequent failure when it is used. 

CWE-436 (Interpretation Conflict) is not applicable because the issue is internal to a single software product (Besu), not a misinterpretation of state between two different products. 

CWE-670 (Always-Incorrect Control Flow Implementation) is less suitable because the control flow path itself (transitioning from one sync step to the next) is not described as always being incorrect. The failure is conditional on the starting state (the specific checkpoint block), which leads to a data initialization problem within that flow, making Improper Initialization the more precise root cause.",closed,"The history expiry sync process fails to properly validate the difficulty of blocks during the transition from pre-merge to post-merge headers, leading to an invalid block import error.","This bug prevents nodes from successfully syncing to the blockchain, potentially resulting in a loss of consensus and the inability to participate in network activities. Nodes encountering this issue may need to restart to continue syncing, leading to a poor user experience and potential network instability.",3075297450,8649,"May 20, 2025 12:33 AM (GMT+8)","May 28, 2025 1:46 PM (GMT+8)","['bug', 'history']",
besu,Besu mis-estimates identity precompile,https://github.com/hyperledger/besu/issues/8527,Execution,"[pectra.yaml.txt](https://github.com/user-attachments/files/19636879/pectra.yaml.txt) contains a kurtosis enclave config which will demonstrate the problem. Run it with:

```
kurtosis run --enclave testnet github.com/ethpandaops/ethereum-package --args-file ~/Desktop/pectra.yaml.txt
```

Once the enclave is up, this script will reproduce the issue: https://gist.github.com/bshastry/ed5bab1d6a099f864c5c4102d6bcd527

```
====================================================
Testing case 1 with input length: 32 bytes
====================================================
Estimating gas on each client...
Gas estimates:
Geth: 22615
Besu: 21530
Reth: 22615
====================================================
Testing case 2 with input length: 96 bytes
====================================================
Estimating gas on each client...
Gas estimates:
Geth: 25180
Besu: 22560
Reth: 25180
====================================================
Testing case 3 with input length: 128 bytes
====================================================
Estimating gas on each client...
Gas estimates:
Geth: 26432
Besu: 23063
Reth: 26432
====================================================
Testing case 4 with input length: 160 bytes
====================================================
Estimating gas on each client...
Gas estimates:
Geth: 27715
Besu: 23578
Reth: 27715
```
",evm: incorrect gas calculation,CWE-682,Incorrect Calculation,"The bug report describes a scenario where the Besu Ethereum client calculates a gas estimate that is different from, and lower than, the estimates produced by other clients like Geth and Reth for the same operation. The bug's functional symptom is explicitly labeled ""evm: incorrect gas calculation"". This aligns perfectly with CWE-682, which is defined as a product performing a calculation that ""generates incorrect or unintended results that are later used in security-critical decisions or resource management."" Gas calculation is a fundamental form of resource management on the Ethereum blockchain, and an incorrect value can lead to consensus failures, which are security-critical. 

CWE-436 (Interpretation Conflict) is a plausible but less accurate choice. While the issue manifests as a conflict between different client implementations (Product A vs. Product B), the root cause is not a misinterpretation of another client's state, but rather an incorrect implementation of the shared protocol's calculation rules within Besu itself. The conflict is a symptom of the underlying incorrect calculation, making CWE-682 a more direct and fundamental classification of the flaw.

CWE-193 (Off-by-one Error) is definitively incorrect, as the differences between Besu's gas estimates and the correct estimates are large, variable, and not consistently off by a value of one.",closed,"The Besu client is mis-estimating the gas required for identity precompile operations compared to other clients, leading to discrepancies in gas estimates.","This mis-estimation can result in inefficient transaction execution and potentially cause transactions to fail due to insufficient gas, impacting user experience and network performance.",2977823091,8527,"April 7, 2025 7:38 PM (GMT+8)","May 6, 2025 12:12 AM (GMT+8)","['bug', 'P2']",
besu,Regression in txpool dump and restore on v25.3.0,https://github.com/hyperledger/besu/issues/8449,Consensus,"### Steps to Reproduce
1. Run Besu on Ethereum mainnet with `--tx-pool=layered --tx-pool-enable-save-restore=true` with no txpool dump file present
2. Leave Besu running for about 5 minutes to saturate the transaction pool and quit Besu
3. Run Besu again with the same arguments

**Expected behavior:** See ""Added X transactions of Y loaded from file Z, before operation was cancelled"" reported within the logs

**Actual behavior:** An non-fatal error is reported as originating from the component TransactionPool ""Error while restoring transaction pool from disk"" with a stacktrace

**Frequency:** Almost every single restart of Besu on Ethereum mainnet since updating to v23.5.0

### Logs
```
2025-03-21 04:32:45.062+00:00 | main | INFO  | NetworkRunner | Supported capabilities: [eth/63, eth/64, eth/65, eth/66, eth/67, eth/68], [snap/1]
2025-03-21 04:32:45.062+00:00 | main | INFO  | DefaultSynchronizer | Starting synchronizer.
2025-03-21 04:32:45.073+00:00 | main | INFO  | TransactionPoolFactory | Enabling transaction handling following initial sync
2025-03-21 04:32:45.084+00:00 | ForkJoinPool.commonPool-worker-7 | INFO  | TransactionPool | Loading transaction pool content from file /var/lib/besu/txpool.dump
2025-03-21 04:32:45.085+00:00 | main | INFO  | DefaultSynchronizer | Stopping block propagation.
2025-03-21 04:32:45.085+00:00 | main | INFO  | DefaultSynchronizer | Stopping the pruner.
2025-03-21 04:32:45.086+00:00 | main | INFO  | Runner | Ethereum main loop is up.
2025-03-21 04:32:47.803+00:00 | ForkJoinPool.commonPool-worker-7 | ERROR | TransactionPool | Error while restoring transaction pool from disk
java.util.concurrent.CompletionException: org.hyperledger.besu.ethereum.rlp.RLPException: Cannot read a arbitrary precision scalar, current item is a list (at bytes 4-1348: fa06067a[f9053d01...b4b9b664]fa06000c...)
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:315)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:320)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1807)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1796)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
Caused by: org.hyperledger.besu.ethereum.rlp.RLPException: Cannot read a arbitrary precision scalar, current item is a list (at bytes 4-1348: fa06067a[f9053d01...b4b9b664]fa06000c...)
	at org.hyperledger.besu.ethereum.rlp.AbstractRLPInput.error(AbstractRLPInput.java:205)
	at org.hyperledger.besu.ethereum.rlp.AbstractRLPInput.checkElt(AbstractRLPInput.java:250)
	at org.hyperledger.besu.ethereum.rlp.AbstractRLPInput.checkScalar(AbstractRLPInput.java:263)
	at org.hyperledger.besu.ethereum.rlp.AbstractRLPInput.readBigIntegerScalar(AbstractRLPInput.java:337)
	at org.hyperledger.besu.ethereum.rlp.BytesValueRLPInput.readBigIntegerScalar(BytesValueRLPInput.java:24)
	at org.hyperledger.besu.ethereum.core.encoding.BlobTransactionDecoder.readTransactionPayloadInner(BlobTransactionDecoder.java:70)
	at org.hyperledger.besu.ethereum.core.encoding.BlobTransactionDecoder.readTransactionPayload(BlobTransactionDecoder.java:53)
	at org.hyperledger.besu.ethereum.core.encoding.BlobTransactionDecoder.decode(BlobTransactionDecoder.java:47)
	at org.hyperledger.besu.ethereum.core.encoding.TransactionDecoder.decodeTypedTransaction(TransactionDecoder.java:102)
	at org.hyperledger.besu.ethereum.core.encoding.TransactionDecoder.decodeTypedTransaction(TransactionDecoder.java:82)
	at org.hyperledger.besu.ethereum.core.encoding.TransactionDecoder.decodeRLP(TransactionDecoder.java:60)
	at org.hyperledger.besu.ethereum.core.Transaction.readFrom(Transaction.java:140)
	at org.hyperledger.besu.ethereum.core.Transaction.readFrom(Transaction.java:136)
	at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool$SaveRestoreManager.lambda$executeLoadFromDisk$6(TransactionPool.java:883)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.WhileOps$1$1.accept(WhileOps.java:99)
	at java.base/java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1950)
	at java.base/java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:129)
	at java.base/java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:527)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:513)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)
	at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool$SaveRestoreManager.executeLoadFromDisk(TransactionPool.java:890)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	... 6 more
```

### Versions (Add all that apply)
* Software version: `besu/v25.3.0/linux-x86_64/openjdk-java-21` (Docker image)
* Java version:
```
openjdk version ""21.0.6"" 2025-01-21
OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-124.04.1)
OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-124.04.1, mixed mode, sharing)
```
* OS Name & Version:
```
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=24.04
DISTRIB_CODENAME=noble
DISTRIB_DESCRIPTION=""Ubuntu 24.04.1 LTS""
PRETTY_NAME=""Ubuntu 24.04.1 LTS""
NAME=""Ubuntu""
VERSION_ID=""24.04""
VERSION=""24.04.1 LTS (Noble Numbat)""
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo
```
* Kernel Version: 
```
Linux [redacted] 6.13.7-arch1-1 #1 SMP PREEMPT_DYNAMIC Thu, 13 Mar 2025 18:12:00 +0000 x86_64 x86_64 x86_64 GNU/Linux
```
(Arch Linux as Podman container host)
* Virtual Machine software & version: `N/A`
* Docker Version:
```
Client:       Podman Engine
Version:      5.4.1
API Version:  5.4.1
Go Version:   go1.24.1
Git Commit:   b79bc8afe796cba51dd906270a7e1056ccdfcf9e
Built:        Wed Mar 12 07:07:00 2025
OS/Arch:      linux/amd64
```
* Cloud VM, type, size: `N/A / Bare metal`
* Consensus Client & Version if using Proof of Stake: Teku 25.3.0

### Additional Information
My best guess from poking around, is that this was introduced in [74a1d8a1ea7f... (Support pending transaction score when saving and restoring txpool (#8363))](https://github.com/hyperledger/besu/commit/74a1d8a1ea7f6cf29fee0ee60b260160f0c17473).

This PR attempts to let `org.hyperledger.besu.ethereum.eth.transactions.TransactionPool` make use of the [POOLED_TRANSACTION encoding context when saving the dump file under executeSaveToDisk()](https://github.com/hyperledger/besu/blob/74a1d8a1ea7f6cf29fee0ee60b260160f0c17473/ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/transactions/TransactionPool.java#L829). While decoding is still being performed under executeLoadFromDisk() through the `org.hyperledger.besu.ethereum.core.Transaction.readFrom()` wrapper, which [assumes a BLOCK_BODY context](https://github.com/hyperledger/besu/blob/2412586d06c2c0d1424fbfacbbababa62f2a5a74/ethereum/core/src/main/java/org/hyperledger/besu/ethereum/core/Transaction.java#L140).

Unrelated, but TransactionPool.executeLoadFromDisk() appears to report the wrong error message [when throwing an IOException](https://github.com/hyperledger/besu/blob/74a1d8a1ea7f6cf29fee0ee60b260160f0c17473/ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/transactions/TransactionPool.java#L915).
",storage: storage persistence failure,CWE-704,Incorrect Type Conversion or Cast,"The bug report describes a failure during the process of restoring a transaction pool from a file. The root cause, as identified in the report's analysis, is a mismatch between the data serialization and deserialization logic. The data is saved to disk using a `POOLED_TRANSACTION` encoding context, but it is read back using a `BLOCK_BODY` context. This discrepancy causes the deserializer to misinterpret the data structure, as evidenced by the `RLPException: Cannot read a arbitrary precision scalar, current item is a list`. The program expects a specific data type (scalar) but encounters a different one (list) in the byte stream. This is a direct example of an incorrect conversion of a data structure from its on-disk representation to the in-memory representation expected by the mismatched decoding logic. 

- CWE-704 (Incorrect Type Conversion or Cast) is the most accurate choice. The definition, 'The product does not correctly convert an object, resource, or structure from one type to a different type,' perfectly describes the situation where data serialized with one structural context is deserialized with another, leading to a type mismatch error during the conversion from bytes to objects.

- CWE-502 (Deserialization of Untrusted Data) is less suitable. The data being deserialized is a file created by the application itself in a previous session. The issue is not about the trustworthiness of the data source but an internal logic flaw in the application's save/restore mechanism.

- CWE-20 (Improper Input Validation) is too general. While one could argue the application fails to validate the input file's format, the core problem is more specific. The error is not a lack of validation, but a fundamental bug where the program attempts to perform an incorrect structural conversion. The exception is thrown precisely because a type check *within* the deserialization process fails, highlighting the type conversion issue.",closed,"The transaction pool is attempting to decode a transaction dump file using an incorrect context (BLOCK_BODY) instead of the appropriate context (POOLED_TRANSACTION), leading to a failure in reading the transaction data.","This bug prevents the proper restoration of the transaction pool from disk, potentially causing the node to lose transactions and disrupt its operational integrity, leading to inconsistencies in transaction processing.",2940200846,8449,"March 22, 2025 7:58 AM (GMT+8)","March 28, 2025 5:35 PM (GMT+8)","['bug', 'P3']",
besu,Cannot convert non-validator to validator on v25.2.2,https://github.com/hyperledger/besu/issues/8425,Consensus,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->

### Steps to Reproduce
I have a besu network with 1 validator and 1 non-validator running v25.2.2. When I send a vote to make the non-validator a validator, I see the following log:

```                                                                                                                                                                                        
2025-03-14 12:00:00.021+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftBesuControllerBuilder | Produced empty block #7 / 0 tx / 0 pending / 0 (0.0%) gas / (0xd9041133b8e7452f1b5f96290b6b632e8cd28f62b2090b979064b4ce2a185795)
2025-03-14 12:00:02.001+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftBlockHeightManager | Validator list change. Previous chain height 7: [0xfc17fcb517bcf04ddf56da7ecda57ebcdfc47212]. Current chain height 8: [0xed0e183c7611650a35ad1f2320f80960802fd044, 0xfc17fcb517bcf04ddf56da7ecda57ebcdfc47212].
2025-03-14 12:03:17.003+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | RoundTimer | Moved to round 2 which will expire in 260 seconds
```

And after this point, the network stops producing blocks, and halts:

```
2025-03-14 12:03:17.003+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | RoundTimer | Moved to round 2 which will expire in 260 seconds
2025-03-14 12:07:37.004+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | RoundTimer | Moved to round 3 which will expire in 520 seconds                                                                               

```

This works with v25.2.1. 

In v25.2.2, I can add another node as a validator successfully but converting a non-validator to a validator when there is only 1 validator in the network is not working. 

**Expected behavior:** Network to successfully convert the non-validator to validator.

**Actual behavior:** Stops producing blocks, halts entirely.

**Frequency:** Always

### Logs
Please post relevant logs from Besu (and the consensus client, if running proof of stake) from before and after the issue.

Pasted above.

### Versions (Add all that apply)
* Software version: 25.2.2
* Java version: [`java -version`]
* OS Name & Version: [`cat /etc/*release`]
* Kernel Version: [`uname -a`]
* Virtual Machine software & version: [`vmware -v`]
* Docker Version: [`docker version`]
* Cloud VM, type, size: [Amazon Web Services I3-large]
* Consensus Client & Version if using Proof of Stake: [e.g. Teku, Lighthouse, Prysm, Nimbus, Lodestar]

### Smart contract information (If you're reporting an issue arising from deploying or calling a smart contract, please supply related information)
* Solidity version [`solc --version`]
* Repo with minimal set of deployable/reproducible contract code - please provide a link
* Please include specifics on how you are deploying/calling the contract
* Have you reproduced the issue on other eth clients

N/A

### Additional Information (Add any of the following or anything else that may be relevant)
* Besu setup info - genesis file, config options
* System info - memory, CPU
",consensus: consensus liveness failure,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report describes a consensus failure that occurs only under a very specific, exceptional condition: converting a non-validator node into a validator when the network consists of only a single validator. The system behaves as expected in other scenarios, such as adding a new node as a validator or when the validator set is larger. The network halting indicates a failure to handle the state transition resulting from this specific edge case. This aligns perfectly with CWE-754, which describes a failure to properly check for or handle 'unusual or exceptional conditions.' The condition of promoting the second-ever validator from an existing non-validator node is precisely such an unusual condition that was not correctly handled, leading to a liveness failure.

CWE-665 (Improper Initialization) is less fitting. While the consensus mechanism enters a broken state, the root cause is not a general initialization error but a failure in the logic that handles a specific runtime event. The resources were likely initialized correctly at startup, but the update logic failed.

CWE-436 (Interpretation Conflict) is not applicable because the issue is internal to a single software product (Besu) and its consensus algorithm. It does not involve a misinterpretation of state or inputs between two different products.",closed,"The bug is caused by the inability of the consensus mechanism to handle the conversion of a non-validator to a validator when there is only one validator in the network, leading to a failure in block production.","The consequence of this bug is that the network halts and stops producing blocks, which can result in a loss of consensus and disrupt the functionality of the blockchain, potentially leading to data inconsistencies and unavailability of services relying on the network.",2920051040,8425,"March 14, 2025 12:07 PM (GMT+8)","March 19, 2025 11:02 PM (GMT+8)","['bug', 'non mainnet (private networks)', 'QBFT']",
besu,Snap sync stalled,https://github.com/hyperledger/besu/issues/8393,Consensus,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->

Besu sync is stalled and also return syncing to CL (Teku) on Holesky

From the log below, the node seems to be completing snap sync

Blockchain sync report was 99% before the restart
```
{""@timestamp"":""2025-03-06T03:30:52,811"",""level"":""INFO"",""thread"":""EthScheduler-Services-42 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 3359400 of 3419675 (98%), Peer count: 16"",""throwable"":""""}
{""@timestamp"":""2025-03-06T03:32:15,663"",""level"":""INFO"",""thread"":""EthScheduler-Services-42 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 3394000 of 3419675 (99%), Peer count: 17"",""throwable"":""""}
{""@timestamp"":""2025-03-06T03:33:22,418"",""level"":""INFO"",""thread"":""EthScheduler-Services-42 (importBlock)"",""class"":""PeerDiscoveryAgent"",""message"":""Writing node record to disk. NodeRecord{seq=3, publicKey=0x03afc03bbd893de8c178affe825318dab41a1ba2c43925ce79840893bdf7c1f50d, udpAddress=Optional[/52.224.121.81:30303], tcpAddress=Optional[/52.224.121.81:30303], udp6Address=Optional.empty, tcp6Address=Optional.empty, asBase64=-Je4QAUMIp0Ib838r0MWg_YxYdkZ-Q7YSE2Nnuofu2HxPGfqVSV6ZgmuFhcDt50BAefJc9mqSzoKIROgFsfTAU-H5KgDg2V0aMfGhN-9m-2AgmlkgnY0gmlwhDTgeVGJc2VjcDI1NmsxoQOvwDu9iT3owXiv_oJTGNq0GhuixDklznmECJO998H1DYN0Y3CCdl-DdWRwgnZf, nodeId=0xa27273071938d18b2e7b10fa6696443fc34da88b9ce609934873dc553f444b18, customFields={tcp=30303, udp=30303, ip=0x34e07951, eth=[[0xdfbd9bed, 0x]], id=V4, secp256k1=0x03afc03bbd893de8c178affe825318dab41a1ba2c43925ce79840893bdf7c1f50d}}"",""throwable"":""""}
```

after the restart

```
{""@timestamp"":""2025-03-06T14:20:36,201"",""level"":""INFO"",""thread"":""main"",""class"":""SnapSyncDownloader"",""message"":""Starting pivot-based sync"",""throwable"":""""}
{""@timestamp"":""2025-03-06T14:20:36,204"",""level"":""INFO"",""thread"":""main"",""class"":""SnapWorldStateDownloader"",""message"":""Downloading world state from peers for pivot block 3419675 (0x7593f7258005f4f18e306657f96ad9ecdd314a80098262eec0129368917807ed). State root 0xae804c40aad4486c7a4ef4c6363781636bc47195657270706c781458d11a3e2b pending requests 0"",""throwable"":""""}
```


[besu.log](https://github.com/user-attachments/files/19110129/besu.log)

@matkt helped with the investigation, and this is due to the fact that Holesky is not finalizing, and snap sync is currently using safe block for the sync, but it is too old to be used by snap sync, so a possible solution is to use head block.",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a 'Snap sync stalled' and a 'consensus liveness failure'. The investigation reveals the cause is that the synchronization process is waiting for a 'safe block' which is too old to be used, a situation arising because the network chain ('Holesky') is not finalizing. This means the sync process is stuck waiting for a condition that cannot be met under the current circumstances. This behavior directly aligns with the definition of CWE-835, 'Loop with Unreachable Exit Condition ('Infinite Loop')', as the process is effectively in a loop (waiting for a suitable block) with an exit condition that has become unreachable. CWE-755, 'Improper Handling of Exceptional Conditions', is a possible candidate since the non-finalizing chain is an exceptional condition. However, CWE-835 is more specific to the direct technical flaw—the stall itself—which is a form of an infinite loop. CWE-400, 'Uncontrolled Resource Consumption', is incorrect because the report describes a lack of progress (a stall), not an exhaustion of resources like memory or CPU.",closed,"The snap sync process is stalled because it relies on a safe block that is too old for synchronization, as Holesky is not finalizing.","The inability to complete snap sync can lead to nodes not being able to sync properly, potentially causing delays in block validation and affecting the overall network performance.",2900582617,8393,"March 6, 2025 2:32 PM (GMT+8)","March 11, 2025 6:56 PM (GMT+8)",['bug'],
besu,BFT transitions with a change of mining beneficiary don't work when `shanghaiTime` is enabled,https://github.com/hyperledger/besu/issues/8384,Consensus,"### Steps to Reproduce
Create a QBFT chain where the genesis contains the following:

```
...
""shanghaiTime"" : 0,
    ""zeroBaseFee"": true,
    ""qbft"" : {
      ""blockperiodseconds"" : 2,
      ""epochlength"" : 30000,
      ""requesttimeoutseconds"" : 4,
      ""miningbeneficiary"": ""0x5c9437de876531c73c9618d13872f7508869f254""
    },
    ""transitions"": {
      ""qbft"": [
        {
          ""block"": 40,
          ""miningbeneficiary"": ""0x5c9437de876531c73c9618d13872f7508869f255"" <<-- different address (note last char)
        }
      ]
    }
...
```

The first block to contain a transaction errors with:


```
 Invalid block 4 (0x7a5acedf9779e2b1251aee407473b8009067e883696432936e52c310dc68e499): state root mismatch (expected=0x99cb57b1c3e70998cc4289ed33e48ea4cc803c3193ec7251cd3b02b53b314827, actual=0x8acc4158bd24376fe17cdb23a831569ed75ebff6c62e4892b3f2e7b183160ccd)
2025-03-05 10:17:14.016+00:00 | BftProcessorExecutor-QBFT-0 | WARN  | MainnetBlockBodyValidator | Invalid block RLP : 0xf9043cf90239a0ec7d487572689f6524e7cec16fd187ebfb1709c65ee61e35f50ba59fe3c5e864a01dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347945c9437de876531c73c9618d13872f7508869f253a099cb57b1c3e70998cc4289ed33e48ea4cc803c3193ec7251cd3b02b53b314827a02b91e6c97adf0dd9b554d76d7005ae6871c3cd71f095538310d4f06bf9197e8da00863a3cc90a513288b79e9697b5b99623e815fcf1bb999c8a5d7834a762e26dab90100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000104871fffffffffffff830219a18467c824aab83cf83aa00000000000000000000000000000000000000000000000000000000000000000d5945c9437de876531c73c9618d13872f7508869f253c080c0a063746963616c2062797a616e74696e65206661756c7420746f6c6572616e636588000000000000000080f901fcf901f980821388830219a18080b901a7608060405234801561001057600080fd5b50610187806100206000396000f3fe608060405234801561001057600080fd5b50600436106100365760003560e01c806360fe47b11461003b5780636d4ce63c14610057575b600080fd5b610055600480360381019061005091906100fa565b610075565b005b61005f6100b6565b60405161006c9190610136565b60405180910390f35b806000819055507f93fe6d397c74fdf1402a8b72e47b68512f0510d7b98a4bc4cbdf6ac7108b3c59816040516100ab9190610136565b60405180910390a150565b60008054905090565b600080fd5b6000819050919050565b6100d7816100c4565b81146100e257600080fd5b50565b6000813590506100f4816100ce565b92915050565b6000602082840312156101105761010f6100bf565b5b600061011e848285016100e5565b91505092915050565b610130816100c4565b82525050565b600060208201905061014b6000830184610127565b9291505056fea26469706673582212203e7d850f923a80956c5c40f8424ff424cb368c87df3c35627be1efe56c05b50664736f6c63430008130033820a96a0c625ee21cf143cd726a358a5fe5dd8defd0e6a078d6c2ba7151a60135e5f8f14a04387aab381bb6958fb8b837647e33d6653f15a1dc03fdb29f514e6cd6f35f5d8c0
2025-03-05 10:17:14.023+00:00 | BftProcessorExecutor-QBFT-0 | WARN  | MainnetBlockBodyValidator | Transaction receipt found in the invalid block TransactionReceipt{stateRoot=null, cumulativeGasUsed=137633, logs=[], bloomFilter=0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, status=1, transactionReceiptType=STATUS}
```",consensus: consensus liveness failure,CWE-682,Incorrect Calculation,"The bug report describes a ""state root mismatch"" error. This error explicitly indicates that the software's calculation of the blockchain's state resulted in a different value (`actual`) than what was expected by the consensus protocol (`expected`). This failure occurs under a specific set of conditions: a scheduled change to the `miningbeneficiary` address while the `shanghaiTime` feature is active. The state root is a critical value derived from complex calculations over the entire system state, and its correctness is fundamental to the security and operation of the blockchain. Therefore, the root cause is an incorrect calculation. CWE-682 (Incorrect Calculation) perfectly describes this scenario, as the product performs a calculation that generates an incorrect result, which is then used in a security-critical decision (block validation and consensus). CWE-665 (Improper Initialization) is less suitable because the issue arises from a state *transition* at a specific block, not from the initial setup. CWE-703 (Improper Check or Handling of Exceptional Conditions) is also a poor fit because a scheduled configuration change is an intended operational path, not a rare, unexpected exceptional condition that requires special handling.",closed,"The issue arises from the incorrect handling of the mining beneficiary transition in the QBFT consensus mechanism when the `shanghaiTime` is enabled, leading to a state root mismatch.","This bug can result in invalid blocks being produced and accepted by the network, potentially leading to chain splits, loss of consensus, and disruption of normal operations in the blockchain.",2896891500,8384,"March 5, 2025 10:18 AM (GMT+8)","March 14, 2025 6:10 PM (GMT+8)","['bug', 'P3', 'non mainnet (private networks)', 'QBFT']",
besu,Passing --rpc-http-enabled=true via command line does not enable rpc for specific options combination,https://github.com/hyperledger/besu/issues/8359,API,"When a specific combination of options passed via command line including `--rpc-http-enabled=true` does not enable the RPC end point and logs a WARN message `--rpc-http-enabled` has not been set in the command line. However same config included in `config.toml` file issue does not occur. Only specific combination of command line options are set in the bug report to help reproduce the issue. Used the latest docker image.

### Steps to Reproduce
1. Start besu using command and watch the starting logs. WARN log appears `| main | WARN  | Besu | --rpc-http-host, --rpc-http-port and --rpc-http-cors-origins has been ignored because --rpc-http-enabled was not defined on the command line.`
```sh
docker run hyperledger/besu:25.2.0 \
  --rpc-http-enabled=true \
  --rpc-http-host=0.0.0.0 \
  --rpc-http-port=8545 \
  --tx-pool-enable-save-restore=true \
  --tx-pool-disable-locals=true \
  --tx-pool-no-local-priority=true \
  --rpc-http-cors-origins=""*""
```
2. Removing any one of the options `--tx-pool-enable-save-restore` or `--tx-pool-disable-locals` or `--tx-pool-no-local-priority` or `--rpc-http-cors-origins` won't log the WARN message.
 
3. Besu should not report that `--rpc-http-enabled` was not defined on the command line` when the option is defined in the command line.

**Actual behavior:**
When option `--rpc-http-enabled` is defined in the command line a WARN message indicates `--rpc-http-enabled was not defined on the command line`


**Frequency:** Everytime

### Logs
```
2025-02-27 02:11:41.708+00:00 | main | INFO  | Besu | Starting Besu
2025-02-27 02:11:41.887+00:00 | main | WARN  | Besu | --rpc-http-host, --rpc-http-port and --rpc-http-cors-origins has been ignored because --rpc-http-enabled was not defined on the command line.
2025-02-27 02:11:41.888+00:00 | main | WARN  | Besu | --rpc-ws-host has been ignored because --rpc-ws-enabled was not defined on the command line.
2025-02-27 02:11:41.891+00:00 | main | WARN  | Besu | --graphql-http-host has been ignored because --graphql-http-enabled was not defined on the command line.
2025-02-27 02:11:41.944+00:00 | main | WARN  | Besu | --rpc-http-host, --rpc-http-port and --rpc-http-cors-origins has been ignored because --rpc-http-enabled was not defined on the command line.
2025-02-27 02:11:41.944+00:00 | main | WARN  | Besu | Engine API authentication enabled without key file. Expect ephemeral jwt.hex file in datadir
2025-02-27 02:11:41.947+00:00 | main | INFO  | Besu | Connecting to 0 static nodes.
```

### Versions (Add all that apply)
* Software version: [`25.2.0`]
* Java version: [`openjdk-java-21`]
* Docker Version: [`27.4.0`]


### Additional Information (Add any of the following or anything else that may be relevant)
Attached [scripts.zip](https://github.com/user-attachments/files/19000631/scripts.zip) helps to reproduced the issue ",api: api unavailability,CWE-665,Improper Initialization,"The bug report describes a scenario where the application, Besu, fails to correctly process its startup configuration from command-line arguments. Specifically, the `--rpc-http-enabled=true` flag is ignored under a specific combination of other valid flags, leading the application to believe the flag was not set. This results in the RPC service, which is a key resource, not being enabled. This directly maps to CWE-665 (Improper Initialization), as the application incorrectly initializes the state of the RPC service based on its configuration inputs, leaving the resource in an unexpected and non-functional state (disabled). 

CWE-436 (Interpretation Conflict) is not suitable because the issue is an internal logic flaw within a single application (Besu) concerning how it parses its own command-line arguments. It is not a conflict between two different products interpreting each other's state.

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is also less accurate. The trigger is a specific combination of valid, standard command-line options, not an unusual or exceptional condition like a system error or malformed data that requires special handling. The failure lies in the normal initialization logic for a specific, albeit complex, configuration.",closed,"The command-line parser incorrectly processes the combination of certain options, leading to a misinterpretation that `--rpc-http-enabled` was not set even when it is specified.","This bug can prevent the RPC endpoint from being enabled when intended, potentially affecting application functionality and user access to the RPC services.",2883230908,8359,"February 27, 2025 2:15 AM (GMT+8)","March 6, 2025 1:09 AM (GMT+8)","['bug', 'P2', 'snack']",
besu,eth_getTransactionCount() can cause `java.util.NoSuchElementException`,https://github.com/hyperledger/besu/issues/8356,API,"### Steps to Reproduce
I hit this by running a basic hardhat app looping round doing simple storage `set()` calls at ~ 10TPS to a QBFT chain. Importantly hardhat was requesting the next nonce for every TX, which was frequent enough to eventually hit this race condition:

```
2025-02-26 15:56:43.046+00:00 | vert.x-worker-thread-8 | ERROR | BaseJsonRpcProcessor | Error processing method: eth_getTransactionCount [""0x00e1ed642904f2e8af9108a4383c95e24532e0b8"",""pending""]
java.util.NoSuchElementException
        at java.base/java.util.TreeMap.key(TreeMap.java:1637)
        at java.base/java.util.TreeMap.lastKey(TreeMap.java:309)
        at org.hyperledger.besu.ethereum.eth.transactions.sorter.PendingTransactionsForSender.maybeNextNonce(PendingTransactionsForSender.java:99)
        at org.hyperledger.besu.ethereum.eth.transactions.sorter.AbstractPendingTransactionsSorter.getNextNonceForSender(AbstractPendingTransactionsSorter.java:419)
        at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool.getNextNonceForSender(TransactionPool.java:569)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetTransactionCount.pendingResult(EthGetTransactionCount.java:74)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.handleParamTypes(AbstractBlockParameterOrBlockHashMethod.java:100)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.response(AbstractBlockParameterOrBlockHashMethod.java:151)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:46)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TracedJsonRpcProcessor.process(TracedJsonRpcProcessor.java:54)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TimedJsonRpcProcessor.process(TimedJsonRpcProcessor.java:45)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92)
        at org.hyperledger.besu.ethereum.api.handlers.AbstractJsonRpcExecutor.executeRequest(AbstractJsonRpcExecutor.java:87)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcObjectExecutor.execute(JsonRpcObjectExecutor.java:57)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$1(JsonRpcExecutorHandler.java:73)
        at java.base/java.util.Optional.ifPresentOrElse(Optional.java:196)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$3(JsonRpcExecutorHandler.java:70)
        at io.vertx.ext.web.impl.BlockingHandlerDecorator.lambda$handle$0(BlockingHandlerDecorator.java:48)
        at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191)
        at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:270)
        at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base/java.lang.Thread.run(Thread.java:1595)
```

**Frequency:**
Very rare - I've never seen it before

### Logs
See above

### Versions (Add all that apply)
* Software version: `25.1.0`",api: api unavailability,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report explicitly identifies the issue as a ""race condition"" that occurs under high load in a multi-threaded environment. The stack trace shows a `java.util.NoSuchElementException` when accessing a `TreeMap` (`lastKey()`), which is part of the shared transaction pool. This indicates that one thread is attempting to access the map while another thread has concurrently modified it (e.g., by removing the last element), leaving it in an unexpected state. This scenario perfectly matches the definition of CWE-362, which describes a ""concurrent code sequence"" accessing a ""shared resource"" where a ""timing window exists in which the shared resource can be modified by another code sequence."" CWE-662 is too general, as it describes the broad category of improper synchronization, while the report points to the specific outcome of a race condition. CWE-367 is a specific type of race condition (TOCTOU), and while plausible, it assumes a specific check-then-use pattern that is not explicitly confirmed in the report. CWE-362 is the most accurate classification as it directly describes the confirmed behavior without making assumptions.",closed,"The bug arises from a race condition when multiple requests for the next nonce are made simultaneously, causing the system to attempt to access a non-existent key in a TreeMap, resulting in a NoSuchElementException.","This bug can lead to application crashes when the eth_getTransactionCount method is invoked under high transaction rates, potentially disrupting service and user experience.",2882158371,8356,"February 26, 2025 4:26 PM (GMT+8)","March 4, 2025 6:46 PM (GMT+8)",['bug'],
besu,Restarted BFT validators can fail to agree on new blocks under certain conditions,https://github.com/hyperledger/besu/issues/8307,Consensus,"I believe this issue only occurs if sufficient BFT validators are restarted with a new `data` directory and they need to resync with existing node(s) before continuing BFT block production. Specific examples would be:

1. A 2 node BFT chain, where a node is restarted with a clean data dir
2. A 4 node BFT chain, where 2 nodes are restarted with clean data dirs
3. ...any other case where a chain does not have `quorum` validators with current `data` dirs.

Another scenario would include 1 validator node that has been producing blocks on its own and then votes in a new validator, where the new validator has a fresh `data` dir. This is another way of reaching `1` above.

Voting in a new validator that has already been following the chain should not be impacted by the issue.

### Steps to Reproduce

- Create a 2-validator QBFT chain (IBFT could also be used)
- Let it mine a few 100 blocks
- Stop node 2, delete its data dir, then restart it

**Expected behavior:**

It syncs with node 1, then continues to agree on new rounds and propose new blocks on its turn

**Actual behavior:**

It starts up but then fails to move its QBFT round timer on, so no new blocks are produced

**Frequency:**

It's a little unclear if there is some timing involved, but for 2-node chains it seems to fail reliably.

There are cases where it is not an issue, which perhaps explains why it's not been seen by many users:

1. A single node (e.g. in a dev environment) doesn't suffer with this because it doesn't go through a sync process if its the only validator
2. A chain with enough validators that `f >= 1` isn't affected if only 1 validator has its data dir deleted and re-syncs, because other validators propose a new block without it. This ""un-sticks"" the restarted node and everything proceeds as expected
3. If a node is restarted but its data dir isn't cleared it doesn't hit the issue

### Versions (Add all that apply)
* Software version: `v25.1.0`",consensus: consensus liveness failure,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report describes a scenario where the blockchain consensus mechanism halts, and no new blocks are produced. This occurs when one or more validators are restarted from a 'clean' state and must resynchronize. The key symptom is that a restarted validator 'fails to move its QBFT round timer on', indicating it is stuck in a specific state. The other validators, in turn, are waiting for the restarted validator to participate in the consensus round to achieve a quorum. This creates a circular waiting condition among the distributed validator nodes, where the system as a whole cannot make progress. This is a classic example of a deadlock in a distributed system. The bug summary even notes 'consensus liveness failure', which is a direct consequence of a deadlock. While CWE-665 (Improper Initialization) is a plausible root cause (the resync process likely initializes the node into a bad state), CWE-833 (Deadlock) more accurately describes the observable, critical failure mode of the system. CWE-362 (Race Condition) is less likely, as the bug appears to be deterministic under the specified conditions rather than dependent on unpredictable timing.",closed,"The issue arises when a BFT validator that has been restarted with a clean data directory fails to synchronize with existing nodes before participating in consensus, leading to a failure to agree on new blocks.","This bug can lead to a halt in block production in scenarios where there are insufficient validators with synchronized data, potentially resulting in network downtime or inability to process transactions until the issue is resolved.",2854124621,8307,"February 14, 2025 4:04 PM (GMT+8)","March 12, 2025 6:16 PM (GMT+8)","['bug', 'P3', 'QBFT']",
besu,Invalid Block Not Properly Tracked in Consensus Bugs,https://github.com/hyperledger/besu/issues/8204,Storage,"When a consensus bug occurs, the invalid block is not properly tracked. Although the block is added to the BadBlockManager, the instance used for at the block processing part is not the same instance used for the RPC tracing functionality.

As a result, when calling tracing APIs such as debug_standardTraceBadBlockToFile, the block is not found, preventing investigation.

To fix this issue, both components (the block processing and the RPC tracing) should share the same BadBlockManager instance

Also, it appears that adding a block to the BadBlockManager does not always happen. For instance, in the case of a state root mismatch, the execution goes through this part of the code without adding the block:
 [MainnetBlockValidator.java#L221](https://github.com/hyperledger/besu/blob/main/ethereum/core/src/main/java/org/hyperledger/besu/ethereum/MainnetBlockValidator.java#L221)

We should investigate why the decision was made not to add the block in this case and determine how to properly handle state root mismatches so that they are also tracked as bad blocks.

**Expected behavior:** [What you expect to happen]

- Ensure that the BadBlockManager instance used for processing blocks is the same as the one used for RPC tracing.
- Investigate why state root mismatches are not added to the BadBlockManager and determine how to fix this behavior.


",api: incorrect api output,CWE-778,Insufficient Logging,"The bug report describes two distinct issues that lead to the same outcome: an invalid block, which is a security-critical event in a consensus system, cannot be investigated. The first issue is that two different instances of `BadBlockManager` are used, preventing the tracing component from accessing blocks recorded by the processing component. The second issue is that certain invalid blocks (e.g., due to a 'state root mismatch') are not added to the `BadBlockManager` at all. The core problem, encompassing both issues, is that the system fails to properly record these critical events for later analysis. This aligns perfectly with the definition of CWE-778, 'Insufficient Logging', which states 'the product either does not record the event or omits important details about the event when logging it.' The `BadBlockManager` serves as a specialized log or record for this purpose, and the failure to use it correctly prevents investigation, which is the primary consequence of insufficient logging.

CWE-665 ('Improper Initialization') is a good fit for the first issue (using two separate instances) but does not cover the second issue (the logic error where a block is not added).

CWE-755 ('Improper Handling of Exceptional Conditions') is a good fit for the second issue (failing to record a block on a 'state root mismatch' error) but is less descriptive of the initialization problem.

CWE-778 is the most accurate choice because it describes the overall functional weakness and consequence of both underlying bugs: the failure to record a critical event.",closed,"The invalid blocks are not tracked correctly in the consensus process due to the use of different instances of BadBlockManager for block processing and RPC tracing, leading to inconsistencies in block validation and tracking.","This bug prevents proper investigation of consensus failures by making it impossible to trace invalid blocks through the RPC APIs, which could hinder debugging and resolution of critical issues in the blockchain network.",2820366530,8204,"January 30, 2025 9:52 AM (GMT+8)","April 3, 2025 4:42 AM (GMT+8)","['bug', 'P2']",
besu,EIP-2935 Hive Failure,https://github.com/hyperledger/besu/issues/8202,Execution,"Failure is an edge case if the system contract doesn't exist by Pectra (which it will in reality), so this shouldn't block devnet-6/testnets

In https://eips.ethereum.org/EIPS/eip-2935

We don't do this...
> if no code exists at HISTORY_STORAGE_ADDRESS, the call must fail silently

We always create the account, https://github.com/hyperledger/besu/blob/ccd35826303fe38d4bba4c517ea4b0b830ecebdc/ethereum/core/src/main/java/org/hyperledger/besu/ethereum/mainnet/blockhash/PragueBlockHashProcessor.java#L71
",evm: execution fault,CWE-436,Interpretation Conflict,"The bug report describes a situation where the Hyperledger Besu client's implementation of EIP-2935 deviates from the official specification. Specifically, the EIP dictates that a call must 'fail silently' if a certain system contract doesn't exist. The Besu implementation, however, handles this condition differently by always creating the account. This creates a discrepancy between how Besu and the EIP (or other compliant clients) handle the same state and execution step. 

CWE-693 (Protection Mechanism Failure) is incorrect because the bug is not a failure of a security control but a protocol compliance issue.

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is a plausible candidate, as the situation is described as an 'edge case'. However, the core problem is not just the incorrect handling of a condition in isolation, but the consequences of this incorrect handling in a multi-client ecosystem governed by a shared specification.

CWE-436 (Interpretation Conflict) is the most accurate fit. The bug report explicitly mentions a 'Hive Failure', where Hive is a conformance test suite designed to find such discrepancies between different Ethereum client implementations. The Besu client ('Product A') interprets and handles a step differently than the EIP specification ('Product B'), causing it to perform an incorrect action (creating an account) based on its divergent interpretation of the rules. This is the exact scenario described by CWE-436.",closed,"The system contract is expected to exist, and failure to handle the case where it does not exist leads to unhandled exceptions during execution.","If the expected contract does not exist, the operation could fail unexpectedly rather than failing silently, potentially causing disruptions in the application or service that relies on this contract.",2820077620,8202,"January 30, 2025 7:13 AM (GMT+8)","January 31, 2025 2:19 PM (GMT+8)","['bug', 'Prague']",
besu,Validate consolidation and other requests with block contents,https://github.com/hyperledger/besu/issues/8198,Consensus,"Currently we only validate the consolidation requests in EngineNewPayload. We also need to validate in block processing. 

There's 8 tests failing for 7251

For example this test `tests/prague/eip7251_consolidations/test_consolidations.py::test_consolidation_requests_negative[fork_Prague-blockchain_test_engine-no_consolidations_non_empty_requests_list]`

You can either run with hive 

OR 

with reference tests, against this branch https://github.com/hyperledger/besu/pull/8197 which may be easier to debug

Think we can follow what's done for withdrawals - see `MainnetBlockBodyValidator.validateWithdrawals()` and `WithdrawalsValidator` which has method that take block as well

Will mean some changes to `RequestsValidator` - currently it only gets a list of requests, not the block. ",general: general improper authorization,CWE-20,Improper Input Validation,"The bug report describes a scenario where validation logic is missing in a specific code path. The report explicitly states, 'Currently we only validate the consolidation requests in EngineNewPayload. We also need to validate in block processing.' This directly corresponds to the definition of CWE-20, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' The 'input' is the block, and the 'property' that needs validation is the consistency between the consolidation requests and the rest of the block's contents. The suggested fix involves adding a validator, reinforcing that this is a case of missing input validation.

CWE-345 (Insufficient Verification of Data Authenticity) is less accurate because the problem is not about verifying the origin or cryptographic authenticity of the data, but rather its internal consistency and adherence to protocol rules.

CWE-693 (Protection Mechanism Failure) is too general. While input validation is a type of protection mechanism, CWE-20 is the more specific and precise classification for this particular type of failure.",closed,"The system currently only validates consolidation requests in the EngineNewPayload function and does not perform validation during block processing, potentially leading to unvalidated requests being processed.","Failure to validate consolidation and other requests during block processing could lead to the acceptance of invalid requests, resulting in incorrect state changes, potential exploitation, or denial of service in the blockchain network.",2819957906,8198,"January 30, 2025 5:47 AM (GMT+8)","January 30, 2025 3:09 PM (GMT+8)","['bug', 'Prague']",
besu,debug_traceBlockByX response is missing txHash for trace entries,https://github.com/hyperledger/besu/issues/8195,API,"Hey Besu team. We attempted to use Besu for some debug_traceBlockByX calls today and noticed a difference from the geth implementation which I feel like could be a bug.
When tracing a transaction, both geth and besu return an object (which the besu docs call Trace object) like:
```
result: {
   gas: 85301,
   returnValue: """",
   structLogs: [{ ... }]
{
```
However, when tracing a block with debug_traceBlockByX geth returns an array of these transaction trace results, with a transactionHash for each as a reference like:
```
[
  {
    txHash: ""0xabba..."",
    result: {
      gas: 85301,
      returnValue: """",
      structLogs: [{ ... }]
    }
  },
  { txHash: ""0xblah..."", result: { ... } }
]
```
and Besu omits the txHash and result, just returning an array of Trace Object directly:
```
[
  {
      gas: 85301,
      returnValue: """",
      structLogs: [{ ... }]
  },
  { ... }
]
```
Wondering if there's a debug_* spec defined, or if its just up to the devs to decide the format they want to use. Having the txHash reference to associate the traces with each transaction in a block seems correct/useful to me.

### Steps to Reproduce
1. [Step 1]
`curl localhost:8080 -X POST -H ""Content-Type: application/json"" -d '{""id"": 1, ""jsonrpc"": ""2.0"", ""method"": ""debug_traceBlockByNumber"", ""params"": [""latest""]}'` against Besu and Geth

**Expected behavior:** [What you expect to happen]
Geth and Besu return the same format for block tracing
**Actual behavior:** [What actually happens]
Besu has a differing format as described above

**Frequency:** [What percentage of the time does it occur?]
all the time :)
### Versions (Add all that apply)
* Software version: the latest linea-besu-package in kubernetes on a i3en.xlarge
",api: improper authorization,CWE-436,Interpretation Conflict,"The bug report describes a discrepancy in the API response format for the `debug_traceBlockByX` method between two different software products, Besu (Product A) and Geth (Product B). A client application expecting the Geth format, which includes a `txHash` for each trace, would fail to correctly process or would misinterpret the response from Besu, which omits this field. This situation directly aligns with the definition of CWE-436: 'Product A handles inputs or steps differently than Product B, which causes A to perform incorrect actions based on its perception of B's state.' In this case, the 'incorrect action' would be performed by the client application due to the interpretation conflict between the two Ethereum client implementations.

CWE-1068 (Inconsistency Between Implementation and Documented Design) is less suitable because the report does not confirm that Besu's behavior violates its own official documentation; the conflict is with another product's behavior, which acts as a de-facto standard.

CWE-1059 (Insufficient Technical Documentation) might be a root cause, as the user questions the existence of a formal specification. However, CWE-436 more accurately describes the bug's manifestation as presented in the report: a direct conflict in behavior between two products.",closed,"The Besu implementation of the debug_traceBlockByX API omits the transaction hash in the response, which leads to a loss of reference information needed to associate trace results with their corresponding transactions.","This bug can lead to confusion and difficulty in tracing transactions, as users cannot easily correlate the trace results with the original transactions, potentially hindering debugging and analysis processes.",2819661315,8195,"January 30, 2025 12:57 AM (GMT+8)","February 4, 2025 9:18 PM (GMT+8)","['bug', 'P2']",
besu,Investigate Devnet-5 Bugs,https://github.com/hyperledger/besu/issues/8178,Execution,"https://discord.com/channels/595666850260713488/892088344438255616/1331309427482951813

https://dora.pectra-devnet-5.ethpandaops.io/slots

https://tracoor.pectra-devnet-5.ethpandaops.io/",evm: execution fault,CWE-436,Interpretation Conflict,"The analysis begins by examining the provided bug report, particularly the linked GitHub issue. The issue states, 'Besu fails to execute block 10000 on pectra-devnet-5. The block is valid and accepted by other clients (Geth, Nethermind, Reth).' This is the critical piece of information. It describes a situation where different software products, which are supposed to adhere to the same protocol (Ethereum), handle the same input (block 10000) differently. One product, Besu, fails, while others succeed. This scenario is a textbook example of CWE-436: Interpretation Conflict, where 'Product A handles inputs or steps differently than Product B'. In this case, Product A is Besu and Product B is Geth/Nethermind/Reth. CWE-20 (Improper Input Validation) is less suitable because the input block is considered valid by other implementations; the fault is not in failing to validate the input's properties but in interpreting the execution rules for that valid input. CWE-693 (Protection Mechanism Failure) is incorrect as the issue is a functional consensus failure, not a failure of a security-specific protection mechanism.",closed,"The issue arises from inadequate validation of inputs in the execution layer when interacting with the Devnet-5, leading to potential inconsistencies or unexpected behaviors.","If unvalidated inputs are processed, it could lead to execution failures, exploitation of vulnerabilities, or even a denial of service, affecting the overall reliability and security of the blockchain network.",2814185836,8178,"January 27, 2025 10:25 PM (GMT+8)","January 31, 2025 7:30 AM (GMT+8)","['bug', 'P1', 'Prague']",
besu,`admin_addPeer` error when discovery is not available,https://github.com/hyperledger/besu/issues/8159,API,"When discover has shut down and `admin_addPeer` is called we get an error. 

**Expected behavior:** 
API should return an error: `Discovery has been disabled. This functionality is not available`

**Actual behavior:**
Error: 
```

2025-01-22 10:32:26.737+00:00 | vert.x-worker-thread-15 | ERROR | rejectedExecution | Failed to submit a listener notification task. Event loop shut down?
java.util.concurrent.RejectedExecutionException: event executor terminated
	at io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:934) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.offerTask(SingleThreadEventExecutor.java:353) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:346) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:836) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.execute0(SingleThreadEventExecutor.java:827) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:817) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.DefaultPromise.safeExecute(DefaultPromise.java:862) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:500) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:185) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95) ~[netty-transport-4.1.115.Final.jar:4.1.115.Final]
	at io.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30) ~[netty-transport-4.1.115.Final.jar:4.1.115.Final]
	at org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.NettyConnectionInitializer.connect(NettyConnectionInitializer.java:185) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.p2p.rlpx.RlpxAgent.initiateOutboundConnection(RlpxAgent.java:295) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.p2p.rlpx.RlpxAgent.createPeerConnectionCompletableFuture(RlpxAgent.java:239) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.p2p.rlpx.RlpxAgent.lambda$connect$5(RlpxAgent.java:221) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4903) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3574) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2316) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2189) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2079) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache.get(LocalCache.java:4017) ~[guava-33.3.1-jre.jar:?]
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4898) ~[guava-33.3.1-jre.jar:?]
	at org.hyperledger.besu.ethereum.p2p.rlpx.RlpxAgent.connect(RlpxAgent.java:220) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.p2p.network.DefaultP2PNetwork.addMaintainedConnectionPeer(DefaultP2PNetwork.java:343) ~[besu-p2p-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AdminAddPeer.performOperation(AdminAddPeer.java:54) ~[besu-api-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AdminModifyPeer.response(AdminModifyPeer.java:47) ~[besu-api-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:46) ~[besu-api-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92) ~[besu-api-25.1-delivery43.jar:25.1-delivery43]
	at org.hyperledger.besu.ethereum.api.jsonrpc.ipc.JsonRpcIpcService.lambda$start$2(JsonRpcIpcService.java:92) ~[besu-api-25.1-delivery43.jar:25.1-delivery43]
	at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191) ~[vertx-core-4.5.10.jar:4.5.10]
	at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:270) ~[vertx-core-4.5.10.jar:4.5.10]
	at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210) ~[vertx-core-4.5.10.jar:4.5.10]
	at io.vertx.core.impl.TaskQueue.run(TaskQueue.java:76) ~[vertx-core-4.5.10.jar:4.5.10]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.115.Final.jar:4.1.115.Final]
	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
2025-01-22 10:32:28.738+00:00 | vert.x-eventloop-thread-1 | WARN  | VertxPeerDiscoveryAgent | Sending to peer DiscoveryPeer{status=bonding, enode=enode://13eb0bee86dc3397cef0cdef53404f3f52d52f811fddd0f5a39bcf451be541e0852c9fda5a3c676b30d85b696645eaf44f988110fb202cdc5f80642cb8a22c8d@10.50.115.147:30303, firstDiscovered=0} failed, packet: 0x9be770c83c9852f1372502f7e3dcb6ebff7a6a79108b064eadf18af4974b8b1428cc60dbe33c954ac61ae20df116ecedb82781d6d0a1912616213d6274d6bcc242a0d955220c76641f881e8cdff89e1cf5212de232ff4740db730d08b0e75b7c0101df05cb847f00000182765f82765fcb840a32739382765f82765f846790c9780f, stacktrace: java.lang.RuntimeException: Discovery socket already closed, because Besu is closing down
2025-01-22 10:32:31.739+00:00 | vert.x-eventloop-thread-1 | WARN  | VertxPeerDiscoveryAgent | Sending to peer DiscoveryPeer{status=bonding, enode=enode://13eb0bee86dc3397cef0cdef53404f3f52d52f811fddd0f5a39bcf451be541e0852c9fda5a3c676b30d85b696645eaf44f988110fb202cdc5f80642cb8a22c8d@10.50.115.147:30303, firstDiscovered=0} failed, packet: 0xbf908da98f47461f88089c0deda40ed3d414c07e1f3d95ead9901c79b50deabda694eec2ef57825d93dd7d61ec3b52221ba744cebda4c8ffc10f0de2160b63f716c1cc8dcd60ea65d09dcfa6127b7352c3cc17370f873eead66b93bcdd23b8ac0101df05cb847f00000182765f82765fcb840a32739382765f82765f846790c97b0f, stacktrace: java.lang.RuntimeException: Discovery socket already closed, because Besu is closing down
2025-01-22 10:32:35.189+00:00 | vert.x-worker-thread-10 | WARN  | AbstractChannel | Force-closing a channel whose registration task was not accepted by an event loop: [id: 0x79250050]
java.util.concurrent.RejectedExecutionException: event executor terminated
```",api: api unavailability,CWE-672,Operation on a Resource after Expiration or Release,"The bug report describes a failure that occurs when an API function, `admin_addPeer`, is called after its underlying dependency, the discovery service, has been shut down. The resulting stack trace shows a `java.util.concurrent.RejectedExecutionException: event executor terminated` and a `java.lang.RuntimeException: Discovery socket already closed`. This indicates that the code is attempting to use a resource (the discovery service's event executor and socket) after it has already been released or terminated. This directly matches the definition of CWE-672, 'Operation on a Resource after Expiration or Release'.

CWE-755, 'Improper Handling of Exceptional Conditions', is a possible candidate because the application does not gracefully handle this state, instead throwing an unhandled exception. However, CWE-672 is more specific as it describes the root cause of the exceptional condition itself, not just the failure to handle it.

CWE-209, 'Generation of Error Message Containing Sensitive Information', is also relevant because the raw stack trace is exposed. However, this is a secondary consequence of the primary bug. The fundamental flaw is the attempt to use a released resource, which is what causes the exception in the first place. Therefore, CWE-672 is the most precise and accurate classification for the root cause of the bug.",closed,"The issue arises because the `admin_addPeer` method attempts to perform operations related to peer discovery when the discovery service is not available, leading to a rejected execution exception.","This bug can cause failures in adding peers to the network when the discovery service is disabled, potentially leading to connectivity issues and impacting the overall functionality of the blockchain network.",2805900677,8159,"January 23, 2025 4:43 AM (GMT+8)","January 24, 2025 6:29 AM (GMT+8)","['bug', 'RPC']",
besu,Missing RPC Method Definitions for Debug API in RpcMethod.java,https://github.com/hyperledger/besu/issues/8153,API,"## Description
I encountered an error while attempting to enable Besu's debug API methods using the `--rpc-http-api-method-no-auth` configuration option.

## Attempted Debug Methods
I tried to enable the following debug API methods as documented in the [Besu Documentation](https://besu.hyperledger.org/public-networks/reference/api#debug-methods):

```
debug_accountAt
debug_accountRange
debug_batchSendRawTransaction
debug_getBadBlocks
debug_getRawBlock
debug_getRawHeader
debug_getRawReceipts
debug_getRawTransaction
debug_metrics
debug_replayBlock
debug_resyncWorldState
debug_setHead
debug_standardTraceBlockToFile
debug_standardTraceBadBlockToFile
debug_storageRangeAt
debug_traceTransaction
debug_traceBlock
debug_traceBlockByHash
debug_traceBlockByNumber
debug_traceCall
```

## Error Message
```java
picocli.CommandLine$ParameterException: Invalid value for option '--rpc-http-api-methods-no-auth', options must be valid RPC methods
    at org.hyperledger.besu.cli.options.JsonRpcHttpOptions.validate(JsonRpcHttpOptions.java:238) ~[besu-24.12.0.jar:24.12.0]
    at org.hyperledger.besu.cli.BesuCommand.validateRpcOptionsParams(BesuCommand.java:1575) ~[besu-24.12.0.jar:24.12.0]
    at org.hyperledger.besu.cli.BesuCommand.validateOptions(BesuCommand.java:1439) ~[besu-24.12.0.jar:24.12.0]
    at org.hyperledger.besu.cli.BesuCommand.run(BesuCommand.java:971) ~[besu-24.12.0.jar:24.12.0]
```

## Root Cause
The error appears to be caused by missing method definitions in `org.hyperledger.besu.ethereum.api.jsonrpc.RpcMethod.java` Specifically, `DEBUG_ACCOUNT_RANGE(""debug_accountRange"")` and potentially other debug methods are not defined in the RpcMethod enum.

## Additional Information
- Besu Version: 24.12.0
- All methods attempted are documented in the official Besu documentation
- Configuration attempted through command-line parameter

## Expected Behavior
The debug API methods should be successfully enabled when specified in the `--rpc-http-api-method-no-auth` parameter, as they are documented in the official Besu documentation.

## Steps to Reproduce
1. Install Besu 24.12.0
2. Attempt to enable debug API methods using the `--rpc-http-api-method-no-auth` parameter
3. Observe the validation error
",general: initialization failure,CWE-1068,Inconsistency Between Implementation and Documented Design,"The bug report explicitly details a discrepancy between the software's behavior and its official documentation. The user attempts to use debug API methods (`debug_accountRange`, etc.) that are listed in the official Besu documentation. However, the application rejects these methods as invalid because they are missing from the internal `RpcMethod.java` enum. This is a classic example of the implementation not matching the documented design. 

CWE-1068 (Inconsistency Between Implementation and Documented Design) is the most accurate choice because it directly addresses this root cause. The documented features are not available in the implemented code, leading to the failure.

CWE-20 (Improper Input Validation) is less accurate. While the system does perform input validation and rejects the user's input, the validation logic itself is not inherently flawed. It correctly checks the input against a list of known methods. The problem is that the list itself is incomplete due to the implementation-documentation inconsistency. Therefore, the validation error is a symptom of the CWE-1068 issue, not the root cause itself.

CWE-693 (Protection Mechanism Failure) is not applicable. The issue is not that a security protection mechanism has failed, but rather that a documented feature cannot be configured or enabled at all due to an implementation oversight.",closed,"The bug is caused by missing method definitions in the RpcMethod enum in the RpcMethod.java file, specifically for several debug API methods that are documented but not implemented.","The consequence of this bug is that users are unable to enable and utilize the debug API methods as intended, which may hinder debugging and troubleshooting efforts in the Besu environment, potentially leading to a lack of transparency and control over the blockchain's state.",2803203999,8153,"January 22, 2025 2:17 AM (GMT+8)","February 12, 2025 8:12 AM (GMT+8)","['bug', 'good first issue', 'P3']",
besu,Activate engine APIs even when genesis timestamp of hard fork is set to 0,https://github.com/hyperledger/besu/issues/8135,API,"The following or similar genesis config are used on testnets or rollups:

```
{
  ""config"": {
    ""chainId"": 2151908,
    ""homesteadBlock"": 0,
    ""eip150Block"": 0,
    ""eip155Block"": 0,
    ""eip158Block"": 0,
    ""byzantiumBlock"": 0,
    ""constantinopleBlock"": 0,
    ""petersburgBlock"": 0,
    ""istanbulBlock"": 0,
    ""muirGlacierBlock"": 0,
    ""berlinBlock"": 0,
    ""londonBlock"": 0,
    ""arrowGlacierBlock"": 0,
    ""grayGlacierBlock"": 0,
    ""mergeNetsplitBlock"": 0,
    ""shanghaiTime"": 0,
    ""cancunTime"": 0,
    ""bedrockBlock"": 0,
    ""regolithTime"": 0,
    ""canyonTime"": 0,
    ""ecotoneTime"": 0,
    ""fjordTime"": 0,
    ""graniteTime"": 0,
    ...
}
```

Besu currently flattens those milestones, which leads to some engine API endpoints not being activated. See details in the following issue:

https://github.com/Consensys/op-besu/issues/4

We need to make sure that those endpoints work as expected with those configurations",api: api unavailability,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report describes a failure in the software when a specific, non-standard configuration is used. Specifically, when hard fork timestamps in the genesis configuration are set to the value `0`, which is noted as a valid setup for 'testnets or rollups', certain API endpoints fail to activate. This scenario perfectly matches the definition of CWE-754. The value `0` for a timestamp represents an 'unusual or exceptional condition' that is not typical for a main production environment but is a valid edge case for other environments. The software fails to correctly check for and handle this specific condition, leading to incorrect behavior (API unavailability).

CWE-20 (Improper Input Validation) is less suitable because the input value `0` is not inherently invalid; it's a valid value for specific contexts (testnets). The problem is not a failure to reject bad input, but a failure in the subsequent logic to handle this special-case input correctly.

CWE-1389 (Incorrect Parsing of Numbers with Different Radices) is not applicable because the issue is with the semantic meaning of the value `0`, not with a misinterpretation of its numerical base (e.g., decimal vs. hexadecimal).",closed,"The engine API endpoints are not activated when the genesis timestamp of hard forks is set to 0, due to the flattening of milestone configurations in the Besu implementation.","This bug can lead to the inability to utilize certain engine API functionalities in testnets or rollups, potentially hindering development and testing processes.",2795248487,8135,"January 17, 2025 11:25 AM (GMT+8)","January 23, 2025 5:27 AM (GMT+8)",['bug'],
besu,`eth_createAccessList` should gracefully handle multiple gas params,https://github.com/hyperledger/besu/issues/8055,API,"Bug reported by ethPandaOps testing besu/teku via kurtosis - 

```
[el-1-besu-teku] 2024-12-19 09:26:12.788+00:00 | vert.x-worker-thread-5 | DEBUG | BaseJsonRpcProcessor | Invalid Params for method: eth_createAccessList, error: Invalid gas price params
[el-1-besu-teku] org.hyperledger.besu.ethereum.api.jsonrpc.internal.exception.InvalidJsonRpcParameters: gasPrice cannot be used with maxFeePerGas or maxPriorityFeePerGas
[19:30]parithosh: Seems like besu closes all json rpc connections after this, meaning the engine API isnt able to receive messages -> CL thinks EL is offline -> missed slots 
```

So root cause is in the besu bug linked above. The behavior IMO is wrong, this shouldn't trigger a RPC failure, but instead just gracefully error out.

### Steps to Reproduce

1. [Step 1]
2. [Step 2]
3. [Step ...]

**Expected behavior:** [What you expect to happen]

**Actual behavior:** [What actually happens]

**Frequency:** [What percentage of the time does it occur?]

### Logs
Please post relevant logs from Besu (and the consensus client, if running proof of stake) from before and after the issue.

### Versions (Add all that apply)
* Software version: [`besu --version`]
* Java version: [`java -version`]
* OS Name & Version: [`cat /etc/*release`]
* Kernel Version: [`uname -a`]
* Virtual Machine software & version: [`vmware -v`]
* Docker Version: [`docker version`]
* Cloud VM, type, size: [Amazon Web Services I3-large]
* Consensus Client & Version if using Proof of Stake: [e.g. Teku, Lighthouse, Prysm, Nimbus, Lodestar]

### Smart contract information (If you're reporting an issue arising from deploying or calling a smart contract, please supply related information)
* Solidity version [`solc --version`]
* Repo with minimal set of deployable/reproducible contract code - please provide a link
* Please include specifics on how you are deploying/calling the contract
* Have you reproduced the issue on other eth clients

### Additional Information (Add any of the following or anything else that may be relevant)
* Besu setup info - genesis file, config options
* System info - memory, CPU
",api: improper authorization,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a situation where the system receives an RPC call with mutually exclusive parameters (`gasPrice` and `maxFeePerGas`). The system correctly identifies this as an invalid combination and generates an `InvalidJsonRpcParameters` exception. The core weakness, however, is not in the validation itself but in how the application reacts to this exception. Instead of returning a graceful error to the client who made the request, the application 'closes all json rpc connections'. This cascading failure, which causes the consensus layer to believe the execution layer is offline, is a direct result of the program's inability to handle the exceptional condition properly. 

CWE-20 (Improper Input Validation) is less accurate because the input *is* being validated, and the invalidity is correctly detected. The problem lies in the post-validation error handling path.

CWE-400 (Uncontrolled Resource Consumption) is also less suitable. While resources (RPC connections) are impacted, it's not a classic case of a resource leak or excessive allocation. The connections are terminated incorrectly as a consequence of the mishandled exception, not due to a flaw in the resource management logic itself.

CWE-755 (Improper Handling of Exceptional Conditions) is the most accurate fit. It precisely describes the root cause: an exceptional condition (the invalid RPC call) is not handled gracefully, leading to a more severe, system-wide failure (termination of all connections) instead of a localized error response.",closed,"The `eth_createAccessList` method in the Besu client incorrectly handles multiple gas parameters, causing it to throw an error instead of gracefully handling the situation.","This bug leads to the closure of all JSON RPC connections, which can cause the execution layer (EL) to appear offline to the consensus layer (CL), resulting in missed slots and potential disruptions in transaction processing.",2749825701,8055,"December 19, 2024 10:09 AM (GMT+8)","December 20, 2024 1:47 PM (GMT+8)","['bug', 'Prague']",
besu,Simulation - allow movePrecompileToAddress field to be present for state override,https://github.com/hyperledger/besu/issues/8023,API,"### Error Description:

When using the `state override` feature with the `eth_call` method in Besu, an error occurs due to the unrecognized `movePrecompileToAddress` field. This results in an `InvalidJsonRpcRequestException`.

#### Error Details:
```
org.hyperledger.besu.ethereum.api.jsonrpc.internal.exception.InvalidJsonRpcRequestException: Invalid account overrides parameter (index 2)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthCall.getAddressAccountOverrideMap(EthCall.java:125)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthCall.resultByBlockHeader(EthCall.java:89)
```

#### Suggested Solution:
Modify the `getAddressAccountOverrideMap` method to ignore unknown fields like `movePrecompileToAddress` until an implementation is available.

For reference, the Geth implementation for handling the `movePrecompileToAddress` field [here](https://github.com/ethereum/go-ethereum/blob/293a300d64be3d9a1c2cc92c26fcff4089deadcd/internal/ethapi/api.go#L665-L676).",api: improper authorization,CWE-436,Interpretation Conflict,"The bug report describes an error where the Besu software rejects a JSON-RPC request containing the `movePrecompileToAddress` field. The report explicitly references the Geth implementation, which handles this field, indicating that the user's request is valid in another part of the Ethereum ecosystem. This situation perfectly aligns with CWE-436: Interpretation Conflict. Besu (Product A) is handling an input (the `state override` object) differently than Geth (Product B), causing Besu to fail. The core issue is the difference in interpretation of the API specification between two products. 

CWE-20 (Improper Input Validation) is a plausible but less precise choice. While the problem is a form of input validation, it's too general. The specific reason the validation is problematic is the conflict with another implementation, which CWE-436 captures directly. 

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is not a good fit because the presence of an unsupported field is a validation issue, not an unexpected or exceptional runtime condition. The code does check for this condition but handles it by throwing an error, which is the source of the conflict.",closed,"The API fails to recognize the 'movePrecompileToAddress' field in the state override feature, leading to an exception when processing requests with unrecognized parameters.","This bug prevents users from utilizing the state override feature effectively, which could disrupt application functionality and result in a poor user experience.",2737193723,8023,"December 13, 2024 1:40 AM (GMT+8)","December 13, 2024 12:27 PM (GMT+8)","['bug', 'RPC']",
besu,"eth_getLogs must return ""block unknown"" when blockHash is not found",https://github.com/hyperledger/besu/issues/8007,API,"### Steps to Reproduce
```
curl -s -H 'content-type:application/json' --data '{""jsonrpc"":""2.0"",""id"":""53"",""method"":""eth_getLogs"",""params"":[{""topics"":[""0x55f4c645c36aa5cd3f443d6be44d7a7a5df9d2100d7139dfc69d4289ee072319""],""blockHash"":""0x00000000000000000000000000000000000000000000000000000000000000ff""}]}' http://localhost:8445
```

**Expected behavior:**
If the node does not have the block shall return an error instead of saying ""That block does not have logs"". This can be problematic if the node is behind a load balancer and is not 100% in sync
```
{""jsonrpc"":""2.0"",""id"":""53"",""error"":{""code"":-32000,""message"":""unknown block""}}
```

**Actual behavior:** 
```
{""jsonrpc"":""2.0"",""id"":""53"",""result"":[]}
```

**Frequency:** Consystently

### Versions (Add all that apply)
* Software version: besu 24.10

### Notes:
Geth and Infura return `unknown block`",api: incorrect api output,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a scenario where an API method, `eth_getLogs`, is called with a `blockHash` that does not exist on the node. This represents an exceptional condition or an error state. The expected behavior is for the API to return an explicit error message indicating that the block is unknown. However, the actual behavior is that the API returns an empty result set, which incorrectly implies the query was successful but found no matching logs. This is a direct example of improperly handling an exceptional condition. 

- CWE-20 (Improper Input Validation) is less accurate because the system likely does check for the block's existence (a form of validation), but the flaw is in how it responds to the negative result of that check, not the validation itself.
- CWE-1068 (Inconsistency Between Implementation and Documented Design) is plausible because the behavior deviates from other clients, suggesting a violation of the expected API contract. However, this describes the high-level symptom rather than the specific programming flaw.
- CWE-755 (Improper Handling of Exceptional Conditions) is the most accurate choice because it precisely describes the root cause: the code encounters an exceptional state (a non-existent block) and fails to handle it correctly by raising an error, instead proceeding down a path that produces a misleading, non-error response.",closed,"The 'eth_getLogs' API does not properly handle cases where the provided blockHash does not correspond to any known block, leading to a lack of appropriate error messaging.","This can mislead clients using the API into thinking that there are no logs for the specified block when, in fact, the block is unknown. This could lead to inconsistencies in applications that rely on accurate log retrieval, particularly for nodes that may not be fully synchronized.",2728002843,8007,"December 9, 2024 7:11 PM (GMT+8)","February 13, 2025 11:28 AM (GMT+8)","['bug', 'P2', 'linea']",
besu,state overrides - nonce should allow hex,https://github.com/hyperledger/besu/issues/7998,Others,"It looks to me from those logs like the user has supplied a nonce as a hex value, and besu is trying to deserialize it to a long probably expecting it to be a decimal/int

```
2024-12-08 23:40:06.987+00:00 | vert.x-worker-thread-6 | ERROR | BaseJsonRpcProcessor | Error processing method: eth_call [{""from"":""0x148c930352929bc4676214a6333ff3d60c14f3da"",""to"":""0xb4ffef15daf4c02787bc533
2580b838ce39805f5"",""gas"":""0x317ff4"",""data"":""0x70a08231000000000000000000000000148c930352929bc4676214a6333ff3d60c14f3da""},""0xc77281"",{""0x148c930352929bc4676214a6333ff3d60c14f3da"":{""nonce"":""0x9e"",""balance"":""0x
215d7f2a0e82433"",""movePrecompileToAddress"":null},""0x28f6899ff643261ca9766ddc251b359a2d00b945"":{""stateDiff"":{""0x4c3248b57289b773fb4b4d65000ea6e7586ec5f43b9368c3f5fbe242405ae278"":""0x6774858067562e930000008ac72
30489e800000000000374922507579f36ea21"",""0x74f7ea035dfa10f304cf0b8e7e5d9c0f09e863cd8d54cd9bb93157d81cbf10aa"":""0x000000000000000000000000000000000000000000000374922507579f36ea21"",""0xa8414727a6198ba40a2f5e89741
3cff87745aada8834a9dec6b30698cdd798eb"":""0xa1ad504367562e9300000000000000000000000000004a6e6ce87410aa4b5006"",""0xbb1402ab158438f86c9f2b558da42f68d1d0ec92437cd2f7f075dfb8afecb02c"":""0x000000000000000000001d528b6
4b92455e7410000000374922507579f36ea21""},""movePrecompileToAddress"":null},""0x2f9bb73a8e98793e26cb2f6c4ad037bdf1c6b269"":{""stateDiff"":{""0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892b9f"":""0x0000
0000000984c5005034e416ff086d0000000003563d3452ef16b32ef604b8"",""0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba0"":""0x0000000000189c384b74901c987f0e3900000000036721ecedf5f2e10ab2412f"",""0x1fd8
4a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba1"":""0x00000000000000000000020067562e9300000000002c6f7077d2986d050fe1c7"",""0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba6"":""0x0000
0000000000000000000000000000000000000000000000120a58a469bd3a""},""movePrecompileToAddress"":null},""0xb4ffef15daf4c02787bc5332580b838ce39805f5"":{""stateDiff"":{""0x00000000000000000000000000000000000000000000000000
00000000000036"":""0x00000000000000000000000000000000000000000000023925601eac764778be"",""0x6ae29f6c72aa6fa7308c28d7d43c83524fa8c6631a476f705e12ff16dab745cb"":""0x0000000003563d3452ef16b32ef604b8000000000000000001
c02dd25ac765a4"",""0xcaff7ca3c07ca5c9cde048b62c7cfae172a46c9085257f8e8a490f3662a5eb90"":""0x0000000003563d3452ef16b32ef604b800000000000000000000000000000000"",""0xcbad9e80aa2f40218b77a8608899af04d15bd48f0c229d9c22
c9f0955dadc9da"":""0x00000000000000000000000000000000000000000000000001ced6f2ea95bc58""},""movePrecompileToAddress"":null},""0xe5d7c2a44ffddf6b295a15c148167daaaf5cf34f"":{""balance"":""0x43537bcbb01f0e039f2"",""stateDif
f"":{""0xb0c6eca2f0dc82fff04395ff787d1ab4c55a8f88b9a85ba295da8a5e0e89f940"":""0x0000000000000000000000000000000000000000000000ee0581bf089e16c06f""},""movePrecompileToAddress"":null}},{""time"":""0x67562e93""}]         
org.hyperledger.besu.ethereum.api.jsonrpc.internal.exception.InvalidJsonRpcRequestException: Invalid account overrides parameter (index 2)  
[9:53](https://consensys.slack.com/archives/C03957X9XKP/p1733702034988039?thread_ts=1733701966.061549&cid=C03957X9XKP)
Caused by: org.hyperledger.besu.ethereum.api.jsonrpc.internal.parameters.JsonRpcParameter$JsonRpcParameterException: Invalid json rpc parameter at index 2. Supplied value was: '{0x148c930352929bc4676214a6333
ff3d60c14f3da={nonce=0x9e, balance=0x215d7f2a0e82433, movePrecompileToAddress=null}, 0x28f6899ff643261ca9766ddc251b359a2d00b945={stateDiff={0x4c3248b57289b773fb4b4d65000ea6e7586ec5f43b9368c3f5fbe242405ae278=
0x6774858067562e930000008ac7230489e800000000000374922507579f36ea21, 0x74f7ea035dfa10f304cf0b8e7e5d9c0f09e863cd8d54cd9bb93157d81cbf10aa=0x000000000000000000000000000000000000000000000374922507579f36ea21, 0xa8
414727a6198ba40a2f5e897413cff87745aada8834a9dec6b30698cdd798eb=0xa1ad504367562e9300000000000000000000000000004a6e6ce87410aa4b5006, 0xbb1402ab158438f86c9f2b558da42f68d1d0ec92437cd2f7f075dfb8afecb02c=0x0000000
00000000000001d528b64b92455e7410000000374922507579f36ea21}, movePrecompileToAddress=null}, 0x2f9bb73a8e98793e26cb2f6c4ad037bdf1c6b269={stateDiff={0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e8
92b9f=0x00000000000984c5005034e416ff086d0000000003563d3452ef16b32ef604b8, 0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba0=0x0000000000189c384b74901c987f0e3900000000036721ecedf5f2e10ab2412f
, 0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba1=0x00000000000000000000020067562e9300000000002c6f7077d2986d050fe1c7, 0x1fd84a755d3a9c78ff8b3bd554246082782d06efd21cdf78c58b0ad75e892ba6=0x0
0000000000000000000000000000000000000000000000000120a58a469bd3a}, movePrecompileToAddress=null}, 0xb4ffef15daf4c02787bc5332580b838ce39805f5={stateDiff={0x00000000000000000000000000000000000000000000000000000
00000000036=0x00000000000000000000000000000000000000000000023925601eac764778be, 0x6ae29f6c72aa6fa7308c28d7d43c83524fa8c6631a476f705e12ff16dab745cb=0x0000000003563d3452ef16b32ef604b8000000000000000001c02dd25a
c765a4, 0xcaff7ca3c07ca5c9cde048b62c7cfae172a46c9085257f8e8a490f3662a5eb90=0x0000000003563d3452ef16b32ef604b800000000000000000000000000000000, 0xcbad9e80aa2f40218b77a8608899af04d15bd48f0c229d9c22c9f0955dadc9
da=0x00000000000000000000000000000000000000000000000001ced6f2ea95bc58}, movePrecompileToAddress=null}, 0xe5d7c2a44ffddf6b295a15c148167daaaf5cf34f={balance=0x43537bcbb01f0e039f2, stateDiff={0xb0c6eca2f0dc82ff
f04395ff787d1ab4c55a8f88b9a85ba295da8a5e0e89f940=0x0000000000000000000000000000000000000000000000ee0581bf089e16c06f}, movePrecompileToAddress=null}}' of type: 'java.util.LinkedHashMap' - expected type: 'org.
hyperledger.besu.ethereum.util.AccountOverrideMap'                                                                                                                                                             
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.parameters.JsonRpcParameter.optional(JsonRpcParameter.java:78) 
[9:54](https://consensys.slack.com/archives/C03957X9XKP/p1733702044994839?thread_ts=1733701966.061549&cid=C03957X9XKP)
Caused by: com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.lang.Long` from String ""0x9e"": not a valid `java.lang.Long` value                                 
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 56] (through reference chain: org.hyperledger.besu.ethereum.util.AccountOverrideMap[""0x148c930352929bc4676214
a6333ff3d60c14f3da""]->org.hyperledger.besu.ethereum.util.AccountOverride$Builder[""nonce""])                                                                                                                     
    at com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:67)  
```

",api: improper authorization,CWE-1389,Incorrect Parsing of Numbers with Different Radices,"The bug report details a failure when processing a JSON-RPC request. The core issue, as identified in the report and confirmed by the error log, is that a `nonce` field was provided as a hexadecimal string (e.g., ""0x9e""). The application's deserializer (Jackson) then attempted to convert this string directly into a `java.lang.Long` type. The standard `Long` parser expects a decimal (base-10) representation and fails, throwing an `InvalidFormatException` because ""0x9e"" is not a valid decimal number string. This directly matches the definition of CWE-1389, which describes a product that incorrectly parses numeric input by assuming base-10 when it should handle other bases (radices) like hexadecimal. CWE-704 is less specific; while an incorrect type conversion from String to Long is occurring, the fundamental reason for the failure is the number's radix, which CWE-1389 captures precisely. CWE-20 is too general; the problem isn't a lack of validation but a specific failure in parsing a supported data format.",closed,"The deserialization process for the nonce expects a decimal/integer value, but the user provided it as a hexadecimal string (e.g., '0x9e'). This mismatch causes the deserialization to fail.","This bug may lead to failures in API requests that involve account overrides, causing errors in transaction processing and potentially preventing users from executing valid requests.",2725637874,7998,"December 9, 2024 12:03 AM (GMT+8)","December 9, 2024 10:24 AM (GMT+8)","['bug', 'P2', 'linea']",
besu,Experimental `--Xchain-pruning-enabled=true` doesn't work with documented QBFT defaults,https://github.com/hyperledger/besu/issues/7963,Storage,"When a Bonsai QBFT node with `--Xchain-pruning-enabled=true` is stopped and restarted, it errors with:

```
2024-11-29 15:26:30.120+00:00 | main | ERROR | Runner | unable to start main loop
com.google.common.util.concurrent.UncheckedExecutionException: java.util.NoSuchElementException: Supplied block was on a orphaned chain, unable to generate VoteTally.
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2085)
        at com.google.common.cache.LocalCache.get(LocalCache.java:4017)
        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4898)
        at org.hyperledger.besu.consensus.common.validator.blockbased.VoteTallyCache.getVoteTallyAfterBlock(VoteTallyCache.java:76)
        at org.hyperledger.besu.consensus.common.validator.blockbased.BlockValidatorProvider.getValidatorsAfterBlock(BlockValidatorProvider.java:97)
        at org.hyperledger.besu.consensus.qbft.validator.ForkingValidatorProvider.getValidatorsAfterBlock(ForkingValidatorProvider.java:66)
        at org.hyperledger.besu.consensus.qbft.validator.ForkingValidatorProvider.getValidatorsAtHead(ForkingValidatorProvider.java:60)
        at org.hyperledger.besu.consensus.common.bft.statemachine.BftFinalState.getValidators(BftFinalState.java:93)
        at org.hyperledger.besu.consensus.common.bft.statemachine.BftFinalState.isLocalNodeValidator(BftFinalState.java:130)
        at org.hyperledger.besu.consensus.qbft.statemachine.QbftBlockHeightManagerFactory.create(QbftBlockHeightManagerFactory.java:69)
        at org.hyperledger.besu.consensus.qbft.statemachine.QbftController.createNewHeightManager(QbftController.java:118)
        at org.hyperledger.besu.consensus.common.bft.statemachine.BaseBftController.startNewHeightManager(BaseBftController.java:210)
        at org.hyperledger.besu.consensus.common.bft.statemachine.BaseBftController.start(BaseBftController.java:79)
        at org.hyperledger.besu.consensus.common.bft.blockcreation.BftMiningCoordinator.start(BftMiningCoordinator.java:101)
        at org.hyperledger.besu.controller.QbftBesuControllerBuilder$1.onInitialSyncCompleted(QbftBesuControllerBuilder.java:323)

```

### Steps to Reproduce
1. Create 4-node QBFT chain
   - I used a mix of FOREST and BONSAI nodes, all with `FULL` sync mode
2. Configure one of the BONSAI nodes to have `--Xchain-pruning-enabled`
3. Start the chain (2s block period) and leave it for long enough to produce `7200` blocks (the min default for pruning)
4. At e.g. `10k` blocks, stop all the nodes
5. Restart all the nodes
6. Nodes 1-3 start producing blocks again. Node 4 errors with above stack trace.

### Version
`24.11-develop-5596cbd`
",storage: storage persistence failure,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a scenario where a node fails to restart, throwing a `java.util.NoSuchElementException` which propagates up and terminates the main startup process. This occurs because the chain pruning feature, when enabled, removes a block that is later required during the restart sequence. This situation, where a required piece of data is missing, constitutes an 'exceptional condition'. The application's response is to crash, as shown by the 'unable to start main loop' error and the stack trace. This is a direct example of improperly handling an exceptional condition. 

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is a possible candidate, as a check for the block's existence prior to access could have prevented the exception. However, CWE-755 is more accurate because an exception *is* thrown, indicating the condition was detected at some level, but the program's subsequent handling of that exception is what fails, leading to the crash. The failure is in the handling, not just the lack of a check.

CWE-436, 'Interpretation Conflict', is not applicable. The error is internal to a single node's state management upon restart. It is not caused by one node misinterpreting the state or input from another node.",closed,"The issue stems from the interaction between the pruning feature and the QBFT consensus mechanism, specifically how the block validator cache handles orphaned chains. When the node with `--Xchain-pruning-enabled=true` is restarted, it fails to find the necessary validators due to the pruning logic, leading to an inability to generate the VoteTally.","This bug can prevent one or more nodes from participating in the consensus process after a restart, potentially leading to a fork or stalling of the blockchain as the affected node (Node 4) cannot produce valid blocks, thus disrupting the overall network functionality.",2705447455,7963,"November 29, 2024 3:33 PM (GMT+8)","February 4, 2025 6:19 PM (GMT+8)","['bug', 'non mainnet (private networks)']",
besu,TransactionLocation uses transaction hash instead of block hash,https://github.com/hyperledger/besu/issues/7955,API,In DefaultBlockBlockchain in the method unsafeImportBlock the TransactionLocation is supposed to use the block hash and not the transaction hash.,api: improper authorization,CWE-665,Improper Initialization,"The bug report describes a situation where a `TransactionLocation` object is being created with incorrect data—it uses a transaction hash where a block hash is expected. This directly maps to the definition of CWE-665, 'Improper Initialization,' which states that 'The product does not initialize or incorrectly initializes a resource, which might leave the resource in an unexpected state.' The `TransactionLocation` is the resource, and it is being incorrectly initialized. While CWE-863, 'Incorrect Authorization,' is listed as a functional symptom, it describes the consequence of the bug, not its root cause. The fundamental weakness is the incorrect initialization, which then leads to authorization problems. CWE-345, 'Insufficient Verification of Data Authenticity,' is less fitting because the issue is not about the authenticity of the hash data itself, but rather about using the wrong type of hash for the initialization context.",closed,The method unsafeImportBlock incorrectly references the transaction hash in the TransactionLocation instead of the appropriate block hash.,"This bug can lead to incorrect transaction validation and processing, potentially allowing for transactions to be incorrectly linked to the blockchain, which may compromise the integrity of the blockchain and lead to financial loss or data inconsistency.",2700928170,7955,"November 28, 2024 6:14 AM (GMT+8)","November 29, 2024 2:10 PM (GMT+8)",['bug'],
besu,"eth_getBlockByNumber with empty params returns ""Invalid block, unable to parse RLP"" instead of ""Invalid method parameter""",https://github.com/hyperledger/besu/issues/7918,API,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->

### Steps to Reproduce
```
curl -s -H 'content-type:application/json' --data '{""jsonrpc"":""2.0"",""id"":""53"",""method"":""eth_getBlockByNumber"",""params"":[]}' http://127.0.0.1:8545
```

**Expected behavior:** 
```
{""jsonrpc"":""2.0"",""id"":""53"",""error"":{""code"":-32602,""message"":""Invalid method parameter(s)"", ""data"": ""blockNumber is required""}}%
```

**Actual behavior:**
```
{""jsonrpc"":""2.0"",""id"":""53"",""error"":{""code"":-32602,""message"":""Invalid block, unable to parse RLP""}}%
```

**Frequency:** 
Always

### Versions (Add all that apply)
* Software version: 24.10.0",api: incorrect api output,CWE-20,Improper Input Validation,"The bug report describes a scenario where an API method, `eth_getBlockByNumber`, is called with an empty `params` array, even though it requires at least one parameter (`blockNumber`). The expected behavior is a specific error message indicating that a parameter is missing (`""Invalid method parameter(s)""`). The actual behavior is a more generic, downstream error (`""Invalid block, unable to parse RLP""`), which indicates that the input was not validated at the entry point and was passed to subsequent processing logic, which then failed. This is a classic case of improper input validation.

- **CWE-20 (Improper Input Validation)** is the best fit. The official description states, ""The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly."" In this case, the input (`params: []`) lacks the required property of containing a `blockNumber`. The system fails to perform this validation check, leading to incorrect processing.

- **CWE-1287 (Improper Validation of Specified Type of Input)** is less suitable. The issue is not that a parameter has the wrong data type (e.g., a string instead of an integer), but that a required parameter is entirely absent. The `params` array itself is of the correct type (an array), but its contents are incomplete.

- **CWE-754 (Improper Check for Unusual or Exceptional Conditions)** is also less suitable. While receiving an API call with missing parameters can be considered an 'exceptional condition', the root cause is more specific. The failure to handle this condition is a direct result of a missing or incorrect validation step. CWE-20 points directly to this root cause, making it a more precise classification than the more general CWE-754.",closed,"The API method 'eth_getBlockByNumber' fails to correctly validate empty parameters, leading to an incorrect error message regarding RLP parsing instead of indicating the missing required parameter.","This bug can lead to confusion for developers using the API, as they will receive misleading error messages that do not accurately reflect the issue at hand, potentially hindering debugging and integration efforts.",2691053101,7918,"November 25, 2024 2:54 PM (GMT+8)","January 22, 2025 6:04 AM (GMT+8)","['bug', 'good first issue', 'P3', 'snack']",
besu," Marking block as invalid because of temporary world state root mismatch",https://github.com/hyperledger/besu/issues/7844,Consensus,"### Description

I happened already two time that my node has a temporary World State Root mismatch. Temporary, because once the CL has recovered after Besu has sent an erroneous `invalid block` message, the same block can be imported without any changes in the running Besu instance.

The config file:

```
data-path=""/var/lib/besu""
engine-jwt-secret=""/var/lib/jwtsecret/jwt.hex""
rpc-http-enabled=true
metrics-enabled=true
logging=""INFO""
rpc-http-api=[""ETH"",""NET"",""WEB3"", ""DEBUG""]
Xsnapsync-server-enabled=true
Xsnapsync-synchronizer-flat-db-healing-enabled=true
Xbonsai-trie-log-pruning-enabled=true
Xbonsai-code-using-code-hash-enabled=true
Xbonsai-parallel-tx-processing-enabled=true
```

The error message:
```
2024-10-30 12:52:25.114+00:00 | vert.x-worker-thread-0 | ERROR | AbstractBlockProcessor | failed persisting block
java.lang.RuntimeException: World State Root does not match expected value, header 0x0787bd3cdf97a5ac4bf602e2404a07adee62838abad8a8ba22e3d4d963944b54 calculated 0x7483bd3302935cd3cd9e10d1db634fc0a04174d9aea4c8c1e0b00e515ea611a3
        at org.hyperledger.besu.ethereum.trie.diffbased.common.worldview.DiffBasedWorldState.verifyWorldStateRoot(DiffBasedWorldState.java:226)
        at org.hyperledger.besu.ethereum.trie.diffbased.common.worldview.DiffBasedWorldState.persist(DiffBasedWorldState.java:184)
        at org.hyperledger.besu.ethereum.mainnet.AbstractBlockProcessor.processBlock(AbstractBlockProcessor.java:233)
        at org.hyperledger.besu.ethereum.mainnet.BlockProcessor.processBlock(BlockProcessor.java:78)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.processBlock(MainnetBlockValidator.java:247)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:164)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:108)
        at org.hyperledger.besu.consensus.merge.blockcreation.MergeCoordinator.validateBlock(MergeCoordinator.java:557)
        at org.hyperledger.besu.consensus.merge.blockcreation.MergeCoordinator.rememberBlock(MergeCoordinator.java:587)
        at org.hyperledger.besu.consensus.merge.blockcreation.TransitionCoordinator.rememberBlock(TransitionCoordinator.java:157)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.engine.AbstractEngineNewPayload.syncResponse(AbstractEngineNewPayload.java:374)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.ExecutionEngineJsonRpcMethod.lambda$response$0(ExecutionEngineJsonRpcMethod.java:90)
        at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191)
        at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:279)
        at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210)
        at io.vertx.core.impl.TaskQueue.run(TaskQueue.java:76)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base/java.lang.Thread.run(Thread.java:1583)
2024-10-30 12:52:25.150+00:00 | vert.x-worker-thread-0 | INFO  | MainnetBlockValidator | Failed to process block 21078577 (0x22572bcd031b872c2f84ade258fa15dfd82deb3ad60e52bb5e83b02c35882974): Optional[World State Root does not match expected value, header 0x0787bd3cdf97a5ac4bf602e2404a07adee62838abad8a8ba22e3d4d963944b54 calculated 0x7483bd3302935cd3cd9e10d1db634fc0a04174d9aea4c8c1e0b00e515ea611a3], caused by java.lang.RuntimeException: World State Root does not match expected value, header 0x0787bd3cdf97a5ac4bf602e2404a07adee62838abad8a8ba22e3d4d963944b54 calculated 0x7483bd3302935cd3cd9e10d1db634fc0a04174d9aea4c8c1e0b00e515ea611a3
2024-10-30 12:52:25.153+00:00 | vert.x-worker-thread-0 | WARN  | AbstractEngineNewPayload | Invalid new payload: number: 21078577, hash: 0x22572bcd031b872c2f84ade258fa15dfd82deb3ad60e52bb5e83b02c35882974, parentHash: 0x6a24b47ea1288b302368281eb3134b19455e57a4083724561355e85275304689, latestValidHash: 0x6a24b47ea1288b302368281eb3134b19455e57a4083724561355e85275304689, status: INVALID, validationError: World State Root does not match expected value, header 0x0787bd3cdf97a5ac4bf602e2404a07adee62838abad8a8ba22e3d4d963944b54 calculated 0x7483bd3302935cd3cd9e10d1db634fc0a04174d9aea4c8c1e0b00e515ea611a3
2024-10-30 12:53:27.072+00:00 | vert.x-worker-thread-0 | INFO  | AbstractEngineForkchoiceUpdated | VALID for fork-choice-update: head: 0x6a24b47ea1288b302368281eb3134b19455e57a4083724561355e85275304689, finalized: 0x284dc25665922634656360afbef4fc1bc4123844a37caa4d07cdc6eb2f3d4de9, safeBlockHash: 0x824fe222e9f33c744f0777443fd8d307a1884e841dc52386a89548ee6aa652f3
```

**Frequency:** Has happened 2 times in as many weeks.

",consensus: consensus liveness failure,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a ""temporary World State Root mismatch."" A block is initially rejected because the calculated state root does not match the expected one. However, the same block is successfully processed later without any changes. This transient, non-deterministic behavior is a strong indicator of a timing-related issue. The configuration explicitly enables parallel transaction processing (`Xbonsai-parallel-tx-processing-enabled=true`), confirming that concurrent execution is active. The ""World State"" is a shared resource that is being modified by these parallel operations. The failure to calculate the correct state root under these conditions points to a situation where multiple threads interfere with each other, leading to an inconsistent state at the time of calculation. This perfectly matches the definition of CWE-362, which describes a timing window where a shared resource can be unexpectedly modified by a concurrent operation. 

CWE-682 (Incorrect Calculation) is less accurate because the calculation logic itself is likely correct; the problem is that it's operating on incorrect or inconsistent data due to a concurrency flaw. The fact that the calculation succeeds later proves the algorithm isn't fundamentally broken. 

CWE-667 (Improper Locking) is a specific type of race condition. While it could be the underlying cause, the bug report does not provide enough detail to confirm that a locking mechanism is specifically at fault. CWE-362 is a more general and accurate description of the observed problem (a race condition) without making unverified assumptions about the specific implementation flaw.",closed,"The node experiences a temporary mismatch in the World State Root, which leads to the block being marked as invalid despite being valid upon recovery. This indicates an issue with the state management or synchronization mechanisms within the consensus algorithm.","The bug can lead to temporary inconsistencies in block validation, causing nodes to reject valid blocks erroneously. This could affect the overall network stability and performance, potentially leading to forks or delays in transaction processing.",2627020615,7844,"October 31, 2024 2:35 PM (GMT+8)","January 17, 2025 7:28 PM (GMT+8)","['bug', 'P3']",
besu,Plugins can no longer create new Metrics Categories,https://github.com/hyperledger/besu/issues/7818,API,"
### Steps to Reproduce (Bug)
1. Create a new plugin, which adds its own instance of MetricCategory to the MetricsCategoryRegistry service that is provided in the BesuContext at plugin registry time. Give it a unique name.
2. Deploy the plugin to any instance of Besu.
3. Startup the instance, with your new metrics category specified in the list of `--metrics-categories` to collect data on.

**Expected behavior:** new metrics are produced under the new category.

**Actual behavior:** Startup fails, because there is no MetricCategoryConverter for the string provided as an option to `--metrics-categories`. Plugin registration happens AFTER those converters are setup and used to parse the supplied `--metrics-categories` options.

**Frequency:** always

### Logs (if a bug)
Please post relevant logs from Besu (and the consensus client, if running proof of stake) from before and after the issue. 

### Versions (Add all that apply)
* Software version: 24.10.0+
* Java version: 21
",storage: missing data,CWE-665,Improper Initialization,"The bug report describes a failure during application startup caused by an incorrect order of operations. Specifically, the application parses command-line arguments (`--metrics-categories`) before it loads plugins that are supposed to register new, valid metric categories. When the argument parser encounters a category name from a plugin, it fails because that category has not been registered yet. This is a classic initialization problem. The system's resources for handling metric categories are used before they have been fully and correctly initialized by the plugins. 

- CWE-665 (Improper Initialization) is the most accurate choice. The official description states, 'The product does not initialize or incorrectly initializes a resource, which might leave the resource in an unexpected state when it is accessed or used.' In this case, the `MetricsCategoryRegistry` and its associated converters are the resource, and they are accessed (by the command-line parser) before being fully initialized by the plugins, leading to a startup failure.

- CWE-362 (Race Condition) is not applicable. The problem is not caused by two or more concurrent threads accessing a shared resource in an unsynchronized manner. It's a deterministic, sequential logic flaw in the startup process that will fail every time, regardless of thread scheduling.

- CWE-20 (Improper Input Validation) is less accurate. While the failure occurs during the processing of input, the validation logic itself is not the primary flaw. The system correctly identifies that the provided category is unknown *at that point in time*. The root cause is not the validation check but the fact that the system is in an incompletely initialized state when the check is performed. Therefore, Improper Initialization is the more fundamental weakness.",closed,"The issue arises because the plugin registration occurs after the MetricCategoryConverter setup, leading to a failure in recognizing the new metric category specified in the startup options.","This bug prevents the creation and use of custom metric categories by plugins, limiting the functionality and metrics collection capabilities of the Besu instance.",2619358879,7818,"October 28, 2024 7:32 PM (GMT+8)","October 31, 2024 7:50 PM (GMT+8)","['bug', 'P2']",
besu,Besu returns empty trace on block 21030627,https://github.com/hyperledger/besu/issues/7804,API,"**Actual behavior**
Execute
curl -H ""Content-Type: application/json"" -d '{""id"": 1,""jsonrpc"": ""2.0"",""method"": ""trace_block"",""params"":[""0x140e6e3""]}' localhost:8545

Result:
{""jsonrpc"":""2.0"",""id"":1,""result"":[]}

**Expected behavior**
Expected response is a list of traces.

cc @joshuafernandes ",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a scenario where a specific API call (`trace_block` with block `0x140e6e3`) returns an incorrect result (an empty list) instead of the expected data (a list of traces). This is not a crash, but a logical failure for a specific case.

1.  **Analysis of CWE-20 (Improper Input Validation):** This CWE is not a good fit. The input, a block number `0x140e6e3`, is syntactically valid for the API call. The problem is not that the input is malformed or fails validation, but that the application's logic fails to process this specific, valid input correctly.

2.  **Analysis of CWE-391 (Unchecked Error Condition):** This CWE is a possibility but is less precise than the alternative. While the incorrect empty result *could* be the consequence of an internal error being ignored, the bug report does not provide evidence of an unchecked error. The primary observable symptom is the incorrect output, not a confirmed ignored error.

3.  **Analysis of CWE-703 (Improper Check or Handling of Exceptional Conditions):** This is the most accurate CWE. The specific block number likely triggers a rare or exceptional state within the tracing logic that the developers did not anticipate. The system's response—returning an empty list instead of the correct traces or a descriptive error—is a clear example of improperly handling this exceptional condition. The system doesn't crash but produces an incorrect output, which directly aligns with the CWE's description of failing to handle rare conditions correctly.",closed,"The API method 'trace_block' is not returning the expected execution traces for the specified block, possibly due to a misconfiguration or an issue in the tracing mechanism.","Users relying on execution traces for analysis or debugging will not receive the necessary information, which could hinder their ability to investigate transactions or understand block execution.",2610176897,7804,"October 24, 2024 1:35 AM (GMT+8)","November 23, 2024 12:03 AM (GMT+8)","['bug', 'P2']",
besu,p2p-host config leak,https://github.com/hyperledger/besu/issues/7721,API,"Pointed out by `@seamonkey82` on discord.

> Current master attempts to open --metrics-port on the --p2p-host address.

I have verified the bug was introduced in https://github.com/hyperledger/besu/commit/f4dc48d94d276f1ed504b707b8f9ccf278a5cc63

To recreate...
```
 $BESU --p2p-host=9.9.9.9
...
2024-10-04 11:34:28.916+10:00 | main | INFO  | EngineJsonRpcService | Starting JSON-RPC service on 9.9.9.9:8551
```

By default we start JSON-RPC service for engine API on 127.0.0.1. The bug means setting p2p-host is overwriting other host configs.

When you specify the relevant host, that correctly takes precedence...

```
$BESU --rpc-http-host=1.1.1.1 --p2p-host=9.9.9.9
2024-10-04 11:40:22.499+10:00 | main | INFO  | EngineJsonRpcService | Starting JSON-RPC service on 1.1.1.1:8551
```
",api: improper authorization,CWE-284,Improper Access Control,"The bug report describes a situation where a configuration value intended for one service (`--p2p-host`) is incorrectly used by another service (the Engine JSON-RPC service). The direct consequence is that the JSON-RPC service, which should default to a private interface (`127.0.0.1`), instead binds to a potentially public IP address. This action exposes the service to the network, removing the intended network-level access control. 

CWE-284 (Improper Access Control) is the most accurate classification because the bug's primary security impact is that it 'incorrectly restricts access to a resource (the JSON-RPC service) from an unauthorized actor'. By binding to the wrong interface, the application fails to enforce the intended access boundary.

CWE-922 (Insecure Storage of Sensitive Information) is not applicable as the bug does not relate to how information is stored, but rather to the network accessibility of a running service.

CWE-20 (Improper Input Validation) is less accurate. While the root cause is the incorrect use of an input configuration, the input itself (`9.9.9.9`) is not invalid. The core security flaw is not the validation of the input, but the logical error that leads to the exposure of a service, which is an access control failure. Therefore, CWE-284 describes the resulting vulnerability more precisely.",closed,"The implementation of the p2p-host configuration incorrectly allows the metrics port to be opened on the specified p2p-host address, exposing the JSON-RPC service to unintended network interfaces.","This bug could potentially expose the JSON-RPC service to the public internet or other unauthorized networks, leading to unauthorized access and potential exploitation of the service.",2565257236,7721,"October 4, 2024 1:36 AM (GMT+8)","October 4, 2024 5:27 PM (GMT+8)",['bug'],
besu,Bug in `engine_getClientVersionV1` response,https://github.com/hyperledger/besu/issues/7661,API,"### Description

Besu seems to not be following the current spec for `engine_getClientVersionV1`:

https://github.com/hyperledger/besu/blob/9d689b940134b4f7a9b80020829d506417c2065e/ethereum/api/src/main/java/org/hyperledger/besu/ethereum/api/jsonrpc/internal/methods/engine/EngineGetClientVersionV1.java#L50-L56

To me this looks like a single client version object will be returned, but the correct format is a _list_ of versions (usually with 1 element). Spec: 

https://github.com/ethereum/execution-apis/blob/main/src/engine/identification.md#engine_getclientversionv1

We had a bug report on Lighthouse that seems to match this interpretation:

> Sep 21 19:05:11.003 WARN Execution engine call failed            error: Json(Error(""invalid type: map, expected a sequence"", line: 0, column: 0)), service: exec 
> Sep 21 19:05:11.003 WARN Failed to populate engine version cache, error: ApiError(Json(Error(""invalid type: map, expected a sequence"", line: 0, column: 0))), service: beacon 

Lighthouse is expecting a list (sequence) but received a map/JSON object.

### Versions (Add all that apply)

User reported this issue with Besu version v24.9.1, which as far as I can tell is the first version where the endpoint is supported (according to the release notes).

I don't have any other details about their setup, but I don't think they're relevant for this issue.
",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report describes a classic interoperability issue where two software products, Besu and Lighthouse, have different interpretations of a shared API specification. Besu implements the `engine_getClientVersionV1` endpoint to return a single JSON object. However, the official specification and the consuming client, Lighthouse, expect a JSON list (a sequence). This discrepancy in how the specification is interpreted and implemented is the core of the problem. When Lighthouse (Product A) receives the unexpected object from Besu (Product B), it fails to parse the response, leading to an error. This scenario is a direct match for CWE-436, 'Interpretation Conflict', where one product's handling of a step (API response generation) differs from another's (API response consumption), causing a failure. CWE-1389 is irrelevant as the bug does not involve parsing numbers or different radices. CWE-1288 is also incorrect because the issue is with the format of the *output* generated by Besu, not its validation of a complex *input*.",closed,The `engine_getClientVersionV1` method in Besu is returning a single client version object instead of the required list format as specified in the Ethereum execution API documentation.,"This bug may lead to compatibility issues with clients expecting a list of versions, resulting in errors during execution engine calls and potential failure to populate version caches, thereby affecting the overall functionality and interoperability of the blockchain network.",2541425532,7661,"September 23, 2024 2:09 AM (GMT+8)","October 3, 2024 3:13 PM (GMT+8)","['bug', 'RPC']",
besu,"java.util.NoSuchElementException: No value present, processing method: `eth_getBlockReceipts` ",https://github.com/hyperledger/besu/issues/7635,API,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description

It seems that something that could be assent is not handled the right way

```
2024-09-18 14:50:19.794	2024-09-18 12:50:19.788+00:00 | vert.x-worker-thread-0 | ERROR | BaseJsonRpcProcessor | Error processing method: eth_getBlockReceipts [""0x59ede5a197a89592387ba9a5f491692b66769be0a2ffffc88cbbe22f6af9a6b9""]
2024-09-18 14:50:19.794	java.util.NoSuchElementException: No value present
2024-09-18 14:50:19.794		at java.base/java.util.Optional.get(Optional.java:143) ~[?:?]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetBlockReceipts.lambda$getBlockReceiptsResult$0(EthGetBlockReceipts.java:98) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:?]
2024-09-18 14:50:19.794		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682) ~[?:?]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetBlockReceipts.lambda$getBlockReceiptsResult$1(EthGetBlockReceipts.java:99) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at java.base/java.util.Optional.map(Optional.java:260) ~[?:?]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetBlockReceipts.getBlockReceiptsResult(EthGetBlockReceipts.java:95) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetBlockReceipts.resultByBlockHash(EthGetBlockReceipts.java:69) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.handleParamTypes(AbstractBlockParameterOrBlockHashMethod.java:143) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.response(AbstractBlockParameterOrBlockHashMethod.java:151) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:44) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TracedJsonRpcProcessor.process(TracedJsonRpcProcessor.java:54) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TimedJsonRpcProcessor.process(TimedJsonRpcProcessor.java:45) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.handlers.AbstractJsonRpcExecutor.executeRequest(AbstractJsonRpcExecutor.java:87) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.handlers.JsonRpcObjectExecutor.execute(JsonRpcObjectExecutor.java:57) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$0(JsonRpcExecutorHandler.java:57) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at java.base/java.util.Optional.ifPresentOrElse(Optional.java:196) ~[?:?]
2024-09-18 14:50:19.794		at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$2(JsonRpcExecutorHandler.java:54) ~[besu-api-24.9-delivery32.jar:24.9-delivery32]
2024-09-18 14:50:19.794		at io.vertx.ext.web.impl.BlockingHandlerDecorator.lambda$handle$0(BlockingHandlerDecorator.java:48) ~[vertx-web-4.5.9.jar:4.5.9]
2024-09-18 14:50:19.794		at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191) ~[vertx-core-4.5.9.jar:4.5.9]
2024-09-18 14:50:19.794		at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:279) ~[vertx-core-4.5.9.jar:4.5.9]
2024-09-18 14:50:19.794		at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210) ~[vertx-core-4.5.9.jar:4.5.9]
2024-09-18 14:50:19.795		at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
2024-09-18 14:50:19.795		at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
2024-09-18 14:50:19.795		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.112.Final.jar:4.1.112.Final]
2024-09-18 14:50:19.795		at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
```",api: api unavailability,CWE-755,Improper Handling of Exceptional Conditions,"The bug report shows a `java.util.NoSuchElementException` being thrown from a call to `java.util.Optional.get()`. This specific exception occurs when `.get()` is called on an empty `Optional` object. This indicates that the code did not properly handle the case where the Optional might not contain a value, which is an 'exceptional condition'. 

- CWE-476 (NULL Pointer Dereference) is not the best fit. Although conceptually similar to accessing a null value, the error is a `NoSuchElementException` from an `Optional`, not a `NullPointerException`. The `Optional` type is specifically used to avoid null pointer issues, but it requires proper handling.

- CWE-248 (Uncaught Exception) is also not the most accurate choice. The stack trace shows the exception is logged by `BaseJsonRpcProcessor`, which implies it was caught by a general-purpose handler higher up the call stack. The fundamental weakness is not that the exception was completely uncaught, but that the code logic within the `EthGetBlockReceipts` method failed to handle a foreseeable exceptional state (the empty Optional), thus causing the exception to be thrown in the first place.

- CWE-755 (Improper Handling of Exceptional Conditions) is the most accurate description. The code failed to check if the `Optional` had a value before attempting to retrieve it, which is a failure to correctly handle the exceptional condition of the value being absent. This improper handling is the direct cause of the runtime exception.",closed,"The method `eth_getBlockReceipts` attempts to access a value from an `Optional` that is empty, leading to a `NoSuchElementException`. This indicates that the code does not properly check for the presence of a value before attempting to retrieve it.","This bug can cause the API to fail when attempting to retrieve block receipts for a specific block hash that does not exist or is not available, resulting in a poor user experience and potential service downtime.",2533704911,7635,"September 18, 2024 1:10 PM (GMT+8)","October 11, 2024 7:14 AM (GMT+8)","['bug', 'good first issue', 'RPC']",
besu,Bela Verification Failed - account hash missing storage trie node,https://github.com/hyperledger/besu/issues/7620,Storage,"Successfully synced and bug-free nodes can occasionally still have trie node data missing, as discovered through running [Bela BonsaiTreeVerifier](https://github.com/Consensys/bela/blob/871f0b36a13bc49c554f84ea21d05ce98b5df5ca/src/main/java/org/hyperledger/bela/utils/bonsai/BonsaiTreeVerifier.java)

For example:
```
account hash 0x615cd098e18cd36c5a62016fb4e096c02cf71532abcb04f2e7a5661972a86932 
missing storage trie node for hash
 0x9987f9dc77f7516f7710cbf0514f6941d3905bc9c4e14c864586fea3f42856a6 and location 0x
```

Frequency: Three occurrences in recent burn ins.

Each time it has been the storage root hash, `0x` that has been missing. Some child node data is present for this storage trie..

More details: https://github.com/Consensys/protocol-misc/issues/972#issuecomment-2339351262",storage: missing data,CWE-345,Insufficient Verification of Data Authenticity,"The bug report describes an intermittent data corruption issue where a 'storage trie node' is found to be missing 'occasionally' on 'successfully synced' nodes. The intermittent and unpredictable nature of the bug ('occasionally', 'Three occurrences in recent burn ins') is a classic symptom of a race condition. In a complex system like a blockchain node, multiple processes or threads likely operate concurrently to write data to storage (the shared resource). The missing data suggests that these concurrent operations are not properly synchronized, leading to a state where the data structure becomes inconsistent. This aligns perfectly with the definition of CWE-362, which describes a timing window where a shared resource can be improperly modified by concurrent code. 

CWE-1304 is incorrect as the bug report makes no mention of power save/restore operations or hardware configuration state. 

CWE-841 is a less suitable fit. While one could argue a data writing 'workflow' is failing, the root cause described by the symptoms points more specifically to a concurrency problem rather than a general failure to enforce a sequence of behaviors by an actor. The problem is a low-level data integrity failure, not a user-level or session-level workflow violation.",closed,"The issue arises from the inability of the system to verify the presence of all necessary trie nodes during synchronization, leading to missing storage trie nodes even in successfully synced nodes.","This bug could lead to discrepancies in account states, causing potential data integrity issues, which may affect smart contract execution, user balances, and overall trust in the blockchain network.",2527272400,7620,"September 16, 2024 12:00 AM (GMT+8)","October 2, 2024 7:29 PM (GMT+8)","['bug', 'P3']",
besu,MerkleTrieException: Unable to load trie node value for hash,https://github.com/hyperledger/besu/issues/7619,Storage,"During the Flat DB Heal Phase:

```
{""@timestamp"":""2024-08-18T07:18:32,388"",""level"":""INFO"",""thread"":""EthScheduler-Services-34 (batchHealAndPersistFlatStorageData)"",""class"":""Pipeline"",""message"":""Unexpected exception in pipeline. Aborting.
Throwable summary: org.hyperledger.besu.ethereum.trie.MerkleTrieException: Unable to load trie node value for hash 0x267b3bb0ed916698d79ef287f7075fcb8ed14c5f7da6e804823d376404e9f781 location 0x02030b0b
	at: org.hyperledger.besu.ethereum.trie.StoredNode.lambda$load$0(StoredNode.java:135)"",""throwable"":""""}
```

Symptoms are that the node is essentially unrecoverable without resyncing the world state. One of the nodes did actually get lucky and heal the broken part of the node upon restarting...this probably can occur if the repivot contains changes to the relevant part of the trie.

Frequency: Three occurrences in recent burn ins.

Each time it's been preceeded by a RocksDB Busy error in the Trie Heal Phase:
```
{""@timestamp"":""2024-08-17T14:03:38,441"",""level"":""INFO"",""thread"":""EthScheduler-Services-26 (batchPersistTrieNodeData)"",""class"":""PersistDataStep"",""message"":""Encountered 1 retryable RocksDB errors, latest error message org.rocksdb.RocksDBException: Busy"",""throwable"":""""}
```

More details here https://github.com/Consensys/protocol-misc/issues/972#issuecomment-2339351262",storage: storage persistence failure,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a sequence of events where a 'retryable RocksDB errors, latest error message org.rocksdb.RocksDBException: Busy' occurs, which is an exceptional condition. The system's subsequent failure to handle this condition correctly leads to a more severe, fatal exception: 'org.hyperledger.besu.ethereum.trie.MerkleTrieException: Unable to load trie node value'. This results in the node entering an unrecoverable state, requiring a full resync. This chain of events directly aligns with the definition of CWE-703, which states 'The product does not properly anticipate or handle exceptional conditions that rarely occur during normal operation of the product.' The initial 'Busy' error is the exceptional condition, and the subsequent 'MerkleTrieException' and unrecoverable state are the results of the improper handling. While CWE-662 (Improper Synchronization) could be a potential root cause for the 'RocksDB Busy' error due to the multi-threaded environment, the bug report's primary evidence points to the failure in the error handling logic itself, making CWE-703 the most direct and accurate classification of the manifested weakness. CWE-841 is not applicable as the issue is not about an incorrect sequence of operations but rather a failure to handle an error within a workflow.",closed,"The bug arises from an inability to load a trie node due to a failure in the underlying RocksDB causing it to be busy, which leads to exceptions during the trie healing process.","The node becomes unrecoverable without resyncing the world state, which could lead to data loss or downtime for the blockchain network, affecting transaction processing and overall network reliability.",2527270840,7619,"September 15, 2024 11:55 PM (GMT+8)","October 9, 2024 6:01 PM (GMT+8)","['bug', 'P2']",
besu,"`evmtool` Returns Long Null String in JSON `error` Field When Executing `REVERT` ",https://github.com/hyperledger/besu/issues/7608,Execution,"

### Description
Hello developers!

I'm doing fuzzing on EVM implementations, and I'm using `besu/evm-tool` for testing. I found a log error that when executing the opcode REVERT(0XFD), the `getRevertReason()` of `besu/evm-tool` will return a long null string in the `error` field of json when no revert reason is available, such as `\u0000\u0000`.

### Steps to Reproduce 
1. I try to reproduce this on the latest develop version of `besu/evm-tool`(6ed1db32ae3c1b5bdc0576321fee35157feb6ae4). I build `evmtool` with: 
```shell
./gradlew --parallel ethereum:evmTool:installDist 
```
2. The bytecode to be executed:
```
# BYTECODE
60255ffd
# MENMONICS
PUSH1 25 //size
PUSH0 //offset
REVERT
```
3. Run the besu/evm-tool with:
```shell
./ethereum/evmtool/build/install/evmtool/bin/evmtool --code 60255ffd --json
```
**Expected behavior:** If no Revert reason is available, no `error` field is needed.

**Actual behavior:** `evmtool` will output meaningless `\u0000`s.
```json
{""pc"":0,""op"":96,""gas"":""0x2540be400"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":2,""op"":95,""gas"":""0x2540be3fd"",""gasCost"":""0x2"",""memSize"":0,""stack"":[""0x25""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":3,""op"":253,""gas"":""0x2540be3fb"",""gasCost"":""0x6"",""memSize"":0,""stack"":[""0x25"",""0x0""],""depth"":1,""refund"":0,""opName"":""REVERT"",""error"":""\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000""}

{""stateRoot"":""0x24ac5f36f02918efac8340b49f4cb41f45ac0bedb8dcfa511b4bfac6da08299a"",""output"":""0x00000000000000000000000000000000000000000000000000000000000000000000000000"",""gasUsed"":""0xb"",""pass"":true,""fork"":""Cancun"",""timens"":4076285,""time"":4076}
```

**Frequency:** Always.

### Logs (if a bug)
This is a reference result from `geth/evm`:
```json
{""pc"":0,""op"":96,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":2,""op"":95,""gas"":""0xfffffc"",""gasCost"":""0x2"",""memSize"":0,""stack"":[""0x25""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":3,""op"":253,""gas"":""0xfffffa"",""gasCost"":""0x6"",""memSize"":0,""stack"":[""0x25"",""0x0""],""depth"":1,""refund"":0,""opName"":""REVERT""}
{""pc"":3,""op"":253,""gas"":""0xfffffa"",""gasCost"":""0x6"",""memory"":""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",""memSize"":64,""stack"":[],""depth"":1,""refund"":0,""opName"":""REVERT"",""error"":""execution reverted""}
{""output"":""00000000000000000000000000000000000000000000000000000000000000000000000000"",""gasUsed"":""0xb"",""error"":""execution reverted""}
```

### Versions (Add all that apply)
* Software version: 24.8.0
* Java version: 22.0.2
* OS Name & Version: Ubuntu 20.04
* Virtual Machine software & version: WSL version：2.2.4.0

Thanks for your time!

",evm: simulation inconsistency,CWE-20,Improper Input Validation,"The bug report describes a situation where the `evmtool` processes the EVM's `REVERT` opcode. When no specific revert reason is provided, the underlying memory is likely zero-initialized. The tool's `getRevertReason()` function reads a specified number of bytes from this memory and includes them directly in the JSON output's `error` field, resulting in a string of null characters (`\u0000...`). The expected behavior is to either omit the `error` field or provide a standard message, which implies a check should be performed. This aligns best with CWE-20 (Improper Input Validation). The 'input' in this context is the segment of EVM memory designated as the revert reason. The software fails to validate this input to determine if it contains a meaningful reason before processing it into the output string. This leads to incorrect, meaningless output. CWE-170 (Improper Null Termination) is less suitable because the problem is not a missing or incorrect string terminator causing a buffer over-read; rather, it's the content of the string itself that is improper due to a lack of validation. CWE-400 (Uncontrolled Resource Consumption) is not applicable as the report does not describe any issue related to resource exhaustion.",closed,"The `getRevertReason()` function in `besu/evm-tool` returns a long null string when no revert reason is provided, instead of omitting the `error` field entirely.","This bug could lead to confusion for developers and users testing the EVM implementation, as the presence of an unnecessary long null string in the `error` field may obscure meaningful output and hinder debugging efforts.",2521933628,7608,"September 12, 2024 10:01 AM (GMT+8)","October 28, 2024 1:19 PM (GMT+8)","['bug', 'good first issue', 'P3']",
besu,EngineGetClientVersionV1 fails for local build of Besu,https://github.com/hyperledger/besu/issues/7585,API,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
The `engine_getClientVersionV1` fails with an NPE when running Besu locally using Intellij without doing a gradle build. This is caused by the commit being null and attempting to split the null string in the `EngineGetClientVersionV1` method.

Error in the log:
2024-09-09 08:54:50.573+10:00 | vert.x-eventloop-thread-8 | ERROR | ExecutionEngineJsonRpcMethod | failed to exec consensus method engine_getClientVersionV1, error: Cannot invoke ""String.substring(int, int)"" because ""this.commit"" is null",api: api unavailability,CWE-476,NULL Pointer Dereference,"The bug report explicitly details a failure caused by a Null Pointer Exception (NPE). The provided error log, `Cannot invoke ""String.substring(int, int)"" because ""this.commit"" is null`, is a direct manifestation of a null pointer (or null reference in Java) being used as if it were a valid object. This aligns perfectly with the definition of CWE-476: 'The product dereferences a pointer that it expects to be valid but is NULL.' The code attempts to call the `.substring()` method on the `commit` variable, which is `null`, causing the application to crash. While CWE-665 (Improper Initialization) describes the root cause for why the `commit` variable is null (it's not set correctly during a local IDE run), CWE-476 describes the direct, immediate fault that is reported. CWE-20 (Improper Input Validation) is unsuitable because the `commit` variable is internal state derived from the build environment, not external input that needs validation. Therefore, CWE-476 is the most accurate and specific classification for the fault described in the bug report.",closed,"The method `EngineGetClientVersionV1` attempts to operate on a null string (commit) without proper null checks, leading to a NullPointerException (NPE).","This bug prevents the retrieval of the client version, which may hinder local development and testing efforts, as users will not be able to successfully call this API method.",2512613754,7585,"September 8, 2024 11:01 PM (GMT+8)","September 30, 2024 7:15 AM (GMT+8)","['bug', 'good first issue', 'snack', 'RPC', 'TeamCerberus']",
besu,Bug in `SimpleWorld.commit()` ?,https://github.com/hyperledger/besu/issues/7524,Others,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
Currently, `SimpleWorld.commit()` is defined as follows:

```java
@Override
  public void commit() {
    accounts.forEach(
        (address, account) -> {
          if (!account.updateParent()) {
            parent.accounts.put(address, account);
          }
        });
  }
```

However, this seems to be in conflict with this:

```java
  @Override
  public Collection<Address> getDeletedAccountAddresses() {
    return accounts.entrySet().stream()
        .filter(e -> e.getValue() == null)
        .map(Map.Entry::getKey)
        .toList();
  }
```

It seems to me that we want `account == null || !account.updateParent()` as the criteria in `commit()` above.

Thoughts?",general: general improper authorization,CWE-476,NULL Pointer Dereference,"The bug report describes a situation in the `commit()` method where the code iterates through a map of accounts. For each account, it directly calls `account.updateParent()`. However, as indicated by the logic in `getDeletedAccountAddresses()`, an entry in the accounts map can have a `null` value to signify a deleted account. The original code does not check if the `account` variable is `null` before attempting to call a method on it (`.updateParent()`). This action of using a variable that could be `null` as if it were a valid object reference is a direct instance of a NULL Pointer Dereference. This perfectly aligns with the definition of CWE-476: 'The product dereferences a pointer that it expects to be valid but is NULL.' The proposed fix `account == null || !account.updateParent()` explicitly adds the missing null check. CWE-703 is too general, as CWE-476 describes the specific cause of the exceptional condition. CWE-20 is not applicable because the issue is not with validating external input, but with handling the state of an internal data structure.",closed,"The `commit()` method in `SimpleWorld` does not properly handle cases where an account is null, leading to potential inconsistencies when updating parent accounts.","This bug could lead to accounts not being updated correctly, potentially allowing deleted accounts to persist incorrectly in the parent structure, which may cause data integrity issues within the blockchain state.",2487367142,7524,"August 26, 2024 5:21 PM (GMT+8)","September 2, 2024 8:16 PM (GMT+8)","['bug', 'good first issue', 'testing', 'P4', 'snack']",
besu,"debug_traceCall fails with ""gasPrice is less than the current BaseFee"" while `eth_call` works",https://github.com/hyperledger/besu/issues/7503,API,"Reported on Eth R&D.

Example call that fails
```
curl --data '{
      ""jsonrpc"": ""2.0"",
      ""id"": 0,
      ""method"": ""debug_traceCall"",
      ""params"": [ {
            ""to"": ""0x0aae40965e6800cd9b1f4b05ff21581047e3f91e"",
            ""data"": ""0x000000000000000000000000000000000000000000000000000000000001A00E""
        }, ""latest""]
    }'  -H ""Content-Type: application/json""  -X POST

{""jsonrpc"":""2.0"",""id"":0,""error"":{""code"":-32603,""message"":""Internal error"",""data"":""gasPrice is less than the current BaseFee""}} 
```
",api: api unavailability,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report describes a scenario where the `debug_traceCall` API method fails with an internal error when the optional `gasPrice` parameter is not provided. The error message, ""gasPrice is less than the current BaseFee"", indicates that a specific conditional check is failing. This situation, where an optional parameter is omitted, represents an unusual but valid condition that the software should handle. The fact that a similar method, `eth_call`, handles the same input correctly demonstrates that the input is valid, but the internal logic for `debug_traceCall` is flawed.

CWE-1389 (Incorrect Parsing of Numbers with Different Radices) is incorrect because the bug is not related to misinterpreting the base of a number.

CWE-20 (Improper Input Validation) is too general. The input is not inherently invalid, as another part of the application (`eth_call`) processes it successfully. The issue is not a failure to validate the input at the boundary, but rather a failure in the subsequent internal logic that handles this specific case.

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is the most accurate fit. The bug arises because the code for `debug_traceCall` does not correctly handle the exceptional condition of a missing `gasPrice`. It proceeds to a state where a check for this condition is performed improperly, leading to the failure. This perfectly aligns with the CWE's description of not checking or incorrectly checking for unusual or exceptional conditions.",closed,"The `debug_traceCall` method is failing due to a mismatch between the gas price specified in the call and the current base fee required by the Ethereum network, which is not enforced by the `eth_call` method.","This bug can lead to confusion for developers and users relying on `debug_traceCall` for debugging and analysis, as it can falsely indicate that a transaction is invalid due to gas price issues when it might work under other methods like `eth_call`. This could hinder development and debugging processes.",2478305699,7503,"August 21, 2024 3:11 PM (GMT+8)","September 13, 2024 9:35 PM (GMT+8)","['bug', 'good first issue', 'RPC']",
besu,"[QBFT] Besu Tesnet , Not getting token in alloc address ",https://github.com/hyperledger/besu/issues/7484,Utilities,"Hi there, 

Im trying to run besu QBFT private network , with following genesis file :

`{
  ""genesis"": {
    ""config"": {
      ""chainId"": 7474,
      ""berlinBlock"": 0,
      ""shanghaiTime"":17034870,
      ""contractSizeLimit"": 2147483647,
      ""qbft"": {
        ""blockperiodseconds"": 60,
        ""epochlength"": 30000,
        ""requesttimeoutseconds"": 60
      }
    },
    ""nonce"": ""0x0"",
    ""timestamp"": ""0x58ee40ba"",
    ""gasLimit"": ""0x1fffffffffffff"",
    ""difficulty"": ""0x1"",
    ""mixHash"": ""0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365"",
    ""coinbase"": ""0x0000000000000000000000000000000000000000"",
    ""alloc"": {
       ""0xf606b4B10E0B6863165d0E8077e36Bf06e199123"": { 
        ""balance"": ""0x3635C9ADC5DEA00000"" 
      },
      ""0x0Ce98c77E8ffB8Da3eea4dC5C985e53Ae0f670F8"": { 
      ""balance"": ""0x3635C9ADC5DEA00000"" 
      }
    }
  },
  ""blockchain"": {
    ""nodes"": {
      ""generate"": true,
      ""count"": 5
    }
  }
}`

Blocks are getting produced , but im not getting the token in particular wallet address.
",general: initialization failure,CWE-665,Improper Initialization,"The user is reporting an initialization failure where the system does not correctly set up the initial state based on a provided configuration file. The `genesis.json` file serves as the primary input for the blockchain's initial setup. The bug is that the `alloc` section of this input, which specifies initial token balances for certain addresses, is not processed correctly, resulting in those addresses not receiving their funds. This is a direct failure to correctly handle input data. 

- CWE-20 (Improper Input Validation) is the best fit. The official description states the product 'does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' The system is failing to process the `alloc` input data correctly, leading to an incorrect blockchain state. 

- CWE-390 (Detection of Error Condition Without Action) is not suitable because there is no indication in the report that the system detected an error at all. It simply proceeded with an incorrect configuration.

- CWE-754 (Improper Check for Unusual or Exceptional Conditions) is also not a good fit. Specifying initial account allocations in a genesis file is a standard, expected operation for setting up a private network, not an unusual or exceptional condition.",closed,"The issue arises from the improper allocation of tokens to specific wallet addresses in the genesis configuration, potentially due to misconfiguration in the genesis file or a bug in the token allocation logic.","The consequence of this bug is that the specified wallet addresses do not receive the allocated tokens, which could lead to issues with transaction validation, user trust, and overall functionality of the private network.",2473622247,7484,"August 19, 2024 3:20 PM (GMT+8)","September 30, 2024 8:05 AM (GMT+8)","['bug', 'P2', 'question', 'non mainnet (private networks)']",
besu,CLI option --override-genesis-config not working as it used to,https://github.com/hyperledger/besu/issues/7439,Utilities,"### Description

I noticed a side effect of a change in Besu that has made it incompatible with Teku acceptance tests. The TLDR is that Besu is not respecting the parameters we use with the option `--override-genesis-config`.

For example, in Teku acceptance tests, we calculate the genesis time of the network and use the override to set `shanghaiTime`.

This problem seems to have started here:  https://github.com/hyperledger/besu/pull/7012, unfortunately, I started looking into it but it was taking too long and I had other things that I had to do. The gist of the issue is how we are not propagating `Map<String, String> genesisConfigOverrides` down to `ConsensusScheduleBesuControllerBuilder` how we used to.

The result is that some values are being correctly overwritten, while some others are not (it really depends on what object is consuming the correct map of overrides).

### Acceptance Criteria
* `--override-genesis-config` values being correctly applied, as if the values were part of the original genesis file.

### Steps to Reproduce (Bug)
1. Start Besu with `--override-genesis-config=""shanghaiTime=123""`

**Expected behavior:** `shanghaiTime` correctly applied on protocol schedule. 

**Actual behavior:** `shanghaiTime` is not correctly applied on protocol schedule.

**Frequency:** Always

### Logs (if a bug)
N/A

### Versions (Add all that apply)
All versions post https://github.com/hyperledger/besu/commit/690a2ea81e2bf62508ff16675cd7dbaeb006fa83",general: initialization failure,CWE-665,Improper Initialization,"The bug report describes a scenario where a command-line option, `--override-genesis-config`, fails to correctly apply configuration values during the startup process. The report explicitly states that the `genesisConfigOverrides` map is not being correctly propagated to the `ConsensusScheduleBesuControllerBuilder`. This builder is responsible for initializing the protocol schedule resource. Because the builder does not receive the necessary override data, it initializes the resource incorrectly, leaving it in an unexpected state where the `shanghaiTime` value is not what the user specified. This directly matches the definition of CWE-665: 'The product does not initialize or incorrectly initializes a resource, which might leave the resource in an unexpected state.'

CWE-1389 is incorrect because the issue is not related to parsing a number with the wrong base (radix); the configuration value is ignored altogether, not misinterpreted.

CWE-436 is less suitable because, while the bug does cause an 'Interpretation Conflict' with the Teku testing suite, this describes the external symptom of the bug's impact on another system. CWE-665 is more precise as it identifies the root cause of the vulnerability within the Besu application itself: a failure during the initialization phase.",closed,"The bug arises from a failure to propagate the 'genesisConfigOverrides' map to the 'ConsensusScheduleBesuControllerBuilder' after changes made in a recent code update, resulting in inconsistent application of override values.","As a consequence, the expected genesis configuration values, such as 'shanghaiTime', are not applied correctly, leading to potential incompatibility with acceptance tests and incorrect behavior in the blockchain protocol.",2459766175,7439,"August 11, 2024 9:20 PM (GMT+8)","August 21, 2024 7:50 AM (GMT+8)","['bug', 'good first issue', 'P2']",
besu,`eth_estimateGas` does not respect the `block` parameter,https://github.com/hyperledger/besu/issues/7414,API,"### Description
As defined by the standard https://ethereum.github.io/execution-apis/api-documentation/ `eth_estimateGas` have a second optional parameter that specified the block to use for the estimation, we ignore that option and just use the chain head in every case.

### Acceptance Criteria

`eth_estimateGas` adhere to the standard and accepts and uses the value passed in the `block` parameter to perform the estimation.

",api: improper authorization,CWE-670,Always-Incorrect Control Flow Implementation,"The bug report states that the `eth_estimateGas` function has an optional `block` parameter which is ignored, and the function always uses the 'chain head' instead. The intended algorithm, as defined by the standard, requires the function to use the `block` parameter for estimation if it is provided. The current implementation has a faulty control flow; it does not branch to handle the case where the `block` parameter is present. Instead, it always follows a single, unconditional path (using the chain head), which is incorrect whenever the `block` parameter is supplied. 

- **CWE-20 (Improper Input Validation)** is incorrect because the issue is not with validating the input's properties but with the program logic completely ignoring the valid input.

- **CWE-436 (Interpretation Conflict)** is plausible because the implementation's behavior conflicts with the standard. However, it's a high-level description of the problem's context rather than the specific code-level flaw.

- **CWE-670 (Always-Incorrect Control Flow Implementation)** is the most accurate choice. It precisely describes the root cause: 'The code contains a control flow path that does not reflect the algorithm that the path is intended to implement'. The implementation fails to correctly implement the conditional logic required by the standard, leading to an always-incorrect behavior for a specific input scenario (when the `block` parameter is used).",closed,"`eth_estimateGas` does not implement the functionality to use the `block` parameter as specified in the Ethereum execution API standard, leading to the default usage of the chain head for gas estimation.","This bug can lead to inaccurate gas estimations, potentially causing transactions to fail due to insufficient gas if the block parameter was meant to reflect a different state of the blockchain.",2440045820,7414,"July 31, 2024 1:19 PM (GMT+8)","September 5, 2024 10:25 PM (GMT+8)","['bug', 'good first issue', 'RPC']",
besu,debug_metrics Method Error,https://github.com/hyperledger/besu/issues/7383,API,"
### Description
When invoking the `debug_metrics` method, a `ClassCastException` is thrown.

### Acceptance Criteria
* The `debug_metrics` method should return metrics data without throwing exceptions.

### Steps to Reproduce (Bug)
1. Start Besu with the following command:
Execute the following curl command:

curl -X POST --data '{""jsonrpc"":""2.0"",""method"":""debug_metrics"",""params"":[],""id"":1}' http://192.168.40.91:8545
Expected behavior: The debug_metrics method should execute without throwing an exception and return the appropriate metrics data.
Actual behavior: A ClassCastException is thrown, indicating that a java.lang.Double cannot be cast to a java.util.Map.
Frequency: 100% of the time.

Logs (if a bug)
2024-07-26 11:04:29.415+09:00 | vert.x-worker-thread-9 | ERROR | BaseJsonRpcProcessor | Error processing method: debug_metrics []
java.lang.ClassCastException: class java.lang.Double cannot be cast to class java.util.Map (java.lang.Double and java.util.Map are in module java.base of loader 'bootstrap')
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.getNextMapLevel(DebugMetrics.java:75)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.addLabelledObservation(DebugMetrics.java:64)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.addObservation(DebugMetrics.java:57)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.lambda$response$0(DebugMetrics.java:46)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
    at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
    at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
    at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
    at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
    at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
    at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
    at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
    at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
    at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
    at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
    at java.base/java.util.concurrent.ConcurrentHashMap$KeySpliterator.forEachRemaining(ConcurrentHashMap.java:3573)
    at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
    at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
    at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
    at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
    at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
    at java.base/java.util.concurrent.ConcurrentHashMap$KeySpliterator.forEachRemaining(ConcurrentHashMap.java:3573)
    at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
    at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
    at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
    at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
    at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
    at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.response(DebugMetrics.java:46)
    at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:44)
    at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TracedJsonRpcProcessor.process(TracedJsonRpcProcessor.java:54)
    at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TimedJsonRpcProcessor.process(TimedJsonRpcProcessor.java:45)
    at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92)
    at org.hyperledger.besu.ethereum.api.handlers.AbstractJsonRpcExecutor.executeRequest(AbstractJsonRpcExecutor.java:87)
    at org.hyperledger.besu.ethereum.api.handlers.JsonRpcObjectExecutor.execute(JsonRpcObjectExecutor.java:57)
    at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$0(JsonRpcExecutorHandler.java:57)
    at java.base/java.util.Optional.ifPresentOrElse(Optional.java:196)
    at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$2(JsonRpcExecutorHandler.java:54)
    at io.vertx.ext.web.impl.BlockingHandlerDecorator.lambda$handle$0(BlockingHandlerDecorator.java:48)
    at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191)
    at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:279)
    at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210)
    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
    at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    at java.base/java.lang.Thread.run(Thread.java:1583)


Besu version 24.6.0
Software version: besu/v24.6.0/linux-x86_64/openjdk-java-21
Java version: openjdk 21
OS Name & Version: Ubuntu 20.04.2 LTS

### Please solve this problem....
",api: api unavailability,CWE-704,Incorrect Type Conversion or Cast,"The bug report explicitly details a `java.lang.ClassCastException` with the message 'class java.lang.Double cannot be cast to class java.util.Map'. This is the central issue. I will now evaluate the provided CWEs against this core fact.

1. **CWE-704 (Incorrect Type Conversion or Cast):** The official definition is 'The product does not correctly convert an object, resource, or structure from one type to a different type.' The observed `ClassCastException` is a direct manifestation of this weakness. The code attempts to use an object of type `Double` as if it were a `Map`, which is a failed type cast. This CWE is a perfect match for the root cause of the bug.

2. **CWE-248 (Uncaught Exception):** While it is true that an exception is thrown and bubbles up, causing the method to fail, this is a symptom of the problem, not the root cause. The reason the exception is thrown in the first place is the incorrect cast. Therefore, CWE-704 is a more precise and fundamental classification of the error than CWE-248.

3. **CWE-20 (Improper Input Validation):** The bug report shows the method is called with an empty `params` array. The error occurs deep within the method's logic while processing internal metrics data, not while handling the external input. The issue is an incorrect assumption about the type of this internal data, not a failure to validate user-provided input. Therefore, CWE-20 is not applicable.

Conclusion: CWE-704 is the most accurate choice as it directly describes the root cause of the failure—an incorrect and failing type cast—which is explicitly stated in the bug report's logs.",closed,"The bug is caused by an incorrect type casting in the `debug_metrics` method, where a `java.lang.Double` is attempted to be cast to a `java.util.Map`, leading to a `ClassCastException`.","This bug prevents the `debug_metrics` method from functioning correctly, causing it to throw an exception every time it is called. As a result, users are unable to retrieve critical metrics data, which can hinder diagnostics and monitoring efforts.",2431281900,7383,"July 26, 2024 2:17 AM (GMT+8)","August 23, 2024 8:06 AM (GMT+8)","['bug', 'good first issue', 'P3', 'RPC']",
besu,TrieLogPruner.preloadQueue Performance Issue,https://github.com/hyperledger/besu/issues/7322,Storage,"First alerted when Discord user **ktmkancha** mentioned they upgraded to Besu 24.6.0 (which enabled bonsai-limit-trie-log-enabled by default) and TrieLogPruner was taking 45mins+ to load. It is suspected this user hadn't pruned their trie log backlog and is it not known how much trie log data they have.

A second instance of this was reported to me by @gfukushima when upgrading his node, `dev-clc-bu-tk-mainnet-mainnet-archive-bkp` which contained 112 GiB (47 GiB of which is SST files, 64 GiB is BlobDB files):
```
| Column Family                  | Keys            | Total Size  | SST Files Size  | Blob Files Size  |
|--------------------------------|-----------------|-------------|-----------------|------------------|
| TRIE_LOG_STORAGE               | 1564331         | 112 GiB     | 47 GiB          | 64 GiB           |
```

The time taken was ~45 mins...

```
{""@timestamp"":""2024-07-11T23:45:46,224"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loading first 30000 trie logs from database..."",""throwable"":""""}
{""@timestamp"":""2024-07-12T00:32:30,543"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loaded 30000 trie logs from database"",""throwable"":""""}
```

Subsequent restarts of this node took ~2 mins to load...
```
{""@timestamp"":""2024-07-13T03:16:19,846"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loading first 30000 trie logs from database..."",""throwable"":""""}
{""@timestamp"":""2024-07-13T03:18:20,768"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loaded 30000 trie logs from database"",""throwable"":""""}
```

Note, that the first restart pruned ~30_000 trie logs so the total to load reduced by ~2% (from 1,564,331 keys to 1,534,331).

I did some further testing of another canary, `prd-elc-besu-lighthouse-mainnet-nightly-bonsai-snap` which contained 70 GiB of trie logs (majority of which is BlobDB files)...
```
|--------------------------------|-----------------|-------------|-----------------|------------------|
| Column Family                  | Keys            | Total Size  | SST Files Size  | Blob Files Size  |
|--------------------------------|-----------------|-------------|-----------------|------------------|
| TRIE_LOG_STORAGE               | 954612          | 70 GiB      | 42 MiB          | 70 GiB           |
```

This yielded loading times of only 20 seconds...
```
""@timestamp"":""2024-07-12T03:36:29,189"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loading first 30000 trie logs from database..."",""throwable"":""""}
{""@timestamp"":""2024-07-12T03:36:47,824"",""level"":""INFO"",""thread"":""main"",""class"":""TrieLogPruner"",""message"":""Loaded 30000 trie logs from database"",""throwable"":""""}
```

The default loading window size is 30_000. This was based on some testing which showed this to take between 4-7 seconds for a node with 37 GiB of TRIE_LOG_STORAGE (which predates the [storage of trie logs as BlobDB](https://github.com/hyperledger/besu/pull/6289) so it would have been all SST files): https://github.com/hyperledger/besu/pull/6026#issuecomment-1786302255

---

Since the tests were only done on 37 GiB of data, it seems plausible that the performance degrades in a non-linear fashion, potentially quite rapidly if the size of the database is large.

The difference between the canaries could be explained by the amount of SST vs BlobDB files. A large number of SST files would be present on older nodes since the BlobDB was only enabled in [24.3.0](https://github.com/hyperledger/besu/releases/tag/24.3.0) and applies from time of upgrade onwards, it is not retrospectively applied to old SST files.

An interesting observation is that for gfukushima's node, `dev-clc-bu-tk-mainnet-mainnet-archive-bkp`, loading time dropped from 45 mins to 2 mins, with only a difference of 30_000 trie logs. This perhaps suggests there is something else going on beyond simply the size of the TRIE_LOG_STORAGE column family.

Another potentially significant factor is that both the user and gfukushima's nodes' besu version was being upgraded when the 45mins loading event occurred. In gfukushima's case, from 24.3.0 -> 24.6.0.
",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a severe performance issue where a process, `TrieLogPruner.preloadQueue`, takes an excessive amount of time (45+ minutes) to complete. This behavior is triggered when the system encounters a large volume of unpruned trie log data (e.g., 112 GiB). The core problem is that the time required for the operation grows in a non-linear, uncontrolled fashion with the size of the input data, making the application extremely slow to start. This is a classic example of uncontrolled resource consumption, where the primary resource being consumed is time/CPU cycles. 

- **CWE-400 (Uncontrolled Resource Consumption)** is the most accurate fit. The official description states, 'The product does not properly control the allocation and maintenance of a limited resource.' In this case, processing time is the limited resource, and the application fails to control its consumption when faced with a large database, leading to a form of denial of service (prolonged startup). The bug's symptom, 'general performance degradation,' directly points to a resource consumption problem.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions)** is a less precise fit. While a very large, unpruned database could be considered an 'exceptional condition,' the fundamental weakness is not the failure to check for this condition but the algorithmic inefficiency that causes excessive resource use when the condition occurs. CWE-400 better describes the consequence and nature of the vulnerability.

- **CWE-1335 (Incorrect Bitwise Shift of Integer)** is not applicable. The bug report provides no information to suggest that an incorrect bitwise shift operation is the cause of the performance issue.",closed,"The TrieLogPruner's loading performance is significantly affected by the size and composition of the TRIE_LOG_STORAGE database, particularly the ratio of SST files to BlobDB files. The performance degrades non-linearly with larger datasets, resulting in excessive loading times.","This performance issue can lead to long loading times for nodes, potentially affecting network synchronization and overall user experience. In severe cases, it could render nodes inoperative during initialization, impacting their ability to participate in network consensus.",2407996567,7322,"July 15, 2024 6:53 AM (GMT+8)","July 30, 2024 3:22 PM (GMT+8)","['bug', 'performance']",
besu,Erroneous stateDiff in API calls for failed transactions,https://github.com/hyperledger/besu/issues/7318,API,"### Description

The `stateDiff` field of the result of a pure transfer tx in `trace_replayBlockTransactions` call is `null` if the transaction failed. 

### Steps to Reproduce (Bug)

On an archive Besu node on the 

1. Have RPC access to an archive Besu node following Holesky
2. Replay [this tx's block](https://holesky.etherscan.io/tx/0xb457838013969202364745b586e4094c4edd1bd376244dac87c496eef777b6c7) and look at the result for the 16th tx with the following `curl`/`jq` command:

```
curl -X POST -H ""Content-Type: application/json"" --data '{
    ""jsonrpc"": ""2.0"",
    ""id"": 1,
    ""method"": ""trace_replayBlockTransactions"",
    ""params"": [""0x1D1921"", [""stateDiff""]]
    }' http://localhost:8545 | jq "".result[15]""
```

**Expected behavior:** 

`stateDiff` should contain the balance changes for the tx sender and the block validator (here is the correct output as provided by QuickNode: 

```
{
  # This is the sender
  ""0x5324ff21932b3ae69a6d46aaf29eca5bbfb86b73"": {
    ""balance"": {
      ""*"": {
        ""from"": ""0x5bb96a5487a77495"",
        ""to"": ""0x5bb9573b1619f045""
      }
    },
    ""code"": ""="",
    ""nonce"": {
      ""*"": {
        ""from"": ""0xe3"",
        ""to"": ""0xe4""
      }
    },
    ""storage"": {}
  },
  # This is the miner
  ""0x9baa3244565d51d9c7897c0eb6679ed4890e536e"": {
    ""balance"": {
      ""*"": {
        ""from"": ""0xa39659f932cf1b4668b"",
        ""to"": ""0xa39659fa646633eb68b""
      }
    },
    ""code"": ""="",
    ""nonce"": ""="",
    ""storage"": {}
  }
}
```

**Actual behavior:** 

`stateDiff` is `null`.

**Frequency:**

100%

### Versions (Add all that apply)
* Software version: freshly compiled from `main` branch, as well as 24.5.2
* Java version: 17 & 21
* OS Name & Version: Debian bookworm
* Consensus Client & Version if using Proof of Stake: Teku 24.4.0

### Additional Information (Add any of the following or anything else that may be relevant)

It seems that this issue is triggered by simple transfer TXs running out of gas. The bug may be coming [from this line](https://github.com/hyperledger/besu/blob/main/ethereum/api/src/main/java/org/hyperledger/besu/ethereum/api/jsonrpc/internal/results/tracing/diff/StateDiffGenerator.java#L41), where the generation of the state diff is entirely skipped if there are no frames in the tx execution, hence ignoring the balance changes to the sender & miner.
",api: incorrect api output,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a scenario where an API call, `trace_replayBlockTransactions`, returns an incorrect result (`null` for `stateDiff`) when processing a transaction that has failed. The specific trigger identified is a transaction running out of gas. A transaction failure, especially one like running out of gas, is a well-defined exceptional condition within the system's logic. The expected behavior is for the system to handle this exception by still calculating and returning the state changes related to gas fees and nonce increments. However, the actual behavior shows that the system handles this condition improperly by skipping the state difference calculation entirely, leading to an incorrect `null` output. This directly aligns with the definition of CWE-755, where the product incorrectly handles an exceptional condition. 

CWE-20 (Improper Input Validation) is not suitable because the input to the API call is valid. The problem is not with the data provided by the user, but with how the application's internal logic processes the outcome of the transaction specified by that input. 

CWE-841 (Improper Enforcement of Behavioral Workflow) is also unsuitable as the issue does not relate to enforcing a sequence of actions by an actor. It is a processing error within a single, self-contained API call.",closed,"The generation of the stateDiff is skipped for failed transactions due to the absence of execution frames, which leads to a null response instead of the expected balance changes.","Users and developers relying on accurate stateDiff information for transaction tracing will receive incorrect or incomplete data, potentially leading to confusion and misinterpretation of transaction outcomes, especially in cases of failed transactions.",2406808316,7318,"July 13, 2024 8:58 AM (GMT+8)","August 15, 2024 12:54 AM (GMT+8)","['bug', 'P3']",
besu,eth_call gasLimit param - different behavior compared to spec,https://github.com/hyperledger/besu/issues/7294,API,"Different behavior on eth_call compared with geth. Originally reported via linea https://github.com/Consensys/linea-besu/issues/41

workaround is to omit the gasLimit param from eth_call and rely on gas param

Currently transitioning the linea mainnet nodes using geth binary to besu binary and discovered an issue regarding the accepted parameters for the eth_call method (reference here: https://besu.hyperledger.org/public-networks/reference/api/objects#transaction-call-object:~:text=Parameter%20for%20eth_call%2C%20eth_createAccessList%2C%20and%20eth_estimateGas.) It looks like gasLimit is not accepted in the besu binary.

The issue seems to be that the besu binary doesn't support the same parameters for eth_call as the geth binary, as proven with the following request which works on the node running geth and fails on the one with besu. Below I've attached the request and the expected answer (from the geth node), and the error from the linea node running besu.
`curl https://linea-mainnet.public.blastapi.io -H ""Content-Type: application/json"" -d '{
  ""jsonrpc"": ""2.0"",
  ""method"": ""eth_call"",
  ""params"": [{
    ""data"": ""0x535b355c000000000000000000000000cebb9d8349a793439a5f9002934688698783eb740000000000000000000000000000000000000000000000000000f65ad6215c00"",
    ""from"": ""0xaf8ae6955d07776ab690e565ba6fbc79b8de3a5d"",
    ""to"": ""0xcf68a2721394dcf5dcf66f6265c1819720f24528"",
    ""gas"": ""0x15522"",
    ""gasLimit"": ""0x15522"",
    ""value"": ""0x0""
  }, ""latest""],
  ""id"": 1
}'`
Output from the geth node:
`{""jsonrpc"":""2.0"",""id"":1,""result"":""0x""}`
Output from the besu node:
`{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32602,""message"":""Invalid params""}}`
It seems that if I remove the gasLimit parameter when sending the request to the linea node with besu binary it works and provides the expected output. Any suggestions? Thanks",api: improper authorization,CWE-436,Interpretation Conflict,"The bug report describes a situation where two different software products, `besu` and `geth`, which are intended to be interoperable implementations of the Ethereum protocol, handle the same API call (`eth_call`) differently. Specifically, `geth` accepts the `gasLimit` parameter, while `besu` rejects it, causing an error. This directly aligns with the definition of CWE-436: 'Product A handles inputs or steps differently than Product B'. Here, `besu` is Product A and `geth` is Product B. The conflict in interpretation of the valid parameters for `eth_call` is the central issue. 

CWE-20 (Improper Input Validation) is less accurate because the validation in `besu` might be correct according to its own specification; the problem is the *difference* in validation compared to another standard implementation (`geth`), which is the essence of an interpretation conflict. 

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is not applicable because the `gasLimit` parameter is not an unusual or exceptional condition, but rather a standard parameter that is handled differently between the two products.",closed,"The besu binary does not accept the 'gasLimit' parameter for the 'eth_call' method, leading to incompatible behavior compared to the geth binary.","This inconsistency may cause applications and users relying on the 'eth_call' method to fail when transitioning from geth to besu, potentially leading to service disruptions and reduced functionality.",2389493319,7294,"July 3, 2024 9:12 PM (GMT+8)","July 16, 2024 5:19 PM (GMT+8)","['bug', 'P2', 'RPC']",
besu,"eth_gasPrice ERROR Could not retrieve block ",https://github.com/hyperledger/besu/issues/7287,API,"

While retesting #6965, which involved running a QBFT node and throwing https://github.com/MariusVanDerWijden/tx-fuzz at it. I received a new error:

```
2024-07-01 16:08:56.279+10:00 | vert.x-worker-thread-8 | ERROR | BaseJsonRpcProcessor | Error processing method: eth_gasPrice null
java.lang.IllegalStateException: Could not retrieve block #10
	at org.hyperledger.besu.ethereum.api.query.BlockchainQueries.lambda$gasPrice$25(BlockchainQueries.java:994)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at org.hyperledger.besu.ethereum.api.query.BlockchainQueries.lambda$gasPrice$26(BlockchainQueries.java:993)
	at java.base/java.util.stream.LongPipeline$1$1.accept(LongPipeline.java:177)
	at java.base/java.util.stream.Streams$RangeLongSpliterator.forEachRemaining(Streams.java:232)
	at java.base/java.util.Spliterator$OfLong.forEachRemaining(Spliterator.java:777)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:575)
	at java.base/java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260)
	at java.base/java.util.stream.ReferencePipeline.toArray(ReferencePipeline.java:616)
	at org.hyperledger.besu.ethereum.api.query.BlockchainQueries.gasPrice(BlockchainQueries.java:999)
	at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGasPrice.calculateGasPrice(EthGasPrice.java:49)
	at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGasPrice.response(EthGasPrice.java:45)
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:44)
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TracedJsonRpcProcessor.process(TracedJsonRpcProcessor.java:54)
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TimedJsonRpcProcessor.process(TimedJsonRpcProcessor.java:45)
	at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92)
	at org.hyperledger.besu.ethereum.api.handlers.AbstractJsonRpcExecutor.executeRequest(AbstractJsonRpcExecutor.java:87)
	at org.hyperledger.besu.ethereum.api.handlers.JsonRpcObjectExecutor.execute(JsonRpcObjectExecutor.java:57)
	at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$0(JsonRpcExecutorHandler.java:57)
	at java.base/java.util.Optional.ifPresentOrElse(Optional.java:196)
	at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$2(JsonRpcExecutorHandler.java:54)
	at io.vertx.ext.web.impl.BlockingHandlerDecorator.lambda$handle$0(BlockingHandlerDecorator.java:48)
	at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:191)
	at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:279)
	at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:210)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)
```

This PR had main pulled in recently. Previous test was based on May 21st main, that area of code had changed around May 2nd, in https://github.com/hyperledger/besu/commit/8df6bcadddc817fd8099c1849fe25b0ca7f66e3c#diff-2ef41086175ba1eea041526cfd1d92a80688eeeb8e4e1f17566b2f3d65ed7cae

Still trying to recreate it consistently.",api: api unavailability,CWE-755,Improper Handling of Exceptional Conditions,"The bug report shows a `java.lang.IllegalStateException` with the message ""Could not retrieve block #10"". This exception is thrown because the code attempts to retrieve a block, which it expects to exist, but fails to find it. The stack trace indicates that this failure occurs within a `java.util.Optional.orElseThrow()` call, meaning an operation that was expected to return a value instead returned an empty `Optional`. This empty `Optional` represents an exceptional condition: the requested block is not available. The program's response is to throw a generic `IllegalStateException`, which causes the API call (`eth_gasPrice`) to fail with a server error. This is a classic example of improperly handling an exceptional condition. A more robust implementation would catch this specific failure and return a structured, meaningful error to the API caller instead of letting an unhandled exception terminate the request processing.

- **CWE-755 (Improper Handling of Exceptional Conditions)** is the most accurate choice. The exceptional condition is the failure to retrieve a block. The handling is improper because it results in a generic `IllegalStateException` and an API failure, rather than a graceful error response.

- **CWE-476 (NULL Pointer Dereference)** is incorrect. The error is an `IllegalStateException`, not a `NullPointerException`. The use of `java.util.Optional` is a mechanism to avoid null pointer issues, and the failure happens when the `Optional` is empty, not when a null pointer is dereferenced.

- **CWE-362 (Race Condition)** is less suitable. While a race condition might be the underlying reason why the block could not be retrieved (especially given the concurrent environment and difficulty in reproduction), the immediate bug demonstrated in the stack trace is the *code's reaction* to the block's absence. The weakness is in the error handling logic itself, not necessarily in the synchronization of shared resources. CWE-755 describes the direct fault shown in the report, whereas CWE-362 would be an assumption about the root cause.",closed,The error occurs due to the inability to retrieve a specific block (block #10) when processing the `eth_gasPrice` method. This suggests a potential issue with the handling of blockchain state or resource management in the API layer.,"This bug can lead to failures in gas price estimation, which may affect transactions being processed on the network, causing delays and possible denial of service for users attempting to submit transactions.",2385029599,7287,"July 2, 2024 1:52 AM (GMT+8)","August 19, 2024 9:20 PM (GMT+8)","['bug', 'good first issue', 'P2']",
besu,Besu discards Transaction with Zero Gas Price on Free-Gas Network,https://github.com/hyperledger/besu/issues/7136,Execution,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
As an Besu, I want to deploy a SmartContract on a free-gas Network  so that I can use Besu as a Node for my private Blockchain. 

### Acceptance Criteria
* SmartContract Transaction with gas price of zero can be deployed.

### Steps to Reproduce (Bug)
1. Set up Besu with a private Network with Clique Consensus and zero Base Fee
2. Send a ContractCreation Transaction to Besu
3. See Besu denying the Transaction with Reason `{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32009,""message"":""Gas price below configured minimum gas price""}`

**Expected behavior:** Transaction gets accepted an the Contract is created

**Actual behavior:** Besu denying the Transaction with Reason `{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32009,""message"":""Gas price below configured minimum gas price""}`

**Frequency:** Every ContractCreation request

### Logs (if a bug)
[besu.log](https://github.com/hyperledger/besu/files/15417996/besu.log)
[genesis.json](https://github.com/hyperledger/besu/files/15418008/genesis.json)

config.toml
```toml
data-path=""/data""
rpc-http-enabled=true
rpc-http-api=[
    ""ETH"",
    ""NET"",
    ""CLIQUE"",
]
rpc-http-port=8545
rpc-http-cors-origins=[""all""]

host-allowlist=[""*""]

genesis-file=""/genesis.json""

min-gas-price=0
api-gas-price-max=0

network-id=1337
```
docker-compose.yml
```yaml
---
services:
  besu0:
    image: hyperledger/besu:24.5.1
    command: --config-file=/config.toml --p2p-port=30304 --logging=ALL --min-gas-price=0 --api-gas-price-max=0
    ports:
      - 8545:8545
      - 30304:30304
    networks:
      besu-p2p:
       ipv4_address: 10.5.0.2
    volumes:
      - ./besu-config.toml:/config.toml:ro
      - ./genesis.json:/genesis.json:ro
      - ./node-data:/data:rw
  besu1:
    image: hyperledger/besu:24.5.1
    depends_on:
      - besu0
    command: --config-file=/config.toml --p2p-port=30305 --bootnodes=enode://1c6c4139e6863cee7cfcc55326fea3d91d1e78649cef1a5a969c3c02098deb083d76537655732dfc32e7dae7334fac333429309ff2a0f903f56bfe47451b282b@10.5.0.2:30304 --min-gas-price=0 --api-gas-price-max=0
    ports:
      - 8546:8545
      - 30305:30305
    networks:
      besu-p2p:
       ipv4_address: 10.5.0.3
    volumes:
      - ./besu-config.toml:/config.toml:ro
      - ./genesis.json:/genesis.json:ro
      - ./node-data1:/data:rw
networks:
  besu-p2p:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: 10.5.0.1
```

Gas Price Calls from both Nodes in the Cluster: 
```log
joshua@LJ243WK6LG ~/g/o/besu-clique (master)> curl -X POST --data '{""jsonrpc"":""2.0"",""method"":""eth_gasPrice"",""params"":[],""id"":53}' http://127.0.0.1:8545
{""jsonrpc"":""2.0"",""id"":53,""result"":""0x0""}⏎                                                                                                                                                                                                                                                                                                                                                                                                 joshua@mac~/g/o/besu-clique (master)> 
joshua@mac ~/g/o/besu-clique (master)> 
joshua@mac ~/g/o/besu-clique (master)> curl -X POST --data '{""jsonrpc"":""2.0"",""method"":""eth_gasPrice"",""params"":[],""id"":53}' http://127.0.0.1:8546
{""jsonrpc"":""2.0"",""id"":53,""result"":""0x0""}⏎                                                                                                                                                                                                                                                                                                                                                                                                 joshua@mac ~/g/o/besu-clique (master)> 
```


### Versions (Add all that apply)
* Software version: [`besu --version`] 24.5.1 docker container
* OS Name & Version: [`cat /etc/*release`] docker
* Kernel Version: [`uname -a`] docker
* Docker Version: [`docker version`] Docker Desktop  4.30.0 (149282), 
```
Server: Docker Desktop 4.30.0 (149282)
 Engine:
  Version:          26.1.1
  API version:      1.45 (minimum version 1.24)
  Go version:       go1.21.9
  Git commit:       ac2de55
  Built:            Tue Apr 30 11:48:04 2024
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          1.6.31
  GitCommit:        e377cd56a71523140ca6ae87e30244719194a521
 runc:
  Version:          1.1.12
  GitCommit:        v1.1.12-0-g51d5e94
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```
* Consensus Client & Version if using Proof of Stake: [e.g. Teku, Lighthouse, Prysm, Nimbus, Lodestar]

### Smart contract information (If you're reporting an issue arising from deploying or calling a smart contract, please supply related information)
Contract is deployed with `eth_sendRawTransaction` and works elsewhere.

### Additional Information (Add any of the following or anything else that may be relevant)
* Besu setup info - genesis file, config options -> attached
* System info - memory, CPU -> Apple MacBook Pro M3
",general: general improper authorization,CWE-697,Incorrect Comparison,"The user is reporting that when they configure their Besu node for a 'free-gas network' by setting the `min-gas-price` to 0, the node still rejects transactions that have a gas price of 0. The error message returned is `""Gas price below configured minimum gas price""`. This explicitly states that a comparison is being made between the transaction's gas price and the configured minimum. The bug is that this comparison is yielding an incorrect result; the system incorrectly concludes that 0 is 'below' 0. This points directly to a flaw in the comparison logic.

- CWE-20 (Improper Input Validation) is a possible but overly broad category. While this is a form of incorrect validation, CWE-697 is more specific about the nature of the failure.
- CWE-754 (Improper Check for Unusual or Exceptional Conditions) is not applicable because a zero gas price is the *intended* and *expected* condition for this specific user configuration, not an unusual or exceptional one.
- CWE-697 (Incorrect Comparison) is the most accurate choice. The core of the issue is that the product compares two entities (the transaction's gas price and the configured minimum gas price) and this comparison is incorrect, leading to the rejection of a valid transaction. The bug's root cause is the faulty comparison itself.",closed,"The Besu node configuration is set to reject transactions with a gas price below the configured minimum gas price, which is not correctly allowing zero gas price transactions in a free-gas network scenario.","This bug prevents users from deploying smart contracts on a private network where gas fees are intended to be free, thus hindering the functionality of the Besu blockchain in specific use cases.",2313031153,7136,"May 23, 2024 2:09 PM (GMT+8)","September 13, 2024 10:22 PM (GMT+8)","['bug', 'P3', 'non mainnet (private networks)']",
besu,Could not confirm best peer had pivot block,https://github.com/hyperledger/besu/issues/7109,Consensus,"latest besu from this commit https://github.com/hyperledger/besu/commit/27e5a649d74757330a6cd22094ae06d7251d0cc4
1 of 6 Azure nodes stuck with this recurring error

`{""@timestamp"":""2024-05-16T03:45:24,313"",""level"":""DEBUG"",""thread"":""EthScheduler-Timer-0"",""class"":""SyncTargetManager"",""message"":""Could not confirm best peer had pivot block"",""throwable"":"" java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException: Timeout after 5000 MILLISECONDS\n\tat java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)\n\tat java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)\n\tat java.base/java.util.concurrent.CompletableFuture$OrApply.tryFire(CompletableFuture.java:1576)\n\tat java.base/java.util.concurrent.CompletableFuture$CoCompletion.tryFire(CompletableFuture.java:1219)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)\n\tat org.hyperledger.besu.ethereum.eth.manager.EthScheduler.lambda$failAfterTimeout$11(EthScheduler.java:301)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.util.concurrent.TimeoutException: Timeout after 5000 MILLISECONDS\n\tat org.hyperledger.besu.ethereum.eth.manager.EthScheduler.lambda$failAfterTimeout$11(EthScheduler.java:300)\n\t... 5 more\n""}`


looks like a chain halt - nothing in INFO logs for 3h after this:

`{""@timestamp"":""2024-05-15T23:14:08,234"",""level"":""INFO"",""thread"":""EthScheduler-Services-36 (requestCompleteTask)"",""class"":""SnapWorldDownloadState"",""message"":""Pausing world state download while waiting for sync to complete"",""throwable"":""""}
{""@timestamp"":""2024-05-15T23:14:45,654"",""level"":""INFO"",""thread"":""EthScheduler-Services-279 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 12582224 of 19878555 (63%), Peer count: 25"",""throwable"":""""}
{""@timestamp"":""2024-05-15T23:22:41,709"",""level"":""INFO"",""thread"":""EthScheduler-Services-225 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 12606638 of 19878555 (63%), Peer count: 24"",""throwable"":""""}
{""@timestamp"":""2024-05-15T23:24:47,420"",""level"":""INFO"",""thread"":""EthScheduler-Services-258 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 12614838 of 19878555 (63%), Peer count: 25"",""throwable"":""""}
{""@timestamp"":""2024-05-15T23:32:05,457"",""level"":""INFO"",""thread"":""EthScheduler-Services-283"",""class"":""SnapWorldDownloadState"",""message"":""Running world state heal process from peers with pivot block 19878650"",""throwable"":""""}
{""@timestamp"":""2024-05-15T23:34:06,377"",""level"":""INFO"",""thread"":""EthScheduler-Services-283 (importBlock)"",""class"":""ImportBlocksStep"",""message"":""Block import progress: 12639013 of 19878650 (63%), Peer count: 25"",""throwable"":""""}`",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a ""consensus liveness failure"" and a ""chain halt,"" where a node becomes ""stuck"" and stops making progress. The logs show a recurring `TimeoutException` with the message ""Could not confirm best peer had pivot block."" This indicates the system is repeatedly attempting an operation that consistently fails to complete within the allotted time. This cycle of attempting an action, timing out, and presumably retrying, traps the process in a state where it cannot advance. This behavior directly aligns with the definition of CWE-835, ""Loop with Unreachable Exit Condition ('Infinite Loop')."" The exit condition for this operational loop—successfully confirming the peer's block—has become unreachable, leading to a functional infinite loop and a denial of service (liveness failure).

CWE-362 ('Race Condition') is less suitable. While the timeout could be a symptom of a deadlock (a type of race condition), the report lacks direct evidence of improper resource synchronization. The primary description is of a recurring logical failure, not a data corruption or inconsistent state typical of race conditions.

CWE-400 ('Uncontrolled Resource Consumption') is also incorrect. The report does not mention high CPU, memory leaks, or the exhaustion of any specific resource. The issue is a logical stall, not resource depletion.",closed,"The system is unable to confirm that the best peer has the required pivot block due to a timeout error after waiting for 5000 milliseconds, leading to a block import failure.","This bug may result in a chain halt, preventing the node from synchronizing with the network and processing transactions, which can lead to service disruptions and loss of consensus within the distributed system.",2299283134,7109,"May 16, 2024 3:56 AM (GMT+8)","June 20, 2024 12:54 PM (GMT+8)","['bug', 'P2']",
besu,Transaction that is added to a node's pool may not be propagated to the pools of its peer nodes,https://github.com/hyperledger/besu/issues/7081,Consensus,"### Introduction

In certain situations, **a transaction that is added to a node's pool (of sequenced type) may not be propagated to the pools of its peer nodes,** resulting in the transaction being present only in the transaction receptor node's pool rather than being distributed across all nodes' pools.

### Summary

We are using the following five nodes setup for a private Besu network with QBFT protocol:
- A non-validator node that doesn’t participate in the consensus protocol.
- One node acting as a validator.

**Users connect to the non-validator node to send transactions**, and it propagates them to the validator so that they are included in new blocks.

**Starting from a scenario where all the nodes have a transaction** (let’s call it “tx_a”) in the pool, as shown in the first image.

![first image](https://github.com/hyperledger/besu/assets/50823157/bc8d8032-ef08-4189-93db-74fe42f1d5f2)

If the transaction is dropped from the pool of the nodes for any reason, **the pools of the nodes are empty** as we can see in the second image.

![second image](https://github.com/hyperledger/besu/assets/50823157/a6a64722-ec51-4bd1-a95c-abceae883fc3)

Then, if the transaction is sent again to the non-validator, it is added to its pool, **but it is not added to the validator pool** as we can see in the third image.

![third image](https://github.com/hyperledger/besu/assets/50823157/89477ecc-a416-4b93-a2de-1fb7376e7c13)

### Detailed description

We have observed 2 problematic scenarios related to how the nodes handle their caches:

1. When a client sends a transaction to the non-validator node, if this node dropped the transaction before, [the node doesn't propagate the transaction to the peers](https://github.com/hyperledger/besu/blob/main/ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/transactions/PeerTransactionTracker.java#L69-L71) in the network. If the transaction is not propagated to a validator, it will never be mined.
2. When a peer propagates a transaction to the validator node, if this node has already received the transaction from a peer, [the transaction is not promoted to the transactions pool](https://github.com/hyperledger/besu/blob/main/ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/transactions/TransactionsMessageProcessor.java#L69-L70). If the transaction is not promoted to the transactions pool, it will never be mined.

Both scenarios are problematic if the transaction is valid but the node dropped it from the pool before mining the transaction for any reason, e.g. exceeding `tx-pool-retention-hours` limit.

**We were able to add that transaction again to the validator’s pool only by restarting all the nodes and sending the transaction again.**

It seems to be a bug by which internal caches are not updated properly when transactions are dropped/evicted from the pool, not allowing those transactions to be added into new blocks as they are not propagated by the non-validator node and they are rejected by the validator as well.

### Versions

This issue occurs in the latest version of the system, as of the time of this writing (v24.3.3). We believe that this occurs in previous versions as well.

### Steps to reproduce

This is an explanation of how we were able to reproduce the bug: 

1 . Set up at least one non-validator node and at least one validator node with a QBFT network configuration. 
3. Send a new transaction using a higher nonce than the expected one, so a nonce gap is created, and that transaction will remain in the pool of both the non-validator and validator nodes. 
4. Force the transaction to be dropped from the pool (for example waiting for the tx-pool-retention-hours to expire).
5. Resend the transaction to the non-validator node and you will be able to check that it won’t appear in the validator’s pool (as it does not get propagated by the non-validator nor accepted by the validator because it gets filtered due to be categorized as an already seen transaction).

### Expected behavior
:white_check_mark: = already happening
:x: = not happening

1. The user sends a transaction, which is received by the non-validator node and added to the pool :white_check_mark: 
2. The transaction is propagated to the validator nodes. :white_check_mark:
3. The validator nodes accept the transaction and add it to their pool. :white_check_mark:
4. Every node drops the transaction from its pool. :white_check_mark:
6. The user resends the transaction, which is received by the non-validator node and added to the pool. :white_check_mark:
7. The same as step 2. :x:
8. The same as step 3. :x:

### Nodes execution arguments

```
--tx-pool-max-size=5
--tx-pool=sequenced
--tx-pool-limit-by-account-percentage=1
```
### Nodes config

**Non-validator node**

```
# Network
p2p-host=""127.0.0.1""
p2p-port=1232
max-peers=42

rpc-http-enabled=true
rpc-http-api=[""ETH"",""NET"",""WEB3"",""IBFT"",""QBFT"",""TXPOOL"",""ADMIN""]

host-whitelist=[""*""]
rpc-http-cors-origins=[""all""]

rpc-http-host=""0.0.0.0""
rpc-http-port=8545

rpc-ws-enabled=true
rpc-ws-host=""0.0.0.0""
rpc-ws-port=30303

# Mining
miner-enabled=true
miner-coinbase=""0xfe3b557e8fb62b89f4916b721be55ceb828dbd73""

min-gas-price=""0""
revert-reason-enabled=true

metrics-category=[ ""ETHEREUM"", ""BLOCKCHAIN"",""EXECUTORS"",""JVM"",""NETWORK"",""PEERS"",""PROCESS"",""KVSTORE_ROCKSDB"",""KVSTORE_ROCKSDB_STATS"",""RPC"",""SYNCHRONIZER"", ""TRANSACTION_POOL"" ]
metrics-enabled=true
metrics-host=""0.0.0.0""
metrics-port=9095
```

**Validator node config**

```
# Network
p2p-host=""127.0.0.1""
p2p-port=1234
max-peers=42

rpc-http-enabled=true
rpc-http-api=[""ETH"",""NET"",""WEB3"",""IBFT"",""QBFT"",""TXPOOL""]

host-whitelist=[""*""]
rpc-http-cors-origins=[""all""]

rpc-http-host=""0.0.0.0""
rpc-http-port=8585

rpc-ws-enabled=true
rpc-ws-host=""0.0.0.0""
rpc-ws-port=30305

# Mining
miner-enabled=true
miner-coinbase=""0xfe3b557e8fb62b89f4916b721be55ceb828dbd73""

min-gas-price=""0""
revert-reason-enabled=true

metrics-category=[ ""ETHEREUM"", ""BLOCKCHAIN"",""EXECUTORS"",""JVM"",""NETWORK"",""PEERS"",""PROCESS"",""KVSTORE_ROCKSDB"",""KVSTORE_ROCKSDB_STATS"",""RPC"",""SYNCHRONIZER"", ""TRANSACTION_POOL"" ]
metrics-enabled=true
metrics-host=""0.0.0.0""
metrics-port=9097
```

**genesis.json**

```
{
 ""config"": {
   ""muirGlacierBlock"": 0,
   ""chainId"": 44844,
   ""contractSizeLimit"": 2147483647,
   ""qbft"": {
     ""blockperiodseconds"": 1,
     ""epochlength"": 30000,
     ""requesttimeoutseconds"": 10
   }
 },
 ""nonce"": ""0x0"",
 ""timestamp"": ""0x58ee40ba"",
 ""gasLimit"": ""0x5F5E100"",
 ""difficulty"": ""0x1"",
 ""mixHash"": ""0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365"",
 ""coinbase"": ""0x0000000000000000000000000000000000000000"",
 ""alloc"": {
   ""fe3b557e8fb62b89f4916b721be55ceb828dbd73"": {
     ""privateKey"": ""8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63"",
     ""comment"": ""private key and this comment are ignored.  In a real chain, the private key should NOT be stored"",
     ""balance"": ""0xad78ebc5ac6200000""
   },
   ""627306090abaB3A6e1400e9345bC60c78a8BEf57"": {
     ""privateKey"": ""c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3"",
     ""comment"": ""private key and this comment are ignored.  In a real chain, the private key should NOT be stored"",
     ""balance"": ""90000000000000000000000""
   },
   ""f17f52151EbEF6C7334FAD080c5704D77216b732"": {
     ""privateKey"": ""ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f"",
     ""comment"": ""private key and this comment are ignored.  In a real chain, the private key should NOT be stored"",
     ""balance"": ""90000000000000000000000""
   }
 },
 ""extraData"": ""0xf87aa00000000000000000000000000000000000000000000000000000000000000000f85494792fc5093a85bd8fb52c781aefee7da96d2180cf9414275b2f4cefb4c72f12ca32ce0044578923e1b694fcbc96c1e8a673b7cdc333c6687f07fa2c28befe94b5ec93ab0a6ad8f8c0e404e3225b16cb2ea23a1ec080c0""
}
```",consensus: consensus liveness failure,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a situation where a transaction is dropped from a node's transaction pool (e.g., due to a retention timeout), but internal caches that track 'seen' transactions are not updated to reflect this removal. When the same transaction is submitted again, the node consults its cache, incorrectly determines the transaction has already been processed or seen by peers, and consequently fails to propagate it. This directly maps to CWE-404: Improper Resource Shutdown or Release. In this context, the entry for the transaction in the 'seen' cache is a 'resource'. When the transaction is dropped from the pool, this cache resource is not properly 'released' or cleared. This failure to release the cache entry prevents the transaction from being 're-used' (i.e., re-added and re-propagated) later. 

CWE-703 (Improper Check or Handling of Exceptional Conditions) is a plausible but less precise fit. While dropping and resubmitting a transaction is an exceptional condition, the specific failure mechanism is a resource management problem, which CWE-404 describes more accurately. 

CWE-436 (Interpretation Conflict) is not applicable because the problem is an internal state management flaw within a single software product (Besu), not a conflict in how two different products interpret data or state.",closed,"The internal caches of the nodes are not updated properly when transactions are dropped or evicted from the pool, preventing valid transactions from being propagated and accepted by the nodes.","Transactions that are valid may not be included in new blocks since they are not propagated to validator nodes, leading to potential loss of transaction validity and disruption in the transaction processing of the network.",2287070224,7081,"May 9, 2024 7:23 AM (GMT+8)","November 8, 2024 7:26 PM (GMT+8)","['bug', 'P2']",
besu,BAD Block in private QBFT chain,https://github.com/hyperledger/besu/issues/7036,Consensus,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/private-networks/how-to -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
We ran a private chain of 4 nodes, with QBFT and all the milestones enabled. We added Shanghai once we migrated to 24.3.0.
One node, which is our JSON-RPC node fell out of sync. It showed a `BAD BLOCK` error and from there we couldn't make it join the network any more (we ran into #6760 then).

My question is: do you see a way a heavy (relatively) load on the JSON-RPC could end up with bad blocks? 
Looking through other issues with bad blocks here, I'm pretty unsure how we caused it.",storage: storage corruption,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a node encountering a `BAD BLOCK` error under a heavy load, causing it to fall out of sync and subsequently become unable to rejoin the network. This scenario directly aligns with the definition of CWE-703. The `BAD BLOCK` represents a critical, exceptional condition. The system's failure to handle this condition gracefully—by recovering, re-syncing, or providing a path to resolution—is the core of the reported issue. The node's inability to rejoin the network is a clear manifestation of improperly handling an exceptional condition. While CWE-362 (Race Condition) could be the underlying cause of the `BAD BLOCK` due to the mention of 'heavy load' implying concurrency, the bug report's focus is on the system's failure to manage the resulting error state, making CWE-703 a more direct and accurate classification of the observed behavior. CWE-400 (Uncontrolled Resource Consumption) is less fitting because the primary symptom is data corruption (`BAD BLOCK`) and a state machine failure, not a resource exhaustion issue like a crash or denial of service.",closed,"The issue arises from a node falling out of sync and reporting a BAD BLOCK error, which may be exacerbated by heavy load on the JSON-RPC, leading to failure in properly handling consensus decisions.","The inability of a node to rejoin the network after encountering a BAD BLOCK error disrupts the consensus process, potentially leading to network instability and a lack of consistency in the blockchain state.",2275338737,7036,"May 2, 2024 11:45 AM (GMT+8)","May 17, 2024 7:43 AM (GMT+8)","['bug', 'non mainnet (private networks)']",
besu,Worldstate download halt,https://github.com/hyperledger/besu/issues/6908,Consensus,"Besu version 24.4.0-RC2 (seen three times in burnin nodes)

Including tests of main, this has been seen on 7 / 32 nodes = 22% occurrence 
 - this number is in flux as analysis still being done, as well as data being gathered.

",consensus: consensus liveness failure,CWE-833,Deadlock,"The bug report describes a ""Worldstate download halt"" and a ""consensus liveness failure"". This indicates that the system has stopped making progress. I will evaluate the provided CWEs based on these symptoms.

1.  **CWE-400 (Uncontrolled Resource Consumption):** This CWE is less likely because the report does not mention any symptoms of resource exhaustion, such as out-of-memory errors, high CPU usage, or disk space issues. The problem is described as a ""halt,"" not a crash due to resource depletion.

2.  **CWE-835 (Loop with Unreachable Exit Condition 'Infinite Loop'):** An infinite loop can cause a process to stop making progress and become unresponsive, which aligns with the ""halt"" and ""liveness failure"" symptoms. This is a plausible cause.

3.  **CWE-833 (Deadlock):** A deadlock occurs when multiple threads wait for each other to release resources, causing all of them to stop progressing. This is a classic cause of a ""halt"" and a ""liveness failure,"" especially in a multi-threaded environment like a ""Consensus"" mechanism.

**Conclusion:** Between CWE-835 and CWE-833, CWE-833 is the most accurate fit. The bug's location is specified as ""Consensus,"" a system that inherently relies on multi-threaded coordination and locking. A ""liveness failure"" in this context strongly suggests that multiple interacting components are stuck waiting for one another, which is the precise definition of a deadlock. While an infinite loop (CWE-835) could cause a halt, a deadlock (CWE-833) is a more specific and common failure pattern for the type of system described.",closed,"The issue arises from a failure in the worldstate download mechanism that causes it to halt under certain conditions, likely related to the handling of node synchronization or data retrieval processes.","If the worldstate download halts, it can lead to nodes being unable to synchronize their state, potentially resulting in inconsistencies across the network and affecting transaction processing and overall network reliability.",2232302584,6908,"April 8, 2024 11:24 PM (GMT+8)","May 3, 2024 8:43 AM (GMT+8)","['bug', 'P1', 'mainnet', 'syncing']",
besu,NPE when making a JSON/RPC call too early that requires the transaction pool to be initialized,https://github.com/hyperledger/besu/issues/6863,API,"### Description
I start a new Besu node and before it has synced I submit a new transaction. This requires the nonce for the sender to be determined, which hits the following NPE because the transaction pool hasn't been initialized yet:

```
java.lang.NullPointerException: Cannot invoke ""org.hyperledger.besu.ethereum.eth.transactions.PendingTransactions.getNextNonceForSender(org.hyperledger.besu.datatypes.Address)"" because ""this.pendingTransactions"" is null
        at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool.getNextNonceForSender(TransactionPool.java:539)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthGetTransactionCount.pendingResult(EthGetTransactionCount.java:60)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.handleParamTypes(AbstractBlockParameterOrBlockHashMethod.java:100)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractBlockParameterOrBlockHashMethod.response(AbstractBlockParameterOrBlockHashMethod.java:151)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:44)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TracedJsonRpcProcessor.process(TracedJsonRpcProcessor.java:41)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.TimedJsonRpcProcessor.process(TimedJsonRpcProcessor.java:45)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92)
        at org.hyperledger.besu.ethereum.api.handlers.AbstractJsonRpcExecutor.executeRequest(AbstractJsonRpcExecutor.java:87)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcObjectExecutor.execute(JsonRpcObjectExecutor.java:57)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$0(JsonRpcExecutorHandler.java:57)
        at java.base/java.util.Optional.ifPresentOrElse(Optional.java:196)
        at org.hyperledger.besu.ethereum.api.handlers.JsonRpcExecutorHandler.lambda$handler$2(JsonRpcExecutorHandler.java:54)
        at io.vertx.ext.web.impl.BlockingHandlerDecorator.lambda$handle$0(BlockingHandlerDecorator.java:48)
        at io.vertx.core.impl.ContextImpl.lambda$executeBlocking$1(ContextImpl.java:190)
        at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:276)
        at io.vertx.core.impl.ContextImpl.lambda$internalExecuteBlocking$2(ContextImpl.java:209)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base/java.lang.Thread.run(Thread.java:833)
^C2024-04-02 16:40:43.003+01:00 | BesuCommand-Shutdown-Hook |
```

### Steps to Reproduce (Bug)
1. Run `besu --genesis-file=genesis.json --profile=enterprise --data-storage-format=FOREST --data-path=./data --rpc-http-enabled`
2. Before the node has synced and started mining blocks, submit a new transaction

**Expected behavior:**
No NPE. I think the correct behaviour is either a) a suitable error code being returned to the JSON/RPC call or b) the transaction pool accepting the transaction and it being mined when the node has synced.

**Actual behavior:**
NPE shown above

**Frequency:**
Always

### Versions (Add all that apply)
* Software version: `besu/v24.4-develop-cf5e3dae98/osx-aarch_64/openjdk-java-17`

",api: api unavailability,CWE-665,Improper Initialization,"The bug report describes a `NullPointerException` that occurs when a JSON/RPC call is made before a component, the `transaction pool`, has been fully initialized. I will analyze the three provided CWE options to determine the best fit.

1.  **CWE-476 (NULL Pointer Dereference):** This CWE accurately describes the direct symptom of the bug. The stack trace clearly shows a `java.lang.NullPointerException` because the code attempts to call a method on the `pendingTransactions` object, which is `null`. However, this is the result of the bug, not its root cause. A more precise classification should describe *why* the pointer was null.

2.  **CWE-362 (Race Condition):** This CWE is a plausible candidate. The bug is triggered by a timing issue—an API request is processed concurrently with the node's startup/synchronization process. The request 'races' against the initialization logic, and if the request wins, it accesses the uninitialized component. This is a specific type of race condition.

3.  **CWE-665 (Improper Initialization):** This CWE describes the core of the problem most accurately. The bug report explicitly states, ""the transaction pool hasn't been initialized yet."" The `pendingTransactions` object is `null` because the initialization sequence that is supposed to create it has not completed. The system's flaw is that it allows access to the `TransactionPool` component before it has been put into a valid, initialized state. While a race condition (CWE-362) is the mechanism that exposes this flaw, the fundamental weakness is the improper handling of the resource's lifecycle, leaving it in an uninitialized state when used. Therefore, CWE-665 is the most precise description of the root cause.

**Conclusion:** CWE-665 is the best fit. It pinpoints the root cause—the resource being in an uninitialized state when accessed—which is more fundamental than the resulting NPE (CWE-476) or the timing mechanism that triggers it (CWE-362).",closed,"The transaction pool has not been initialized when a JSON/RPC call is made to fetch the nonce for a sender's transaction, leading to a NullPointerException.","The application crashes when a transaction is submitted before the node has fully synced, potentially disrupting service and user experience.",2220867559,6863,"April 2, 2024 3:49 PM (GMT+8)","April 8, 2024 3:42 PM (GMT+8)","['bug', 'P2', 'RPC']",
besu,NPE in registerDisconnect,https://github.com/hyperledger/besu/issues/6840,Network,"peer is null so getId() fails - this exception should be caught

`
{""@timestamp"":""2024-03-29T00:25:19,903"",""level"":""DEBUG"",""thread"":""nioEventLoopGroup-3-10"",""class"":""Subscribers"",""message"":""Error in callback: {}"",""throwable"":"" java.lang.NullPointerException: Cannot invoke \""org.hyperledger.besu.ethereum.eth.manager.EthPeer.getId()\"" because \""peer\"" is null\n\tat org.hyperledger.besu.ethereum.eth.manager.EthPeers.registerDisconnect(EthPeers.java:180)\n\tat org.hyperledger.besu.ethereum.eth.manager.EthProtocolManager.handleDisconnect(EthProtocolManager.java:421)\n\tat org.hyperledger.besu.ethereum.p2p.network.NetworkRunner.lambda$setupHandlers$4(NetworkRunner.java:167)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.PeerConnectionEvents.lambda$dispatchDisconnect$0(PeerConnectionEvents.java:55)\n\tat org.hyperledger.besu.util.Subscribers.lambda$forEach$0(Subscribers.java:131)\n\tat java.base/java.lang.Iterable.forEach(Iterable.java:75)\n\tat org.hyperledger.besu.util.Subscribers.forEach(Subscribers.java:128)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.PeerConnectionEvents.dispatchDisconnect(PeerConnectionEvents.java:55)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.AbstractPeerConnection.disconnect(AbstractPeerConnection.java:188)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.RlpxAgent.handleIncomingConnection(RlpxAgent.java:332)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.NettyConnectionInitializer$2.lambda$initChannel$0(NettyConnectionInitializer.java:229)\n\tat org.hyperledger.besu.util.Subscribers.lambda$forEach$0(Subscribers.java:131)\n\tat java.base/java.lang.Iterable.forEach(Iterable.java:75)\n\tat org.hyperledger.besu.util.Subscribers.forEach(Subscribers.java:128)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.NettyConnectionInitializer$2.lambda$initChannel$1(NettyConnectionInitializer.java:229)\n\tat java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:718)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.DeFramer.decode(DeFramer.java:200)\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:529)\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:468)\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.AbstractHandshakeHandler.channelRead0(AbstractHandshakeHandler.java:144)\n\tat org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.AbstractHandshakeHandler.channelRead0(AbstractHandshakeHandler.java:45)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\n""}
`",api: api unavailability,CWE-476,NULL Pointer Dereference,"The bug report's title is ""NPE in registerDisconnect"", where NPE stands for Null Pointer Exception. The details explicitly state, ""peer is null so getId() fails"". The provided stack trace confirms this with the error message: `java.lang.NullPointerException: Cannot invoke ""...EthPeer.getId()"" because ""peer"" is null`. This directly and precisely matches the definition of CWE-476, which is ""The product dereferences a pointer that it expects to be valid but is NULL."" The code attempted to call the `getId()` method on the `peer` variable, which was null, leading to the crash. While the exception was also uncaught (CWE-248) and this could be seen as a failure to check for an exceptional condition (CWE-754), CWE-476 is the most specific and accurate classification of the root cause of the fault itself.",closed,The bug occurs due to a null pointer exception when trying to invoke the getId() method on a 'peer' object that is null. This indicates that proper null checks were not implemented before accessing the peer object.,"This bug can lead to application crashes or unexpected behavior during the disconnection process of peers in the network, potentially disrupting communication and stability of the blockchain network.",2214399025,6840,"March 29, 2024 12:41 AM (GMT+8)","March 29, 2024 9:56 AM (GMT+8)","['bug', 'peering', 'snack']",
besu,24.3.0version debug_metrics error,https://github.com/hyperledger/besu/issues/6821,API,"HyperLedger Besu 24.3.0 v

http rpc debug_metrics call 
(curl -X POST --data '{""jsonrpc"":""2.0"",""method"":""debug_metrics"",""params"":[],""id"":1}' http://127.0.0.1:8545)

return code 
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32603,""message"":""Internal error""}} 


besu node error 
org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.getNextMapLevel Error

2024-03-27 09:22:04.624+09:00 | vert.x-worker-thread-5 | ERROR | BaseJsonRpcProcessor | Error processing method: debug_metrics []
java.lang.ClassCastException: class java.lang.Double cannot be cast to class java.util.Map (java.lang.Double and java.util.Map are in module java.base of loader 'bootstrap')
	at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.DebugMetrics.getNextMapLevel(DebugMetrics.java:75)
",api: api unavailability,CWE-704,Incorrect Type Conversion or Cast,"The bug report's core evidence is the Java stack trace, which explicitly states: `java.lang.ClassCastException: class java.lang.Double cannot be cast to class java.util.Map`. This error indicates that the program attempted to convert an object of type `Double` into an object of type `Map`, which is an invalid operation. This directly corresponds to the definition of CWE-704, 'Incorrect Type Conversion or Cast', which describes when a product does not correctly convert an object from one type to another. CWE-755, 'Improper Handling of Exceptional Conditions', is less accurate because while an unhandled exception does occur, the root cause of that exception is the incorrect cast itself. Classifying by the root cause (the bad cast) is more precise than classifying by the symptom (the unhandled exception). CWE-436, 'Interpretation Conflict', is not applicable as the error is an internal logic flaw within a single software component, not a misinterpretation of state or data between two different products.",closed,"The bug occurs due to a ClassCastException when the code attempts to cast a Double to a Map, which indicates a type mismatch in the data being processed by the debug_metrics method.","This bug can lead to the failure of the debug_metrics API call, preventing users from retrieving important metrics, which can hinder monitoring and debugging efforts for the HyperLedger Besu node.",2209595056,6821,"March 27, 2024 12:47 AM (GMT+8)","December 6, 2024 12:10 PM (GMT+8)","['bug', 'P3', 'snack', 'RPC', 'ux']",
besu,Low Peer Numbers,https://github.com/hyperledger/besu/issues/6805,Network,"Multiple reports of peering issues, this is a placeholder to track and gather info.

Anecdotally seems like issues began after Dencun fork on March 13th and are worse during initial sync.

* @garyschulte suspected a Dencun fork id issue on March 22nd related to geth during snap server testing...it ultimately turned out to be an old version of geth, but there were still a lack geth peers on our canary nodes.

* Other devs internally have noticed issues connecting to geth peers while trying to sync Holesky.
  * > This node syncs basically using 2 Geth nodes and disconnects all non Geth nodes, because they are useless. After the sync, when we stop sending snap requests we do find peers, but out of a max of 21, I have 2 Geth nodes, 1 reth node, 1 besu node, and the rest is nethermind. Something is not right here!

* Issue reported on geth https://github.com/ethereum/go-ethereum/issues/29312

### User reports from EthStaker #besu-helpdesk Discord
 
* GGubignou — 17/03/2024 19:51
> Hi, I updated to the latest Besu via eth-docker and it now seems to struggle finding peers. I was previously at 25 peers constantly but now it oscillates between 8-13 peers. Has anything been changed with regards to port forwarding in the latest version?
> (FYI my consensus client Teku finds peers as usual and I have otherwise not changed anything to my setup) 
  * GGubignou — 18/03/2024 16:49
> Hi @siladu, after a couple hours of struggle it eventually managed to go back to 25 peers and it seems fine now. I upgrade frequently so I was likely on the previous release before that.
  * ktmkancha — 23/03/2024 01:05
> Hi Siladu- I've been having trouble with Peer connections. I hadn't updated my node prior to the Dencun fork for few months so I was probably few updates behind. I have been hovering around 9-11 peers in the last few hours. It hasn't really climbed up or down. Any advice? 
  * ktmkancha — 26/03/2024 05:28
> Since the Dencun update, my peer count has been single digits. I used to get consistently 25 peers prior to this, any advise? Thank you
  * ktmkancha — 28/03/2024 02:27
> Hi @siladu Just wanted to report that after the besu node sync up with the top of the chain- the peer count is back up to 15+.  It's better than single digits, but compared to dencun update- it's still 10 less peers. I used to get 25 peers consistenly. Will keep an eye out of the any besu updates! thanks
  * MrPrezident — 24/03/2024 03:08
> I noticed that while syncing besu, it is consistently using only 1 peer, whereas teku currently has 24 peers. Is that because I'm doing a checkpoint sync?
  * MrPrezident — 24/03/2024 06:32
 > teku is connected to 28 peers, so I don't think it is having any problems. Only besu is having issues with peers. Both teku and besu are being run on the same host using ethdocker
The only firewall should be my pfsense router.
but I have portforwarding turned on in pfsense
  * MrPrezident — 24/03/2024 14:26
> Just for testing purposes, I reconfigured my ethdocker to use geth/prysm and restarted syncing to see if it would have the same problem as besu/teku. It did finish syncing on both execution and consensus clients, but I noticed that the consensus client (prysm) is hovering at about 70 peers and the execution client (geth) is hovering at about 5 peers. That seems like a huge discrepancy. That is sort of in line with what I was seeing with besu/teku. Besu was only getting 1 or 2 peers vs about 20 peers with Teku. Is this normal to have less peers with the execution client? How many peers should I expect to see with the execution client?
  * MrPrezident — Yesterday at 00:51
> This morning I looked at my dashboard and now I see 33 execution peers and 72 consensus peers (this is with geth/prysm). I didn't change anything. I just let it run overnight. I assume this is a normal range? It would be good to know how many peers I should expect. (this is on holesky)
  * scott — 26/03/2024 05:32
> Also happening here, seems to be a known issue with an unknown root cause right now.
  * All Might — 26/03/2024 06:01
> Same here, my peers have been at 5 the entire day. Has happened several times in the last 5 days and I don't know how to fix it
  * RemiRaznor — 28/03/2024 00:01
> I'm having the same issue with low to no peer count. I'm trying to rebuild my Besu database after switching from goerli to holesky. For 2 days, I have gotten ""Unable to find sync target. Currently checking 0 peers for usefulness"" messages. Once or twice it found 1 or 2 peers enough for the download progress to be just 13.49%. I have restarted besu 4 or 5 times in the last 2 days with no success.   This validator was working fine in goerli. All ports are open. 
  * RemiRaznor — 28/03/2024 06:10
> I got it to sync finally by adding the --p2p-port=30303  card to the Besu service. After restarting the EL, I was able to connect with one peer just enough to get the download started again and then I got one more peer which got me to 57% and then I lost the peers again and stalled. I started adding the other ports, rpc port, engine port and metrics port one by one until after the metrics port the sync started up again.  Not sure if this will help but good luck... 

",network: faulty peer management,CWE-436,Interpretation Conflict,"The bug report describes a situation where different Ethereum client implementations (Besu, Geth, Nethermind, etc.) are having trouble maintaining peer-to-peer connections with each other, particularly after a network-wide protocol update (the Dencun fork). This strongly suggests that the different clients ('Product A', 'Product B', etc.) are interpreting or implementing the new network protocols differently, leading to peering failures. One user explicitly notes their node 'disconnects all non Geth nodes, because they are useless,' which is a direct example of one product taking an incorrect action (disconnecting) based on its perception of another product's state or communication. This perfectly aligns with the definition of CWE-436.

CWE-400 (Uncontrolled Resource Consumption) is not applicable because the issue is a failure to acquire or maintain a resource (peer connections), not an uncontrolled consumption or exhaustion of it.

CWE-703 (Improper Check or Handling of Exceptional Conditions) is less precise. While a network fork is an event outside of typical moment-to-moment operation, the core of the problem described is not a generic failure to handle an exception, but a specific failure of interoperability between different software products, which is more accurately captured by CWE-436.",closed,"The issue seems to stem from connectivity problems leading to a significant decrease in the number of peers available for syncing after the Dencun fork, possibly exacerbated by an outdated version of geth and specific network configurations.","This bug could severely affect the ability of nodes to sync properly, leading to delays in transaction processing, reduced network resilience, and potential fragmentation of the blockchain network due to insufficient peer connectivity.",2207030757,6805,"March 26, 2024 1:02 AM (GMT+8)","May 12, 2024 6:55 PM (GMT+8)","['bug', 'P2', 'mainnet', 'peering']",
besu,QBFT/Shanghai blocks failing withdrawal validation on import,https://github.com/hyperledger/besu/issues/6760,Consensus,"### Description
Running 4 QBFT validators with `shanghaiTime: 0` the nodes mine blocks correctly and accept transactions correctly.

However, when a new validator joins and syncs with the chain it fails to validate the imported blocks because the block body `withdrawals` element is `null` (represented as `Optional.empty()` in the code)

In the QBFT/Shanghai PR (https://github.com/hyperledger/besu/pull/6353) I disabled `withdrawal` validation for all BFT protocol schedules (see https://github.com/matthew1001/besu/blob/97c50417787f21bca8acf0a8b7d4e74d65f9f19e/consensus/common/src/main/java/org/hyperledger/besu/consensus/common/bft/BaseBftProtocolScheduleBuilder.java#L120) since withdrawals aren't a thing for BFT chains.

In hindsight I think the correct way to treat them would have been to always include an empty withdrawals list, rather than no list at all. This would pass `withdrawal` validation by `shanghai` and onwards protocol schedule validators.

Removing the BFT protocol schedule override:

```
.withdrawalsValidator(
            new WithdrawalsValidator
                .ProhibitedWithdrawals()) // QBFT/IBFT doesn't support withdrawals
```

means that BFT nodes will use whichever withdrawal validator is used by the given protocol schedule.

### Versions (Add all that apply)
* Software version: `24.3.0`",general: general improper authorization,CWE-284,Improper Access Control,"The bug report describes a situation where two parts of a distributed system have different understandings of a data structure. The existing QBFT validators generate blocks where the `withdrawals` field is `null`, based on the assumption that withdrawals are not applicable to BFT chains. However, a new validator joining the network uses the standard 'Shanghai' protocol validation logic, which expects this field to be an empty list (`[]`) and considers `null` to be invalid. This discrepancy causes the new node to fail when importing blocks. This is a classic example of CWE-436: Interpretation Conflict, where 'Product A' (the new validator) handles an input (the block) differently than 'Product B' (the existing validator) intended, leading to an incorrect action (validation failure). CWE-20 (Improper Input Validation) is less accurate because the validation logic on the new node is not inherently improper; it's correctly applying the standard Shanghai rules. The fault lies in the conflicting interpretations between the block producer and the block consumer. CWE-703 (Improper Check or Handling of Exceptional Conditions) is unsuitable as a new node syncing is a normal operation, not a rare exceptional condition, and the `null` value was an intended state from the producer's perspective.",closed,"The QBFT protocol schedule incorrectly disables withdrawal validation, leading to the omission of withdrawal lists in imported blocks when new validators join, causing validation failures.","New validators cannot successfully sync with the chain due to failed withdrawal validation, potentially leading to network disruptions and inability to process transactions correctly.",2195027554,6760,"March 19, 2024 1:47 PM (GMT+8)","March 28, 2024 1:05 AM (GMT+8)","['bug', 'non mainnet (private networks)']",
besu,Backward sync stuck in a loop,https://github.com/hyperledger/besu/issues/6749,Consensus,"### Description
The backward sync (BWS) is getting stuck in a loop with these recurring log messages:
```
{""@timestamp"":""2024-03-05T13:57:59,199"",""level"":""INFO"",""thread"":""EthScheduler-Timer-0"",""class"":""BackwardSyncContext"",""message"":""Current backward sync session failed, it will be restarted"",""throwable"":""""}
{""@timestamp"":""2024-03-05T13:58:01,114"",""level"":""INFO"",""thread"":""vert.x-worker-thread-0"",""class"":""BackwardSyncContext"",""message"":""Starting a new backward sync session"",""throwable"":""""}
```
Enough peers are present.

Restarting the node fixes the problem.

### Reason
We receive an fcu containing the block hash of a head block. This block is added to the hashesToAppend queue. The block get's reorged and when we try to retrieve that block in the BWS from out peers none of them is able to provide it to us. This causes the BWS to fail, and when we receive the next fcu, a new hash might be added to the queue, but a new BWS will be started, trying to retrieve the same block that we have unsuccessfully tried to retrieve before.

This happened on 7 out of 8 nodes I started based on 24.2.0-RC4:
dev-elc-besu-teku-mainnet-dev-stefan-rc4-(1,2,4)
dev-elc-besu-teku-mainnet-dev-stefan-ss-(1,2,3,4)

The block reorged had the hash 0x4550b82492bf1738af79efb6140770c5443d368b9512ae8551583909554a040f.

Link to Kibane should work for about another 3 weeks:
Kibana: https://kibana.dev.protocols.consensys.net/app/r?l=DISCOVER_APP_LOCATOR&v=8.11.0&lz=N4IgjgrgpgTgniAXKSsGJANwLYH0B2AhtlIgDogAmUmAtFADYDGtARlAM4S0AuUA1t2yEAlvnxQetanQ58AZoXy0KAAiWVVJDh0IBzUhQAMADwAsAVgtHWADgBMZgJz3W8gIwB2AMy3C8zycoeVYANnczI09PIyYLMzNvSm9Q21YnC3d7QihbK3cLW28nIwz4wiNI%2BTUQABoQBiU9CH0oJBBBNBAAX3qOAHsYHiQAbRGQAAEeEW0eYgAHOqpOJhAAXTX6pn6GCGx8DlGsPCISJe1dA3X6sWoTdvsCs3t7eSdaIqLaS1DKWicnN4WEF5IlvEZKJ43GYlmI%2BDBMIQGO1CBAeP0lvIRAx4YdECNNlRCHMAGoiKAAdwAkpQHk8Xm8Pr5vN8LL9%2FoDgcEwRCoaCltMSAAlJptZAgeQwfrYdr4foU2jgygAelp9XRsvlPXqMGCuo4AAsqfh4YjkeKzdAkKEjLajPV5qiOGKeDBoN1ukA%3D%3D

Node rc4-1 has been restarted and finished syncing successfully.",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a situation where the backward sync (BWS) process repeatedly fails and restarts. The title is 'Backward sync stuck in a loop', the logs show a repeating cycle of failure and restart messages, and the detailed reason explains that the process is 'trying to retrieve the same block that we have unsuccessfully tried to retrieve before'. This describes a logical loop. The loop's exit condition would be the successful retrieval of a specific block. However, this block has become permanently unavailable due to a reorg, making the exit condition unreachable. This scenario directly matches the definition of CWE-835, 'Loop with Unreachable Exit Condition'.

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is also relevant as the root cause is the failure to handle the exceptional condition of a block becoming permanently unavailable. However, CWE-835 describes the direct and most prominent manifestation of the bug as reported (the infinite loop), making it a more specific and accurate classification of the observable problem.

CWE-400, 'Uncontrolled Resource Consumption', is not suitable because the report does not mention excessive use of memory, CPU, or other resources. The primary issue is a functional liveness failure, not resource exhaustion.",closed,"The backward sync is stuck in a loop because it fails to retrieve a reorged block from peers. When a block is added to the hashesToAppend queue and then reorged, subsequent attempts to sync with that block lead to repeated failures, causing the sync process to restart indefinitely.","This bug can lead to nodes being unable to progress in the synchronization process, potentially causing delays in network consensus and increasing the time for nodes to catch up with the latest state of the blockchain. In severe cases, it may render some nodes unusable until they are manually restarted.",2191061421,6749,"March 18, 2024 1:50 AM (GMT+8)","March 26, 2024 11:01 AM (GMT+8)","['bug', 'P2']",
besu,make `maxBlobFeePerGas` optional for `eth_call` with blob `versionedHashes`,https://github.com/hyperledger/besu/issues/6709,API,"Follow up to #6657 

We shouldn’t require `maxFeePerBlobGas` for eth_call for the same reason regular gas fee settings aren’t necessary for eth_call for transactions without blobs.

Current implementation uses transaction validation so this would require checking the fields on the eth_call CallParameter",api: improper authorization,CWE-20,Improper Input Validation,"The bug report describes an issue where the `eth_call` API method incorrectly requires the `maxFeePerBlobGas` parameter. The report explicitly states that the 'Current implementation uses transaction validation' and the fix would involve 'checking the fields on the eth_call CallParameter'. This points directly to a problem with how the input to the API call is being processed. 

CWE-20, 'Improper Input Validation', is the most accurate fit because its definition states, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' In this case, the system is *incorrectly validating* the input by enforcing a mandatory field that should be optional for the `eth_call` context, just as other gas fees are.

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is less suitable. An `eth_call` is a standard, expected operation, not an 'unusual or exceptional condition'. The bug is in the normal logic path for a common API call, not in handling an error state or an unexpected event. Therefore, the core of the problem lies in the incorrect validation of normal input, which is precisely what CWE-20 describes.",closed,"The current implementation of the eth_call API requires the maxFeePerBlobGas parameter for transactions involving blobs, leading to unnecessary validation checks for parameters that should be optional.","If the maxFeePerBlobGas parameter is enforced as mandatory, it may lead to usability issues and hinder developers' ability to execute eth_call operations efficiently, potentially causing transaction failures or increased complexity in interaction with the API.",2180442897,6709,"March 11, 2024 11:35 PM (GMT+8)","March 19, 2024 11:31 AM (GMT+8)","['bug', 'P2', 'RPC']",
besu,"Invalid block detected (BREACH_OF_PROTOCOL) | IBFT 2.0 ",https://github.com/hyperledger/besu/issues/6680,Storage,"### Description
After the node stop and then tries to re-run it seems to get an `invalid block detected `error and then the peer disconnects. We build blockchain using besu for private networks. 

### Config 
```
besu/bin/besu \
     --api-gas-price-max=1000000000000000 \
     --min-gas-price=1000000000 \
     --data-path=Node-1/data \
     --data-storage-format=BONSAI \
     --network-id=6666 \
     --rpc-http-enabled=true \
     --rpc-http-host=0.0.0.0 \
     --rpc-http-port=8545 \
     --rpc-http-cors-origins=""*"" \
     --rpc-http-api=NET,WEB3,ETH,IBFT,ENGINE,TXPOOL,TRACE \
     --rpc-http-authentication-jwt-algorithm=RS256 \
     --rpc-ws-enabled=true \
     --rpc-ws-api=NET,WEB3,ETH,IBFT,ENGINE,TXPOOL,TRACE \
     --rpc-ws-host=0.0.0.0 \
     --rpc-ws-port=8546 \
     --rpc-ws-max-active-connections=100 \
     --rpc-ws-max-frame-size=1048576 \
     --genesis-file=genesis.json \
     --host-allowlist=""*"" \
     --engine-rpc-enabled=true \
     --engine-host-allowlist=""*"" \
     --engine-jwt-secret=jwtsecret.hex \
     --engine-rpc-port=8551 \
     --node-private-key-file=/Node-1/data/key \
     --max-peers=4 \
     --Xp2p-peer-lower-bound=4 \
     --sync-mode=FULL \
     --p2p-enabled=true \
     --p2p-host=XXX.XXX.XXX.XXX \
     --p2p-port=30303 \
     --logging=INFO \
     --metrics-enabled=true \
     --metrics-host=0.0.0.0 \
     --metrics-port=9545 \
     --metrics-protocol=PROMETHEUS \
     --metrics-category=BLOCKCHAIN,ETHEREUM,EXECUTORS,NETWORK,PEERS,PERMISSIONING,PRUNER,RPC,SYNCHRONIZER,TRANSACTION_POOL,STRATUM,JVM,PROCESS 

```
### Logs (if a bug)

```
2024-03-05 02:05:41.425+00:00 | BftProcessorExecutor-IBFT-0 | ERROR | AbstractBlockProcessor | failed persisting block
org.hyperledger.besu.plugin.services.exception.StorageException: org.rocksdb.RocksDBException: Busy
	at org.hyperledger.besu.plugin.services.storage.rocksdb.RocksDBTransaction.commit(RocksDBTransaction.java:95)
	at org.hyperledger.besu.services.kvstore.SegmentedKeyValueStorageTransactionValidatorDecorator.commit(SegmentedKeyValueStorageTransactionValidatorDecorator.java:65)
	at org.hyperledger.besu.ethereum.bonsai.storage.BonsaiWorldStateKeyValueStorage$Updater.commit(BonsaiWorldStateKeyValueStorage.java:466)
	at org.hyperledger.besu.ethereum.bonsai.worldview.BonsaiWorldState.persist(BonsaiWorldState.java:432)
	at org.hyperledger.besu.ethereum.mainnet.AbstractBlockProcessor.processBlock(AbstractBlockProcessor.java:194)
	at org.hyperledger.besu.ethereum.mainnet.BlockProcessor.processBlock(BlockProcessor.java:79)
	at org.hyperledger.besu.ethereum.MainnetBlockValidator.processBlock(MainnetBlockValidator.java:207)
	at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:135)
	at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:72)
	at org.hyperledger.besu.consensus.ibft.validation.MessageValidator.validateBlock(MessageValidator.java:97)
	at org.hyperledger.besu.consensus.ibft.validation.MessageValidator.validateProposal(MessageValidator.java:80)
	at org.hyperledger.besu.consensus.ibft.statemachine.RoundState.setProposedBlock(RoundState.java:88)
	at org.hyperledger.besu.consensus.ibft.statemachine.IbftRound.updateStateWithProposedBlock(IbftRound.java:228)
	at org.hyperledger.besu.consensus.ibft.statemachine.IbftRound.updateStateWithProposalAndTransmit(IbftRound.java:170)
	at org.hyperledger.besu.consensus.ibft.statemachine.IbftRound.createAndSendProposalMessage(IbftRound.java:123)
	at org.hyperledger.besu.consensus.ibft.statemachine.IbftBlockHeightManager.handleBlockTimerExpiry(IbftBlockHeightManager.java:127)
	at org.hyperledger.besu.consensus.common.bft.statemachine.BaseBftController.handleBlockTimerExpiry(BaseBftController.java:167)
	at org.hyperledger.besu.consensus.common.bft.EventMultiplexer.handleBftEvent(EventMultiplexer.java:65)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at org.hyperledger.besu.consensus.common.bft.BftProcessor.run(BftProcessor.java:65)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.rocksdb.RocksDBException: Busy
	at org.rocksdb.Transaction.commit(Native Method)
	at org.rocksdb.Transaction.commit(Transaction.java:208)
	at org.hyperledger.besu.plugin.services.storage.rocksdb.RocksDBTransaction.commit(RocksDBTransaction.java:89)
	... 22 more
2024-03-05 02:05:41.428+00:00 | BftProcessorExecutor-IBFT-0 | INFO  | MainnetBlockValidator | Invalid block 2704803 (0x0743edf2e2fd0a61c11ff76cdc1dd82d09e675fc1c4c7c78235af506a2178d3b): Optional[org.rocksdb.RocksDBException: Busy], caused by org.hyperledger.besu.plugin.services.exception.StorageException: org.rocksdb.RocksDBException: Busy
2024-03-05 02:05:41.428+00:00 | BftProcessorExecutor-IBFT-0 | INFO  | MessageValidator | Invalid Proposal message, block did not pass validation. Reason Optional[org.rocksdb.RocksDBException: Busy]
2024-03-05 02:05:41.601+00:00 | BftProcessorExecutor-IBFT-0 | ERROR | AbstractBlockProcessor | failed persisting block
```


```
2024-03-05 02:05:41.602+00:00 | BftProcessorExecutor-IBFT-0 | INFO  | MainnetBlockValidator | Invalid block 2704878 (0xf8f7026f524b33db9bb0115c4053e5b3f4141de166617f6e51c6c5ff47731cc5): Optional[org.rocksdb.RocksDBException: Busy], caused by org.hyperledger.besu.plugin.services.exception.StorageException: org.rocksdb.RocksDBException: Busy
2024-03-05 02:05:41.602+00:00 | BftProcessorExecutor-IBFT-0 | INFO  | MessageValidator | Invalid Proposal message, block did not pass validation. Reason Optional[org.rocksdb.RocksDBException: Busy]
2024-03-05 02:05:41.663+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | MainnetBlockValidator | Invalid block 2704921 (0x5758b561fa7b427883ed71e4975cbe72836fa21d52b6196f8262d048f86c51e8): Optional[Unable to process block because parent world state 0x964e562dbcd2113159cda36946fac806e5ef48e3f10a7289d3c34b84a6635501 is not available]
2024-03-05 02:05:41.666+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | Pipeline | Unexpected exception in pipeline. Aborting.
org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block at #2704921 (0x5758b561fa7b427883ed71e4975cbe72836fa21d52b6196f8262d048f86c51e8)

```



```
2024-03-05 02:05:41.668+00:00 | EthScheduler-Services-5 (importBlock) | WARN  | PipelineChainDownloader | Invalid block detected (BREACH_OF_PROTOCOL). Disconnecting from sync target. Failed to import block: Invalid block at #2704921 (0x5758b561fa7b427883ed71e4975cbe72836fa21d52b6196f8262d048f86c51e8)
2024-03-05 02:05:41.675+00:00 | EthScheduler-Services-5 (importBlock) | WARN  | PipelineChainDownloader | Chain download failed. Restarting after short delay.
java.util.concurrent.CompletionException: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block at #2704921 (0x5758b561fa7b427883ed71e4975cbe72836fa21d52b6196f8262d048f86c51e8)

```",consensus: consensus liveness failure,CWE-404,Improper Resource Shutdown or Release,"The bug report indicates that an error occurs after a node is stopped and then restarted. The core of the error is a `org.rocksdb.RocksDBException: Busy` which happens when the application tries to persist a block to its database (RocksDB). This 'Busy' status implies that a resource, likely a lock on the database file, is being held and cannot be accessed. The trigger condition (stop and restart) strongly suggests that the resource was not properly released during the shutdown of the previous process instance. When the new process starts, it finds the resource still locked, leading to the exception. 

- CWE-362 (Race Condition) and CWE-662 (Improper Synchronization) describe issues with concurrent threads within a running process. While the 'Busy' exception is a symptom of a resource conflict that can be caused by improper synchronization, these CWEs do not capture the crucial detail that the problem is triggered by a stop/restart cycle. 

- CWE-404 (Improper Resource Shutdown or Release) perfectly matches the scenario. It describes a situation where a product does not release a resource correctly. In this case, the Besu node likely failed to release the lock on its RocksDB database during shutdown. Upon restart, the new instance cannot acquire the lock because it was never released, resulting in the 'Busy' exception. This makes CWE-404 the most accurate and specific classification for the described bug.",closed,"The node is unable to successfully process and commit blocks after a restart due to a 'Busy' state in the RocksDB storage engine, leading to invalid blocks being detected.","This bug can lead to node disconnection from peers, failure to synchronize the blockchain properly, and ultimately result in data inconsistency within the network, affecting the reliability of the private blockchain.",2168144639,6680,"March 5, 2024 2:23 AM (GMT+8)","June 13, 2024 9:14 AM (GMT+8)","['bug', 'P2', 'mainnet', 'non mainnet (private networks)']",
besu,`block export` (or any sub command) starts a BFT mining coordinator,https://github.com/hyperledger/besu/issues/6674,Utilities,"### Description
When running the `block export` or `block import` commands, a BFT mining coordinator is started. If the node is the only validator is will continue to produce new blocks even during `export`/`import`.

### Acceptance Criteria
Don't start a mining coordinator when running any of the sub-commands

### Steps to Reproduce (Bug)
Run `besu --genesis-file=../genesis.json --data-path=./data blocks export --to=blocks.bin`. If the node is the only validator it will produce new blocks during the export
",storage: storage corruption,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a situation where running a utility command, such as `block export`, incorrectly triggers the start of a BFT mining coordinator. This results in two processes running concurrently: the export/import operation and the block production (mining) operation. Both of these processes access and modify the same shared resource: the blockchain data storage. The bug report explicitly mentions that the node will ""produce new blocks even during `export`/`import`"" and lists ""storage corruption"" as a functional symptom. This scenario directly aligns with the definition of CWE-362. It involves a 'concurrent code sequence' (mining) that modifies a 'shared resource' (the blockchain data) during a 'timing window' where another code sequence (the export/import command) requires stable access to that resource, but this access is not properly synchronized or prevented. 

CWE-436, 'Interpretation Conflict', is not applicable because the issue is internal to a single product and does not involve a misinterpretation of state or inputs between two different products. 

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is less precise. While the root cause might be a failure to check for the condition of 'running a subcommand', the actual vulnerability manifested is the concurrent access to a shared resource. CWE-362 describes the nature of the vulnerability itself—the race condition—more accurately than CWE-754 describes its cause.",closed,The BFT mining coordinator is incorrectly initialized or not properly disabled during the execution of block export or import commands.,"The node can produce new blocks unintentionally while exporting or importing, leading to inconsistencies in the blockchain state and potential forks.",2166850437,6674,"March 4, 2024 1:27 PM (GMT+8)","March 12, 2024 6:26 PM (GMT+8)",['bug'],
besu,Add 4844 transaction fields to the `CallParameter`,https://github.com/hyperledger/besu/issues/6657,API,"currently eth_call does not work for blob transactions.

Spec for eth_call params 
https://github.com/ethereum/execution-apis/blob/main/src/schemas/transaction.yaml",api: api unavailability,CWE-436,Interpretation Conflict,"The bug report indicates that the `eth_call` API in Hyperledger Besu does not work for blob transactions because the `CallParameter` object is missing the necessary fields (`maxFeePerBlobGas`, `blobVersionedHashes`) as defined in the Ethereum execution API specification. This is a classic case of CWE-436: Interpretation Conflict. The Besu implementation (Product A) has an interpretation of the `eth_call` parameters that is different from the official specification (which can be considered Product B, or the standard that other clients/nodes adhere to). This conflict in interpretation leads to the observed functional bug where the API is unavailable for this specific transaction type. CWE-755 (Improper Handling of Exceptional Conditions) is less accurate because the inability to process a new, valid transaction type is a functional deficit based on a specification mismatch, not a failure to handle an unexpected error or exceptional state. CWE-20 (Improper Input Validation) is also not the best fit because the problem is not that the input is being validated incorrectly; the problem is that the API's data structure is not designed to accept the new input fields at all, making it a structural discrepancy with the standard rather than a validation logic flaw.",closed,"The API does not currently support blob transactions in the eth_call method, leading to a lack of necessary transaction fields for these types of calls.","This bug prevents users from executing blob transactions via eth_call, which could limit functionality and create inconsistencies in how transactions are processed within the network.",2162482138,6657,"March 1, 2024 2:50 AM (GMT+8)","March 6, 2024 7:06 AM (GMT+8)","['bug', 'P2', '4844']",
besu,"Besu Fails Repeatedly During Initial Full Sync - ""World State Root does not match expected value""",https://github.com/hyperledger/besu/issues/6615,Storage,"Greetings!

I am running into an issue with multiple versions of Besu failing at the same block (11,114,732) when trying to do an initial sync for a full archive node, limited details follow:

1. Running slightly older Besu and Teku versions, error at block 11,114,732 occurs

2. Update Besu to 24.1.2-dev-b6a6402b (and Teku to teku/v24.1.1+44-ge6c81905a6/linux-x86_64/-privatebuild-openjdk64bitservervm-java-19), start Besu (and Teku), error at block 11,114,732 occurs

3. Restored Besu/Teku data from previous backup (~around block 5,000,000), start Besu (and Teku) and let run, error at block 11,114,732 occurs

4. Deleted Besu/Teku data, start Besu (and Teku), error at block 11,114,732 occurs

*** Command line:

#!/bin/bash
/usr/local/java/besu/besu-build/bin/besu \
--sync-mode=FULL \
--data-storage-format=BONSAI \
--data-path=""/mnt/md0/data/ethereum_data-besu"" \
--max-peers=96 \
--rpc-http-api=ETH,NET,WEB3,DEBUG \
--rpc-http-enabled=true \
--rpc-http-host=""0.0.0.0"" \
--rpc-http-cors-origins=""*"" \
--rpc-http-max-batch-size=10000 \
--rpc-ws-enabled=true \
--rpc-ws-host=""0.0.0.0"" \
--host-allowlist=""*"" \
--engine-rpc-port=8551 \
--engine-jwt-secret=/usr/local/java/jwt-secret/jwtsecret.hex

*** O/S Info:

Distributor ID: Ubuntu
Description:    Ubuntu 23.10
Release:        23.10
Codename:       mantic

*** Besu Info:

Besu version: 24.1.2-dev-b6a6402b

Configuration:
Network: Mainnet
Network Id: 1
Data storage: Bonsai
Sync mode: Full
RPC HTTP APIs: ETH,NET,WEB3,DEBUG
RPC HTTP port: 8545
Engine APIs: ENGINE,ETH
Engine port: 8551
Engine JWT: /usr/local/java/jwt-secret/jwtsecret.hex
Using LAYERED transaction pool implementation
Using STACKED worldstate update mode

Host:
Java: openjdk-java-19
Maximum heap size: 15.64 GB
OS: linux-x86_64
glibc: 2.38
Total memory: 62.53 GB
CPU cores: 24

Plugins:
TOTAL = 0 of 0 plugins successfully loaded
from /usr/local/java/besu/besu-build/plugins

*** Most recent stacktrace:

2024-02-27 01:55:32.608+00:00 | EthScheduler-Services-9 (importBlock) | ERROR | AbstractBlockProcessor | failed persisting block
java.lang.RuntimeException: World State Root does not match expected value, header 0x5b4efb7aa73344c4817fb7d6d916b185ef3356237ce2e67c4efebecde6c3951e calculated 0xaae985d0795a47a0d69029ace31ff69755742d272074508ad981a6c5f1d61535
        at org.hyperledger.besu.ethereum.trie.bonsai.worldview.BonsaiWorldState.verifyWorldStateRoot(BonsaiWorldState.java:476)
        at org.hyperledger.besu.ethereum.trie.bonsai.worldview.BonsaiWorldState.persist(BonsaiWorldState.java:434)
        at org.hyperledger.besu.ethereum.mainnet.AbstractBlockProcessor.processBlock(AbstractBlockProcessor.java:194)
        at org.hyperledger.besu.ethereum.mainnet.BlockProcessor.processBlock(BlockProcessor.java:79)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.processBlock(MainnetBlockValidator.java:207)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:135)
        at org.hyperledger.besu.ethereum.MainnetBlockValidator.validateAndProcessBlock(MainnetBlockValidator.java:72)
        at org.hyperledger.besu.ethereum.mainnet.MainnetBlockImporter.importBlock(MainnetBlockImporter.java:45)
        at org.hyperledger.besu.ethereum.core.BlockImporter.importBlock(BlockImporter.java:45)
        at org.hyperledger.besu.ethereum.eth.sync.fullsync.FullImportBlockStep.accept(FullImportBlockStep.java:63)
        at org.hyperledger.besu.ethereum.eth.sync.fullsync.FullImportBlockStep.accept(FullImportBlockStep.java:32)
        at org.hyperledger.besu.services.pipeline.CompleterStage.run(CompleterStage.java:37)
        at org.hyperledger.besu.services.pipeline.Pipeline.lambda$runWithErrorHandling$3(Pipeline.java:170)
        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base/java.lang.Thread.run(Thread.java:1589)
2024-02-27 01:55:32.608+00:00 | EthScheduler-Services-9 (importBlock) | INFO  | MainnetBlockValidator | Invalid block 11114732 (0x878633f621aa8e89837ee8160d3acff74e7765d05df2e99bbcff11c8659e5fca): Optional[World State Root does not match expected value, header 0x5b4efb7aa73344c4817fb7d6d916b185ef3356237ce2e67c4efebecde6c3951e calculated 0xaae985d0795a47a0d69029ace31ff69755742d272074508ad981a6c5f1d61535], caused by java.lang.RuntimeException: World State Root does not match expected value, header 0x5b4efb7aa73344c4817fb7d6d916b185ef3356237ce2e67c4efebecde6c3951e calculated 0xaae985d0795a47a0d69029ace31ff69755742d272074508ad981a6c5f1d61535
2024-02-27 01:55:32.608+00:00 | EthScheduler-Services-9 (importBlock) | INFO  | Pipeline | Unexpected exception in pipeline. Aborting.
Throwable summary: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block at #11114732 (0x878633f621aa8e89837ee8160d3acff74e7765d05df2e99bbcff11c8659e5fca)
        at: org.hyperledger.besu.ethereum.eth.sync.fullsync.FullImportBlockStep.accept(FullImportBlockStep.java:65)
2024-02-27 01:55:32.608+00:00 | EthScheduler-Services-9 (importBlock) | WARN  | PipelineChainDownloader | Invalid block detected (BREACH_OF_PROTOCOL). Disconnecting from sync target. Failed to import block: Invalid block at #11114732 (0x878633f621aa8e89837ee8160d3acff74e7765d05df2e99bbcff11c8659e5fca)
2024-02-27 01:55:32.608+00:00 | EthScheduler-Services-9 (importBlock) | WARN  | PipelineChainDownloader | Chain download failed. Restarting after short delay.
java.util.concurrent.CompletionException: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block at #11114732 (0x878633f621aa8e89837ee8160d3acff74e7765d05df2e99bbcff11c8659e5fca)
        at java.base/java.util.concurrent.CompletableFuture.encodeRelay(CompletableFuture.java:368)
        at java.base/java.util.concurrent.CompletableFuture.completeRelay(CompletableFuture.java:377)
        at java.base/java.util.concurrent.CompletableFuture$UniRelay.tryFire(CompletableFuture.java:1097)
        at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
        at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
        at org.hyperledger.besu.services.pipeline.Pipeline.abort(Pipeline.java:207)
        at org.hyperledger.besu.services.pipeline.Pipeline.lambda$runWithErrorHandling$3(Pipeline.java:186)
        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.hyperledger.besu.ethereum.eth.sync.tasks.exceptions.InvalidBlockException: Failed to import block: Invalid block at #11114732 (0x878633f621aa8e89837ee8160d3acff74e7765d05df2e99bbcff11c8659e5fca)
        at org.hyperledger.besu.ethereum.eth.sync.fullsync.FullImportBlockStep.accept(FullImportBlockStep.java:65)
        at org.hyperledger.besu.ethereum.eth.sync.fullsync.FullImportBlockStep.accept(FullImportBlockStep.java:32)
        at org.hyperledger.besu.services.pipeline.CompleterStage.run(CompleterStage.java:37)
        at org.hyperledger.besu.services.pipeline.Pipeline.lambda$runWithErrorHandling$3(Pipeline.java:170)
        ... 5 more

...above error repeats over and over and over and over...

Please let me know if you need any additional information, apologies if this is a duplicate issue but the solutions offered in other tickets with a similar description did not work, perhaps due to my node still doing the full import?",consensus: consensus liveness failure,CWE-682,Incorrect Calculation,"The bug report details a failure during a blockchain synchronization process. The core of the issue is explicitly stated in the error message: `World State Root does not match expected value, header 0x... calculated 0x...`. This means the software is performing a complex calculation (deriving the world state root from block transactions) and arriving at a result that differs from the expected, correct value stored in the block header. This discrepancy causes a validation check to fail, halting the synchronization process. This is a security-critical operation, as correctly validating the state root is fundamental to maintaining consensus in a blockchain.

Let's evaluate the provided CWEs:
- **CWE-345 (Insufficient Verification of Data Authenticity):** This CWE is not a good fit. The software is, in fact, performing a verification of data authenticity by comparing the calculated state root to the one in the header. The verification process itself is working correctly; it is successfully detecting a mismatch and rejecting the block. The problem is not insufficient verification, but an error in the data generation (the calculation) that precedes the verification.
- **CWE-1286 (Improper Validation of Syntactic Correctness of Input):** This CWE is also not applicable. The issue is not with the syntax of the incoming block data (e.g., malformed fields). The problem lies in the semantic processing of the block's contents—specifically, the state transition calculations.
- **CWE-682 (Incorrect Calculation):** This CWE is the most accurate description of the bug. The software performs a calculation (the world state root) that yields an incorrect result. This incorrect result is then used in a security-critical decision (verifying the block's validity). The failure of this decision leads directly to the observed bug, a consensus liveness failure. The error message itself pinpoints a failed calculation as the root cause.",closed,The Besu node fails to validate the world state root against the expected value during the block import process. This indicates a potential issue in the world state verification logic or the handling of state transitions that leads to a mismatch.,"The inability to sync successfully at block 11,114,732 prevents the node from becoming a fully archived node, which could lead to loss of functionality for users relying on the node for accurate state data and may disrupt the overall network if multiple nodes encounter the same issue.",2155529715,6615,"February 27, 2024 2:36 AM (GMT+8)","August 13, 2024 11:11 PM (GMT+8)","['bug', 'P2', 'mainnet', 'bonsai']",
besu,Private blockchain stalling when less than 1/3 of validators are down - BftProcessorExecutor-QBFT-0 | INFO  | ProposalValidator | Invalid Proposal Payload: Latest Prepared Metadata blockhash does not align with proposed block,https://github.com/hyperledger/besu/issues/6613,Consensus,"### Description
I have a private blockchain with 7 validators, I take down 2 validators and the chain seems to freeze and is unable to produce blocks. 

### Acceptance Criteria
* Blockchain is able to handle up to 1/3 of the validators going down (should be able to handle 2 validators going offline) 

### Steps to Reproduce (Bug)
I have tested this a few times and it is inconsistent. Sometimes the chain does not stall, other times the chain does stall.

Shut down two validators and then trigger events to happen on the blockchain.

**Expected behavior:** [What you expect to happen]
Blockchain works with 2 validators down. 

**Actual behavior:** [What actually happens]
The blockchain will stall and gives `BftProcessorExecutor-QBFT-0 | INFO  | ProposalValidator | Invalid Proposal Payload: Latest Prepared Metadata blockhash does not align with proposed block` errors along with `EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.`

**Frequency:** [What percentage of the time does it occur?]
This happens about half the times I have run testing.

### Logs (if a bug)
```
2024-02-23 20:03:53.753+00:00 | nioEventLoopGroup-3-6 | DEBUG | EthPeer | handleDisconnect - EthPeer PeerId 0x9ee..., reputation PeerReputation 109, validated? true, disconnected? true, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 131.... with peer 0x9ee... inboundInitiated false initAt 1708716292348], enode enode://9ee...
2024-02-23 20:03:53.753+00:00 | nioEventLoopGroup-3-6 | DEBUG | EthPeers | Disconnected EthPeer PeerId 0x9ee..., reputation PeerReputation 109, validated? true, disconnected? true, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 1311626227 with peer 0x9ee... inboundInitiated false initAt 170...], enode enode://9e...
2024-02-23 20:03:53.754+00:00 | nioEventLoopGroup-3-6 | DEBUG | EthProtocolManager | Disconnect - Inbound - 0x08 CLIENT_QUITTING - 0x9e... - 9 peers left
9 EthPeers {
PeerId 0x0ff..., reputation PeerReputation 101, validated? true, disconnected? false, client: besu/v23.4.4/linux-x86_64/openjdk-java-17, connection [Connection with hashCode -1461... with peer 0x0ff... inboundInitiated true initAt 170...], enode enode://0ff...?discport=0,
PeerId 0x95..., reputation PeerReputation 101, validated? true, disconnected? false, client: besu/v23.4.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 134... with peer 0x95... inboundInitiated true initAt 170...], enode enode://95...?discport=0,

PeerId 0x0c7..., reputation PeerReputation 102, validated? true, disconnected? false, client: besu/v23.4.4/linux-x86_64/openjdk-java-17, connection [Connection with hashCode -166... with peer 0x0c7... inboundInitiated true initAt 170...], enode enode://0c7...?discport=0,

PeerId 0x31..., reputation PeerReputation 103, validated? true, disconnected? false, client: besu/v23.10.1/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 577... with peer 0x31... inboundInitiated true initAt 170...], enode enode://31...?discport=0,
PeerId 0xa5..., reputation PeerReputation 106, validated? true, disconnected? false, client: besu/v23.10.2/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 392... with peer 0xa5... inboundInitiated true initAt 170...], enode enode://a5...?discport=0,
PeerId 0x2f..., reputation PeerReputation 107, validated? true, disconnected? false, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 114... with peer 0x2f... inboundInitiated false initAt 170...], enode enode://2f...,
PeerId 0xbe..., reputation PeerReputation 107, validated? true, disconnected? false, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode -133... with peer 0xbe... inboundInitiated false initAt 170...], enode enode://be...,
PeerId 0x035..., reputation PeerReputation 111, validated? true, disconnected? false, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 202... with peer 0x035... inboundInitiated false initAt 170...], enode enode://035...,
PeerId 0x5a..., reputation PeerReputation 126, validated? true, disconnected? false, client: besu/v23.10.0/linux-x86_64/openjdk-java-17, connection [Connection with hashCode 317... with peer 0x5a... inboundInitiated false initAt 170...], enode enode://5a}
2024-02-23 20:03:54.353+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftRound | Importing proposed block to chain. round=ConsensusRoundIdentifier{Sequence=129..., Round=1}, hash=0xcfc....
2024-02-23 20:03:54.565+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftBesuControllerBuilder | Imported #12,904,735 / 4 tx / 0 pending / 21,993,755 (0.0%) gas / (0xcfc...)
2024-02-23 20:03:54.656+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftBesuControllerBuilder | Imported #12,904,736 / 0 tx / 0 pending / 0 (0.0%) gas / (0xc9b...)
2024-02-23 20:03:57.950+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:02.950+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:04.595+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftRound | Importing proposed block to chain. round=ConsensusRoundIdentifier{Sequence=129..., Round=1}, hash=0xd47...
2024-02-23 20:04:04.734+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | QbftBesuControllerBuilder | Imported #12,904,737 / 4 tx / 0 pending / 12,986,827 (0.0%) gas / (0xd47...)
2024-02-23 20:04:04.735+00:00 | EthScheduler-Workers-0 | INFO  | PersistBlockTask | Block 129... (0xd47...) is already imported
2024-02-23 20:04:07.951+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:12.951+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:17.465+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | ProposalValidator | Invalid Proposal Payload: Latest Prepared Metadata blockhash does not align with proposed block
2024-02-23 20:04:17.952+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:22.952+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:27.953+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:32.953+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:33.592+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | ProposalValidator | Invalid Proposal Payload: Latest Prepared Metadata blockhash does not align with proposed block
2024-02-23 20:04:37.953+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:42.954+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:47.954+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:52.955+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:04:57.955+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:05:02.956+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:05:05.711+00:00 | BftProcessorExecutor-QBFT-0 | INFO  | ProposalValidator | Invalid Proposal Payload: Latest Prepared Metadata blockhash does not align with proposed block
2024-02-23 20:05:07.956+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:05:12.957+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected.
2024-02-23 20:05:17.957+00:00 | EthScheduler-Timer-0 | DEBUG | WaitForPeerTask | Waiting for new peer connection. 9 peers currently connected
```

### Versions (Add all that apply)
* Software version: [`besu --version`]
* besu/v23.10.0/linux-x86_64/openjdk-java-17
* Java version: [`java -version`]
* openjdk 17.0.9 2023-10-17
* OS Name & Version: [`cat /etc/*release`]
* Ubuntu 22.04.2 LTS
* Kernel Version: [`uname -a`]
* Linux 22.04.1-Ubuntu SMP Wed Jan 10 22:54:16 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
* Cloud VM, type, size: [Amazon Web Services I3-large]
* AWS T2-Large
",consensus: consensus liveness failure,CWE-354,Improper Validation of Integrity Check Value,"The most relevant Common Weakness Enumeration (CWE) for the described bug is CWE-354: Improper Validation of Integrity Check Value.
Root Cause Analysis
The core of the issue lies in the QBFT consensus mechanism of Hyperledger Besu. A blockchain, at its heart, is a state machine, and for it to be secure, all participants (validators) must agree on the state. This agreement is reached through a consensus mechanism. In this case, the mechanism was failing.
The bug manifested as a stalled blockchain, with validators failing to produce new blocks, because of ""Invalid Proposal Payload"" errors. This happened when some validators were offline. The investigation revealed that the root cause was an incorrect hashing method for validating block proposals. Specifically, the hash of a proposal for a new round, which was based on a block from a previous round, was not being calculated correctly. The round number, a crucial piece of information for proposal validation, was not being properly included in the hash calculation.
The fix, as detailed in the pull request, was to correct the hashing function (BlockHeaderFunctions) to ensure the round number was correctly factored in. This ensures that the hash of the proposed block correctly aligns with the prepared block from the previous round, even when the proposal is for a new round.
Justification for CWE-354
CWE-354: Improper Validation of Integrity Check Value is the most fitting description of this vulnerability. Here's why:
• Integrity Check Value: The hash of the block proposal serves as an integrity check. It's a cryptographic checksum that ensures the proposal has not been tampered with and is the correct one to be considered for the next block.
• Improper Validation: The bug was a direct result of the validation of this integrity check (the hash) being implemented incorrectly. The logic for calculating the hash was flawed, leading to valid proposals being rejected as invalid.
Other Related CWEs
While CWE-354 is the most precise, other CWEs also describe aspects of this vulnerability:
• CWE-325: Missing Cryptographic Step: One could argue that a ""correct"" cryptographic step (the hashing with the proper round number) was missing and an incorrect one was in its place.
• CWE-1240: Use of a Cryptographic Primitive with a Risky Implementation: The hash function (a cryptographic primitive) was used in a risky way by not including all the necessary data (the round number) in the hash calculation.
• CWE-358: Improperly Implemented Security Check for Standard: The consensus protocol acts as a standard, and the security check (proposal validation) was improperly implemented.",closed,"The consensus mechanism fails to handle the scenario where the number of validators drops below the required threshold for block production, leading to inconsistent behavior in processing proposals.","If more than one-third of the validators are down, the blockchain may stall, preventing the generation of new blocks and disrupting the normal operation of the network.",2155259283,6613,"February 26, 2024 10:12 PM (GMT+8)","December 6, 2024 12:32 PM (GMT+8)","['bug', 'P2', 'non mainnet (private networks)']",
besu,Inconsistent Trace Details and Missing Error Messages in `trace_block` Method Output,https://github.com/hyperledger/besu/issues/6591,API,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/en/stable/HowTo/Monitor/Logging/ -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
As a developer working with Ethereum node trace methods, I want the `trace_block` method to accurately reflect trace details, including `subTraces` and `error` messages, so that I can reliably analyze transaction execution and failures.

### Acceptance Criteria
- The `trace_block` method should accurately report the number of `subTraces` for each trace.
- Error messages, such as ""out of gas"", should be correctly reported in the trace details when applicable.
- The trace output from `trace_block` should be consistent with what is returned by `debug_traceBlockByNumber` when using the `callTracer`.


### Steps to Reproduce (Bug)
- Execute a `trace_block` request for block `0x20F6DF` (block number 2160351) using the provided JSON-RPC request.
- Note the `subTraces` count and lack of `error` message for the delegate call trace.
- Execute a `debug_traceBlockByNumber` request for the same block using the `callTracer`.
- Compare the results, noting discrepancies in the `subTraces` count (only in parity style traces) and the presence of an ""out of gas"" error in the `debug_traceBlockByNumber` output but not in the `trace_block` output.

**Request Example:**
```
{""jsonrpc"":""2.0"",""method"":""trace_block"",""params"": [""0x20F6DF""],""id"":0}
```

**Response Example (trace_block):**
```
[
    {
        ""jsonrpc"": ""2.0"",
        ""id"": 0,
        ""result"": [
            {
                ""action"": {
                    ""callType"": ""call"",
                    ""from"": ""0xd8422593f16cd6d65c3f4cfa28b5b5a862037123"",
                    ""gas"": ""0x1a18"",
                    ""input"": ""0x5b7d7482000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000a0000000000000000000000000000000000000000000000000000000000000004034313465376364326235656636313337656166383661396134653064666430333536313063323562323536333031633662396361356361313531653233373965000000000000000000000000000000000000000000000000000000000000004034646163313738646333376331303736346235643862373862633135323635366437316662343865626537396361613835343437336530663031313132313732"",
                    ""to"": ""0xd1a3abf42f9e66be86cfdea8c5c2c74f041c5e14"",
                    ""value"": ""0x0""
                },
                ""blockHash"": ""0x2345afc92f072449294eba81a33116da5d014e74ecbe5db53e5d72b40145976f"",
                ""blockNumber"": 2160351,
                ""result"": {
                    ""gasUsed"": ""0x0"",
                    ""output"": ""0x""
                },
                ""subtraces"": 0,
                ""traceAddress"": [],
                ""transactionHash"": ""0xea89b8082ab1e9e8f0a025ead197ce8e2cdf4b1212d4ec13a91e97570485a053"",
                ""transactionPosition"": 0,
                ""type"": ""call""
            },
            {
                ""action"": {
                    ""callType"": ""delegatecall"",
                    ""from"": ""0xd1a3abf42f9e66be86cfdea8c5c2c74f041c5e14"",
                    ""gas"": ""0x6dd"",
                    ""input"": ""0x5b7d7482000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000a0000000000000000000000000000000000000000000000000000000000000004034313465376364326235656636313337656166383661396134653064666430333536313063323562323536333031633662396361356361313531653233373965000000000000000000000000000000000000000000000000000000000000004034646163313738646333376331303736346235643862373862633135323635366437316662343865626537396361613835343437336530663031313132313732"",
                    ""to"": ""0x564477025731ee7197eecf2c4a0d0106cc3e4572"",
                    ""value"": ""0x0""
                },
                ""blockHash"": ""0x2345afc92f072449294eba81a33116da5d014e74ecbe5db53e5d72b40145976f"",
                ""blockNumber"": 2160351,
                ""result"": {
                    ""gasUsed"": ""0xffffffffffffece0"",
                    ""output"": ""0x""
                },
                ""subtraces"": 0,
                ""traceAddress"": [
                    0
                ],
                ""transactionHash"": ""0xea89b8082ab1e9e8f0a025ead197ce8e2cdf4b1212d4ec13a91e97570485a053"",
                ""transactionPosition"": 0,
                ""type"": ""call""
            },
            {
                ""action"": {
                    ""author"": ""0x8f81e2e3f8b46467523463835f965ffe476e1c9e"",
                    ""rewardType"": ""block"",
                    ""value"": ""0x0""
                },
                ""blockHash"": ""0x2345afc92f072449294eba81a33116da5d014e74ecbe5db53e5d72b40145976f"",
                ""blockNumber"": 2160351,
                ""result"": null,
                ""subtraces"": 0,
                ""traceAddress"": [],
                ""type"": ""reward""
            }
        ]
    }
]
```

**Response Example (`debug_traceBlockByNumber`) used to cross-check error:**
```
[
            {
                ""result"": {
                    ""calls"": [
                        {
                            ""error"": ""out of gas"",
                            ""from"": ""0xd1a3abf42f9e66be86cfdea8c5c2c74f041c5e14"",
                            ""gas"": ""0x6dd"",
                            ""gasUsed"": ""0x6dd"",
                            ""input"": ""0x5b7d7482000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000a0000000000000000000000000000000000000000000000000000000000000004034313465376364326235656636313337656166383661396134653064666430333536313063323562323536333031633662396361356361313531653233373965000000000000000000000000000000000000000000000000000000000000004034646163313738646333376331303736346235643862373862633135323635366437316662343865626537396361613835343437336530663031313132313732"",
                            ""to"": ""0x564477025731ee7197eecf2c4a0d0106cc3e4572"",
                            ""type"": ""DELEGATECALL"",
                            ""value"": ""0x0""
                        }
                    ],
                    ""error"": ""out of gas"",
                    ""from"": ""0xd8422593f16cd6d65c3f4cfa28b5b5a862037123"",
                    ""gas"": ""0x7690"",
                    ""gasUsed"": ""0x7690"",
                    ""input"": ""0x5b7d7482000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000a0000000000000000000000000000000000000000000000000000000000000004034313465376364326235656636313337656166383661396134653064666430333536313063323562323536333031633662396361356361313531653233373965000000000000000000000000000000000000000000000000000000000000004034646163313738646333376331303736346235643862373862633135323635366437316662343865626537396361613835343437336530663031313132313732"",
                    ""to"": ""0xd1a3abf42f9e66be86cfdea8c5c2c74f041c5e14"",
                    ""type"": ""CALL"",
                    ""value"": ""0x0""
                }
            }
        ]
```

**Expected behavior:** The `trace_block` method should accurately report subTraces and include error messages where applicable, consistent with the detailed trace data provided by `debug_traceBlockByNumber` using `callTracer`.

**Actual behavior:** The `trace_block` method reports `subTraces` as 0 for a trace that appears to have a child trace and does not include an ""out of gas"" `error` message for a delegate call that, according to `debug_traceBlockByNumber` output, failed due to running ""out of gas"".

**Frequency:** This discrepancy is observed consistently for the specified block but may occur in other blocks as well.",api: incorrect api output,CWE-221,Information Loss or Omission,"The bug report describes two primary issues with the `trace_block` API method: 1) it reports an incorrect value for `subTraces`, and 2) it completely omits an `error` message (specifically ""out of gas"") that is known to have occurred. The stated goal of the user is to ""reliably analyze transaction execution and failures,"" which is being prevented by this bug. 

Let's evaluate the provided CWEs:
- **CWE-682 (Incorrect Calculation):** This could apply to the incorrect `subTraces` count. However, it does not adequately describe the more critical issue of the missing error message, which is an omission of data, not a miscalculation.
- **CWE-754 (Improper Check for Unusual or Exceptional Conditions):** This is not the best fit because the system *does* seem to detect the exceptional ""out of gas"" condition, as shown by the output of another API call (`debug_traceBlockByNumber`). The failure is not in the check itself, but in the reporting of the check's outcome.
- **CWE-221 (Information Loss or Omission):** This is the most accurate CWE. The definition states the product ""does not record, or improperly records, security-relevant information that... hampers later analysis."" The `trace_block` method fails to record the ""out of gas"" error (information loss) and improperly records the `subTraces` count. This directly ""hampers later analysis"" of transaction failures, as described in the bug report. This CWE covers all aspects of the reported bug.",closed,"The `trace_block` method does not accurately reflect the execution details of transactions, specifically failing to report subtraces and error messages that should be included based on the actual execution context.","Inaccurate trace output can lead developers to misinterpret the execution flow of transactions, potentially resulting in incorrect debugging, failure to identify transaction failures, and an overall lack of reliability in transaction analysis.",2141802183,6591,"February 19, 2024 8:31 AM (GMT+8)","February 26, 2024 9:40 AM (GMT+8)","['bug', 'P1', 'TeamRevenant']",
besu,Bonsai RocksDB trielog inconsistency,https://github.com/hyperledger/besu/issues/6569,Storage,"When Besu doesn't shutdown gracefully due to a forceful kill sometimes there is an inconsistency between the trielog and the world state. This manifests as a worldstate mismatch error caused by a missing parent world state.

e.g.
```
{""@timestamp"":""2024-02-12T04:17:36,399"",""level"":""INFO"",""thread"":""EthScheduler-Services-9 (importBlock)"",""class"":""MainnetBlockValidator"",""message"":""Invalid block 7823908 (0x2f63f1be4e566e609f011dfedc7cfe34f78f5d0a97ab88515042bc99de775cac): Optional[Unable to process block because parent world state 0x211c1dcdb86f605b6dac592e5389a11f5f735cbed0485e13ba0d3a05573915f1 is not available]"",""throwable"":""""}
```

A transaction was added previously to ensure that the worldstate was committed consistently. The theory is that this should be extended to also include the committing the trielog as well to ensure consistency with trielogs the worldstate.

**Acceptance Criteria**
- Ensure that both worldstate and the trielog are consistent with each other after hard kill of Besu",consensus: consensus liveness failure,CWE-841,Improper Enforcement of Behavioral Workflow,"The bug report describes a state inconsistency between two data structures, the 'trielog' and the 'world state', which occurs when the application is forcefully terminated. This happens because the update process involves multiple steps that are not performed atomically. A forceful kill can interrupt the process after one step (e.g., committing the worldstate) but before another (committing the trielog), leading to a corrupt or inconsistent state. 

CWE-841, 'Improper Enforcement of Behavioral Workflow', is the most accurate fit. The 'behavioral workflow' in this context is the multi-step operation of updating both the worldstate and the trielog to maintain consistency. The system fails to enforce that this entire workflow completes successfully as a single unit. The bug manifests when this sequence is interrupted, which is a direct failure to enforce the required behavior for data integrity.

CWE-362, 'Race Condition', is less suitable because the problem is not described as two concurrent threads racing to modify a resource, but rather as a single sequence of operations being interrupted by an external event (a forceful kill).

CWE-404, 'Improper Resource Shutdown or Release', is incorrect. The issue is not about leaking a resource (like a file handle or memory) but about the integrity of the data *within* the resource being compromised due to an incomplete operation during an abrupt shutdown.",closed,"The inconsistency between the trielog and the world state arises due to Besu not shutting down gracefully, which prevents proper synchronization between these components.","This bug can lead to invalid block processing, causing potential disruptions in the blockchain's operation, including the inability to validate or import blocks correctly, which may compromise the integrity of the blockchain.",2133684285,6569,"February 14, 2024 7:04 AM (GMT+8)","April 2, 2025 11:24 PM (GMT+8)","['bug', 'P2', 'bonsai']",
besu,Layered Transaction Pool Index OOB,https://github.com/hyperledger/besu/issues/6489,Consensus,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/en/stable/HowTo/Monitor/Logging/ -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
Encountered large stack trace on mainnet node with Index out of bounds error :
```
execution-1  | 2024-01-27 10:07:39.063+00:00 | nioEventLoopGroup-3-2 | WARN  | LayeredPendingTransactions | Unexpected error java.lang.IndexOutOfBoundsException: Index -7 out of bo
unds for length 200 when adding transaction {sequence: 185214, addedAt: 1706350059053, isLocal=false, hasPriority=false, 0x0175282e5954f0d43cf6230189e05d6e9344256f283f9c5c7960081ad
503f48c={MessageCall, 30, 0x94c0a3b6ff5d9c158817addd3378932e4eec4994, EIP1559, mf: 7.63 gwei, pf: 100.00 mwei, gl: 21000, v: 5.00 finney, to: 0x45a318273749d6eb00f5f6ca3bc7cd3de26d
642a}}, current sender status prioritized[[34, 35, 36]] ready[Empty] sparse[Empty]
execution-1  | 2024-01-27 10:07:39.063+00:00 | nioEventLoopGroup-3-2 | WARN  | LayeredPendingTransactions | Stack trace
execution-1  | java.lang.IndexOutOfBoundsException: Index -7 out of bounds for length 200
execution-1  |  at java.base/jdk.internal.util.Preconditions.outOfBounds(Unknown Source)
execution-1  |  at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Unknown Source)
execution-1  |  at java.base/jdk.internal.util.Preconditions.checkIndex(Unknown Source)
execution-1  |  at java.base/java.util.Objects.checkIndex(Unknown Source)
execution-1  |  at java.base/java.util.ArrayList.get(Unknown Source)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.SparseTransactions.lambda$canAdd$1(SparseTransactions.java:102)
execution-1  |  at java.base/java.util.HashMap.compute(Unknown Source)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.SparseTransactions.canAdd(SparseTransactions.java:98)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.add(AbstractTransactionsLayer.java:150)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.addToNextLayer(AbstractTransactionsLayer.java:282)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.addToNextLayer(AbstractTransactionsLayer.java:266)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.add(AbstractTransactionsLayer.java:154)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.addToNextLayer(AbstractTransactionsLayer.java:282)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.addToNextLayer(AbstractTransactionsLayer.java:266)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.AbstractTransactionsLayer.add(AbstractTransactionsLayer.java:154)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.layered.LayeredPendingTransactions.addTransaction(LayeredPendingTransactions.java:96)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool.addTransaction(TransactionPool.java:242)
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool.lambda$addRemoteTransactions$5(TransactionPool.java:193)
...
execution-1  |  at org.hyperledger.besu.ethereum.eth.transactions.TransactionPool.addRemoteTransactions(TransactionPool.java:189)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.task.BufferedGetPooledTransactionsFromPeerFetcher.lambda$requestTransactions$0(BufferedGetPooledTransactionsFromPeerFet
cher.java:98)
...
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.task.AbstractPeerRequestTask.lambda$executeTask$2(AbstractPeerRequestTask.java:83)
...
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.task.AbstractPeerRequestTask.lambda$handleMessage$3(AbstractPeerRequestTask.java:106)
execution-1  |  at java.base/java.util.Optional.ifPresent(Unknown Source)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.task.AbstractPeerRequestTask.handleMessage(AbstractPeerRequestTask.java:104)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.task.AbstractPeerRequestTask.lambda$executeTask$0(AbstractPeerRequestTask.java:67)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.RequestManager$ResponseStream.dispatchBufferedResponses(RequestManager.java:211)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.RequestManager$ResponseStream.processMessage(RequestManager.java:202)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.RequestManager.lambda$dispatchResponse$0(RequestManager.java:82)
execution-1  |  at java.base/java.util.Optional.ifPresentOrElse(Unknown Source)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.RequestManager.dispatchResponse(RequestManager.java:81)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.EthPeer.lambda$dispatch$7(EthPeer.java:425)
execution-1  |  at java.base/java.util.Optional.ifPresentOrElse(Unknown Source)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.EthPeer.dispatch(EthPeer.java:424)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.EthPeers.dispatchMessage(EthPeers.java:252)
execution-1  |  at org.hyperledger.besu.ethereum.eth.manager.EthProtocolManager.processMessage(EthProtocolManager.java:333)
execution-1  |  at org.hyperledger.besu.ethereum.p2p.network.NetworkRunner.lambda$setupHandlers$1(NetworkRunner.java:142)
execution-1  |  at org.hyperledger.besu.ethereum.p2p.rlpx.connections.PeerConnectionEvents.lambda$dispatchMessage$1(PeerConnectionEvents.java:64)
execution-1  |  at org.hyperledger.besu.util.Subscribers.lambda$forEach$0(Subscribers.java:131)
execution-1  |  at java.base/java.lang.Iterable.forEach(Unknown Source)
execution-1  |  at org.hyperledger.besu.util.Subscribers.forEach(Subscribers.java:128)
execution-1  |  at org.hyperledger.besu.ethereum.p2p.rlpx.connections.PeerConnectionEvents.dispatchMessage(PeerConnectionEvents.java:64)
execution-1  |  at org.hyperledger.besu.ethereum.p2p.rlpx.connections.netty.ApiHandler.channelRead0(ApiHandler.java:112)
...
```

### Acceptance Criteria
* catch and handle this case correctly, without the massive stack trace

### Steps to Reproduce (Bug)
1. run on mainnet for some while with the layered tx pool

**Expected behavior:** [What you expect to happen]

**Actual behavior:** [What actually happens]

**Frequency:** [What percentage of the time does it occur?]

### Logs (if a bug)
Please post relevant logs from Besu (and the consensus client, if running proof of stake) from before and after the issue. 

### Versions (Add all that apply)
* Software version: 24.1.2-SNAPSHOT , ethdocker
* Java version: 17.0.9

",general: general performance degradation,CWE-129,Improper Validation of Array Index,"The bug report's central evidence is a Java stack trace showing a `java.lang.IndexOutOfBoundsException: Index -7 out of bounds for length 200`. This exception is thrown when code attempts to access an array or list with an index that is outside its valid range (in this case, less than 0). The stack trace originates from the processing of a remote transaction (`addRemoteTransactions`), which constitutes external, untrusted input. The error occurs because a value, derived from this input, is used as an index for an `ArrayList` without first being validated to ensure it is a non-negative number within the bounds of the list's size. 

- CWE-129 (Improper Validation of Array Index) is the most precise fit. The official definition states that the software 'uses untrusted input when calculating or using an array index, but the product does not validate or incorrectly validates the index'. This directly maps to the observed behavior: an index calculated from external data is used without proper validation, leading to an out-of-bounds access attempt.

- CWE-125 (Out-of-bounds Read) describes the result of the flaw. The attempt to access index -7 is an out-of-bounds read. However, CWE-129 describes the root cause—the failure to validate the index *before* the read attempt. As CWE-129 is more specific about the cause of the vulnerability, it is the better choice.

- CWE-20 (Improper Input Validation) is a very general category. While the bug is indeed a failure of input validation, CWE-129 is far more specific and accurately describes the exact nature of the validation that is missing.",closed,"The bug is caused by an index out of bounds error when attempting to access an element in an ArrayList using a negative index, which indicates improper handling of transaction sequences in the layered transaction pool.","This bug can lead to application crashes or unexpected behavior in the transaction processing system, potentially affecting transaction validity and overall network performance.",2106512520,6489,"January 29, 2024 9:59 PM (GMT+8)","April 2, 2024 9:29 PM (GMT+8)","['bug', 'P3', 'mainnet', 'TeamChupa']",
besu,IPv6 peer discovery errors,https://github.com/hyperledger/besu/issues/6475,Network,"<!-- Have you done the following? -->
<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  
<!--     comply with it, including treating everyone with respect: -->
<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Read the debugging docs: https://besu.hyperledger.org/en/stable/HowTo/Monitor/Logging/ -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->
<!-- Note:  Not all sections will apply to all issue types. -->

### Description
Since #6224, we are seeing a lot of ipv6 protocol errors from ping packet data with an ipv6 from address, e.g.:
```
VertxPeerDiscoveryAgent | Sending to peer DiscoveryPeer
{ 
  status=bonding,  
 enode=enode://018794617924fd5bc2b207aaa0073279a3bb77e0c5e6285797a262ec7c3dcb05d0bfca64696abc7bdd5dd04730b5bf80d059dc45b9c20fd61557f9ad4716e77c@[2a01:4f9:4b:4f55::2:11]:30303?discport=58267,
  firstDiscovered=1706378307270, 
  lastContacted=0, 
  lastSeen=1706378322275
} failed, 
native error code -97, 
packet: 0x943174d51399b001708462c9a3c361eba66ac98e3505906a1e9090bd9f3b2e6da40e86e7aa16e840b60b2eb56982e620af0aedb39909564c3088db9f1284e8e274d99f1aa06785b8887955cdd4cd9ec7ffae6b1ac05bd9cfe1df9449aee37e770101eb05cb847f000001829d6f829d6fd7902a0104f9004b4f55000000000002001182e39b82765f8465b5448f16,
stacktrace: io.netty.channel.unix.Errors$NativeIoException: sendToAddress(..) failed: Address family not supported by protocol
```

### Acceptance Criteria
* Survey the current state of IPv6 support in besu
* Decide whether to fix IPv6 discovery or fall back to IPv4 source address when we encounter it

### Steps to Reproduce (Bug)
1. run on mainnet for a while with the PeerDiscoveryAgent currently in `main`
2. observe ipv6 protocol errors in the logs

**Expected behavior:** [What you expect to happen]
No errors responding to peer discoveruy

**Actual behavior:** [What actually happens]
ping packets with ipv6 from addresses fail

**Frequency:** [What percentage of the time does it occur?]
100%

### Logs (if a bug)
```
2024-01-27 17:58:43.521+00:00 | vert.x-eventloop-thread-1 | WARN  | VertxPeerDiscoveryAgent | Sending to peer DiscoveryPeer{status=bonding, enode=enode://018794617924fd5bc2b207aaa0073279a3bb77e0c5e6285797a262ec7c3dcb05d0bfca64696abc7bdd5dd04730b5bf80d059dc45b9c20fd61557f9ad4716e77c@[2a01:4f9:4b:4f55::2:11]:30303?discport=58267, firstDiscovered=1706378307270, lastContacted=0, lastSeen=1706378322275} failed, native error code -97, packet: 0x943174d51399b001708462c9a3c361eba66ac98e3505906a1e9090bd9f3b2e6da40e86e7aa16e840b60b2eb56982e620af0aedb39909564c3088db9f1284e8e274d99f1aa06785b8887955cdd4cd9ec7ffae6b1ac05bd9cfe1df9449aee37e770101eb05cb847f000001829d6f829d6fd7902a0104f9004b4f55000000000002001182e39b82765f8465b5448f16, stacktrace: io.netty.channel.unix.Errors$NativeIoException: sendToAddress(..) failed: Address family not supported by protocol
```

### Versions (Add all that apply)
* Software version: 24.1.2-SNAPSHOT
* eth-docker

",network: faulty peer management,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a failure when the software attempts to send a network packet to an IPv6 address. This results in a `io.netty.channel.unix.Errors$NativeIoException` with the message `sendToAddress(..) failed: Address family not supported by protocol`. This exception indicates that an operation was attempted under conditions that the underlying system does not support (using an IPv6 address on a socket not configured for it). This is a classic exceptional condition. The software does not handle this exception gracefully; instead, it logs a warning and the peer communication fails. 

CWE-703, 'Improper Check or Handling of Exceptional Conditions', is the best fit. The description states, 'The product does not properly anticipate or handle exceptional conditions that rarely occur during normal operation.' The reception of an IPv6 address is the exceptional condition, and the resulting `NativeIoException` is not handled in a way that allows the program to recover or adapt (e.g., by falling back to IPv4 as suggested in the acceptance criteria). The core issue is the inadequate response to the exception.

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is a close but less accurate choice. It focuses on the failure to *check* for the condition beforehand. While a check could prevent the exception, the provided evidence (the stack trace) demonstrates that the exception *is* occurring, making the failure in *handling* it the most direct and observable weakness.

CWE-436, 'Interpretation Conflict', is not applicable. The software correctly interprets the address as IPv6; the problem is its inability to act on that information, not a misinterpretation of state between two products.",closed,The system attempts to send ping packets to IPv6 addresses but encounters a failure due to the native error indicating that the address family (IPv6) is not supported by the protocol being used.,"This bug prevents successful peer discovery over IPv6, leading to potential connectivity issues in the network, reduced peer availability, and reliance on IPv4, which may not be optimal for all network configurations.",2103704646,6475,"January 27, 2024 6:08 PM (GMT+8)","September 5, 2024 1:22 AM (GMT+8)","['bug', 'TeamGroot', 'P3', 'TeamRevenant', 'TeamChupa', 'snack']",
besu,Under heavy load `eth_estimateGas` returns `INTERNAL_ERROR`,https://github.com/hyperledger/besu/issues/6344,API,"### Description
Running a moderately high workload using caliper, after ~ 2000 transactions `eth_estimateGas` returns `INTERNAL_ERROR` to the caliper WS client

### Command that was run to start Besu (single validator):
`besu --data-path=data --genesis-file=../genesis.json --min-gas-price=0  --sync-mode=FULL --rpc-http-enabled --rpc-ws-enabled --rpc-http-apis=DEBUG,TXPOOL,WEB3,ETH,TRACE,QBFT,ADMIN --tx-pool-limit-by-account-percentage=0.20 --rpc-ws-max-active-connections=300 --tx-pool=sequenced -l TRACE`

### Logs
I've pinned it down to this code block:

```
final BlockHeader blockHeader = blockHeader();
if (blockHeader == null) {
    return errorResponse(requestContext, RpcErrorType.INTERNAL_ERROR);
}
```

https://github.com/hyperledger/besu/blob/e0cd89f9b5ca27763ba4b7b2589d486df81a9626/ethereum/api/src/main/java/org/hyperledger/besu/ethereum/api/jsonrpc/internal/methods/EthEstimateGas.java#L53

It was difficult to pin down the offending line using `TRACE` but adding a `new Exception().printStackTrace()` to the `JsonRpcErrorResponse(...)` constructor gave the stack trace:

```
java.lang.Exception
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.response.JsonRpcErrorResponse.<init>(JsonRpcErrorResponse.java:47)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractEstimateGas.errorResponse(AbstractEstimateGas.java:135)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.AbstractEstimateGas.errorResponse(AbstractEstimateGas.java:130)
        at org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.EthEstimateGas.response(EthEstimateGas.java:53)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.BaseJsonRpcProcessor.process(BaseJsonRpcProcessor.java:44)
        at org.hyperledger.besu.ethereum.api.jsonrpc.execution.JsonRpcExecutor.execute(JsonRpcExecutor.java:92)
        at org.hyperledger.besu.ethereum.api.jsonrpc.websocket.WebSocketMessageHandler.lambda$handle$1(WebSocketMessageHandler.java:90)
        at io.vertx.core.impl.ContextBase.lambda$null$0(ContextBase.java:137)
        at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:264)
        at io.vertx.core.impl.ContextBase.lambda$executeBlocking$1(ContextBase.java:135)
        at io.vertx.core.impl.TaskQueue.run(TaskQueue.java:76)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base/java.lang.Thread.run(Thread.java:833)
```

Once I've got a fix in place I might add some additional `TRACE` logs in `EthEstimateGas` wherever an `INTERNAL_ERROR` is returned, to make diagnosing similar issues a little quicker.",api: api unavailability,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report explicitly states that the issue occurs ""Under heavy load"" and after a significant number of transactions. The stack trace confirms a multi-threaded, concurrent environment, originating from a `WebSocketMessageHandler` and using a `ThreadPoolExecutor`. The identified root cause is the `blockHeader()` method returning `null`, which leads to an `INTERNAL_ERROR`. This behavior, where a value is unexpectedly null under high concurrency, is a classic symptom of a race condition. It suggests that one thread is attempting to read a shared resource (the data used to generate the block header) while another concurrent operation is modifying it or has left it in an inconsistent state. This directly aligns with the definition of CWE-362, which describes a timing window where a shared resource can be modified by another concurrent operation, leading to a failure.

CWE-400 (Uncontrolled Resource Consumption) is less appropriate because the direct cause of the error is a `null` value from a method call, not an error indicating resource exhaustion (like an `OutOfMemoryError` or running out of connections). While high load is the trigger, the weakness is in the logic handling concurrency, not in resource management itself.

CWE-404 (Improper Resource Shutdown or Release) is also incorrect as there is no evidence of a resource leak, such as unclosed file handles or connections. The problem is a logical error within the application's state, not a failure to release a system resource.",closed,"The `eth_estimateGas` method is unable to retrieve a valid `BlockHeader`, resulting in an `INTERNAL_ERROR` response when processing transactions under heavy load.","This bug can lead to service disruptions for clients relying on the `eth_estimateGas` API, potentially causing transaction processing delays and affecting the overall reliability of the blockchain application.",2064241887,6344,"January 3, 2024 3:39 PM (GMT+8)","January 8, 2024 5:20 PM (GMT+8)",['bug'],
java-tron,The startup parameter `--save-internaltx` does not take effect,https://github.com/tronprotocol/java-tron/issues/6217,API,"#### Software Versions

```
OS : Mac OS X
JVM : Amazon.com Inc. 1.8.0_362 x86_64
Git : e811deff938578d8f85f497f9be2c4045d4da8c6
Version : 4.7.7
Code : 18386
```

#### Expected behaviour
When I turn on the switch for internal transaction logging by adding the `--save-internaltx` parameter to the startup parameters, the internal transactions that occur in the transaction are never available through the fullnode http interface.

Here is the test contract I deployed
```
// SPDX-License-Identifier: MIT

pragma solidity >=0.8.0;

contract A {
    function a() external payable {
        payable(msg.sender).transfer(msg.value);
    }
}

```

Here are the results of the transaction_info I queried

```
curl http://127.0.0.1:8090/wallet/gettransactioninfobyid?value=34ba7609907e3432df4d54da787d22f6556ab390a2b454da52380f1e3dbda065

{
""id"": ""34ba7609907e3432df4d54da787d22f6556ab390a2b454da52380f1e3dbda065"",
""fee"": 693200,
""blockNumber"": 52,
""blockTimeStamp"": 1740553053000,
""contractResult"": [
""""
],
""contract_address"": ""41b665df62df91aceb92712d4f06443cccbfb88050"",
""receipt"": {
""energy_fee"": 693200,
""energy_usage_total"": 6932,
""net_usage"": 284,
""result"": ""SUCCESS""
}
}
```


#### Actual behaviour
I should be able to query an internal transaction.

#### Frequency
Always

#### Steps to reproduce the behaviour

1. Start a private chain with the command `java -jar FullNode.jar -c config.conf --witness --save-internaltx`
2. Deploy a test contract as described above.
3. Call the a method of the deployed contract.
4. Query the transaction execution results through the `/wallet/gettransactioninfobyid` interface.

#### Backtrace

None
",api: incorrect api output,CWE-20,Improper Input Validation,"The bug report describes a situation where a command-line startup parameter, `--save-internaltx`, is provided to the application, but the corresponding feature (saving internal transactions) is not enabled. Command-line arguments are a form of input to a program. The core issue is that the application is not correctly processing this input to configure its behavior as expected. 

CWE-20, 'Improper Input Validation', is the best fit. The official description states, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' In this context, 'processing the data correctly' includes acting upon the configuration specified by the input. The program receives the `--save-internaltx` input but fails to process it correctly, leading to the incorrect behavior where the feature remains disabled.

CWE-754, 'Improper Check for Unusual or Exceptional Conditions', is not a good fit. Using a documented startup flag is a normal, expected operational mode, not an 'unusual or exceptional condition'. The bug is a failure of a standard feature to activate based on its configuration, not a failure to handle an error or an unexpected state.",closed,"The startup parameter `--save-internaltx` is not properly implemented or recognized by the full node, resulting in internal transactions not being logged or retrievable via the API.","Users are unable to access internal transaction logs through the API, which may hinder debugging, transaction analysis, and transparency in transaction execution.",2880702994,6217,"February 26, 2025 8:31 AM (GMT+8)","March 7, 2025 8:10 AM (GMT+8)","['type:bug', 'v4.8.0']",
java-tron,NullPointerException was thrown while the node was starting,https://github.com/tronprotocol/java-tron/issues/6215,Consensus,"#### Software Versions
OS : Linux
JVM : Oracle Corporation 1.8.0_161 amd64
Git : e811deff938578d8f85f497f9be2c4045d4da8c6
Version : 4.7.7
Code : 18386


#### Expected behavior
`NullPointerException` should not be thrown, blocks can be synced quickly.


#### Actual behavior
After startup, blocks are not synced fast, and `NullPointerException `is thrown.


#### Frequency
Occasionally, not always.

#### Backtrace

````
21:44:43.100 ERROR [sync-handle-block] [net](SyncService.java:315) Process sync block Num:59376024,ID:00000000038a019878cb2e751e2f31d0ff2b67ebab4a15c7cc27225fa1e856a1 failed
java.lang.NullPointerException: null
 at org.tron.consensus.Consensus.receiveBlock(Consensus.java:31)
 at org.tron.core.db.Manager.pushBlock(Manager.java:1267)
 at org.tron.core.net.TronNetDelegate.processBlock(TronNetDelegate.java:270)
 at org.tron.core.net.service.sync.SyncService.processSyncBlock(SyncService.java:306)
 at org.tron.core.net.service.sync.SyncService.lambda$handleSyncBlock$9(SyncService.java:292)
 at java.util.concurrent.ConcurrentHashMap.forEach(ConcurrentHashMap.java:1597)
 at org.tron.core.net.service.sync.SyncService.handleSyncBlock(SyncService.java:271)
 at org.tron.core.net.service.sync.SyncService.lambda$init$1(SyncService.java:88)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
````


",general: initialization failure,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report details a `java.lang.NullPointerException`. This immediately suggests CWE-476 (NULL Pointer Dereference) as a possibility, as it directly describes the symptom. However, the report provides crucial additional context. The bug occurs ""Occasionally, not always,"" which points towards a non-deterministic issue, a classic sign of a timing problem. The stack trace confirms the operation is running in a highly concurrent environment, with classes like `ThreadPoolExecutor`, `ScheduledThreadPoolExecutor`, `ConcurrentHashMap`, and `SyncService`. This evidence strongly supports a race condition. CWE-362 ('Race Condition') describes a situation where concurrent access to a shared resource is improperly synchronized, leading to unpredictable behavior. The intermittent `NullPointerException` is a very common result of a race condition, where one thread accesses a resource before another thread has properly initialized it. CWE-457 (Use of Uninitialized Variable) is less fitting because a simple failure to initialize a variable would likely cause the error consistently, not occasionally. Therefore, CWE-362 is the most accurate choice as it describes the root cause (a timing issue in concurrent code) rather than just the symptom (the null pointer dereference).",closed,"The code attempts to access a null reference in the `Consensus.receiveBlock` method, leading to a `NullPointerException` during the block synchronization process.","The occurrence of a `NullPointerException` during node startup can disrupt the block synchronization process, potentially causing delays or failures in processing new blocks, which can affect the overall performance and reliability of the blockchain network.",2877540839,6215,"February 25, 2025 8:24 AM (GMT+8)","February 26, 2025 4:16 PM (GMT+8)","['type:bug', 'v4.8.0']",
java-tron,Illegal argument with createShieldedContractParameters,https://github.com/tronprotocol/java-tron/issues/6165,API,"#### Software Versions

OS : Linux
JVM : Oracle Corporation 1.8.0_161 amd64
Version : 4.7.4
Code : 18306

#### Expected behavior
The gRPC API of the wallet should specify the root cause when request failed, not the error log stack.

#### Actual behavior
I was running a fullnode on Nile, and constructed `PrivateShieldedTRC20Parameters` with the following values in my program:
```
{
    ""ask"":""c2513e9e308494932bd82e0ce53662d17421d90b72a8471a0a12b8552a336e02"",
    ""nsk"":""4c6bf3dd4a0643d20b628f7e45980c5e187f07a51d6f3e86aaf1ab916c07eb0d"",
    ""ovk"":""17a58d9a5058da6e42ca12cd289d0a6aa169b926c18e19bca518b8d6f8674e43"",
    ""from_amount"":""100"",
    ""shielded_receives"":[
        {
            ""note"":{
                ""value"":10,
                ""payment_address"":"""",
                ""rcm"":""16b6f5e40444ab7eeab11ae6613c27f35117971efa87b71560b5813829c9390d""
            }
        }
    ],
    ""shielded_TRC20_contract_address"":""41D7175DEDFD7EA842493CB4CDA6B066501F0FA1C8""
}
```
Then I called the gRPC API `createShieldedContractParameters` with above `PrivateShieldedTRC20Parameters`. I found the fullnode throws error stack in tron.log:
```
11:08:59.477 ERROR [rpc-full-executor-1] [API](RpcApiService.java:2485) createShieldedContractParameters: 
java.lang.IllegalArgumentException: Input too short: 0
        at org.tron.common.utils.Bech32.decode(Bech32.java:149)
        at org.tron.core.zen.address.KeyIo.decodePaymentAddress(KeyIo.java:33)
        at org.tron.core.Wallet.buildShieldedTRC20Output(Wallet.java:3467)
        at org.tron.core.Wallet.createShieldedContractParameters(Wallet.java:3536)
        at org.tron.core.Wallet$$FastClassBySpringCGLIB$$3f6b5781.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753)
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89)
        at org.tron.common.prometheus.MetricAspect.walletAroundAdvice(MetricAspect.java:43)
        at sun.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:634)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:624)
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:72)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753)
        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698)
        at org.tron.core.Wallet$$EnhancerBySpringCGLIB$$476d52c3.createShieldedContractParameters(<generated>)
        at org.tron.core.services.RpcApiService$WalletApi.createShieldedContractParameters(RpcApiService.java:2477)
        at org.tron.api.WalletGrpc$MethodHandlers.invoke(WalletGrpc.java:11234)
        at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
        at io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
        at io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
        at io.grpc.ForwardingServerCallListener$SimpleForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:40)
        at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:355)
        at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:867)
        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)

```
It was an uncaught exception. This interface should deal with it elegantly.

Therefore, I tried with the HTTP API `wallet/createshieldedcontractparameters` using the same parameter:
```
curl --location 'http://localhost:8090/wallet/createshieldedcontractparameters' --header 'Content-Type:application/json' --data '{
    ""ask"":""c2513e9e308494932bd82e0ce53662d17421d90b72a8471a0a12b8552a336e02"",
    ""nsk"":""4c6bf3dd4a0643d20b628f7e45980c5e187f07a51d6f3e86aaf1ab916c07eb0d"",
    ""ovk"":""17a58d9a5058da6e42ca12cd289d0a6aa169b926c18e19bca518b8d6f8674e43"",
    ""from_amount"":""100"",
    ""shielded_receives"":[
        {
            ""note"":{
                ""value"":10,
                ""payment_address"":"""",
                ""rcm"":""16b6f5e40444ab7eeab11ae6613c27f35117971efa87b71560b5813829c9390d""
            }
        }
    ],
    ""shielded_TRC20_contract_address"":""41D7175DEDFD7EA842493CB4CDA6B066501F0FA1C8""
}
```

I got the following result:
```
{""Error"":""class java.lang.IllegalArgumentException : Input too short: 0""}
```
but the log didn’t show any error. It’s more elegant.

#### Frequency

I can repeat it certainly using the gRPC API.


#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them in text, not screenshots.

",api: incorrect api output,CWE-209,Generation of Error Message Containing Sensitive Information,"The user's bug report describes a scenario where providing invalid input (an empty `payment_address`) to a gRPC API endpoint causes the application to log a full Java stack trace. The report explicitly contrasts this with an HTTP API endpoint that handles the same error gracefully by returning a concise error message. The core complaint is about the nature of the error output. The expected behavior is a clean error message, while the actual behavior is a verbose stack trace. 

Let's analyze the provided CWE options:
- CWE-20 (Improper Input Validation): This is the root cause of the problem. The application fails because it doesn't validate that the `payment_address` is non-empty before processing it. While true, the report focuses on the *consequence* of this failure, not the lack of validation itself.
- CWE-248 (Uncaught Exception): This is the direct cause of the stack trace. An `IllegalArgumentException` is thrown and not caught by the gRPC API handler, causing it to propagate up. The reporter even states, ""It was an uncaught exception."" This is a very accurate description of the code-level fault.
- CWE-209 (Generation of Error Message Containing Sensitive Information): This describes the primary symptom and security concern highlighted in the report. A stack trace exposes sensitive internal details about the application, such as class names, method names, file names, and the software stack (Java, Spring). The user's main point is the undesirable exposure of this ""error log stack"" instead of a clean message. The comparison with the ""more elegant"" HTTP API response reinforces that the issue is the information revealed in the error.

While all three CWEs are related, CWE-209 is the single most accurate choice because it best captures the essence of the reported vulnerability. The report is framed around the undesirable output—the error message containing sensitive information—rather than the underlying cause (uncaught exception or improper validation). The security weakness is the information disclosure itself.",closed,"The `createShieldedContractParameters` function does not validate the `payment_address` field in the input parameters, leading to an uncaught `IllegalArgumentException` when it is empty.","This bug could lead to a poor user experience as the API fails without providing a clear error message. It may also expose sensitive information through error logs, potentially aiding malicious actors in understanding the system's vulnerabilities.",2847689896,6165,"February 12, 2025 9:41 AM (GMT+8)","March 5, 2025 11:40 AM (GMT+8)","['type:bug', 'v4.8.0']",
java-tron,Out of Memory when 'MSTORE' operation executing for a contract on tron private chain,https://github.com/tronprotocol/java-tron/issues/6072,Execution,"<!-- Have you done the following? -->
<!--   * Reproduced the issue in the latest version of the software -->
<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Atronprotocol/java-tron -->

#### Software Versions
<!-- `java -jar FullNode.jar -v` -->
The FullNode.jar version is **v4.7.6**
<!-- 
```
OS : Linux
JVM : Oracle Corporation 1.8.0_161 amd64
Git : b1fc2f0f2bd79527099bc3027b9aba165c2e20c2
Version : 4.7.4
Code : 18260
```
-->
OS : Ubuntu(20.04) server 
openjdk version ""1.8.0_422""
OpenJDK Runtime Environment (build 1.8.0_422-8u422-b05-1~20.04-b05)
OpenJDK 64-Bit Server VM (build 25.422-b05, mixed mode)
#### Expected behaviour
<!--[What you expect to happen] -->
I expected the the contract functions to work as they work on EVM.

#### Actual behaviour
<!--[What you expect to happen] -->
This contract is not working because of the memory keyword(MSTORE).
The build version is v4.7.6
(You can find the contract code below)

**WORKING**

1. storeAddresses
2. sumArray

**NOT WORKING**

1. manipulateName
2. createTempStruct
3. combineArrays

Error in **manipulateName** and **createTempStruct** is

>Error: class org.tron.core.vm.program.Program$OutOfMemoryException : Out of Memory when 'MSTORE' operation executing

#### Frequency
<!-- [What percentage of the time does it occur?] -->
Every time
#### Steps to reproduce the behaviour

1. Make the changes in the code for java-tron( TAG->GreatVoyage-v4.7.6) i.e

>byte ADD_PRE_FIX_BYTE_MAINNET = (byte) 0x41; //41 + address
>byte ADD_PRE_FIX_BYTE_MAINNET = (byte) 0x37; //37 + address address_change

>Wallet.setAddressPreFixByte((byte) 0x41);
>Wallet.setAddressPreFixByte((byte) 0x37);

>public static final byte ADD_PRE_FIX_BYTE_MAINNET = (byte) 0x41; //41 + address
>public static final String ADD_PRE_FIX_STRING_MAINNET = ""41"";
>public static final byte ADD_PRE_FIX_BYTE_MAINNET = (byte) 0x37; //37 + address
>public static final String ADD_PRE_FIX_STRING_MAINNET = ""37"";

>// (0x41) Get the block’s coinbase address
>public static final int COINBASE = 0x41;
>// (0x37) Get the block’s coinbase address
>public static final int COINBASE = 0x37;

2.Setup the tron private chain network
3. Deploy the contract
```
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

contract MemoryUsageExample {
    // State variable to store a name (just for demonstration)
    string public storedName;
    address[] public addresses;

    // Function to accept an array of addresses and store them
    function storeAddresses(address[] memory _addresses) external {
        addresses.push(_addresses[0]);
    }
    // Function to set a name temporarily using `memory`
    function setNameTemporarily(
        string memory name
    ) public pure returns (string memory) {
        string memory tempName = name; // Temporary `memory` variable
        return tempName;
    }

    // Function that creates and modifies a temporary array in `memory`
    function sumArray(uint[] memory numbers) public pure returns (uint) {
        uint sum = 0;
        for (uint i = 0; i < numbers.length; i++) {
            sum += numbers[i];
        }
        return sum; // Returning the sum calculated in `memory`
    }

    // Function that uses `memory` to manipulate a copy of `storedName`
    function manipulateName(
        string memory newName
    ) public view returns (string memory) {
        string memory tempStoredName = storedName; // Copying state variable to `memory`
        return string(abi.encodePacked(tempStoredName, "" "", newName)); // Concatenating and returning result
    }

    // Function that takes two arrays and combines them using `memory`
    function combineArrays(
        uint[] memory array1,
        uint[] memory array2
    ) public pure returns (uint[] memory) {
        uint[] memory combinedArray = new uint[](array1.length + array2.length); // Creating new array in `memory`

        for (uint i = 0; i < array1.length; i++) {
            combinedArray[i] = array1[i];
        }
        for (uint j = 0; j < array2.length; j++) {
            combinedArray[array1.length + j] = array2[j];
        }

        return combinedArray; // Returning the combined array
    }

    // Function that creates a struct in `memory` for temporary calculations
    struct TempStruct {
        uint id;
        string name;
    }

    function createTempStruct(
        uint _id,
        string memory _name
    ) public pure returns (string memory) {
        TempStruct memory temp = TempStruct({id: _id, name: _name}); // Creating struct in `memory`
        return temp.name;
    }
}
4. Trigger these methods
           - manipulateName
          - createTempStruct
          - combineArrays",evm: execution fault,CWE-400,Uncontrolled Resource Consumption,"The bug report describes an `OutOfMemoryException` that occurs when specific smart contract functions are executed. These functions utilize the `MSTORE` operation, which allocates temporary memory within the Tron Virtual Machine. The error message explicitly indicates that the system is running out of a finite resource (memory). This directly aligns with the definition of CWE-400, which describes a failure to properly control the allocation of a limited resource. CWE-131 is less suitable because the issue is a failure to allocate memory at all, not an incorrect size calculation leading to a buffer overflow. CWE-789 is also less accurate because the problem is not explicitly tied to an untrusted, excessively large input size; rather, it seems to be a more fundamental problem with how the virtual machine handles memory allocation for certain standard operations, making the broader CWE-400 the most fitting classification.",closed,The Out of Memory error occurs during the execution of the MSTORE operation due to insufficient memory allocation for handling the size of data being processed by the contract functions.,"If this bug is not resolved, it can lead to contract execution failures, preventing users from utilizing the affected functions, and potentially harming the reliability and usability of the blockchain application.",2646020864,6072,"November 9, 2024 1:00 PM (GMT+8)","November 10, 2024 9:43 PM (GMT+8)",['type:bug'],
java-tron,I cannot get results from api eth_getLogs sometimes,https://github.com/tronprotocol/java-tron/issues/6037,Others,"#### Software Versions

```
OS : Linux
JVM : Oracle Corporation 1.8.0_161 amd64
Git : a8ad2a169e58946b5b8de6ecf7b7ef5b8db05aff
Version : 4.7.5
Code : 18306
```

#### Expected behavior

If the JSON-RPC service is enabled, users should be able to search for events based on contract addresses and topics. However, after I enabled the service, there should be an address-related log in a certain block, but I couldn't find it. 

#### Actual behavior
I use the following interface to get events:
```
curl --location 'http://localhost:8545/jsonrpc' --header 'Content-Type:application/json' --data '{
    ""jsonrpc"": ""2.0"",
    ""method"": ""eth_getLogs"",
    ""params"": [
        {
            ""address"":[
                ""0x034e5a6bbf5d4bacd1c92c4a9bd2a67554c755a5""
            ],
            ""fromBlock"": ""0x30f22c0"",
            ""toBlock"":""0x30f22c0""
        }
    ],
    ""id"": 1
}'
```
And get nothing:
```
{""jsonrpc"":""2.0"",""id"":1,""result"":[]}
```

But the following log really exists in block 51323584(""0x30f22c0""):
```
        {
            ""address"": ""0x034e5a6bbf5d4bacd1c92c4a9bd2a67554c755a5"",
            ""blockHash"": ""0x00000000030f22c0a2db59c5b94ca345ef97ff3ec3eef3cd45863907cabd04f8"",
            ""blockNumber"": ""0x30f22c0"",
            ""data"": ""0x0000000000000000000000006e0617948fe030a7e4970f8389d4ad295f249b7e0000000000000000000000000000000000000000000000000000000000000000"",
            ""logIndex"": ""0x44"",
            ""removed"": false,
            ""topics"": [
                ""0xcdee897399ab5e465acb1bd3ed5e32c695f196321764546c59720fa6c9ce4c69""
            ],
            ""transactionHash"": ""0xb2c4a682fdfe6352b93ef79fa7b890ac5daf7f6a240f52e2b528c5f1c817a96f"",
            ""transactionIndex"": ""0xe5""
        },
```

 I used the same interface with the JSON parameter and dropped the ‘address’ to verify it:
```
curl --location 'http://localhost:8545/jsonrpc' --header 'Content-Type:application/json' --data '{
    ""jsonrpc"": ""2.0"",
    ""method"": ""eth_getLogs"",
    ""params"": [
        {
            ""fromBlock"": ""0x30f22c0"",
            ""toBlock"":""0x30f22c0""
        }
    ],
    ""id"": 1
}'
```

I tried to use another address `0xa614f803b6fd780986a42c78ec9c7f77e6ded13c` and got the log successfully.
#### Frequency
I have no idea. But I have not gotten logs using the address `0x034e5a6bbf5d4bacd1c92c4a9bd2a67554c755a5` in other blocks yet. 

",api: api unavailability,CWE-178,Improper Handling of Case Sensitivity,"The bug report describes a situation where an API call to `eth_getLogs` fails to retrieve a specific log entry when filtering by an address, but succeeds when the address filter is removed. The log is confirmed to exist in the specified block. This behavior, where a lookup fails for a specific identifier but not for others, is a classic symptom of an incorrect comparison. Given that the identifier is an Ethereum address (a hexadecimal string), the most likely cause of the incorrect comparison is a failure to handle case sensitivity properly. Ethereum addresses are fundamentally case-insensitive, but are often represented with mixed-case (EIP-55 checksum). If the system performs a case-sensitive string comparison between the user-provided address and the stored address, a mismatch in case would cause the lookup to fail, leading to the inconsistent results reported.

- **CWE-178 (Improper Handling of Case Sensitivity):** This is the most accurate CWE. The definition states the product 'does not properly account for differences in case sensitivity when accessing or determining the properties of a resource, leading to inconsistent results.' This directly maps to the bug: the system is accessing a log (the resource) by its address (a property) and fails because it's not handling the case-insensitivity of the address correctly, resulting in the log not being found.

- **CWE-697 (Incorrect Comparison):** This is a plausible but overly general choice. While the bug does involve an incorrect comparison, CWE-178 is more specific about the *nature* of the incorrectness (case sensitivity), making it a better fit.

- **CWE-436 (Interpretation Conflict):** This CWE is not applicable. The issue is not an interoperability problem between two different products but an internal logic flaw within a single component's data filtering mechanism.",closed,"The API method 'eth_getLogs' may not be properly validating the input parameters, particularly the address field, leading to cases where valid logs are not returned.","If users cannot retrieve logs for specific contract addresses, it may hinder their ability to verify transactions and events on the blockchain, potentially leading to trust issues and reduced usability of the API.",2578283557,6037,"October 10, 2024 9:54 AM (GMT+8)","March 5, 2025 11:43 AM (GMT+8)","['type:bug', 'v4.8.0']",
java-tron,Timeout occurred when synchronizing blocks,https://github.com/tronprotocol/java-tron/issues/5913,Network,"#### System information
OS : Linux
JVM : Oracle Corporation 1.8.0_411 amd64
Version : 4.7.5

#### Expected Behavior
Blocks can be synchronized and broadcasted normally, and no timeout should occur.

#### Actual Behavior
I deployed a private chain locally. The two nodes have been synchronizing and broadcasting blocks normally. However, after a while, they suddenly disconnected due to a TIME_OUT. Here is the last interaction log.
```
23:09:48.561 INFO  [peerClient-23] [net](PeerConnection.java:175) Send peer /192.168.0.15:18888 message type: SYNC_BLOCK_CHAIN
size: 5, start block: Num:61885758,ID:0000000003b04d3e2e00336955e1385188e9b60d8cf10b41dcf7da7477ff51ac, end block Num:61885778,ID:0000000003b04d52c62137c5f12f421309888ed8e3118b7b2a57e1d311dd2b3c
23:09:48.850 INFO  [peerClient-23] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /192.168.0.15:18888, type: BLOCK_CHAIN_INVENTORY
size: 3, first blockId: Num:61885778,ID:0000000003b04d52c62137c5f12f421309888ed8e3118b7b2a57e1d311dd2b3c, end blockId: Num:61885780,ID:0000000003b04d541a1c5a38f31f3ca8eefa5a77d5f3cc2522a7026e349256f5, remain_num: 0
23:10:19.831 WARN  [peer-status-check] [net](PeerStatusCheck.java:51) Peer /192.168.0.15 not sync for a long time
23:10:19.831 INFO  [peer-status-check] [net](PeerConnection.java:175) Send peer /192.168.0.15:18888 message type: P2P_DISCONNECT
reason: TIME_OUT
```",network: p2p protocol error,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a situation where a peer-to-peer connection is terminated due to a `TIME_OUT`. The logs show a warning `Peer ... not sync for a long time` followed by a disconnection. This indicates that a process, specifically block synchronization, is taking longer than a predefined threshold, which is a form of resource exhaustion where the resource is processing time. 

- **CWE-400 (Uncontrolled Resource Consumption)** is the best fit. The official description states, 'The product does not properly control the allocation and maintenance of a limited resource.' In this case, the limited resource is time allocated for a network operation. The operation exceeds its time budget, leading to a timeout. This directly matches the observed behavior.

- **CWE-833 (Deadlock)** is less suitable. While a deadlock could cause a process to hang and result in a timeout, the bug report provides no direct evidence of a deadlock, such as multiple threads waiting on each other's locks. The timeout is a symptom, but attributing it to a deadlock without more information is speculative.

- **CWE-407 (Inefficient Algorithmic Complexity)** is also a possible underlying cause for the timeout, but it's too specific. The report doesn't contain enough detail to confirm that the slowness is due to an inefficient algorithm rather than other potential issues like I/O bottlenecks or network latency. CWE-400 is a more general and accurate classification of the observed failure mode (timeout due to excessive time usage) without assuming a specific, unconfirmed root cause.",closed,"The nodes in the private blockchain setup are unable to maintain a stable connection due to a timeout, likely caused by network latency or resource constraints leading to failure in synchronizing blocks.","The disconnection of nodes due to timeout can disrupt the blockchain synchronization process, potentially leading to data inconsistency, stalled transactions, or a complete halt in the network's ability to operate effectively.",2410363796,5913,"July 16, 2024 6:55 AM (GMT+8)","July 23, 2024 11:06 AM (GMT+8)",['type:bug'],
java-tron,Sync stuck at block 62808277 after server restart,https://github.com/tronprotocol/java-tron/issues/5877,Storage,"After server hangup and restart the FullNode.jar does not continue to sync. I suspect that the DB is corrupted, but there are no records showing that in the log file. Using config file from docs.

#### Software Versions
```
OS : Linux
Version : 4.7.5
```

#### Expected behaviour
Should sync


#### Actual behaviour
Stuck at block 62808277


[tron.log](https://github.com/user-attachments/files/15942459/tron.log)
",storage: storage corruption,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a system failure that occurs after a 'server hangup and restart'. This event is a classic example of an 'exceptional condition' that is not part of the software's normal operational flow. The software's inability to recover and continue syncing, getting 'Stuck at block 62808277', directly aligns with the definition of CWE-703, which states 'The product does not properly anticipate or handle exceptional conditions that rarely occur'. The suspected database corruption is a likely consequence of this failure to handle the abnormal termination. 

CWE-395 is incorrect as the bug report makes no mention of NullPointerExceptions or how they are handled. 

CWE-404, 'Improper Resource Shutdown or Release', is a plausible contributing factor, as the server hangup likely prevented a clean shutdown of the database resource. However, the core weakness described is the application's overall failure to recover from this abnormal state, which is more accurately and broadly described as a failure to handle an exceptional condition (CWE-703) rather than the specific mechanism of resource release.",closed,"The FullNode.jar fails to continue synchronization after a server restart, likely due to potential corruption in the database or improper handling of state recovery.","The node becomes non-functional for syncing, which can lead to outdated state information, reduced reliability in the network, and possible loss of transaction validation capabilities.",2368217245,5877,"June 23, 2024 4:04 AM (GMT+8)","July 11, 2024 11:40 AM (GMT+8)",['type:bug'],
java-tron,Corruption: corrupted compressed block contents,https://github.com/tronprotocol/java-tron/issues/5853,Storage,"After updating and rebuilding the node, it stopped syncing at block 61909967 with the error:

```
15:05:14.991 ERROR [sync-handle-block] [DB](Manager.java:1337) Corruption: corrupted compressed block contents
org.tron.core.exception.ValidateSignatureException: Corruption: corrupted compressed block contents
        at org.tron.core.db.Manager.preValidateTransactionSign(Manager.java:1984)
        at org.tron.core.db.Manager.processBlock(Manager.java:1739)
        at org.tron.core.db.Manager.applyBlock(Manager.java:1043)
        at org.tron.core.db.Manager.pushBlock(Manager.java:1329)
        at org.tron.core.net.TronNetDelegate.processBlock(TronNetDelegate.java:266)
        at org.tron.core.net.service.sync.SyncService.processSyncBlock(SyncService.java:304)
        at org.tron.core.net.service.sync.SyncService.lambda$handleSyncBlock$9(SyncService.java:290)
        at java.util.concurrent.ConcurrentHashMap.forEach(ConcurrentHashMap.java:1597)
        at org.tron.core.net.service.sync.SyncService.handleSyncBlock(SyncService.java:269)
        at org.tron.core.net.service.sync.SyncService.lambda$init$1(SyncService.java:88)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

15:05:14.993 INFO  [sync-handle-block] [DB](PendingManager.java:57) Pending tx size: 0.

15:05:14.993 ERROR [sync-handle-block] [net](TronNetDelegate.java:295) Process block failed, Num:61909967,ID:0000000003b0abcf2ac1e3f669e39810fafa0188378a289ea48e2e28f39e4517, reason: Corruption: corrupted compressed block contents

15:05:14.994 ERROR [sync-handle-block] [net](SyncService.java:307) Process sync block Num:61909967,ID:0000000003b0abcf2ac1e3f669e39810fafa0188378a289ea48e2e28f39e4517 failed, type: 10, bad block
```

After launch, several tens of blocks are synchronized until they reach block 61909967

",storage: storage corruption,CWE-354,Improper Validation of Integrity Check Value,"The bug report describes a failure during blockchain synchronization with the error message ""Corruption: corrupted compressed block contents"" and an exception of type `org.tron.core.exception.ValidateSignatureException`. This occurs within a method named `preValidateTransactionSign`. This evidence points directly to a failure in a data integrity check. Blockchain blocks rely on cryptographic signatures and hashes to ensure their integrity, and the system is failing while trying to validate a specific block. 

CWE-354, 'Improper Validation of Integrity Check Value', is the most accurate fit. The description mentions the product failing to correctly validate integrity check values, which prevents it from detecting if data has been modified or corrupted. In this case, the system *is* throwing an error, indicating it has detected corruption. However, the presence of a corrupt block that halts the chain suggests a potential flaw in the validation logic, either in a prior step that allowed the corrupt data or in the current step's handling of an edge case. The core issue revolves around the validation of the block's integrity.

CWE-502, 'Deserialization of Untrusted Data', is less suitable. While the system is processing untrusted data (a block from the network) which involves deserialization, the error is specifically a `ValidateSignatureException`, pointing to a logical validation failure after the data has been at least partially deserialized, rather than a failure in the deserialization process itself.

CWE-404, 'Improper Resource Shutdown or Release', is irrelevant as the bug report details a data processing and validation error, not a problem with resource management like memory leaks or unclosed file handles.",closed,"The node encountered corrupted compressed block contents while processing block number 61909967, preventing further synchronization.","This bug can lead to a halt in the node synchronization process, which may cause the node to become out of sync with the blockchain network and potentially disrupt the functionality of the blockchain system or its applications.",2343901711,5853,"June 10, 2024 1:15 PM (GMT+8)","June 12, 2024 1:19 PM (GMT+8)",['type:bug'],
java-tron,Node stopped syncing at block 62292059,https://github.com/tronprotocol/java-tron/issues/5847,Network,"#### Software Versions
[GreatVoyage-v4.7.5(Cleobulus)](https://github.com/tronprotocol/java-tron/releases/tag/GreatVoyage-v4.7.5)


OS : Linux
JVM : Oracle Corporation 1.8.0_161 amd64

#### Expected behaviour
Should sync


#### Actual behaviour
After upgrading to 4.7.5 the node stopped syncing new blocks and stuck at 62292059. Tried previous version, restarting, etc with no results. Please advise.



#### Backtrace

````
============ Peer stats: all 31, active 11, passive 20

Peer /116.202.171.24:56926
connect time: 27s [0ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7521
syncChainRequested:0
blockInProcess:0

Peer /3.252.86.18:45868
connect time: 16s [1ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:14049750
syncChainRequested:0
blockInProcess:0

Peer /142.132.135.170:34284
connect time: 21s [2ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:9477885
syncChainRequested:0
blockInProcess:0

Peer /111.193.229.212:46030
connect time: 16s [2ms]
last know block num: 45094995
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:17195382
syncChainRequested:0
blockInProcess:0

Peer /78.46.80.62:18889
connect time: 21s [3ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:15513652
syncChainRequested:0
blockInProcess:0

Peer /5.75.129.230:55150
connect time: 11s [7ms]
last know block num: 6298094
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:55993965
syncChainRequested:0
blockInProcess:0

Peer /135.125.87.237:45708
connect time: 6s [7ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7528
syncChainRequested:0
blockInProcess:0

Peer /163.172.102.242:58054
connect time: 26s [12ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7522
syncChainRequested:0
blockInProcess:0

Peer /162.19.112.144:39930
connect time: 18s [12ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:2218717
syncChainRequested:0
blockInProcess:0

Peer /212.80.18.112:63671
connect time: 14s [43ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7526
syncChainRequested:0
blockInProcess:0

Peer /172.111.38.94:35524
connect time: 28s [45ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7521
syncChainRequested:0
blockInProcess:0

Peer /65.108.108.6:18888
connect time: 10s [52ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:58364611
syncChainRequested:0
blockInProcess:0

Peer /103.195.100.142:55472
connect time: 257s [68ms]
last know block num: 18590652
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:43701395
syncChainRequested:0
blockInProcess:0

Peer /64.31.33.130:58840
connect time: 19s [74ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7524
syncChainRequested:0
blockInProcess:0

Peer /18.188.97.63:48350
connect time: 258s [98ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:false
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:0
syncChainRequested:0
blockInProcess:0

Peer /3.146.65.40:58938
connect time: 259s [98ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:false
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:0
syncChainRequested:0
blockInProcess:0

Peer /3.144.96.49:33840
connect time: 258s [98ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:false
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:0
syncChainRequested:0
blockInProcess:0

Peer /18.222.184.3:54058
connect time: 258s [98ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:false
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:0
syncChainRequested:0
blockInProcess:0

Peer /47.121.133.241:40722
connect time: 2s [114ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7530
syncChainRequested:0
blockInProcess:0

Peer /8.219.160.220:51808
connect time: 63s [145ms]
last know block num: 17751755
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:44540304
syncChainRequested:0
blockInProcess:0

Peer /43.199.1.186:18204
connect time: 29s [147ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:1449279
syncChainRequested:0
blockInProcess:0

Peer /34.235.33.215:18888
connect time: 10s [189ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7527
syncChainRequested:0
blockInProcess:0

Peer /35.174.93.198:18888
connect time: 10s [190ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7527
syncChainRequested:0
blockInProcess:0

Peer /18.221.72.178:18888
connect time: 26s [216ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:1449279
syncChainRequested:0
blockInProcess:0

Peer /3.138.190.200:18888
connect time: 26s [217ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:1449279
syncChainRequested:0
blockInProcess:0

Peer /34.83.60.177:18888
connect time: 10s [293ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7527
syncChainRequested:0
blockInProcess:0

Peer /34.168.181.106:18888
connect time: 9s [294ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7527
syncChainRequested:0
blockInProcess:0

Peer /66.29.129.233:18888
connect time: 9s [294ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:11032850
syncChainRequested:0
blockInProcess:0

Peer /63.251.15.87:22310
connect time: 24s [347ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:false
syncToFetchSize:4000
syncToFetchSizePeekNum:62292060
syncBlockRequestedSize:0
remainNum:7522
syncChainRequested:0
blockInProcess:0

Peer /185.74.222.171:18888
connect time: 13s [755ms]
last know block num: 0
needSyncFromPeer:false
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:245936
syncChainRequested:0
blockInProcess:0

Peer /66.23.202.138:34758
connect time: 0s [0ms]
last know block num: 0
needSyncFromPeer:true
needSyncFromUs:true
syncToFetchSize:0
syncToFetchSizePeekNum:-1
syncBlockRequestedSize:0
remainNum:0
syncChainRequested:0
blockInProcess:0


04:29:00.209 INFO  [peerWorker-19] [net](ChannelManager.java:214) Receive message from channel: /162.19.112.217:49762, [HelloMessage: from {
  address: ""162.19.112.217""
  port: 18888
  nodeId: ""&L\233\""\006\326\277\367q\311\210\352\246m\022di\252\3016\347S\236\005\250\326\373\262p\317\313\320,\017r\0327]\267\251\212\210\321\374$Gh-5]@\027C\346\262M\033\037\345\214\037\232\227\261""
}
network_id: 11111
timestamp: 1717554540187
version: 1

04:29:00.209 INFO  [peerWorker-19] [net](ChannelManager.java:117) Peer /162.19.112.217:49762 | 264c9b2206d6bff771c988eaa66d126469aac136e7539e05a8d6fbb270cfcbd02c0f721a375db7a98a88d1fc2447682d355d401743e6b24d1b1fe58c1f9a97b1 recently disconnected
04:29:00.209 INFO  [peerWorker-19] [net](Channel.java:140) Send message to channel /162.19.112.217:49762, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
code: 3
timestamp: 1717554540187
version: 1

04:29:00.209 INFO  [peerWorker-19] [net](ChannelManager.java:178) Try to close channel: /162.19.112.217:49762, reason: RECENT_DISCONNECT
04:29:00.209 INFO  [peerWorker-19] [net](P2pChannelInitializer.java:45) Close channel:/162.19.112.217:49762
04:29:00.210 INFO  [peerWorker-19] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.214 INFO  [peerWorker-18] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /66.23.202.138:34758, type: P2P_HELLO
from: /66.23.202.138:18888
timestamp: 1717554540010
headBlockId: Num:62303589,ID:0000000003b6ad65e29d08f7d89c2892c4db63dec8669ae1a319bbd76e32048d
nodeType: 1
lowestBlockNum: 53264937
codeVersion:4.7.4

04:29:00.214 INFO  [peerWorker-18] [DB](Manager.java:1912) HeadNumber: 62292059, syncBeginNumber: 62292041, solidBlockNumber: 62292041.
04:29:00.214 INFO  [peerWorker-18] [net](SyncService.java:197) Get block chain summary, low: 62292041, highNoFork: 62292059, high: 62292059, realHigh: 62292059
04:29:00.214 INFO  [peerWorker-18] [net](PeerConnection.java:175) Send peer /66.23.202.138:34758 message type: SYNC_BLOCK_CHAIN
size: 5, start block: Num:62292041,ID:0000000003b6804971ea2e5e00f837a41f4eefa45c94dd7084a2eb99ab29751a, end block Num:62292059,ID:0000000003b6805bd6c8cf15db9a21e90d6947b837d8dc88dad6c5ccf4f7c7b7
04:29:00.436 INFO  [peerWorker-24] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /111.193.229.212:46030, type: FETCH_INV_DATA
invType: BLOCK, size: 100, First hash: 0000000002b0100ff22372794f5887ba8d0aadc04b8cc1a90601093feccd3049, End hash: 0000000002b010a279e11380cd62093cf6ac8e1680a4d9d6213cd8bc945dc9aa
04:29:00.437 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45092879,ID:0000000002b0100ff22372794f5887ba8d0aadc04b8cc1a90601093feccd3049, trx size: 160

04:29:00.438 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45092880,ID:0000000002b01010972e96993276fa3f74c1dcdf2f9f6285e7edca84bc9ee18e, trx size: 183

04:29:00.438 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45092881,ID:0000000002b0101189230a5616c9f97577264a4850cd132441eceb9f6b04eb90, trx size: 159

04:29:00.462 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093000,ID:0000000002b010883af5a7db28c183125fbdc051d900b5d9febc075cd716cbd5, trx size: 122

04:29:00.463 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093001,ID:0000000002b01089ab9ae36eae0b5331ad51a3c1271d2b39d9d69bfb3434228d, trx size: 122

04:29:00.463 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093002,ID:0000000002b0108a864951b3a197d6441d6de0420f251a61fd410993a9946b68, trx size: 101

04:29:00.463 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093003,ID:0000000002b0108bce079586af806996730038f043872ede3474b196f8264cf8, trx size: 127

04:29:00.463 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093004,ID:0000000002b0108c159aac56087332d03d590632aaf31dbd455d729d1cfb8956, trx size: 106

04:29:00.464 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093005,ID:0000000002b0108df0ce6a43aa9b58391cf6c5a952ab139942155e388c703aaa, trx size: 132

04:29:00.464 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093006,ID:0000000002b0108e16e1dd6a8fc4dd264b3f17f99633cd30b8d2724773996751, trx size: 97

04:29:00.464 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093007,ID:0000000002b0108f0eac14f64564f36855b10d34bdaf605d9a3a69d9807db8be, trx size: 143

04:29:00.464 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093008,ID:0000000002b01090d5c8fcd8d4399ec4eb53496094bdbc70a74f5a1d1d7880eb, trx size: 141

04:29:00.465 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093009,ID:0000000002b01091e5867ec342f1c892f25af19ce21fc43eb526f5036e8011ad, trx size: 131

04:29:00.464 INFO  [peerWorker-18] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /66.23.202.138:34758, type: BLOCK_CHAIN_INVENTORY
size: 2001, first blockId: Num:62292059,ID:0000000003b6805bd6c8cf15db9a21e90d6947b837d8dc88dad6c5ccf4f7c7b7, end blockId: Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b, remain_num: 9530
04:29:00.465 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093010,ID:0000000002b01092de7924de0b2ab55cebb44b3bdfc3b3dc6dfeb78ac24f24bd, trx size: 106

04:29:00.465 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093011,ID:0000000002b01093180eef6022175059d9ab5f800de9f347557d142f3f380a4b, trx size: 190

04:29:00.465 INFO  [peerWorker-18] [DB](Manager.java:1912) HeadNumber: 62292059, syncBeginNumber: 62292041, solidBlockNumber: 62292041.
04:29:00.465 INFO  [peerWorker-18] [net](SyncService.java:197) Get block chain summary, low: 62292041, highNoFork: 62292059, high: 62292059, realHigh: 62294059
04:29:00.466 INFO  [peerWorker-18] [net](PeerConnection.java:175) Send peer /66.23.202.138:34758 message type: SYNC_BLOCK_CHAIN
size: 11, start block: Num:62292041,ID:0000000003b6804971ea2e5e00f837a41f4eefa45c94dd7084a2eb99ab29751a, end block Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b
04:29:00.466 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093012,ID:0000000002b01094719f51fa516ef38f65c45f6551bca6ddc831e26f7958ea42, trx size: 488

04:29:00.466 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093013,ID:0000000002b01095c399bba069c3a2e617a53c57e5e2b9eda40f2b31aeeeb6e2, trx size: 137

04:29:00.467 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093014,ID:0000000002b010966b3a45fcff5a6f013b29081f7531e7539539e5e6fb656bdc, trx size: 152

04:29:00.467 INFO  [peerWorker-24] [net](PeerConnection.java:175) Send peer /111.193.229.212:46030 message type: BLOCK
Num:45093015,ID:0000000002b0109742318217d03e5a630ab599243a5acf7d3456a16f8abec875, trx size: 139

04:29:00.553 INFO  [peerWorker-18] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /66.23.202.138:34758, type: BLOCK_CHAIN_INVENTORY
size: 2001, first blockId: Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b, end blockId: Num:62296059,ID:0000000003b68ffb1df061da552ccf0edc590dd7ff5b66bddee469838957f0d7, remain_num: 7531
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /46.4.94.252:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /94.130.124.92:28888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /47.90.243.148:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /192.210.129.50:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /47.90.201.118:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /23.175.144.144:28888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /192.161.172.154:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /8.209.102.162:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /185.177.229.89:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /3.10.70.76:18888
04:29:00.656 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /35.244.102.41:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /54.221.56.110:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /3.69.90.88:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /18.133.57.195:18888
04:29:00.657 INFO  [peerClient-3] [net](Channel.java:140) Send message to channel /46.4.94.252:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540656
version: 1

04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /147.135.136.186:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /5.199.161.176:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /82.200.155.164:28888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /35.227.149.90:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /178.63.0.176:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /188.64.149.12:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /31.7.66.220:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /16.162.26.11:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /66.29.128.128:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /162.0.208.202:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /35.76.48.223:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /18.142.183.117:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /223.72.35.143:2630
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /18.166.99.110:18888
04:29:00.657 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /18.136.173.214:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /3.121.247.36:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /44.212.88.238:18888
04:29:00.657 INFO  [peerClient-21] [net](Channel.java:140) Send message to channel /178.63.0.176:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /3.127.155.121:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /49.13.205.69:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /35.176.40.38:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /104.196.225.61:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /18.209.42.127:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /54.255.114.102:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /132.145.152.100:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /61.75.3.195:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /78.135.66.25:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /34.81.159.17:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /122.228.236.111:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /34.86.86.229:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /65.109.64.124:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /5.39.223.8:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /51.77.92.242:18888
04:29:00.658 INFO  [connPool] [net](ConnPoolService.java:194) Connect to peer /136.243.89.13:18888
04:29:00.659 INFO  [peerClient-21] [net](ChannelManager.java:214) Receive message from channel: /178.63.0.176:18888, [HelloMessage: from {
  address: ""178.63.0.176""
  port: 18888
  nodeId: ""\270\222\037$R\340\231>_\217\301Q\230\356<h\303g\\!\035)3@\250\373\0214\016\317\371\240\fF\025\333W0\207\251\350\370\272\000\257\216\340Z\221M\333JV\246)\306\215\016\360\225`e\a\b""
}
network_id: 11111
code: 1
timestamp: 1717554540657
version: 1

04:29:00.659 INFO  [peerClient-21] [net](ChannelManager.java:148) Add peer /178.63.0.176:18888, total channels: 32
04:29:00.659 INFO  [peerClient-1] [net](Channel.java:140) Send message to channel /136.243.89.13:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.659 INFO  [peerClient-21] [net](HandshakeService.java:58) Handshake failed /178.63.0.176:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.659 INFO  [peerClient-21] [net](ChannelManager.java:178) Try to close channel: /178.63.0.176:18888, reason: TOO_MANY_PEERS
04:29:00.659 INFO  [peerClient-3] [net](ChannelManager.java:214) Receive message from channel: /46.4.94.252:18888, [HelloMessage: from {
  address: ""46.4.94.252""
  port: 18888
  nodeId: ""D\020\352\327\220\373\307\232u;\217A\340\326\234aw\305p\251\256\211\205q\215r\217?Ou\344\234j\001\350\200\325\336\270\253\202\326(o\277)Z\023\001v2\200\217\031\352\303\024\336\270\272Y\\})""
}
network_id: 11111
code: 3
timestamp: 1717554540656
version: 1

04:29:00.659 INFO  [peerClient-3] [net](ChannelManager.java:148) Add peer /46.4.94.252:18888, total channels: 33
04:29:00.659 INFO  [peerClient-21] [net](P2pChannelInitializer.java:45) Close channel:/178.63.0.176:18888
04:29:00.659 INFO  [peerClient-3] [net](HandshakeService.java:58) Handshake failed /46.4.94.252:18888, code: 3, reason: TIME_BANNED, networkId: 11111, version: 1
04:29:00.659 INFO  [peerClient-3] [net](ChannelManager.java:178) Try to close channel: /46.4.94.252:18888, reason: RECENT_DISCONNECT
04:29:00.659 INFO  [peerClient-21] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 31, active 11, passive 20
04:29:00.659 INFO  [peerClient-3] [net](P2pChannelInitializer.java:45) Close channel:/46.4.94.252:18888
04:29:00.660 INFO  [peerClient-3] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.660 INFO  [peerClient-1] [net](ChannelManager.java:214) Receive message from channel: /136.243.89.13:18888, [HelloMessage: from {
  address: ""136.243.89.13""
  port: 18888
  nodeId: ""\002tE\237\274[\245\226\373D\242\2708\262\274\324AE\235L\255\003\315\217\241\354\230j\335\315\231L\217\331\356=\327\352\262\334B\207\247;\t\206\224\372\335\bm\022\232\177!\t\223\202Em\273hc\026""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.660 INFO  [peerClient-1] [net](ChannelManager.java:148) Add peer /136.243.89.13:18888, total channels: 32
04:29:00.660 INFO  [peerClient-1] [net](HandshakeService.java:58) Handshake failed /136.243.89.13:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.661 INFO  [peerClient-1] [net](ChannelManager.java:178) Try to close channel: /136.243.89.13:18888, reason: TOO_MANY_PEERS
04:29:00.661 INFO  [peerClient-1] [net](P2pChannelInitializer.java:45) Close channel:/136.243.89.13:18888
04:29:00.661 INFO  [peerClient-1] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.662 INFO  [peerClient-11] [net](Channel.java:140) Send message to channel /49.13.205.69:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.664 INFO  [peerClient-8] [net](Channel.java:140) Send message to channel /3.121.247.36:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.664 INFO  [peerClient-10] [net](Channel.java:140) Send message to channel /3.127.155.121:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.665 INFO  [peerClient-24] [net](Channel.java:140) Send message to channel /51.77.92.242:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.665 INFO  [peerClient-11] [net](P2pChannelInitializer.java:45) Close channel:/49.13.205.69:18888
04:29:00.665 INFO  [peerClient-11] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.670 INFO  [peerClient-8] [net](ChannelManager.java:214) Receive message from channel: /3.121.247.36:18888, [HelloMessage: from {
  address: ""3.121.247.36""
  port: 18888
  nodeId: ""(\223T\\\275\002\304\020\364\214|`\023\000\342W0\260\270p\231+\343\301\'\243\022~\362\312\373\373\274\317\255\376\372F\f\343\006\037\356\340\367\036\325\347}N[\331q\267\001d\254n\276[\017\210G\254""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.670 INFO  [peerClient-8] [net](ChannelManager.java:148) Add peer /3.121.247.36:18888, total channels: 32
04:29:00.670 INFO  [peerClient-23] [net](Channel.java:140) Send message to channel /5.39.223.8:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.670 INFO  [peerClient-8] [net](HandshakeService.java:58) Handshake failed /3.121.247.36:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.670 INFO  [peerClient-8] [net](ChannelManager.java:178) Try to close channel: /3.121.247.36:18888, reason: TOO_MANY_PEERS
04:29:00.670 INFO  [peerClient-8] [net](P2pChannelInitializer.java:45) Close channel:/3.121.247.36:18888
04:29:00.670 INFO  [peerClient-8] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.671 INFO  [peerClient-10] [net](ChannelManager.java:214) Receive message from channel: /3.127.155.121:18888, [HelloMessage: from {
  address: ""3.127.155.121""
  port: 18888
  nodeId: ""\021\211\343S\371\226\337;\231+\375\351d\177\255\322\351\tR\264\301\351\306H\313\254\354\n\263\337\302\323\300\275\217z\002\270\227\310[\375\2619\221@\347jP\350\201$\000\266\373.k\303\302\214\243\257\261\341""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.671 INFO  [peerClient-10] [net](ChannelManager.java:148) Add peer /3.127.155.121:18888, total channels: 32
04:29:00.671 INFO  [peerClient-10] [net](HandshakeService.java:58) Handshake failed /3.127.155.121:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.671 INFO  [peerClient-10] [net](ChannelManager.java:178) Try to close channel: /3.127.155.121:18888, reason: TOO_MANY_PEERS
04:29:00.671 INFO  [peerClient-10] [net](P2pChannelInitializer.java:45) Close channel:/3.127.155.121:18888
04:29:00.671 INFO  [peerClient-10] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.671 INFO  [peerClient-24] [net](ChannelManager.java:214) Receive message from channel: /51.77.92.242:18888, [HelloMessage: from {
  address: ""51.77.92.242""
  port: 18888
  nodeId: ""\fI#\320\370\326\303\027\274d3\272#/p\254\250\026\345B\035V\225\316G\271\026\273i0\032:\372\367\023\b\225\262\210\026\025Z\001\037<m\210\n>\225\302V\352\357\305\344Q\035f\323\355A\303h""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.672 INFO  [peerClient-24] [net](ChannelManager.java:148) Add peer /51.77.92.242:18888, total channels: 32
04:29:00.672 INFO  [peerClient-24] [net](HandshakeService.java:58) Handshake failed /51.77.92.242:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.672 INFO  [peerClient-24] [net](ChannelManager.java:178) Try to close channel: /51.77.92.242:18888, reason: TOO_MANY_PEERS
04:29:00.672 INFO  [peerClient-24] [net](P2pChannelInitializer.java:45) Close channel:/51.77.92.242:18888
04:29:00.672 INFO  [peerClient-24] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.672 INFO  [peerClient-17] [net](Channel.java:140) Send message to channel /147.135.136.186:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.678 INFO  [peerClient-12] [net](Channel.java:140) Send message to channel /3.10.70.76:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540656
version: 1

04:29:00.678 INFO  [peerClient-16] [net](Channel.java:140) Send message to channel /18.133.57.195:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.679 INFO  [peerClient-12] [net](Channel.java:140) Send message to channel /35.176.40.38:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.682 INFO  [peerClient-23] [net](ChannelManager.java:214) Receive message from channel: /5.39.223.8:18888, [HelloMessage: from {
  address: ""5.39.223.8""
  port: 18888
  nodeId: ""\tuN\270pa\203A\031\024\006\204\317UX\273\334\300\231\264U\315p\343!\212?\331\3678\376b\026\276\256\273\230\367\020\017\242\375fU-\277\231\271\266hD\342\001+U\'\266?\215\340\204\316\223o""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.682 INFO  [peerClient-23] [net](ChannelManager.java:148) Add peer /5.39.223.8:18888, total channels: 32
04:29:00.682 INFO  [peerClient-23] [net](HandshakeService.java:58) Handshake failed /5.39.223.8:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.682 INFO  [peerClient-23] [net](ChannelManager.java:178) Try to close channel: /5.39.223.8:18888, reason: TOO_MANY_PEERS
04:29:00.682 INFO  [peerClient-23] [net](P2pChannelInitializer.java:45) Close channel:/5.39.223.8:18888
04:29:00.683 INFO  [peerClient-23] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.683 INFO  [peerClient-22] [net](Channel.java:140) Send message to channel /65.109.64.124:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.689 INFO  [peerClient-17] [net](ChannelManager.java:214) Receive message from channel: /147.135.136.186:18888, [HelloMessage: from {
  address: ""147.135.136.186""
  port: 18888
  nodeId: ""\020\331T\226|\025~\001[\251\377\273\245\313f\237\337\241W~\353\3515K\215\367\354\016\371(\017 \235\372j7IThPPn\277\244&\252j~a\022\227\366\261\003\037\000\277\241\234\221\352\265\366\277""
}
network_id: 11111
code: 1
timestamp: 1717554540657
version: 1

04:29:00.689 INFO  [peerClient-17] [net](ChannelManager.java:148) Add peer /147.135.136.186:18888, total channels: 32
04:29:00.689 INFO  [peerClient-17] [net](HandshakeService.java:58) Handshake failed /147.135.136.186:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.689 INFO  [peerClient-17] [net](ChannelManager.java:178) Try to close channel: /147.135.136.186:18888, reason: TOO_MANY_PEERS
04:29:00.689 INFO  [peerClient-17] [net](P2pChannelInitializer.java:45) Close channel:/147.135.136.186:18888
04:29:00.689 INFO  [peerClient-17] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.699 INFO  [peerClient-12] [net](ChannelManager.java:214) Receive message from channel: /3.10.70.76:18888, [HelloMessage: from {
  address: ""3.10.70.76""
  port: 18888
  nodeId: ""\033\346e\377\333\356\350N\224T*\243\365\035\214\230\200\005\017\226\362\366BG\223\257^\333\212\300\306xd\205\276\025=\030&\213\037\315\202\222\017\222\251:\344Az\344~q\222\210\322\2332\234\'H\252\264""
}
network_id: 11111
code: 1
timestamp: 1717554540656
version: 1

04:29:00.699 INFO  [peerClient-12] [net](ChannelManager.java:148) Add peer /3.10.70.76:18888, total channels: 32
04:29:00.699 INFO  [peerClient-12] [net](HandshakeService.java:58) Handshake failed /3.10.70.76:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.699 INFO  [peerClient-12] [net](ChannelManager.java:178) Try to close channel: /3.10.70.76:18888, reason: TOO_MANY_PEERS
04:29:00.699 INFO  [peerClient-12] [net](P2pChannelInitializer.java:45) Close channel:/3.10.70.76:18888
04:29:00.699 INFO  [peerClient-12] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.700 INFO  [peerClient-16] [net](ChannelManager.java:214) Receive message from channel: /18.133.57.195:18888, [HelloMessage: from {
  address: ""18.133.57.195""
  port: 18888
  nodeId: ""\372z\321c\360;>k\\\320\\\027\'b\375`\342y\342\303\""qi\217\336.\227\034\245g\036\035\237\204\243\263Y\334\037\246\266q\325\314\251\026\213~9\002|]\000\036\030\260|\262Z\330*\372|\376""
}
network_id: 11111
code: 1
timestamp: 1717554540657
version: 1

04:29:00.700 INFO  [peerClient-16] [net](ChannelManager.java:148) Add peer /18.133.57.195:18888, total channels: 32
04:29:00.700 INFO  [peerClient-16] [net](HandshakeService.java:58) Handshake failed /18.133.57.195:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.700 INFO  [peerClient-16] [net](ChannelManager.java:178) Try to close channel: /18.133.57.195:18888, reason: TOO_MANY_PEERS
04:29:00.700 INFO  [peerClient-16] [net](P2pChannelInitializer.java:45) Close channel:/18.133.57.195:18888
04:29:00.700 INFO  [peerClient-16] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.701 INFO  [peerClient-12] [net](ChannelManager.java:214) Receive message from channel: /35.176.40.38:18888, [HelloMessage: from {
  address: ""35.176.40.38""
  port: 18888
  nodeId: ""\021T^\245\252\205\t\b\267\035\215\261\216\240X\333X\027\333\360&l\342\272\313iq\300\0176\021\212at\230\234\314kq\357\300\037*o\256\rk7\324}\036\301\251\321\312\317`\331\304\304\t\332\271\373""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.701 INFO  [peerClient-12] [net](ChannelManager.java:148) Add peer /35.176.40.38:18888, total channels: 32
04:29:00.701 INFO  [peerClient-12] [net](HandshakeService.java:58) Handshake failed /35.176.40.38:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.701 INFO  [peerClient-12] [net](ChannelManager.java:178) Try to close channel: /35.176.40.38:18888, reason: TOO_MANY_PEERS
04:29:00.701 INFO  [peerClient-12] [net](P2pChannelInitializer.java:45) Close channel:/35.176.40.38:18888
04:29:00.701 INFO  [peerClient-12] [net](ConnPoolService.java:261) Peer stats: channels 31, activePeers 31, active 11, passive 20
04:29:00.710 INFO  [peerClient-22] [net](ChannelManager.java:214) Receive message from channel: /65.109.64.124:18888, [HelloMessage: from {
  address: ""65.109.64.124""
  port: 18888
  nodeId: ""\a\350f\320\f\001\317\224\252x\275rN_n9I\200=\257\324\006U\320J\310\364\214\027A<\320\251\325\231h@!x\312H\177\255\005\362\300\235\343\002\234\274\326\2553~\3253L\031bN/\342\317""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.710 INFO  [peerClient-22] [net](ChannelManager.java:148) Add peer /65.109.64.124:18888, total channels: 32
04:29:00.710 INFO  [peerClient-22] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 32, active 12, passive 20
04:29:00.710 INFO  [peerClient-22] [net](PeerConnection.java:175) Send peer /65.109.64.124:18888 message type: P2P_HELLO
from: /142.132.218.251:18888
timestamp: 1717554540658
headBlockId: Num:62292059,ID:0000000003b6805bd6c8cf15db9a21e90d6947b837d8dc88dad6c5ccf4f7c7b7
nodeType: 0
lowestBlockNum: 0
codeVersion:4.7.4

04:29:00.710 INFO  [peerClient-22] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /65.109.64.124:18888, type: P2P_HELLO
from: /65.109.64.124:18888
timestamp: 1717554540701
headBlockId: Num:62303590,ID:0000000003b6ad668a5675ea78b8cbba1903a18967f4d1c39d252a4d203c2c0d
nodeType: 0
lowestBlockNum: 0
codeVersion:4.7.4

04:29:00.710 INFO  [peerClient-22] [DB](Manager.java:1912) HeadNumber: 62292059, syncBeginNumber: 62292041, solidBlockNumber: 62292041.
04:29:00.711 INFO  [peerClient-22] [net](SyncService.java:197) Get block chain summary, low: 62292041, highNoFork: 62292059, high: 62292059, realHigh: 62292059
04:29:00.711 INFO  [peerClient-22] [net](PeerConnection.java:175) Send peer /65.109.64.124:18888 message type: SYNC_BLOCK_CHAIN
size: 5, start block: Num:62292041,ID:0000000003b6804971ea2e5e00f837a41f4eefa45c94dd7084a2eb99ab29751a, end block Num:62292059,ID:0000000003b6805bd6c8cf15db9a21e90d6947b837d8dc88dad6c5ccf4f7c7b7
04:29:00.711 INFO  [peerClient-18] [net](Channel.java:140) Send message to channel /78.135.66.25:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.751 INFO  [peerClient-21] [net](Channel.java:140) Send message to channel /34.86.86.229:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.752 INFO  [peerClient-14] [net](Channel.java:140) Send message to channel /54.221.56.110:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.753 INFO  [peerClient-14] [net](Channel.java:140) Send message to channel /18.209.42.127:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.754 INFO  [peerClient-9] [net](Channel.java:140) Send message to channel /44.212.88.238:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.758 INFO  [peerClient-19] [net](Channel.java:140) Send message to channel /82.200.155.164:28888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.762 INFO  [peerClient-16] [net](Channel.java:140) Send message to channel /132.145.152.100:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.766 INFO  [peerClient-18] [net](ChannelManager.java:214) Receive message from channel: /78.135.66.25:18888, [HelloMessage: from {
  address: ""78.135.66.25""
  port: 18888
  nodeId: ""\001%@\021\325K\244\200AH\2007\312p\264g\263^\340\315<J66Z\237A<s\354\330\374xS\022LrYih\324e\273)W\002V\233\231{4?WU\310\r<G\247\345\027\027(\221""
}
network_id: 11111
code: 3
timestamp: 1717554540658
version: 1

04:29:00.766 INFO  [peerClient-18] [net](ChannelManager.java:148) Add peer /78.135.66.25:18888, total channels: 33
04:29:00.766 INFO  [peerClient-18] [net](HandshakeService.java:58) Handshake failed /78.135.66.25:18888, code: 3, reason: TIME_BANNED, networkId: 11111, version: 1
04:29:00.766 INFO  [peerClient-18] [net](ChannelManager.java:178) Try to close channel: /78.135.66.25:18888, reason: RECENT_DISCONNECT
04:29:00.766 INFO  [peerClient-18] [net](P2pChannelInitializer.java:45) Close channel:/78.135.66.25:18888
04:29:00.766 INFO  [peerClient-18] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 32, active 12, passive 20
04:29:00.790 INFO  [peerClient-22] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /65.109.64.124:18888, type: BLOCK_CHAIN_INVENTORY
size: 2001, first blockId: Num:62292059,ID:0000000003b6805bd6c8cf15db9a21e90d6947b837d8dc88dad6c5ccf4f7c7b7, end blockId: Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b, remain_num: 9531
04:29:00.791 INFO  [peerClient-22] [DB](Manager.java:1912) HeadNumber: 62292059, syncBeginNumber: 62292041, solidBlockNumber: 62292041.
04:29:00.791 INFO  [peerClient-22] [net](SyncService.java:197) Get block chain summary, low: 62292041, highNoFork: 62292059, high: 62292059, realHigh: 62294059
04:29:00.791 INFO  [peerClient-22] [net](PeerConnection.java:175) Send peer /65.109.64.124:18888 message type: SYNC_BLOCK_CHAIN
size: 11, start block: Num:62292041,ID:0000000003b6804971ea2e5e00f837a41f4eefa45c94dd7084a2eb99ab29751a, end block Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b
04:29:00.795 INFO  [peerClient-2] [net](Channel.java:140) Send message to channel /162.0.208.202:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.804 INFO  [peerClient-13] [net](Channel.java:140) Send message to channel /104.196.225.61:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540658
version: 1

04:29:00.804 INFO  [peerClient-20] [net](Channel.java:140) Send message to channel /35.227.149.90:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.805 INFO  [peerClient-1] [net](Channel.java:140) Send message to channel /66.29.128.128:18888, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.821 INFO  [peerClient-22] [net](P2pEventHandlerImpl.java:168) Receive message from  peer: /65.109.64.124:18888, type: BLOCK_CHAIN_INVENTORY
size: 2001, first blockId: Num:62294059,ID:0000000003b6882be0757c7e3ab0e2f9c94f064b99ed4b9bde9e060630f8aa2b, end blockId: Num:62296059,ID:0000000003b68ffb1df061da552ccf0edc590dd7ff5b66bddee469838957f0d7, remain_num: 7531
04:29:00.843 INFO  [peerClient-21] [net](ChannelManager.java:214) Receive message from channel: /34.86.86.229:18888, [HelloMessage: from {
  address: ""34.86.86.229""
  port: 18888
  nodeId: ""\000G\242G\232S\250\365\205V\217\2430A\311\240\215?\225PuC\253\356YUR^\037M\207QA\361\306\362\247\364\301\202\325E\244WD\034\025V\307v\254\200c\254\021\341OD\267\221\267\233\331\254""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.844 INFO  [peerClient-21] [net](ChannelManager.java:148) Add peer /34.86.86.229:18888, total channels: 33
04:29:00.844 INFO  [peerClient-21] [net](HandshakeService.java:58) Handshake failed /34.86.86.229:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.844 INFO  [peerClient-21] [net](ChannelManager.java:178) Try to close channel: /34.86.86.229:18888, reason: TOO_MANY_PEERS
04:29:00.844 INFO  [peerClient-21] [net](P2pChannelInitializer.java:45) Close channel:/34.86.86.229:18888
04:29:00.844 INFO  [peerClient-21] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 32, active 12, passive 20
04:29:00.848 INFO  [peerClient-14] [net](ChannelManager.java:214) Receive message from channel: /54.221.56.110:18888, [HelloMessage: from {
  address: ""54.221.56.110""
  port: 18888
  nodeId: ""\250D\371\362\310UR\350\""\363\225\2351k\235t\344\361\271\272w\027 >ZB6e\017\214\234\362\227\353\306x\""\030\300\324\030I\331\364\204\263\035\2515\343\341\221\304\311\332\b\331\324\322\226.\366X[""
}
network_id: 11111
code: 1
timestamp: 1717554540657
version: 1

04:29:00.848 INFO  [peerClient-14] [net](ChannelManager.java:148) Add peer /54.221.56.110:18888, total channels: 33
04:29:00.848 INFO  [peerClient-14] [net](HandshakeService.java:58) Handshake failed /54.221.56.110:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.848 INFO  [peerClient-14] [net](ChannelManager.java:178) Try to close channel: /54.221.56.110:18888, reason: TOO_MANY_PEERS
04:29:00.848 INFO  [peerClient-14] [net](P2pChannelInitializer.java:45) Close channel:/54.221.56.110:18888
04:29:00.848 INFO  [peerClient-14] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 32, active 12, passive 20
04:29:00.848 INFO  [peerClient-14] [net](ChannelManager.java:214) Receive message from channel: /18.209.42.127:18888, [HelloMessage: from {
  address: ""18.209.42.127""
  port: 18888
  nodeId: ""\a\352t\3358\031\3005\357\274\245!\243\372\003\234\364@\277&\212TZ\304\004\233f\334&V\020\21659\376\331>\270\320\336&\201H72\314\006\017\360O\215\234R\330\201yG\305\366\032\024~]\307""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.848 INFO  [peerClient-14] [net](ChannelManager.java:148) Add peer /18.209.42.127:18888, total channels: 33
04:29:00.849 INFO  [peerClient-14] [net](HandshakeService.java:58) Handshake failed /18.209.42.127:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.849 INFO  [peerClient-14] [net](ChannelManager.java:178) Try to close channel: /18.209.42.127:18888, reason: TOO_MANY_PEERS
04:29:00.849 INFO  [peerClient-9] [net](ChannelManager.java:214) Receive message from channel: /44.212.88.238:18888, [HelloMessage: from {
  address: ""44.212.88.238""
  port: 18888
  nodeId: ""(4T\363\337\213h25\tB\t\247\315\214?&2\202d\023\310\022\023\223\205\v\322K\r|\002\037\340\370\252*>\233~\203\221\271b\033\235\310\035\277uLef\304\032\225\""E\365\227{y\224s""
}
network_id: 11111
code: 1
timestamp: 1717554540658
version: 1

04:29:00.849 INFO  [peerClient-9] [net](ChannelManager.java:148) Add peer /44.212.88.238:18888, total channels: 34
04:29:00.849 INFO  [peerClient-14] [net](P2pChannelInitializer.java:45) Close channel:/18.209.42.127:18888
04:29:00.849 INFO  [peerClient-9] [net](HandshakeService.java:58) Handshake failed /44.212.88.238:18888, code: 1, reason: TOO_MANY_PEERS, networkId: 11111, version: 1
04:29:00.849 INFO  [peerClient-9] [net](ChannelManager.java:178) Try to close channel: /44.212.88.238:18888, reason: TOO_MANY_PEERS
04:29:00.849 INFO  [peerClient-14] [net](ConnPoolService.java:261) Peer stats: channels 33, activePeers 32, active 12, passive 20
04:29:00.849 INFO  [peerClient-9] [net](P2pChannelInitializer.java:45) Close channel:/44.212.88.238:18888
04:29:00.849 INFO  [peerClient-9] [net](ConnPoolService.java:261) Peer stats: channels 32, activePeers 32, active 12, passive 20
04:29:00.851 INFO  [peerClient-5] [net](Channel.java:140) Send message to channel /223.72.35.143:2630, [HelloMessage: from {
  address: ""142.132.218.251""
  port: 18888
  nodeId: ""\214Sx\216}~a\260\201b\026\207\327\032(\312\363\024\220\330T)P\206\021 \000\2374\317\355g*\026\\u\307\210q[*\n\327q\211\243y9MRu\242\353l\216.\210\246^u\017>\021\227""
}
network_id: 11111
timestamp: 1717554540657
version: 1

04:29:00.865 INFO  [peerClient-19] [net](ChannelManager.java:214) Receive message from channel: /82.200.155.164:28888, [HelloMessage: from {
  address: ""82.200.155.164""
  port: 28888
  nodeId: ""\001,\217Tb^!\212\352X\rC=\271tLcJ\351\344\36263{\374\373\370\306v)yr\335hs\374\250+\377\024\b\321\337\260\247m\326\226$\301\231\207\307Q\333\037\316\024\322\222\217euw""
}
network_id: 11111
timestamp: 1717554540657
version: 1

````

",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a blockchain node that has become 'stuck' at a specific block number (62292059). The provided logs show that the node is aware of more recent blocks on the network (e.g., `realHigh: 62294059`) and repeatedly attempts to synchronize by sending `SYNC_BLOCK_CHAIN` requests to its peers. However, despite these repeated attempts, the node's head block number does not advance. This cyclical behavior of attempting to sync but failing to make progress is a classic symptom of an infinite loop. The condition required to exit this state—successfully processing the next block and advancing the head—is apparently unreachable due to a flaw in the logic. This directly aligns with the definition of CWE-835, 'Loop with Unreachable Exit Condition ('Infinite Loop')'.

CWE-400 (Uncontrolled Resource Consumption) is less appropriate. While the logs show the node is hitting its peer connection limit (`reason: TOO_MANY_PEERS`), this appears to be a symptom rather than the root cause. The node is likely trying to connect to more peers because it is stuck in a loop trying to find a peer it can successfully sync with. The primary issue is the inability to progress, not the consumption of resources itself.

CWE-697 (Incorrect Comparison) could be the underlying implementation error that *causes* the infinite loop (e.g., incorrectly comparing block numbers or hashes), but CWE-835 describes the observable, high-level weakness more accurately based on the provided report. The most direct and certain classification from the symptoms is the infinite loop.",closed,"The node becomes unable to synchronize new blocks after an upgrade, potentially due to compatibility issues or bugs introduced in the new version (v4.7.5).","The inability to sync new blocks can lead to the node falling out of sync with the network, which could result in data inconsistencies, loss of transactions, and a compromised network state.",2334773571,5847,"June 5, 2024 2:31 AM (GMT+8)","June 5, 2024 12:29 PM (GMT+8)",['type:bug'],
java-tron,"Node with event plug-in enabled takes too much memory, or OOM happens ",https://github.com/tronprotocol/java-tron/issues/5821,Storage,"#### System information


**Versions**
* Software version: [`java -jar FullNode.jar -v`] 4.7.3
* Java version: [`java -version`]  openjdk version ""1.8.0_402""
* OS Name & Version: [`cat /etc/*release`] CentOS Linux release 7.9.2009 (Core)
* Kernel Version: [`uname -a`]  x86_64 x86_64 x86_64 GNU/Linux
* Virtual Machine software & version: [`vmware -v`]
* Docker Version: [`docker version`]
* Cloud VM, type, size: [Amazon Web Services I3-large]
* Node Type: [e.g. fullNode, liteFullNode] fullNode
* Blockchain Net: [e.g. main, test or private ] test
* Commit hash : [if `develop`]




#### Expected behavior
Nodes with event plug-ins enabled can run normally and stably.




#### Actual behavior
I deployed a nile node using the snapshot database and started with the mongo plug-in. After running for a period of time (about 20 days), I found that the node was always in sync status. After checking the logs, I found that the block processing took a long time and could not catch up with the latest block. At the same time, the memory usage was as high as 37GB.


#### Steps to reproduce the behavior


Deployed a nile node using the snapshot database, started with the mongo plug-in. Mongo configuration is listed as follow :
```
event.subscribe = {
 native = {
   useNativeQueue = false // if true, use native message queue, else use event plugin.
   bindport = 5555 // bind port
   sendqueuelength = 1000 //max length of send queue
 }


 path = ""/data/event-plugin/build/plugins/plugin-mongodb-1.0.0.zip"" // absolute path of plugin
 server = ""127.0.0.1:27017"" // target server address to receive event triggers
 dbconfig = ""online|oom|oom"" // dbname|username|password
 contractParse = true,
 topics = [
   {
     triggerName = ""block"" // block trigger, the value can't be modified
     enable = true
     topic = ""block"" // plugin topic, the value could be modified
     solidified = true // if set true, just need solidified block, default is false
   },

   {
     triggerName = ""transaction""
     enable = true
     topic = ""transaction""
     solidified = true
     ethCompatible = true // if set true, add transactionIndex, cumulativeEnergyUsed, preCumulativeLogCount, logList, energyUnitPrice, default is false
   },

   {
     triggerName = ""contractevent""
     enable = true
     topic = ""contractevent""
   },

   {
     triggerName = ""contractlog""
     enable = true
     topic = ""contractlog""
     redundancy = true // if set true, contractevent will also be regarded as contractlog
   },

   {
     triggerName = ""solidity"" // solidity block trigger(just include solidity block number and timestamp), the value can't be modified
     enable = true            // the default value is true
     topic = ""solidity""
   },

   {
     triggerName = ""solidityevent""
     enable = true
     topic = ""solidityevent""
   },

   {
     triggerName = ""soliditylog""
     enable = true
     topic = ""soliditylog""
     redundancy = true // if set true, solidityevent will also be regarded as soliditylog
   }

 ]


 filter = {
   fromblock = """" // the value could be """", ""earliest"" or a specified block number as the beginning of the queried range
   toblock = """" // the value could be """", ""latest"" or a specified block number as end of the queried range
   contractAddress = [
     """" // contract address you want to subscribe, if it's set to """", you will receive contract logs/events with any contract address.
   ]

   contractTopic = [
     """" // contract topic you want to subscribe, if it's set to """", you will receive contract logs/events with any contract topic.
   ]
 }

}
```
Later I discovered that all collections had no indexes.


#### Backtrace


Memory monitoring chart:
![image](https://github.com/tronprotocol/java-tron/assets/169016168/9f21cfb7-3a6d-42e3-8b88-bcbcbb7c21ad)


File diagram after dumping memory:

![image](https://github.com/tronprotocol/java-tron/assets/169016168/649f361d-3408-41a5-95e5-7895cc1111a4)

![image](https://github.com/tronprotocol/java-tron/assets/169016168/d6d3a49f-fcfa-4cb7-97aa-8b0a28cd740e)

Note: when submitting logs, please submit them as plain text, not in screenshots.





",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a situation where a node with an event plug-in enabled consumes an increasing amount of memory over time, eventually reaching 37GB and causing performance degradation and potential Out-Of-Memory (OOM) errors. The root cause appears to be an event queue that grows excessively because the downstream consumer (a MongoDB database) is slow, reportedly due to a lack of indexes. This leads to events piling up in the application's memory.

Let's analyze the provided CWE options:
- **CWE-404 (Improper Resource Shutdown or Release):** This CWE describes a classic memory leak where a resource is allocated but never, or incorrectly, released. In this case, the memory for the queued events is intended to be released after being processed. The problem isn't a faulty release mechanism itself, but rather that the release process is stalled due to a bottleneck. The resources are held for too long, but not indefinitely due to a code error in the release path. Thus, CWE-404 is not the best fit.

- **CWE-770 (Allocation of Resources Without Limits or Throttling):** This CWE points to a lack of restrictions on resource allocation. The report shows a configuration `sendqueuelength = 1000`, which is an explicit limit on the queue size. While this limit might be insufficient or there might be other unbounded allocations, the primary issue is not the complete absence of a limit, but the system's inability to handle the resource consumption under the given conditions. The system allocates resources faster than it can free them, leading to exhaustion. This is a plausible choice, but it's a specific case of a broader problem.

- **CWE-400 (Uncontrolled Resource Consumption):** This CWE is a more general but highly accurate description of the problem. It states that 'The product does not properly control the allocation and maintenance of a limited resource.' The limited resource is memory. The application fails to 'properly control' this resource because the event queue is allowed to grow to a point where it exhausts system memory, causing severe performance issues. The imbalance between the rate of event creation (allocation) and event processing (release) leads to this uncontrolled consumption. This CWE perfectly encapsulates the observed behavior: a gradual consumption of a resource to the point of exhaustion, leading to a denial of service (performance degradation and OOM). It is a better fit than CWE-770 because the problem is the overall failure to manage the resource lifecycle under load, not just the simple absence of a numeric limit.

Therefore, CWE-400 is the single most accurate classification for this bug.",closed,"The node's event plug-in is configured to handle a large volume of data without proper indexing in the MongoDB collections, leading to excessive memory usage and eventual out-of-memory (OOM) conditions.","The node becomes unable to process new blocks in a timely manner, risking synchronization issues and potential downtime, which could affect the overall stability and reliability of the blockchain network.",2294190939,5821,"May 14, 2024 2:01 AM (GMT+8)","July 1, 2024 3:36 PM (GMT+8)",['type:bug'],
java-tron,API Services Fail to Start Silently,https://github.com/tronprotocol/java-tron/issues/5820,API,"## Software Versions

OS: Linux
JVM: Oracle Corporation 1.8.0_161 AMD64
Version: 4.7.4
Code: 18260

## Expected behavior

An exception should be thrown and the node service should exit when the API services fail to start.

## Actual behavior

 Node starts with no API services and no exception about it thrown.

## Steps to reproduce the behavior

1. Make gRPC service port 50051 occupied in advance
2. Start the node
3. Try to access the API endpoint

## Backtrace

````service
14:54:41.976 ERROR [rpc] RpcApiService
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:50051
	at io.grpc.netty.NettyServer.start(NettyServer.java:328)
Caused by: java.net.BindException: Address already in use
14:54:41.983 INFO [app] All api services started.

````

````Client:
UNIMPLEMENTED: Method not found: protocol.Wallet/GetAccount
io.grpc.StatusRuntimeException: UNIMPLEMENTED: Method not found: protocol.Wallet/GetAccount
	at io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:271)
	at io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:252)
	at io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:165)
````
",api: api unavailability,CWE-390,Detection of Error Condition Without Action,"The bug report describes a situation where a critical API service fails to start due to a `java.net.BindException`. The application logs show that this exception is detected and logged as an ERROR. However, the application then proceeds as if the startup was successful, even logging an `INFO` message stating 'All api services started.' The expected behavior was for the application to exit, but instead, it continues to run in a non-functional state. This behavior directly maps to CWE-390. The error condition (`BindException`) is detected, but no corrective action (like terminating the application) is taken. CWE-665 is less suitable because the core issue isn't the initialization failure itself (which is an expected outcome if a port is busy), but the application's reaction to it. CWE-755 is a plausible but broader category; CWE-390 is more specific and accurately describes the precise failure mode of detecting an error but then taking no action to alter the program's incorrect control flow.",closed,"The API services fail to start due to a port binding issue, but instead of throwing an exception and exiting, the node starts without the API services running.","The inability to detect the failure of the API services during startup can lead to confusion for users and developers, as the node appears to be operational while critical services are unavailable, potentially resulting in a loss of functionality and trust in the system.",2291703549,5820,"May 13, 2024 3:04 AM (GMT+8)","July 16, 2024 6:57 PM (GMT+8)","['type:bug', 'v4.8.0']",
java-tron,"The node reported ""Handle sync block error"" and no blocks were synchronized in the next 20 seconds.",https://github.com/tronprotocol/java-tron/issues/5813,Storage,"#### System information
Java-tron version: v4.7.4
OS & Version: Linux & macOS

#### Expected behavior
Synchronization of blocks should be normal, no exceptions should occur.


#### Actual behavior
The node reported a `Handle sync block error` exception, and no blocks were synchronized for 20 seconds after the exception occurred.

![image](https://github.com/tronprotocol/java-tron/assets/169016168/255128ba-3648-4a01-b6b7-6eaebdddb95a)


",consensus: consensus liveness failure,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a scenario where the system encounters an exception, specifically a 'Handle sync block error'. The direct consequence of this exception is that a critical function, block synchronization, ceases to operate for 20 seconds, leading to a 'consensus liveness failure'. This directly maps to the definition of CWE-755, 'Improper Handling of Exceptional Conditions', as the system does not handle the exceptional condition correctly, resulting in a denial of service (liveness failure). 

CWE-20 (Improper Input Validation) is less suitable because while the error might be triggered by invalid input (a malformed block), the report's focus is on the system's faulty reaction *to* the error, not the root cause of the error itself. The provided information is insufficient to confirm an input validation flaw.

CWE-476 (NULL Pointer Dereference) is too specific. The bug report mentions a generic 'error' and 'exception' without providing a stack trace that would confirm a NULL pointer dereference as the cause. The core issue described is the failure to recover from an error, whatever its specific type might be. Therefore, CWE-755 is the most accurate and well-supported choice based on the report's details.",closed,"The node encountered an unexpected condition while attempting to synchronize blocks, leading to an error that halted further synchronization.",The failure to synchronize blocks for 20 seconds could lead to a temporary inconsistency in the blockchain state and affect the performance and reliability of the network.,2280006565,5813,"May 6, 2024 4:29 AM (GMT+8)","May 30, 2024 2:26 PM (GMT+8)",['type:bug'],
java-tron,Untimely event consumption may cause node OOM,https://github.com/tronprotocol/java-tron/issues/5721,Storage,"# Rationale

Java-tron can load event plug-ins through configuration files, currently including Mongo plug-ins and Kafka plug-ins. Plug-in implementation refers to <https://github.com/tronprotocol/event-plugin>. The node consumes events and writes them to Mongo through plug-in serialization or streaming to Kafka.

All events are cached through BlockingQueue:

```java
 private BlockingQueue<TriggerCapsule> triggerCapsuleQueue;
```

There are multiple producers, such as org.tron.core.db.Manager#postTransactionTrigger, which writes the log in the transaction to the queue:

```java
 private void postTransactionTrigger(final TransactionCapsule trxCap,
      final BlockCapsule blockCap) {
    TransactionLogTriggerCapsule trx = new TransactionLogTriggerCapsule(trxCap, blockCap);
    trx.setLatestSolidifiedBlockNumber(getDynamicPropertiesStore()
        .getLatestSolidifiedBlockNum());
    if (!triggerCapsuleQueue.offer(trx)) {
      logger.info(""Too many triggers, transaction trigger lost: {}."", trxCap.getTransactionId());
    }
  }
```

But there is only one consumer: org.tron.core.db.Manager#triggerCapsuleProcessLoop:

```java
  private Runnable triggerCapsuleProcessLoop =
      () -> {
        while (isRunTriggerCapsuleProcessThread) {
          try {
            TriggerCapsule triggerCapsule = triggerCapsuleQueue.poll(1, TimeUnit.SECONDS);
            if (triggerCapsule != null) {
              triggerCapsule.processTrigger();
            }
          } catch (InterruptedException ex) {
            logger.info(ex.getMessage());
            Thread.currentThread().interrupt();
          } catch (Throwable throwable) {
            logger.error(""Unknown throwable happened in process capsule loop."", throwable);
          }
        }
      };
```

ProcessTrigger actually serializes events through the 7 APIs of the plug-in IPluginEventListener. If the consumption speed of consumers is much slower than that of producers, the queue may be backlogged. After a while, the node will experience frequent full gc, be unable to synchronize or provide external services, or even run out of memory and incur OOM, eventually leading to data loss.

Possible reasons for slow queue data consumption include:

1.  There is not sufficient bandwidth between fullnode and mongo server.
2.  Mongo does not have any filed index.
3.  Mongo’s unique index is not set correctly.

# Implementation

One possible way is to set the maximum and minimum threshold of the queue’s length. Start a monitoring thread, when the queue’s length exceeds the maximum value, this thread will suspend synchronization or broadcasting block, and timely remind users to deal with queue overflow problems; when the length is below the minimum value, it resumes synchronization.
",general: general performance degradation,CWE-770,Allocation of Resources Without Limits or Throttling,"The bug report describes a classic producer-consumer problem where events are added to a `BlockingQueue` by multiple producers and processed by a single consumer. When the consumer's processing speed is slower than the producers' rate of event generation, the queue grows in size. The report explicitly states that this backlog can lead to an Out-Of-Memory (OOM) error, indicating that the queue's size is not being controlled. This is a direct example of allocating a resource (memory for the queue) without a mechanism to limit its growth.

- **CWE-770 (Allocation of Resources Without Limits or Throttling)** is the most accurate fit. The resource is the memory allocated for the `BlockingQueue`. The weakness is the lack of limits on the queue's size or a throttling mechanism to slow down producers when the queue becomes too large. The proposed solution in the report—adding thresholds to suspend and resume producers—is a direct implementation of throttling, which further reinforces this choice.

- **CWE-400 (Uncontrolled Resource Consumption)** is a broader, more general category. While the bug does represent uncontrolled resource consumption, CWE-770 is more specific about the *cause* of this consumption, which is the absence of limits or throttling on allocation. In CWE classification, it is best practice to choose the most specific and fitting weakness.

- **CWE-789 (Memory Allocation with Excessive Size Value)** is not applicable. This CWE relates to a single memory allocation operation that uses an untrusted and excessively large size value. The bug described here is caused by the accumulation of many smaller, legitimate allocations over time, not one single oversized allocation.",closed,"The bug is caused by a mismatch in the production and consumption rates of events in the BlockingQueue, leading to potential backlog and Out Of Memory (OOM) errors.","If the queue becomes backlogged due to slow consumption, it may lead to frequent garbage collection, inability to synchronize or provide services, and ultimately, OOM errors that can result in data loss.",2124783669,5721,"February 8, 2024 10:07 AM (GMT+8)","April 24, 2024 12:03 PM (GMT+8)","['type:bug', 'topic: Event subscribe']",
java-tron,Cache data not cleared when connection terminated,https://github.com/tronprotocol/java-tron/issues/5720,Network,"#### System information
java-tron version: v4.7.4
OS & Version: Linux & macOS

#### Expected behaviour
Cache data should be cleared when the connection is disconnected.

#### Actual behaviour

The cache clearing data method is used incorrectly, resulting in the data not being cleared, should use the `invalidateAll()` method.
```
advInvReceive.cleanUp();
advInvSpread.cleanUp();
advInvRequest.clear();
syncBlockIdCache.cleanUp();
```",general: general performance degradation,CWE-401,Missing Release of Memory after Effective Lifetime,"The bug report describes a situation where cache data is not cleared when a network connection is terminated. A cache is a software component that uses memory to store data. The failure to clear this cache means the memory it occupies is not freed after it's no longer needed (i.e., after its 'effective lifetime'). This directly aligns with the definition of CWE-401, 'Missing Release of Memory after Effective Lifetime', which states that the product does not release allocated memory after it has been used. The reported symptom of 'general performance degradation' is a classic indicator of a memory leak. 

CWE-404, 'Improper Resource Shutdown or Release', is a plausible but less specific choice. While memory is a resource and it is being improperly released, CWE-401 is more precise because it specifically addresses memory, which is the exact resource at issue in a cache leak. 

CWE-400, 'Uncontrolled Resource Consumption', is less accurate because the primary issue described is not the uncontrolled *allocation* of a resource, but the failure to *release* it during a cleanup phase (connection termination). Therefore, CWE-401 is the single most accurate classification.",closed,"The cache clearing data method is used incorrectly, specifically by not utilizing the appropriate `invalidateAll()` method to clear the cache upon connection termination.","Failure to clear the cache data when connections are terminated could lead to outdated or sensitive data being retained, potentially causing inconsistencies, security vulnerabilities, or unauthorized access to stale data.",2122723533,5720,"February 7, 2024 10:42 AM (GMT+8)","February 22, 2024 11:13 AM (GMT+8)",['type:bug'],
java-tron,RocksDBException: While opendir: xxx: Too many open files  on Mac,https://github.com/tronprotocol/java-tron/issues/5716,Storage,"#### System information

OS: Mac OS X
JVM: Oracle Corporation 1.8.0_321 x86_64
Version: 4.7.3.1

```bash
ulimit -a
```
```
-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8176
-c: core file size (blocks)         0
-v: address space (kbytes)          unlimited
-l: locked-in-memory size (kbytes)  unlimited
-u: processes                       2666
-n: file descriptors                256
```
```bash
 lsof -p pid | wc -l 
```
```
output: 10287
```

#### Expected behaviour

Normal synchronization of blocks on Mac using RocksDB.

#### Actual behaviour

After running for a while, the block stops synchronizing after an error of `Too many open files`.

#### Steps to reproduce the behaviour

Use RocksDB on Mac to start the node.

#### Backtrace

````
16:55:00.757 ERROR [sync-handle-block] [DB](RocksDbDataSourceImpl.java:273) Open Database checkpoint/1706604900706 failed
org.rocksdb.RocksDBException: While opendir: output-directory/database/checkpoint/1706604900706: Too many open files
	at org.rocksdb.RocksDB.open(Native Method)
	at org.rocksdb.RocksDB.open(RocksDB.java:231)
	at org.tron.common.storage.rocksdb.RocksDbDataSourceImpl.initDB(RocksDbDataSourceImpl.java:267)
	at org.tron.common.storage.rocksdb.RocksDbDataSourceImpl.initDB(RocksDbDataSourceImpl.java:199)
	at org.tron.common.storage.rocksdb.RocksDbDataSourceImpl.<init>(RocksDbDataSourceImpl.java:72)
	at org.tron.core.db.TronDatabase.<init>(TronDatabase.java:55)
	at org.tron.core.store.CheckPointV2Store.<init>(CheckPointV2Store.java:18)
	at org.tron.core.db2.core.SnapshotManager.getCheckpointDB(SnapshotManager.java:430)
	at org.tron.core.db2.core.SnapshotManager.createCheckpoint(SnapshotManager.java:408)
	at org.tron.core.db2.core.SnapshotManager.flush(SnapshotManager.java:357)
	at org.tron.core.db2.core.SnapshotManager.buildSession(SnapshotManager.java:144)
	at org.tron.core.db2.core.SnapshotManager.buildSession(SnapshotManager.java:127)
	at org.tron.core.db.Manager.pushBlock(Manager.java:1310)
````

There isn't a configuration to change rocksdb's maxOpenFiles, which is currently fixed at 5000. It is recommended to add the configuration.
",storage: storage persistence failure,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a situation where an application, after running for some time, crashes with a `Too many open files` error. The provided `lsof` command output shows that the process has 10,287 open files, which far exceeds the operating system's configured limit of 256 file descriptors (`ulimit -n: file descriptors 256`). This is a classic symptom of a resource leak, specifically of file descriptors. The application is acquiring file handles but is not closing them when they are no longer needed. Over time, the pool of available file descriptors is exhausted, and subsequent attempts to open new files fail.

- **CWE-770 (Allocation of Resources Without Limits or Throttling)** is not the best fit. This CWE applies when there are no restrictions on resource allocation. In this case, there is a clear limit imposed by the operating system (`ulimit -n 256`), and the application is crashing because it hits this limit. The problem is not a lack of limits, but how the application manages the resources within those limits.

- **CWE-400 (Uncontrolled Resource Consumption)** is a plausible, but general, classification. The application is indeed consuming a resource (file descriptors) in an uncontrolled manner, leading to exhaustion. However, this is a high-level category.

- **CWE-404 (Improper Resource Shutdown or Release)** is the most accurate and specific description of the issue. The accumulation of a large number of open files strongly indicates that the application is not properly releasing or closing file handles after they have been used. This failure to release the resource is the direct cause of the resource exhaustion. Therefore, CWE-404 is more precise than the broader CWE-400 as it points to the specific cause of the uncontrolled consumption.",closed,"The application is hitting the system limit on the number of open file descriptors (256). This is caused by RocksDB's default limit on the maximum number of open files (5000), and the application is exceeding this limit when trying to open multiple files simultaneously.","This bug can lead to the failure of block synchronization, causing the application to stop functioning properly. It may result in data loss or inconsistency if not managed, and it could prevent the system from processing transactions effectively.",2109576417,5716,"January 31, 2024 8:43 AM (GMT+8)","March 20, 2024 7:44 PM (GMT+8)","['type:bug', 'good first issue', 'area:db', 'RocksDB']",
java-tron,prune Lite Fullnode data error: data not found in store,https://github.com/tronprotocol/java-tron/issues/5656,Utilities,"I use Toolkit pruning Lite Fullnode data regularly.

#### Expected behaviour

It can be executed normally.

#### Actual behaviour

The command sometimes quits abnormally.


#### Steps to reproduce the behaviour


#### Backtrace

````
Start create snapshot.
Begin to split the dbs.
Begin to merge checkpoint to dataset.
Begin to fill 65536 block, genesis block and trans to snapshot.
fillBlockAndTrans  99% │███████████████████████████████████████████▉│ 65522/65536 (0:01:34 / 0:00:00)
data not found in store, dbName: block-index, key: [0, 0, 0, 0, 3, 64, -96, 32]
Usage: <main class> db lite [-h] -ds=<datasetPath> -fn=<fnDataPath>
                            [-o=<operate>] [-t=<type>]
Split lite data for java-tron.
      -ds, --dataset-path=<datasetPath>
                            when operation is `split`,`dataset-path` is the
                              path that store the `snapshot` or `history`,when
                              operation is `split`,`dataset-path` is the
                              `history` data path.
      -fn, --fn-data-path=<fnDataPath>
                            the database path to be split or merged.
  -h, --help
  -o, --operate=<operate>   operate: [ split, merge ]. Default: split
  -t, --type=<type>         only used with operate=split: [ snapshot, history
                              ]. Default: snapshot
Exit Codes:
  0   Successful
  1   Internal error: exception occurred,please check toolkit.log
````
",general: incorrect tooling output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a tool that fails intermittently (the report states it ""sometimes quits abnormally""). This intermittent behavior is a classic symptom of a race condition. The tool is performing complex database operations like splitting and merging, which are likely to involve concurrent threads or processes accessing a shared resource (the database store). The specific error, ""data not found in store"", is a plausible result of a race condition where one thread attempts to access data that another thread has already deleted or has not yet written due to a timing issue. Therefore, CWE-362 ('Race Condition') is the most fitting classification as it points to the likely root cause of the intermittent failure.

CWE-476 ('NULL Pointer Dereference') is not a good fit because the error message is ""data not found in store"", not a null pointer exception. While a failed lookup could lead to a null value, the reported error is the lookup failure itself, not a subsequent dereference.

CWE-755 ('Improper Handling of Exceptional Conditions') is a possible but less precise fit. An exceptional condition does occur (data not found), and the program terminates. However, this CWE describes the program's *reaction* to the problem rather than the underlying *cause*. The core issue is not that the program terminates on an error, but that the error state (missing data that should be present) occurs in the first place. CWE-362 provides a stronger explanation for why this exceptional condition arises intermittently.",closed,"The bug occurs due to the failure to validate whether the required data (block-index) exists in the storage before attempting to access it, resulting in an error when data is not found.","This bug can lead to data loss during the process of pruning Lite Fullnode data, causing the application to crash unexpectedly. Users may lose access to important blockchain data and face disruptions in their operations.",2071991594,5656,"January 9, 2024 9:39 AM (GMT+8)","January 11, 2024 4:32 PM (GMT+8)",['type:bug'],
go-ethereum,getLogs should raise pruned history error for block number 0,https://github.com/ethereum/go-ethereum/issues/31939,API,"When querying logs in a pruned node:

```
> eth.getLogs({ fromBlock: '0x0', toBlock: 'latest' })
Error: failed to get logs for block #0 (0xd4e567..cb8fa3)
        at web3.js:6386:9(39)
        at send (web3.js:5115:62(29))
        at <eval>:1:12(7)

> eth.getLogs({ fromBlock: '0x1', toBlock: 'latest' })
Error: pruned history unavailable
        at web3.js:6386:9(39)
        at send (web3.js:5115:62(29))
        at <eval>:1:12(7)
```

It means getLogs somehow sees block 0 as special and doesn't do the pruned history check properly on it. I guess it was because 0 was the special block number for the ""earliest"" tag.
",api: incorrect api output,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report describes a situation where the `getLogs` function handles a query for block `0` differently than for other blocks on a pruned node. A pruned node represents an exceptional state for a historical query. The function correctly identifies this exceptional condition and returns a 'pruned history unavailable' error for block `1`. However, for block `0`, it fails to perform this check correctly, returning a more generic error. This is a direct example of an incorrect check for an exceptional condition. The code has a special path for the input `0` (likely because it can also mean 'earliest'), and in this path, the check for the 'pruned node' condition is flawed. 

CWE-20 (Improper Input Validation) is less accurate because the input `0` is technically valid. The issue is not with the input's format or value itself, but with the program's failure to handle a specific system state (an exceptional condition) when processing that valid input. 

CWE-436 (Interpretation Conflict) is incorrect because the issue is an internal logic flaw within a single software component, not a misinterpretation of state or input between two different products.",closed,"The getLogs function fails to properly handle the block number 0 when querying logs, treating it as a special case without correctly applying the pruned history check.","This bug can lead to incorrect error handling when accessing logs from a pruned node, potentially causing confusion for users and disrupting the expected functionality of the API.",3103490466,31939,"May 30, 2025 3:02 PM (GMT+8)","June 3, 2025 11:14 PM (GMT+8)","['type:bug', 'help wanted']",
go-ethereum,blsync issue mainnet,https://github.com/ethereum/go-ethereum/issues/31814,Consensus,"#### System information

Geth version: `v1.15.11`
CL client & version: `blsync`
OS & Version: Linux

Keep getting this error and the client is not syncing

```
May 12 16:33:13 ip- geth[593]: WARN [05-12|16:33:13.123] Served engine_newPayloadV4               reqid=41 duration=1.659812ms  err=""invalid argument 3: json: cannot unmarshal hex string without 0x prefix into Go value of type hexutil.Bytes""
May 12 16:33:13 ip-  geth[593]: ERROR[05-12|16:33:13.123] Failed NewPayload                        number=22,468,409 hash=9acb83..c8ce2f error=""invalid argument 3: json: cannot unmarshal hex string without 0x prefix into Go value of type hexutil.Bytes""

```


additional info
Here is the payload
```
May 12 17:27:26 ip- geth[2902]: WARN [05-12|17:27:26.545] Served engine_newPayloadV4               reqid=49 duration=5.170625ms err=""invalid argument 3: json: cannot unmarshal hex string without 0x prefix into Go value of type hexutil.Bytes""
May 12 17:27:26 ip- geth[2902]: ERROR[05-12|17:27:26.545]  Payload   engine_newPayloadV4=""[0xc00a5a11e0 [] 0x59935e925e07287827d0c9139f9f45612cf88b38797fde1d7f3d3b4109f97233 [[0 141 30 173 218 15 137 103 95 108 31 185 180 109 109 157 46 90 193 142 24 187 135 214 222 226 245 225 22 89 204 126 113 138 190 128 71 98 93 227 140 207 227 38 162 31 46 35 35 1 0 0 0 0 0 0 0 0 0 0 0 142 96 154 200 15 67 36 228 153 166 239 210 79 34 26 44 170 134 130 36 0 64 89 115 7 0 0 0 177 172 175 179 86 12 21 134 41 6 142 241 94 157 118 129 169 24 146 42 247 29 65 81 40 195 205 119 83 77 211 92 110 183 205 104 146 248 17 203 203 97 32 110 220 19 67 254 14 128 6 159 135 101 174 163 26 185 105 205 78 109 155 114 81 11 200 143 34 157 57 115 167 34 30 217 247 211 140 169 117 126 104 151 49 108 143 105 119 19 245 144 25 183 2 37 71 91 31 0 0 0 0 0]]]""
May 12 17:27:26 ip- geth[2902]: ERROR[05-12|17:27:26.546] Failed NewPayload                        number=22,468,674 hash=c541ea..1ec500 error=""invalid argument 3: json: cannot unmarshal hex string without 0x prefix into Go value of type hexutil.Bytes 
May 12 17:27:26 ip- geth[2902]: WARN [05-12|17:27:26.546] Forkchoice requested unknown head        hash=c541ea..1ec500
May 12 17:27:26 ip- geth[2902]: INFO [05-12|17:27:26.546] Successful ForkchoiceUpdated             head=c541ea..1ec500 status=SYNCING

```

seems like it errors when 
`params = append(params, blobHashes, parentBeaconRoot, event.ExecRequests)`
`event.ExecRequests` has any values


My janky fix

![Image](https://github.com/user-attachments/assets/60c049e3-87b1-483f-9650-73e3b70ea6cd)

I would make a PR but I dont believe this is the right way to fix it ",consensus: consensus liveness failure,CWE-1389,Incorrect Parsing of Numbers with Different Radices,"The bug report's core issue is an error message: `json: cannot unmarshal hex string without 0x prefix into Go value of type hexutil.Bytes`. This error explicitly states that a component is failing to parse a string that is intended to be a hexadecimal number because it is missing the standard `0x` prefix. This is a direct instance of a problem with interpreting a number in a specific, non-decimal base (radix).

- **CWE-1389 (Incorrect Parsing of Numbers with Different Radices)** is the most accurate choice. Its description, `The product parses numeric input assuming base 10 (decimal) values, but it does not account for inputs that use a different base number (radix)`, directly addresses the problem. In this case, the parser *does* expect a different radix (hexadecimal), but it fails because the input string's format doesn't meet the parser's requirements for identifying that radix (the missing `0x` prefix). This is a specific failure in handling the representation of a non-decimal number.

- **CWE-20 (Improper Input Validation)** is a plausible but overly general classification. While the root cause is indeed malformed input from one component to another, CWE-1389 describes the *specific nature* of that invalid input with much greater precision. Best practice is to choose the most specific CWE that applies.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions)** is not the best fit. The system correctly identifies the parsing failure as an exceptional condition and handles it by logging an error and failing the operation (`Failed NewPayload`). The bug is not in the handling of the exception, but in the data that caused the exception in the first place.",closed,"The error occurs because the `event.ExecRequests` does not have the expected format, specifically a hex string without the '0x' prefix, which is required for proper unmarshalling into the Go type `hexutil.Bytes`.","This bug prevents the client from syncing properly, which can lead to nodes not being able to participate in the network consensus and ultimately affect the overall reliability and performance of the blockchain.",3057530385,31814,"May 12, 2025 4:36 PM (GMT+8)","May 13, 2025 6:21 PM (GMT+8)",['type:bug'],
go-ethereum,blobpool: proper error message for blob transactions with too many blobs,https://github.com/ethereum/go-ethereum/issues/31792,Consensus,"#### System information

Geth version: `v1.15.11`
CL client & version: `lighthouse@v7.0.1`
OS & Version: Linux

#### Expected behaviour

Should be able to submit a transaction carrying 9 blobs.


#### Actual behaviour

Running into this error:
```
oversized data: transaction size 1181120, limit 1048576
```

Here it says blob is not included in this size check.

https://github.com/ethereum/go-ethereum/blob/0db99f4e409b05c109cffac26c15dd641757a3ab/core/txpool/blobpool/blobpool.go#L58-L63

However, here we consider the blobs, which results in the issue above.

https://github.com/ethereum/go-ethereum/blob/0db99f4e409b05c109cffac26c15dd641757a3ab/core/txpool/validation.go#L68-L70

https://github.com/ethereum/go-ethereum/blob/0db99f4e409b05c109cffac26c15dd641757a3ab/core/types/transaction.go#L563-L567


#### Steps to reproduce the behaviour

TBA


#### Backtrace

N/A
",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report details an issue where a transaction's size is calculated incorrectly. Specifically, the size of attached blobs is included in a general transaction size check, causing the transaction to exceed a limit it should not be subject to. This directly aligns with CWE-682's definition: 'The product performs a calculation that generates incorrect or unintended results that are later used in security-critical decisions or resource management.' The incorrect size calculation leads to a resource management decision: rejecting a valid transaction from the pool. CWE-20 (Improper Input Validation) is less precise; while the validation is improper, it's specifically due to a flawed calculation, making CWE-682 the more specific and accurate choice. CWE-436 (Interpretation Conflict) is not applicable because the conflict is internal to a single product (Geth), not between two separate products (Product A and Product B) as the definition specifies.",closed,"The transaction validation logic does not properly account for the size of blob data when calculating the total transaction size, leading to an oversized transaction error when submitting transactions with multiple blobs.","Users are unable to submit transactions that exceed the defined size limit due to the oversight in blob size inclusion, potentially disrupting normal transaction processing and user experience.",3051991856,31792,"May 9, 2025 12:16 PM (GMT+8)","May 22, 2025 5:30 PM (GMT+8)",['type:bug'],
go-ethereum,Extra `witness` field in `engine_forkchoiceUpdatedV3` response,https://github.com/ethereum/go-ethereum/issues/31737,API,"#### Overview

Hello developers.

I'm running an Ethereum mainnet node using geth-1.15.9 and Prysm-6.0.0, as well as a separate testnet chain for API testing. While testing, I noticed that the JSON-RPC responses of `engine_forkchoiceUpdatedV3` from geth, besu, nethermind, and reth diverge.

According to the [execution-api](https://ethereum.github.io/execution-apis/api-documentation/), `payloadStatus` is expected to return `latestValidHash`, `status`, and `validationError`. However, Geth includes an additional `witness` field in its response.


#### System information

Geth version: geth version 1.15.9-stable-74165a8f
CL client & version: e.g. Prysm/v6.0.0 (linux amd64)
OS & Version: Ubuntu 20.04

#### Expected behaviour

Return only three attributes as other clients.

#### Actual behaviour

```json
# geth
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null, ""witness"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null, ""witness"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null, ""witness"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null, ""witness"": null}}}
# besu
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
# nethermind
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
# reth
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}
{""id"": 1, ""jsonrpc"": ""2.0"", ""result"": {""payloadId"": null, ""payloadStatus"": {""latestValidHash"": null, ""status"": ""SYNCING"", ""validationError"": null}}}

```

#### Steps to reproduce the behaviour

Expost engine api and call `engine_forkchoiceUpdatedV3`:

```shell
curl localhost:port-X POST -H ""Content-Type: application/json"" -d '{""id"":1,""jsonrpc"":""2.0"",""method"":""engine_forkchoiceUpdatedV3"",""params"":[{""headBlockHash"":""0x3559e851470f6e7bbed1db474980683e8c315bfce99b2a6ef47c057c04de7858"",""safeBlockHash"":""0x3559e851470f6e7bbed1db474980683e8c315bfce99b2a6ef47c057c04de7858"",""finalizedBlockHash"":""0x3b8fb240d288781d4aac94d3fd16809ee413bc99294a085798a589dae51ddd4a""},{""timestamp"":""0x64e7785b"",""prevRandao"":""0xc130d5e63c61c935f6089e61140ca9136172677cf6aa5800dcc1cf0a02152a14"",""suggestedFeeRecipient"":""0xa94f5374fce5edbc8e2a8697c15331677e6ebf0b"",""withdrawals"":[{""index"":""0xf0"",""validatorIndex"":""0xf0"",""address"":""0x00000000000000000000000000000000000010f0"",""amount"":""0x1""},{""index"":""0xf1"",""validatorIndex"":""0xf1"",""address"":""0x00000000000000000000000000000000000010f1"",""amount"":""0x1""}],""parentBeaconBlockRoot"":""0x11f780a954bcba8889998e4e61deaae6388dd2391e9c810bd9c94962cc1eadc1""}]}' | jq

```

#### Backtrace

Spec in [execution-apis](https://github.com/ethereum/execution-apis/blob/5d634063ccfd897a6974ea589c00e2c1d889abc9/src/engine/openrpc/schemas/payload.yaml#L22-L35).

```yaml
RestrictedPayloadStatusV1:
  $ref: '#/components/schemas/PayloadStatusV1'
  properties:
    status:
      $ref: '#/components/schemas/PayloadStatusV1/properties/status'
      description: Set of possible values is restricted to VALID, INVALID, SYNCING
      enum:
        - VALID
        - INVALID
        - SYNCING
    latestValidHash:
      $ref: '#/components/schemas/PayloadStatusV1/properties/latestValidHash'
    validationError:
      $ref: '#/components/schemas/PayloadStatusV1/properties/validationError'
```

Related implementations at:
https://github.com/ethereum/go-ethereum/blob/a511553e448c947a0fe8f34acf7bb6f9818c2b49/beacon/engine/types.go#L132-L137",api: incorrect api output,CWE-1068,Inconsistency Between Implementation and Documented Design,"The bug report describes a situation where the `geth` client's implementation of the `engine_forkchoiceUpdatedV3` API method produces a response that includes an extra field, `witness`. The report explicitly contrasts this behavior with the official `execution-api` specification, which does not include this field in the documented schema for the response. This is a direct example of CWE-1068, where the product's implementation is inconsistent with its documented design. The bug report provides the specification as evidence of the documented design and the JSON output from `geth` as evidence of the inconsistent implementation.

CWE-204 (Observable Response Discrepancy) is less suitable because the core issue is not that the discrepancy reveals sensitive internal state information, but rather that the response format is incorrect according to the specification. The bug report makes no claim of information leakage.

CWE-436 (Interpretation Conflict) is also not the best fit. While a client parsing this non-standard response might encounter an interpretation conflict, the root weakness is within the `geth` product itself—its failure to adhere to the documented API contract. CWE-1068 addresses this root cause directly, whereas CWE-436 would describe a potential consequence of this weakness in a multi-component system.",closed,"The Geth client is returning an extra `witness` field in the JSON-RPC response for the `engine_forkchoiceUpdatedV3` method, which diverges from the expected API specification outlined in the execution API documentation.","This discrepancy can lead to inconsistencies and potential compatibility issues between different Ethereum clients, as other clients do not include the `witness` field. It may cause confusion for developers relying on a standardized response format, affecting the integration and functioning of applications built on top of the Ethereum network.",3027572535,31737,"April 29, 2025 8:58 AM (GMT+8)","April 29, 2025 7:21 PM (GMT+8)",['type:bug'],
go-ethereum,Node stuck / indexer stuck / goroutine leak,https://github.com/ethereum/go-ethereum/issues/31732,Consensus,"#### System information
amd 5950x
128GB ram
7TB NVME

Geth version: V.1.15.10
CL client & version: Prysm
OS & Version: Ubuntu 22.04

I'm running Etgereum  RPC node with Geth  since 3 years without any issue.
My node stop to sync and loose connexion with prysm if it receive lots of `GetTransaction ` request

I have not such problem with Geth V.1.15.5 ( after several tests)

logs:
GETH
```Apr 27 03:10:05 Ubuntu-2204-jammy-amd64-base bash[3592775]: WARN [04-27|03:10:05.226] Served eth_call                          conn=185.240.242.120:54568 req>
Apr 27 03:10:13 Ubuntu-2204-jammy-amd64-base bash[3592775]: INFO [04-27|03:10:13.247] Imported new potential chain segment     number=22,357,008 hash=820d85.>
Apr 27 03:10:13 Ubuntu-2204-jammy-amd64-base bash[3592775]: INFO [04-27|03:10:13.336] Chain reorg detected                     number=22,357,007 hash=1d3216.>
Apr 27 03:12:33 Ubuntu-2204-jammy-amd64-base bash[3592775]: WARN [04-27|03:12:33.065] Beacon client online, but no consensus updates received in a while. Ple>
``` 
PRYSM
```Apr 27 03:10:21 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:21"" level=info msg=""Chain reorg occurred"" commonAncestorRoot=0x96104a0>
Apr 27 03:10:21 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:21"" level=info msg=""Synced new block"" block=0x2122dc91... epoch=361698>
Apr 27 03:10:21 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:21"" level=info msg=""Finished applying state transition"" attestations=1>
Apr 27 03:10:23 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:23"" level=info msg=""Attempted late block reorg aborted due to attestat>
Apr 27 03:10:31 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:31"" level=error msg=""received an undefined execution engine error"" err>
Apr 27 03:10:31 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:31"" level=info msg=""Chain reorg occurred"" commonAncestorRoot=0x96104a0>
Apr 27 03:10:35 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:35"" level=info msg=""Attempted late block reorg aborted due to attestat>
Apr 27 03:10:43 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:43"" level=error msg=""received an undefined execution engine error"" err>
Apr 27 03:10:43 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:43"" level=info msg=""Chain reorg occurred"" commonAncestorRoot=0x96104a0>
Apr 27 03:10:43 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:10:43"" level=error msg=""Could not handle p2p pubsub"" error=""could not not>
Apr 27 03:14:16 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:14:16"" level=info msg=""Connected peers"" inboundQUIC=57 inboundTCP=21 outb>
Apr 27 03:15:00 Ubuntu-2204-jammy-amd64-base prysm.sh[3562493]: time=""2025-04-27 01:15:00"" level=warning msg=""Execution client is not syncing"" prefix=executi>
```
once they lost connexion, node stop to syncing.
service not crashing, but geth not communicate with prysm anymore.

```goroutine.prof | head -n 30
File: geth
Type: goroutine
Time: 2025-04-28 00:58:34 CEST
Showing nodes accounting for 225821, 100% of 225824 total
Dropped 229 nodes (cum <= 1129)
      flat  flat%   sum%        cum   cum%
    225821   100%   100%     225821   100%  runtime.gopark
         0     0%   100%     224926 99.60%  github.com/ethereum/go-ethereum/core.(*BlockChain).GetTransactionLookup
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/core.(*BlockChain).TxIndexProgress (inline)
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/core.(*txIndexer).txIndexProgress (inline)
         0     0%   100%     224926 99.60%  github.com/ethereum/go-ethereum/eth.(*EthAPIBackend).GetTransaction
         0     0%   100%     224916 99.60%  github.com/ethereum/go-ethereum/internal/ethapi.(*TransactionAPI).GetTransactionByHash
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*callback).call
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).handleCall
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).handleCallMsg
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).handleMsg.func1.1
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).handleNonBatchCall
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).runMethod
         0     0%   100%     224928 99.60%  github.com/ethereum/go-ethereum/rpc.(*handler).startCallProc.func1
         0     0%   100%     224928 99.60%  reflect.Value.Call
         0     0%   100%     224928 99.60%  reflect.Value.call
         0     0%   100%     225650 99.92%  runtime.selectgo
```
My start command: 
```
./geth --config ./config.toml --datadir ./mainnet  --cache=20000 --state.scheme=path --rpc.allow-unprotected-txs --history.transactions=0 --http --http.port 18545 --ws.port 18546 --rpc.txfeecap=0 --http.addr 0.0.0.0 --http.api eth,net,web3,txpool  --ws --http.corsdomain '*' --ws.addr 0.0.0.0 --ws.origins '*' --ws.api eth,net,web3,txpool --syncmode=snap --authrpc.addr localhost --authrpc.port 8551 --authrpc.vhosts localhost --authrpc.jwtsecret /home/eth/mainnet/geth/jwtsecret  --metrics  --metrics.addr 0.0.0.0 --metrics.port 6060  --vmodule=""rpc=5"" --pprof --pprof.addr 0.0.0.0 --pprof.port 6065 --pprof.memprofilerate 1 --pprof.blockprofilerate 1 --pprof.cpuprofile cpu.pprof
```

we can see on the left of the grafana screenshot the high go routine peak .
- every goroutine drop is when i restart eth becasue it was stuck
- drawed blue arrow is when i downgraded to geth v.1.15.5  and had no issue anymore.

![Image](https://github.com/user-attachments/assets/8ccdd9ff-e05c-4f04-b78f-8253afcb2ea3)

",consensus: consensus liveness failure,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a condition where the application becomes unresponsive and stops syncing due to a ""goroutine leak"" triggered by a high volume of `GetTransaction` requests. The provided `goroutine.prof` output is the key piece of evidence, showing a massive number of goroutines (over 225,000) stuck in the `runtime.gopark` state. The call stack for these goroutines originates from handling RPC requests for `GetTransaction`. This indicates that resources (goroutines) are being allocated to handle requests but are not being properly terminated or released upon completion, causing them to accumulate over time and exhaust system resources, leading to a denial of service.

- **CWE-404 (Improper Resource Shutdown or Release)** is the most accurate fit. The term ""goroutine leak"" directly corresponds to this weakness. The goroutines are the resource, and the profiling data shows they are not being released, leading to their accumulation. The bug is in the lifecycle management of the resource, where the shutdown/release step is failing.

- **CWE-770 (Allocation of Resources Without Limits or Throttling)** is a plausible but less precise fit. While the problem is triggered by ""lots of"" requests, suggesting a lack of throttling, the core issue is not simply the allocation but the failure to deallocate. Even with throttling, if each goroutine still leaks, the system would eventually fail, just more slowly. The fundamental flaw is the leak itself, which is best described by CWE-404.

- **CWE-400 (Uncontrolled Resource Consumption)** is a general, high-level category that describes the overall symptom. While correct, CWE-404 is more specific because it identifies the root cause of the uncontrolled consumption: the failure to release resources. Therefore, CWE-404 is the more precise and appropriate classification.",closed,"The Geth node experiences a goroutine leak when it receives a high volume of 'GetTransaction' requests, leading to the node becoming unresponsive and losing connection with the Prysm client.","The node becomes stuck and stops syncing, causing a potential loss of data and inability to process transactions, which can disrupt the operation of applications relying on the Ethereum network.",3025467608,31732,"April 28, 2025 4:14 PM (GMT+8)","May 5, 2025 10:07 AM (GMT+8)","['type:bug', 'status:triage']",
go-ethereum,failed to process log index epoch 270: failed to retrieve log at index 18122937602,https://github.com/ethereum/go-ethereum/issues/31729,Storage,"#### System information

Geth version: `1.15.10`
CL client & version: lodestar 1.29.0
OS & Version: linux + docker
Commit hash : N/A

#### Expected behaviour


#### Actual behaviour


#### Steps to reproduce the behaviour
Updated from 1.15.6 to 1.15.10 and ~10 hours later I start getting the following messages.

#### Backtrace

````
... (ALL GOOD)
INFO [04-25|22:05:13.265] Imported new potential chain segment     number=22,348,907 hash=69b737..5b1489 blocks=1   txs=185     mgas=18.382   elapsed=367.542ms    mgasps=50.012  snapdiffs=9.29MiB   triediffs=217.65MiB triedirty=69.07MiB
INFO [04-25|22:05:13.410] Chain head was updated                   number=22,348,907 hash=69b737..5b1489 root=b8d362..6957e9 elapsed=5.92321ms
INFO [04-25|22:05:26.081] Imported new potential chain segment     number=22,348,908 hash=397327..a09a93 blocks=1   txs=151     mgas=14.153   elapsed=181.582ms    mgasps=77.941  snapdiffs=9.33MiB   triediffs=217.38MiB triedirty=69.49MiB
INFO [04-25|22:05:26.223] Chain head was updated                   number=22,348,908 hash=397327..a09a93 root=a498da..c1489e elapsed=4.772658ms
INFO [04-25|22:05:37.575] Imported new potential chain segment     number=22,348,909 hash=fc4957..1b404d blocks=1   txs=210     mgas=24.776   elapsed=686.373ms    mgasps=36.097  snapdiffs=9.37MiB   triediffs=217.16MiB triedirty=69.96MiB
INFO [04-25|22:05:37.695] Chain head was updated                   number=22,348,909 hash=fc4957..1b404d root=049a34..c2f6c5 elapsed=7.018634ms
WARN [04-25|22:05:46.016] Served eth_getLogs                       conn=172.18.0.3:52044 reqid=11052339 duration=1.370535039s err=""failed to process log index epoch 270: failed to retrieve log at index 18122937602: failed to retrieve log value pointer of block 22323558 while binary searching log value index 18122937602: failed to retrieve log value pointer of block 22323558: pebble: not found""
WARN [04-25|22:05:48.466] Served eth_getLogs                       conn=172.18.0.3:52044 reqid=11052341 duration=1.357920462s err=""failed to process log index epoch 270: failed to retrieve log at index 18122937602: failed to retrieve log value pointer of block 22323558 while binary searching log value index 18122937602: failed to retrieve log value pointer of block 22323558: pebble: not found""
INFO [04-25|22:05:49.249] Imported new potential chain segment     number=22,348,910 hash=01a691..771a1b blocks=1   txs=164     mgas=18.495   elapsed=307.970ms    mgasps=60.055  snapdiffs=9.42MiB   triediffs=216.75MiB triedirty=70.46MiB
INFO [04-25|22:05:49.363] Chain head was updated                   number=22,348,910 hash=01a691..771a1b root=fcf438..1acd1c elapsed=5.283277ms
WARN [04-25|22:05:49.447] Blob transaction swapped out by signer   from=0x479B7c95b9509E1A834C994fc94e3581aA8A73B9 nonce=861     id=536,870,913
WARN [04-25|22:05:51.028] Served eth_getLogs                       conn=172.18.0.3:52044 reqid=11052343 duration=1.541003981s err=""failed to process log index epoch 270: failed to retrieve log at index 18122937602: failed to retrieve log value pointer of block 22323558 while binary searching log value index 18122937602: failed to retrieve log value pointer of block 22323558: pebble: not found""
WARN [04-25|22:05:53.436] Served eth_getLogs                       conn=172.18.0.3:52044 reqid=11052345 duration=1.404113283s err=""failed to process log index epoch 270: failed to retrieve log at index 18122937602: failed to retrieve log value pointer of block 22323558 while binary searching log value index 18122937602: failed to retrieve log value pointer of block 22323558: pebble: not found""
````

Looks like a fried DB, but no shutdown has occurred. ",api: api unavailability,CWE-754,Improper Check for Unusual or Exceptional Conditions,"The bug report's key evidence is the recurring error message: `err=""failed to process log index epoch 270: failed to retrieve log at index 18122937602: failed to retrieve log value pointer of block 22323558 ... pebble: not found""`. This message explicitly states that the program failed while attempting to retrieve a 'log value pointer'. The database backend ('pebble') reports 'not found', indicating that the pointer did not lead to a valid, existing data entry.

- **CWE-824 (Access of Uninitialized Pointer):** This is the best fit. The official description is 'The product accesses or uses a pointer that has not been initialized.' The error log shows the program attempting to use a pointer to retrieve a log value, but this operation fails because the pointer does not resolve to a valid location in the database. This is a direct match for the weakness described by CWE-824, where a pointer is used that does not point to a valid, initialized resource.

- **CWE-130 (Improper Handling of Length Parameter Inconsistency):** This CWE is not applicable. The bug report and error logs do not mention any issues with parsing formatted messages, structures, or inconsistent length fields.

- **CWE-662 (Improper Synchronization):** While a synchronization issue could be the root cause of the database corruption that led to the invalid pointer state, it is not the weakness directly observed in the error log. The log shows the *result* of the potential underlying issue, which is the failed pointer access. Based *only* on the provided information, the most direct and accurate classification is the one that describes the immediate failure, which is the access of an invalid pointer.",closed,"The issue arises from the inability to retrieve a log value pointer from the database during a log retrieval operation, indicating potential corruption or mismanagement of the database, specifically with the log index.","This bug can lead to failures in retrieving important log data, which may affect the functionality of the application, hinder debugging efforts, and impact overall system reliability. If logs cannot be retrieved, it could prevent users from accessing crucial transaction information and impair the ability to audit or analyze blockchain activity.",3024119652,31729,"April 28, 2025 8:20 AM (GMT+8)","May 4, 2025 12:40 AM (GMT+8)",['type:bug'],
go-ethereum,RPC timeout issue 1.15.x,https://github.com/ethereum/go-ethereum/issues/31718,Consensus,"#### System information

Geth version: 1.15.10 (full node)
CL client & version: lighthouse v7.0
OS & Version: Linux

#### Expected behaviour
Similar RPC performance to 1.14

#### Actual behaviour
After upgrading from 1.14.13 to 1.15.9 (then 1.15.10) my app started having majority of RPC requests timeout.
My app subscribes to pending transactions and then for each received pending transaction hash calls eth_getTransactionByHash.
When I run this app it also causes other clients to timeout, including lighthouse and `eth.syncing` in geth attach.
If I stop pending transaction subscription timeouts persist for other clients until I restart geth.
CPU usage is elevated (geth uses 110-150% instead of 10-50%) while issue is occurring.
Nothing out of the normal in geth logs, if an eth_call request times out it is logged.
Lighthouse logs ""Error during execution engine upcheck""

I don't think I have any abnormal config, I have `TransactionHistory = 0`. Is there any other new options I've missed?",api: api unavailability,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a situation where a specific operation (subscribing to pending transactions) causes a massive and sustained increase in CPU usage, from a normal 10-50% to an abnormal 110-150%. This excessive CPU consumption directly leads to the primary reported issue: RPC requests timing out, effectively causing a denial of service for the API. This behavior is a textbook example of Uncontrolled Resource Consumption, where the limited resource is CPU time. The application fails to properly control its use of this resource under a specific workload, leading to system degradation.

CWE-835 ('Infinite Loop') is a plausible underlying cause for high CPU usage, but the bug report only describes the symptoms (high CPU, timeouts) and not the specific code-level fault. Classifying it as an infinite loop would be an assumption. CWE-400 is a more accurate and direct description of the observed phenomenon itself.

CWE-404 ('Improper Resource Shutdown or Release') is less fitting. While the issue persists after the trigger is stopped, suggesting a resource might not be released, the core problem described is the active and excessive *consumption* of CPU, not just the holding of a resource that causes blocking. The high CPU usage points directly to an active, uncontrolled process, which is the essence of CWE-400.",closed,"The RPC timeout issue appears to be caused by the upgrade from Geth version 1.14 to 1.15, which introduced changes in the handling of RPC requests, leading to increased CPU usage and timeouts for pending transactions.","This bug can lead to significant performance degradation in applications relying on RPC requests, causing timeouts and potentially affecting the overall functionality of the blockchain client, which can disrupt transaction processing and client synchronization.",3020521903,31718,"April 25, 2025 4:31 PM (GMT+8)","May 6, 2025 2:17 AM (GMT+8)","['type:bug', 'status:triage']",
go-ethereum,deadlock issue of v1.15.6 on eth_getLogs for filter & thus shutdown corruption,https://github.com/ethereum/go-ethereum/issues/31700,API,"#### System information
```

{""jsonrpc"":""2.0"",""id"":1,""result"":""Geth/v1.15.9-stable-74165a8f/linux-amd64/go1.24.2""}
```

#### Expected behaviour
can answer in reasonable time

#### Actual behaviour
slow ,timeout for 1minute, the same call can finish on geth 1.15.3 on some api provider / erigon3.0.2 returning immediately

#### Steps to reproduce the behaviour
```
 curl 0:8545 -X POST   -H ""Content-Type: application/json""   --data '{""method"":""eth_getLogs"",""params"":[{""fromBlock"":""0x154ce96"",""toBlock"":""0x154cefa"",""address"":""0x918778e825747a892b17C66fe7D24C618262867d""}],""id"":1,""jsonrpc"":""2.0""}'
```


#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them as text and not screenshots.
",api: api unavailability,CWE-833,Deadlock,"The bug report's title explicitly states ""deadlock issue"". The described behavior, where an API call becomes unresponsive and times out, is a classic symptom of a deadlock condition where multiple threads are blocked, each waiting for a resource held by another. The official definition of CWE-833, ""The product contains multiple threads or executable segments that are waiting for each other to release a necessary lock, resulting in deadlock,"" perfectly matches this scenario. CWE-662 (Improper Synchronization) is a broader category; while a deadlock is a form of improper synchronization, CWE-833 is more specific and thus more accurate given the details. CWE-400 (Uncontrolled Resource Consumption) is less suitable because the root cause described is a locking contention problem, not an issue of excessive resource allocation like memory or CPU, even though the end result is a denial of service.",closed,"The deadlock issue occurs in the handling of the `eth_getLogs` API call in version v1.15.6, leading to a situation where the process cannot proceed due to waiting on resources that are held by other processes.","This bug can lead to significant performance degradation, causing timeouts and making the API unresponsive, which can affect the user experience and reliability of applications relying on this API for log retrieval.",3015847480,31700,"April 24, 2025 3:42 AM (GMT+8)","April 25, 2025 5:57 PM (GMT+8)","['type:bug', 'status:triage']",
go-ethereum,Reports of debug_standardTraceBadBlockToFile not working,https://github.com/ethereum/go-ethereum/issues/31694,API,There have been reports that debug_standardTraceBadBlockToFile writes empty files when used on mainnet. We need to look into this. When an issue happens this method is useful for debugging.,api: api unavailability,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a function, `debug_standardTraceBadBlockToFile`, which is intended for debugging when an 'issue happens' or for a 'bad block'. This function is failing to perform its task, resulting in an empty file. The function's purpose is to operate under exceptional circumstances (a bad block or an issue). Its failure to produce the correct output is a direct example of incorrectly handling an exceptional condition. 

CWE-362 ('Race Condition') is not suitable because the report provides no information about concurrency, shared resources, or timing issues. 

CWE-252 ('Unchecked Return Value') could be a potential root cause for the failure, but this is an assumption about the implementation. The bug report itself describes the high-level symptom, which is the system's failure to behave correctly in an error state. 

CWE-755 ('Improper Handling of Exceptional Conditions') is the most accurate choice because it directly describes the observed problem: a feature designed to handle a specific exceptional state (a 'bad block') is not functioning correctly.",closed,"The method debug_standardTraceBadBlockToFile fails to handle certain conditions appropriately, leading to the creation of empty files instead of expected debug information.","Debugging efforts on the mainnet could be severely hindered, making it difficult for developers to identify and resolve issues, potentially leading to prolonged outages or undetected bugs.",3010990111,31694,"April 22, 2025 12:47 PM (GMT+8)","May 6, 2025 6:32 PM (GMT+8)",['type:bug'],
go-ethereum,Syncing a pruned node blew up,https://github.com/ethereum/go-ethereum/issues/31616,Consensus,"I synced a node on Sepolia with `--history.chain premerge` and it blew up. I can see that generating the snapshot hadn't yet finished (based on eta):

```
INFO [04-10|14:04:08.868] Aborting state snapshot generation       root=75bca9..46fd2e in=04c48c..aac29e at=20cfcb..18174d accounts=857,124              slots=4,993,293             st
orage=438.77MiB dangling=0 elapsed=40.380s eta=35m27.829s
INFO [04-10|14:04:08.869] Resuming state snapshot generation       root=ad7034..0aaf92 in=04c48c..aac29e at=20cfcb..18174d accounts=857,124              slots=4,993,293             st
orage=438.77MiB dangling=0 elapsed=40.381s eta=35m27.882s

INFO [04-10|14:04:08.873] Imported new chain segment               number=8,091,097 hash=f1826b..0ed21a blocks=15 txs=1662 mgas=215.905 elapsed=6.288s  mgasps=34.332 snapdiffs=270.83K
iB triediffs=112.29MiB triedirty=0.00B
INFO [04-10|14:04:08.873] Syncing: chain download in progress      synced=100.00% chain=411.78GiB  headers=8,091,097@3.66GiB    bodies=8,091,097@357.49GiB  receipts=8,091,097@50.63GiB
   eta=2.373ms

INFO [04-10|14:04:08.887] Snap sync complete, auto disabling
ERROR[04-10|14:04:08.889] Nil finalized block cannot evict old blobs
INFO [04-10|14:04:09.056] New local node record                    seq=1,744,277,683,313 id=575c86a9b7a61201 ip=18.133.228.252 udp=30303 tcp=30303
INFO [04-10|14:04:09.123] Syncing beacon headers                   downloaded=8,108,751 left=0         eta=0s
INFO [04-10|14:04:09.126] Disabled trie database due to state sync
ERROR[04-10|14:04:09.126] Unhandled trie error in Trie.Prove       err=""missing trie node 802f9e8531887e7f6cf9b21b45df62fe4ed8cb8866500dfce61177f06d61c7b8 (owner 04c48cbfd4ae7f91c65e0
6216394591b94554e27dd96bafc7cc61c1fb6aac29e) (path 0203070b0d09) layer stale""
ERROR[04-10|14:04:09.130] State snapshotter failed to iterate trie err=""missing trie node dcaf68d3acd690b08a059910e42b0154ff376f17ece9e0e470993c23e4cf6b72 (owner 04c48cbfd4ae7f91c65e0
6216394591b94554e27dd96bafc7cc61c1fb6aac29e) (path 02) layer stale""
WARN [04-10|14:04:09.155] Retrieved pivot header from local        number=8,091,035 hash=5c9a56..a2127e latest=8,091,099 oldest=8,091,098
INFO [04-10|14:04:09.157] Disabling direct-ancient mode            origin=8,091,034 ancient=8,090,990
INFO [04-10|14:04:09.157] Syncing: state healing in progress       accounts=52254@2.90MiB        slots=327,942@24.71MiB      codes=816@4.21MiB        nodes=1,219,448@294.43MiB pending
=1
WARN [04-10|14:04:09.163] Retrieved beacon headers from local      from=8,091,035 count=63
```

Also I noticed the sync cycle being restarted not long before this happened:

```
INFO [04-10|14:04:00.352] Resuming state snapshot generation       root=1dd785..164482 at=041bb0..f140cd accounts=738,404              slots=3,884,751             storage=342.89MiB da
ngling=0 elapsed=31.864s eta=32m33.801s
WARN [04-10|14:04:00.498] Ignoring payload while snap syncing      number=8,091,099 hash=78032d..e2c10f reason=""chain forked, ancestor: 8091098, hash: 0x32828f0d28dbd9cbb2626da68de1d8
59250f49b893521a379071117a8ae06ad4, want: 0x0d8afbeeaf1f4319398f42efede2a4c188e1b05fe532426a11085203a912c6dd""
INFO [04-10|14:04:00.526] Forkchoice requested sync to new head    number=8,091,099 hash=78032d..e2c10f finalized=8,091,022
INFO [04-10|14:04:00.526] Restarting sync cycle                    reason=""chain forked, ancestor: 8091098, hash: 0x32828f0d28dbd9cbb2626da68de1d859250f49b893521a379071117a8ae06ad4, w
ant: 0x0d8afbeeaf1f4319398f42efede2a4c188e1b05fe532426a11085203a912c6dd""
```

And when healing finished:

```
INFO [04-10|14:03:09.658] Syncing: state healing in progress       accounts=52254@2.90MiB        slots=327,942@24.71MiB      codes=816@4.21MiB        nodes=1,219,448@294.43MiB pending
=0
INFO [04-10|14:03:12.880] Syncing: chain download in progress      synced=99.90%  chain=411.34GiB  headers=8,082,621@3.65GiB    bodies=8,082,621@357.18GiB  receipts=8,082,621@50.51GiB
   eta=20.068s
INFO [04-10|14:03:12.960] Forkchoice requested sync to new head    number=8,091,096 hash=1fa074..f31aa1 finalized=8,091,022
INFO [04-10|14:03:20.915] Syncing: chain download in progress      synced=99.95%  chain=411.58GiB  headers=8,087,333@3.66GiB    bodies=8,087,333@357.35GiB  receipts=8,087,333@50.57GiB
   eta=8.908s
INFO [04-10|14:03:25.310] Forkchoice requested sync to new head    number=8,091,097 hash=f1826b..0ed21a finalized=8,091,022
INFO [04-10|14:03:28.436] Opened erastore                          datadir=/home/ubuntu/datadir-sepolia/geth/chaindata/ancient/state
INFO [04-10|14:03:28.478] Opened ancient database                  database=/home/ubuntu/datadir-sepolia/geth/chaindata/ancient/state readonly=false
INFO [04-10|14:03:28.482] Rebuilt trie database                    root=2dfb0a..810812
INFO [04-10|14:03:28.487] Rebuilding state snapshot
INFO [04-10|14:03:28.490] Committed new head block                 number=8,091,015 hash=a64497..455d83
INFO [04-10|14:03:28.490] Resuming state snapshot generation       root=2dfb0a..810812 accounts=0                    slots=0                     storage=0.00B   dangling=0 elapsed=1.9
13ms
```

Also seeing this error for the first time sometime earlier in the logs. It repeated every once in a while:

```
INFO [04-10|13:59:37.954] Syncing beacon headers                   downloaded=8,108,750 left=7,986,515 eta=4h19m0.522s
ERROR[04-10|13:59:37.954] Reject duplicated disable operation
INFO [04-10|13:59:42.406] Syncing: chain download in progress      synced=98.72%  chain=406.42GiB  headers=7,987,784@3.59GiB    bodies=7,987,784@353.74GiB  receipts=7,987,784@49.08GiB
   eta=4m4.820s
```

Interestingly my lighthouse node has a peculiar complaint:

```
Apr 11 16:54:26.393 WARN Failed to sync chain built on invalid parent, advice: check execution node for corruption then restart it and Lighthouse, parent_root: 0xde1d4242daf923bd9fd93aba05a79e0ea23a31aed7d995566a0f14bd0fcf3a4f
```",general: general performance degradation,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a system failure during a complex operation involving multiple, simultaneous processes: syncing a blockchain, generating state snapshots, and handling chain forks. The log entries are interleaved, indicating concurrent execution (e.g., 'Resuming state snapshot generation' immediately followed by 'Imported new chain segment' and 'Syncing: chain download in progress'). The core of the problem appears when the system has to handle a 'chain forked' event, which forces a 'Restarting sync cycle'. This happens while a state snapshot is being generated. The subsequent errors, such as 'missing trie node... layer stale' and 'State snapshotter failed to iterate trie', strongly suggest that one process is attempting to access data (the trie) that has been modified or invalidated by another concurrent process (the sync cycle restart due to the fork). This is the classic definition of a race condition: multiple threads/processes accessing a shared resource (the state trie/database) without proper synchronization, leading to an inconsistent or corrupt state. While 'CWE-476: NULL Pointer Dereference' is plausible due to the 'Nil finalized block' error, this appears to be a symptom of the underlying state corruption caused by the race condition, rather than the root cause itself. 'CWE-703: Improper Check or Handling of Exceptional Conditions' is also relevant, as a chain fork is an exceptional condition. However, CWE-362 is more specific and accurately describes the likely mechanism of failure—the improper synchronization between concurrent tasks—which is strongly evidenced by the logs.",closed,"The node's state snapshot generation process encounters issues due to missing trie nodes and stale layers during the syncing process, leading to an inability to finalize blocks and manage state correctly.","The bug can cause nodes to fail during the synchronization process, leading to potential inconsistencies in the state of the blockchain and could result in nodes being unable to validate transactions or blocks effectively.",2989165883,31616,"April 11, 2025 4:37 PM (GMT+8)","April 22, 2025 5:22 AM (GMT+8)",['type:bug'],
go-ethereum,Deadlock when resetting head to genesis,https://github.com/ethereum/go-ethereum/issues/31601,Storage,"#### What happened

The node was syncing and it ran out of storage so it gracefully shutdown.

```
INFO [04-09|19:04:50.114] Forkchoice requested sync to new head    number=8,085,869 hash=2167dc..14a9f1 finalized=8,085,789
INFO [04-09|19:04:51.373] Syncing: chain download in progress      synced=94.66%  chain=385.26GiB  headers=7,654,250@3.40GiB    bodies=7,654,250@337.73GiB receipts=7,654,250@44.13GiB   eta=1
7m15.483s
INFO [04-09|19:05:00.089] Syncing: chain download in progress      synced=94.69%  chain=385.42GiB  headers=7,656,686@3.40GiB    bodies=7,656,686@337.85GiB receipts=7,656,686@44.18GiB   eta=1
7m9.838s
INFO [04-09|19:05:00.472] Forkchoice requested sync to new head    number=8,085,870 hash=eca09e..422167 finalized=8,085,789
INFO [04-09|19:05:08.375] Syncing: chain download in progress      synced=94.73%  chain=385.65GiB  headers=7,659,737@3.40GiB    bodies=7,659,737@338.01GiB receipts=7,659,737@44.23GiB   eta=1
7m2.585s
ERROR[04-09|19:05:10.572] Low disk space. Gracefully shutting down Geth to prevent database corruption. available=311.31MiB path=/home/ubuntu/datadir-sepolia/geth
INFO [04-09|19:05:10.574] Got interrupt, shutting down...
INFO [04-09|19:05:10.654] HTTP server stopped                      endpoint=127.0.0.1:8545
INFO [04-09|19:05:10.654] HTTP server stopped                      endpoint=127.0.0.1:8551
INFO [04-09|19:05:10.663] IPC endpoint closed                      url=/home/ubuntu/datadir-sepolia/geth.ipc
ERROR[04-09|19:05:11.521] Beacon backfilling failed                err=""syncing canceled (requested)""
INFO [04-09|19:05:14.969] Ethereum protocol stopped
INFO [04-09|19:05:14.971] Transaction pool stopped
ERROR[04-09|19:05:14.975] Failed to journal state snapshot         err=""snapshot [0x5eb6e371a698b8d68f665192350ffcecbbbf322916f4b51bd79bb6887da3f494] missing""
INFO [04-09|19:05:14.981] Persisting dirty state to disk           root=5eb6e3..a3f494 layers=0
INFO [04-09|19:05:14.985] Failed to journal in-memory trie nodes   err=""layer stale""
INFO [04-09|19:05:15.006] Blockchain stopped
```

Later when I restarted it, it sees that it doesn't have any full state to go back to and tries to go back to genesis. However this goes into deadlock.

```
WARN [04-10|08:58:13.340] Head block missing, resetting chain      hash=25a5cc..3e6dd9
WARN [04-10|08:58:13.340] Rewinding blockchain to block            target=0
WARN [04-10|08:58:13.340] Head block missing, resetting chain      hash=25a5cc..3e6dd9
SIGQUIT: quit
PC=0x40dd0e m=0 sigcode=0

[...]

goroutine 1 gp=0xc000002380 m=nil [chan receive]:
runtime.gopark(0x0?, 0x1?, 0x0?, 0x0?, 0x0?)
        runtime/proc.go:435 +0xce fp=0xc000f05508 sp=0xc000f054e8 pc=0x47a28e
runtime.chanrecv(0xc0011efdc0, 0xc000f055d8, 0x1)
        runtime/chan.go:664 +0x445 fp=0xc000f05580 sp=0xc000f05508 pc=0x411d25
runtime.chanrecv2(0x0?, 0x0?)
        runtime/chan.go:511 +0x12 fp=0xc000f055a8 sp=0xc000f05580 pc=0x4118d2
github.com/ethereum/go-ethereum/internal/syncx.(*ClosableMutex).TryLock(...)
        github.com/ethereum/go-ethereum/internal/syncx/mutex.go:35
github.com/ethereum/go-ethereum/core.(*BlockChain).setHeadBeyondRoot(0xc000237008, 0x0, 0x0, {0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...}, ...)
        github.com/ethereum/go-ethereum/core/blockchain.go:821 +0x6c fp=0xc000f05688 sp=0xc000f055a8 pc=0xac252c
github.com/ethereum/go-ethereum/core.(*BlockChain).SetHead(0xc000237008, 0x0?)
        github.com/ethereum/go-ethereum/core/blockchain.go:583 +0x36 fp=0xc000f05770 sp=0xc000f05688 pc=0xac0096
github.com/ethereum/go-ethereum/core.(*BlockChain).ResetWithGenesisBlock(0xc000237008, 0xc000165b00)
        github.com/ethereum/go-ethereum/core/blockchain.go:993 +0x45 fp=0xc000f05800 sp=0xc000f05770 pc=0xac38e5
github.com/ethereum/go-ethereum/core.(*BlockChain).Reset(...)
        github.com/ethereum/go-ethereum/core/blockchain.go:986
github.com/ethereum/go-ethereum/core.(*BlockChain).loadLastState(0xc000237008)
        github.com/ethereum/go-ethereum/core/blockchain.go:521 +0x21c fp=0xc000f05ad8 sp=0xc000f05800 pc=0xabefbc
github.com/ethereum/go-ethereum/core.(*BlockChain).setHeadBeyondRoot(0xc000237008, 0x0, 0x0, {0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...}, ...)
        github.com/ethereum/go-ethereum/core/blockchain.go:946 +0x4a6 fp=0xc000f05bb8 sp=0xc000f05ad8 pc=0xac2966
github.com/ethereum/go-ethereum/core.(*BlockChain).SetHead(0xc000237008, 0x0?)
        github.com/ethereum/go-ethereum/core/blockchain.go:583 +0x36 fp=0xc000f05ca0 sp=0xc000f05bb8 pc=0xac0096
github.com/ethereum/go-ethereum/core.(*BlockChain).ResetWithGenesisBlock(0xc000237008, 0xc000165b00)
        github.com/ethereum/go-ethereum/core/blockchain.go:993 +0x45 fp=0xc000f05d30 sp=0xc000f05ca0 pc=0xac38e5
github.com/ethereum/go-ethereum/core.(*BlockChain).Reset(...)
        github.com/ethereum/go-ethereum/core/blockchain.go:986
github.com/ethereum/go-ethereum/core.(*BlockChain).loadLastState(0xc000237008)
        github.com/ethereum/go-ethereum/core/blockchain.go:521 +0x21c fp=0xc000f06008 sp=0xc000f05d30 pc=0xabefbc
github.com/ethereum/go-ethereum/core.NewBlockChain({0x21561b0, 0xc0025abf50}, 0x1b004c3?, 0xc0003221a0, 0xc000f06488, {0x214b898, 0xc00036b2a0}, {0x0, 0x0, 0x0, ...}, ...)
        github.com/ethereum/go-ethereum/core/blockchain.go:357 +0xeb2 fp=0xc000f062d8 sp=0xc000f06008 pc=0xabda92
github.com/ethereum/go-ethereum/eth.New(0xc000000700, 0xc00024ce08)
        github.com/ethereum/go-ethereum/eth/backend.go:244 +0x121f fp=0xc000f06678 sp=0xc000f062d8 pc=0x11334ff
github.com/ethereum/go-ethereum/cmd/utils.RegisterEthService(0xc000000700, 0x1afd28c?)
        github.com/ethereum/go-ethereum/cmd/utils/flags.go:1978 +0x25 fp=0xc000f06708 sp=0xc000f06678 pc=0x12ebae5
main.makeFullNode(0xc000018a00)
        github.com/ethereum/go-ethereum/cmd/geth/config.go:198 +0x251 fp=0xc000f07b88 sp=0xc000f06708 pc=0x15fc111
main.geth(0xc000018a00)
        github.com/ethereum/go-ethereum/cmd/geth/main.go:347 +0x125 fp=0xc000f07c30 sp=0xc000f07b88 pc=0x1608425
```

We can see that `loadLastState` keeps calling `Reset` which ends up in `setHeadBeyondRoot` (which takes the lock). `setHeadBeyondRoot` in turn calls `loadLastState` and the whole thing happens again until it reaches the lock.
",storage: storage persistence failure,CWE-833,Deadlock,"The bug report's title explicitly identifies the issue as a ""Deadlock"". The provided stack trace confirms this, showing a goroutine is blocked indefinitely while waiting to acquire a lock (`github.com/ethereum/go-ethereum/internal/syncx.(*ClosableMutex).TryLock`). This directly aligns with the definition of CWE-833, where a thread or executable segment waits for a lock that cannot be released, causing the program to halt. While the issue is triggered by an exceptional condition (low disk space), making CWE-755 (Improper Handling of Exceptional Conditions) a potential candidate, CWE-833 is more specific to the nature of the resulting bug. The user's analysis also mentions a recursive call pattern, which might suggest CWE-674 (Uncontrolled Recursion). However, the primary failure mode is not resource exhaustion (like a stack overflow) as described in CWE-674's definition, but rather a logical impasse due to locking. The recursion is the mechanism that leads to the deadlock, but the deadlock itself is the most accurate description of the weakness. Therefore, CWE-833 is the single most accurate classification.",closed,"The deadlock occurs due to a cyclical dependency in the function calls between `loadLastState` and `setHeadBeyondRoot`, which repeatedly attempts to reset the blockchain head to genesis while holding a lock.","This deadlock prevents the node from recovering and syncing, which can lead to a complete halt of the blockchain operations for the affected node, potentially impacting network stability if multiple nodes experience the same issue.",2985063644,31601,"April 10, 2025 9:32 AM (GMT+8)","April 17, 2025 4:47 PM (GMT+8)",['type:bug'],
go-ethereum,Can't fetch some logs in new fork after a reorg (go-ethereum 1.15.7),https://github.com/ethereum/go-ethereum/issues/31593,Storage,"#### System information

Geth version:  `ethereum/client-go:v1.15.7`
CL client & version: `sigp/lighthouse:v7.0.0-beta.5`

#### Actual behaviour

I'm running a Holesky full node, and found that, after a chain reorg, I try to call `eth_getLogs` to fetch the logs in the new fork, but seems geth can't return the logs at the exact reorged height, it will only return those new logs before / after the reorged height.
",api: api unavailability,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a failure of the `eth_getLogs` API call under a specific, infrequent circumstance: a blockchain reorganization ('reorg'). A reorg is a classic example of an 'exceptional condition' that a blockchain client must handle, but which does not occur during routine block-by-block processing. The software fails to return the correct logs specifically at the reorg height, indicating a failure in the logic that handles this exceptional event. This directly aligns with the definition of CWE-703, 'The product does not properly anticipate or handle exceptional conditions that rarely occur during normal operation of the product.'

CWE-665 (Improper Initialization) is less suitable. While the bug might be caused by a resource not being re-initialized correctly during the reorg process, the fundamental weakness is the failure to handle the reorg event itself. CWE-703 describes the overall context of the failure more accurately than a potential, unconfirmed implementation detail like improper initialization.

CWE-841 (Improper Enforcement of Behavioral Workflow) is not applicable. The bug is an internal processing failure triggered by a network event, not a failure to enforce a required sequence of actions performed by a user or actor.",closed,"The issue arises because the Geth client does not properly handle log fetching at the exact height of a chain reorganization, likely due to the way logs are indexed or stored during a reorg.","This bug could lead to missing important log data that may be critical for applications relying on accurate event tracking during and after a chain reorganization, potentially affecting transparency and accountability in blockchain applications.",2981600237,31593,"April 9, 2025 5:45 AM (GMT+8)","April 17, 2025 5:30 AM (GMT+8)",['type:bug'],
go-ethereum,Timeout Issue After Upgrading to Geth 1.15.7,https://github.com/ethereum/go-ethereum/issues/31589,Storage,"
Dear Geth Team,

We recently upgraded Geth on one of our Ethereum node servers. Below are the details:

- Node IP: 172.31.27.152
- Geth version: 1.15.7
- Command output:

```
root@ip-172-31-27-152:~# geth --version
Geth version: 1.15.7-stable-827d3fcc
```


Synchronization appears to be functioning normally:
```
root@ip-172-31-27-152:~# geth attach http://localhost:8555
> eth.syncing
false
> eth.blockNumber
22223107`
```


However, we are encountering an issue with the eth_getLogs API. Specifically, the following call consistently times out:
```
curl -X POST http://172.31.27.152:8555 \
  -H ""Content-Type: application/json"" \
  --data '{
    ""jsonrpc"": ""2.0"",
    ""method"": ""eth_getLogs"",
    ""params"": [{
      ""address"": ""0x6b175474e89094c44da98b954eedeac495271d0f"",
      ""fromBlock"": ""0x152f4bc"",
      ""toBlock"": ""0x152f4bc"",
      ""topics"": [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef""]
    }],
    ""id"": 1
  }'

```

Response:
```
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32002,""message"":""request timed out""}}
```




```
root@ip-172-31-27-152:~# geth attach http://localhost:8555
Welcome to the Geth JavaScript console!

instance: Geth/v1.15.7-stable-827d3fcc/linux-amd64/go1.24.1
at block: 22223307 (Tue Apr 08 2025 09:32:23 GMT+0000 (UTC))
 datadir: /data/execution/.ethereum
 modules: admin:1.0 debug:1.0 eth:1.0 net:1.0 rpc:1.0 txpool:1.0 web3:1.0

To exit, press ctrl-d or type exit
> eth.getLogs({address: ""0x6b175474e89094c44da98b954eedeac495271d0f"", fromBlock: ""0x152f4bc"", toBlock: ""0x152f4bc""})

Error: request timed out
	at web3.js:6386:9(39)
	at send (web3.js:5115:62(29))
	at <eval>:1:12(9)


```








We are running the same API call on another Ethereum node that is still on Geth 1.14.12 (IP: 172.31.30.65) and it responds correctly with the expected log entries. That node is also fully synced:
```root@ip-172-31-30-65:~# geth --version
Geth version: 1.14.12-stable-293a300d
root@ip-172-31-30-65:~# geth attach http://localhost:8555
> eth.syncing
false
> eth.blockNumber
22223140
```


When we invoke the exact same eth_getLogs request on this node, the response is returned successfully with the expected results.
```
[deployer@ip-172-31-17-105 ~]$ curl -X POST http://172.31.30.65:8555 \
  -H ""Content-Type: application/json"" \
  --data '{
    ""jsonrpc"": ""2.0"",
    ""method"": ""eth_getLogs"",
    ""params"": [{
      ""address"": ""0x6b175474e89094c44da98b954eedeac495271d0f"",
      ""fromBlock"": ""0x152f4bc"",
      ""toBlock"": ""0x152f4bc"",
      ""topics"": [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef""]
    }],
    ""id"": 1
  }'
{""jsonrpc"":""2.0"",""id"":1,""result"":[{""address"":""0x6b175474e89094c44da98b954eedeac495271d0f"",""topics"":[""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"",""0x0000000000000000000000000000000000000000000000000000000000000000"",""0x000000000000000000000000ba58c9b54acb83e66b8b58ed31e7b5e3adc74b00""],""data"":""0x000000000000000000000000000000000000000000003b4a81625fb4b92cd363"",""blockNumber"":""0x152f4bc"",""transactionHash"":""0x0a740e25a2cab85effa90ddb8116a8ec4f95c8d642838a1f299b49e5f3259743"",""transactionIndex"":""0x1"",""blockHash"":""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",""logIndex"":""0x52"",""removed"":false},{""address"":""0x6b175474e89094c44da98b954eedeac495271d0f"",""topics"":[""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"",""0x000000000000000000000000ba58c9b54acb83e66b8b58ed31e7b5e3adc74b00"",""0x000000000000000000000000f6e72db5454dd049d0788e411b06cfaf16853042""],""data"":""0x000000000000000000000000000000000000000000003b4a81625ea3d91cd000"",""blockNumber"":""0x152f4bc"",""transactionHash"":""0x0a740e25a2cab85effa90ddb8116a8ec4f95c8d642838a1f299b49e5f3259743"",""transactionIndex"":""0x1"",""blockHash"":""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",""logIndex"":""0x55"",""removed"":false},{""address"":""0x6b175474e89094c44da98b954eedeac495271d0f"",""topics"":[""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"",""0x0000000000000000000000006228d9027b2840fffa19e104e51644542f418270"",""0x000000000000000000000000b38b3f36bda4c6d5f47a150817e6d754f266eee5""],""data"":""0x00000000000000000000000000000000000000000000043c33c1937564800000"",""blockNumber"":""0x152f4bc"",""transactionHash"":""0xaccef503b3c7e77054c25d44ee8be2d898d83d8fa610848459c0bc067c5f79c1"",""transactionIndex"":""0x4c"",""blockHash"":""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",""logIndex"":""0x207"",""removed"":false},{""address"":""0x6b175474e89094c44da98b954eedeac495271d0f"",""topics"":[""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"",""0x000000000000000000000000aaf26200c40eb606bb56cb1005bcea7fa1baf17f"",""0x0000000000000000000000006228d9027b2840fffa19e104e51644542f418270""],""data"":""0x000000000000000000000000000000000000000000000000002aa1efb94e0000"",""blockNumber"":""0x152f4bc"",""transactionHash"":""0x69d2460cd7638e9324b021a216250f50295e866fd4e1d1dc979a82066232aff0"",""transactionIndex"":""0xb5"",""blockHash"":""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",""logIndex"":""0x29e"",""removed"":false}]}
```



```
root@ip-172-31-30-65:~# geth attach http://localhost:8555
Welcome to the Geth JavaScript console!

instance: Geth/v1.14.12-stable-293a300d/linux-amd64/go1.23.3
at block: 22223315 (Tue Apr 08 2025 09:33:59 GMT+0000 (UTC))
 datadir: /data/execution/.ethereum
 modules: admin:1.0 debug:1.0 eth:1.0 net:1.0 rpc:1.0 txpool:1.0 web3:1.0

To exit, press ctrl-d or type exit
> eth.getLogs({address: ""0x6b175474e89094c44da98b954eedeac495271d0f"", fromBlock: ""0x152f4bc"", toBlock: ""0x152f4bc""})
[{
    address: ""0x6b175474e89094c44da98b954eedeac495271d0f"",
    blockHash: ""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",
    blockNumber: ""0x152f4bc"",
    data: ""0x000000000000000000000000000000000000000000003b4a81625fb4b92cd363"",
    logIndex: ""0x52"",
    removed: false,
    topics: [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"", ""0x0000000000000000000000000000000000000000000000000000000000000000"", ""0x000000000000000000000000ba58c9b54acb83e66b8b58ed31e7b5e3adc74b00""],
    transactionHash: ""0x0a740e25a2cab85effa90ddb8116a8ec4f95c8d642838a1f299b49e5f3259743"",
    transactionIndex: ""0x1""
}, {
    address: ""0x6b175474e89094c44da98b954eedeac495271d0f"",
    blockHash: ""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",
    blockNumber: ""0x152f4bc"",
    data: ""0x000000000000000000000000000000000000000000003b4a81625ea3d91cd000"",
    logIndex: ""0x55"",
    removed: false,
    topics: [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"", ""0x000000000000000000000000ba58c9b54acb83e66b8b58ed31e7b5e3adc74b00"", ""0x000000000000000000000000f6e72db5454dd049d0788e411b06cfaf16853042""],
    transactionHash: ""0x0a740e25a2cab85effa90ddb8116a8ec4f95c8d642838a1f299b49e5f3259743"",
    transactionIndex: ""0x1""
}, {
    address: ""0x6b175474e89094c44da98b954eedeac495271d0f"",
    blockHash: ""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",
    blockNumber: ""0x152f4bc"",
    data: ""0x00000000000000000000000000000000000000000000043c33c1937564800000"",
    logIndex: ""0x207"",
    removed: false,
    topics: [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"", ""0x0000000000000000000000006228d9027b2840fffa19e104e51644542f418270"", ""0x000000000000000000000000b38b3f36bda4c6d5f47a150817e6d754f266eee5""],
    transactionHash: ""0xaccef503b3c7e77054c25d44ee8be2d898d83d8fa610848459c0bc067c5f79c1"",
    transactionIndex: ""0x4c""
}, {
    address: ""0x6b175474e89094c44da98b954eedeac495271d0f"",
    blockHash: ""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",
    blockNumber: ""0x152f4bc"",
    data: ""0x0000000000000000000000000000000000000000000000000000000000000000"",
    logIndex: ""0x261"",
    removed: false,
    topics: [""0x8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925"", ""0x00000000000000000000000014de393d86d4b7679693522241cd45d246c92b37"", ""0x000000000000000000000000722122df12d4e14e13ac3b6895a86e84145b6967""],
    transactionHash: ""0xb324ffc3ec3c5302041acd2919ddba4fecc87e3d0f88e5c7d6d665bc1631cb44"",
    transactionIndex: ""0x87""
}, {
    address: ""0x6b175474e89094c44da98b954eedeac495271d0f"",
    blockHash: ""0x1d798566526ac2727e518e8d2e9f2846e98a08f3cad25ed2ad8987529b3fcb30"",
    blockNumber: ""0x152f4bc"",
    data: ""0x000000000000000000000000000000000000000000000000002aa1efb94e0000"",
    logIndex: ""0x29e"",
    removed: false,
    topics: [""0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"", ""0x000000000000000000000000aaf26200c40eb606bb56cb1005bcea7fa1baf17f"", ""0x0000000000000000000000006228d9027b2840fffa19e104e51644542f418270""],
    transactionHash: ""0x69d2460cd7638e9324b021a216250f50295e866fd4e1d1dc979a82066232aff0"",
    transactionIndex: ""0xb5""
}]

```



We use this shell to start our Geth.
```
#!/usr/bin/env bash

counter=`/usr/bin/pgrep geth | /usr/bin/wc -l`
if [ ${counter} -eq 0 ]
then
  nohup /usr/bin/geth --cache 4096 --http --http.port ""8555"" --http.addr ""0.0.0.0"" --http.api ""net,eth,web3,personal,admin,debug,engine,txpool"" --port ""30303"" --http.vhosts ""*"" --datadir /data/execution/.ethereum --maxpeers 50 --authrpc.addr localhost --authrpc.port 8551 --authrpc.vhosts localhost --authrpc.jwtsecret /root/jwt.hex >/dev/null 2>&1 &

fi
```




We have ruled out any infrastructure-related misconfigurations (such as networking, firewall, or disk issues), and the only difference appears to be the Geth version.

Could this be a regression or behavioral change in Geth 1.15.7 that affects eth_getLogs for historical blocks?

We would greatly appreciate any insights or suggestions on how to resolve this issue.

Best regards,
Leung



",api: api unavailability,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a specific API call (`eth_getLogs`) that consistently times out in a new version of the software, whereas it completed successfully in a previous version. The API call is for a very narrow range (a single block), which should be a fast operation. The timeout indicates that the operation is taking an unexpectedly long time to execute, likely consuming excessive CPU time until the server's timeout threshold is reached. This points to a flaw in the execution logic for this specific query.

- **CWE-834 (Excessive Iteration):** This is the best fit. A timeout in a search or query function, especially for a small, well-defined dataset like a single block, is a classic symptom of an infinite or poorly-bounded loop. The logic introduced in the new version likely contains a flaw that causes it to iterate far more than necessary, or indefinitely, for this specific set of parameters. The definition, ""performs an iteration or loop without sufficiently limiting the number of times that the loop is executed,"" directly describes this probable cause.

- **CWE-400 (Uncontrolled Resource Consumption):** While the timeout is a result of consuming too much of a resource (CPU time), this CWE is less specific than CWE-834. CWE-834 points to the likely *cause* (a bad loop), while CWE-400 describes the *effect* (resource exhaustion). Given the context of a search function failing to terminate in time, 'Excessive Iteration' is a more precise diagnosis of the underlying weakness.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions):** This is not applicable. The issue is not a failure to handle a rare error condition or system exception. It is a performance regression where a standard operation fails to complete within a reasonable time. The system is, in fact, handling the condition by enforcing a timeout.",closed,"The eth_getLogs API call times out after the upgrade to Geth 1.15.7, suggesting a potential issue with resource management or API handling in the new version.","If the API call consistently times out, it can lead to failures in applications relying on event logs, potentially disrupting services that depend on blockchain event monitoring and data retrieval.",2979132059,31589,"April 8, 2025 9:11 AM (GMT+8)","April 17, 2025 5:30 AM (GMT+8)",['type:bug'],
go-ethereum,Archive nodes Bad block with 1.15.6,https://github.com/ethereum/go-ethereum/issues/31507,Storage,"#### System information

Geth version: `1.15.6`
CL client & version: prysm@v5.3.1
OS & Version: Linux
Commit hash : (if `develop`)

#### Expected behaviour
Nodes continue to work after upgrade 

#### Actual behaviour
After upgrading the nodes from 1.15.5 to 1.15.6 archive nodes are seeing bad block issue and not progressing
```
INFO [03-27|14:36:10.385] Skip duplicated bad block                number=7,974,902 hash=c60784..971a41
ERROR[03-27|14:36:10.385] 
########## BAD BLOCK #########
Block: 7974902 (0xc607846e238317f8bbd1675291d39463b0da88094c6a05a3e408a26e48971a41)
Error: could not apply tx 113 [0x1c87a00b1ec2d221a539ed660a0655b927c3e6f3323d45e9a13e0930a2df7547]: nonce too high: address 0x9E07041e26c2D25b6eF78DE4038704d41d9695e8, tx: 55284 state: 0
Platform: geth (devel) go1.23.7 amd64 linux
VCS: af72c643-20250325
Chain config: &params.ChainConfig{ChainID:11155111, HomesteadBlock:0, DAOForkBlock:<nil>, DAOForkSupport:true, EIP150Block:0, EIP155Block:0, EIP158Block:0, ByzantiumBlock:0, ConstantinopleBlock:0, PetersburgBlock:0, IstanbulBlock:0, MuirGlacierBlock:0, BerlinBlock:0, LondonBlock:0, ArrowGlacierBlock:<nil>, GrayGlacierBlock:<nil>, MergeNetsplitBlock:1735371, ShanghaiTime:(*uint64)(0xc0004d22d0), CancunTime:(*uint64)(0xc0004d22d8), PragueTime:(*uint64)(0xc0004d22e0), OsakaTime:(*uint64)(nil), VerkleTime:(*uint64)(nil), TerminalTotalDifficulty:17000000000000000, DepositContractAddress:0x7f02C3E3c98b133055B8B348B2Ac625669Ed295D, EnableVerkleAtGenesis:false, Ethash:(*params.EthashConfig)(0x316a620), Clique:(*params.CliqueConfig)(nil), BlobScheduleConfig:(*params.BlobScheduleConfig)(0x3137540)}
Receipts: 
##############################

WARN [03-27|14:36:10.385] NewPayload: inserting block failed       error=""could not apply tx 113 [0x1c87a00b1ec2d221a539ed660a0655b927c3e6f3323d45e9a13e0930a2df7547]: nonce too high: address 0x9E07041e26c2D25b6eF78DE4038704d41d9695e8, tx: 55284 state: 0""
```

#### Steps to reproduce the behaviour
Upgrade Geth sepolia archive node with 
gcMode: archive
stateScheme: hash
dbEnginer: pebble

Am I missing a parameter change caused by `--history.log`. Does it need to be set to `--history.log=0` for archive nodes

#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them as text and not screenshots.
",storage: storage corruption,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a blockchain node failing to process a new block after a software upgrade. The error message, `Error: could not apply tx ...: nonce too high: address ..., tx: 55284 state: 0`, is the key piece of evidence. This error indicates that the software is validating a transaction with a nonce of 55284 against an account state where the nonce is believed to be 0. In a blockchain, a transaction's nonce must be sequential, so for a transaction with nonce 55284 to be valid, the account's current nonce in the state must be 55283. The value `state: 0` is therefore an incorrect value retrieved or calculated by the software. This incorrect value is then used in the critical process of block validation, leading to the rejection of the block and the node stalling.

- **CWE-682 (Incorrect Calculation):** This is the best fit. The software incorrectly determines the account's nonce from its state database, resulting in the wrong value (`0`). This incorrect result is then used in a security-critical calculation (transaction and block validation), causing the system to make an incorrect decision (rejecting a valid block).

- **CWE-703 (Improper Check or Handling of Exceptional Conditions):** This is not a good fit. The software *is* checking for and handling an exceptional condition (a transaction with an invalid nonce). It correctly identifies the mismatch based on its internal state and rejects the block. The flaw is not in the handling of the exception, but in the incorrect state that caused the exception to be raised in the first place.

- **CWE-436 (Interpretation Conflict):** This is less accurate. The issue appears to be an internal logic error within the new version of the Geth software itself, rather than a conflict in how two different products or components interpret the same data. The node is failing to correctly read its own state after an upgrade.",closed,"The issue arises from the handling of transaction nonces in the new version of the Geth client, where a transaction is being rejected due to its nonce being too high, indicating a potential misalignment in the state or transaction pool after upgrading from version 1.15.5 to 1.15.6.","This bug prevents archive nodes from processing certain blocks, leading to a halt in blockchain synchronization and potentially impacting the integrity and availability of the archive node's data.",2953315607,31507,"March 27, 2025 2:56 PM (GMT+8)","April 1, 2025 12:21 PM (GMT+8)",['type:bug'],
go-ethereum,Fatal error after crlt-c kill: gap in the chain between ancients [...] and leveldb [...],https://github.com/ethereum/go-ethereum/issues/31499,Storage,"#### System information

Geth version: 1.15.6-unstable
CL client & version: nimbus
OS & Version: OSX
Commit hash : 881ee4062f93eaa6d0cc95202326caa7af4f88c9

#### Actual behaviour
After killing geth in the init phase with a ctrl-c, it can't restart.

Killed in the init phase like this:
```
INFO [03-26|10:54:44.566]  - Cancun:                      @1710338135 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/cancun.md)
INFO [03-26|10:54:44.566] 
INFO [03-26|10:54:44.566] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [03-26|10:54:44.566] 
INFO [03-26|10:54:44.567] Loaded most recent local block           number=22,130,311 hash=15955c..c22cee age=21s
INFO [03-26|10:54:44.567] Loaded most recent local finalized block number=22,130,237 hash=b807f1..b0ba95 age=15m9s
INFO [03-26|10:54:44.567] Loaded last snap-sync pivot marker       number=22,124,002
WARN [03-26|10:54:44.567] Head state missing, repairing            number=22,130,311 hash=15955c..c22cee snaproot=ce4bcb..5631b6
INFO [03-26|10:54:44.574] Rewound to block with state              number=22,129,711 hash=9c1ded..575df6
^C
```

Restarting fails like this
```
INFO [03-26|11:09:38.551] Starting Geth on Ethereum mainnet...
INFO [03-26|11:09:38.551] Bumping default cache on mainnet         provided=1024 updated=4096
INFO [03-26|11:09:38.552] Maximum peer count                       ETH=50 total=50
INFO [03-26|11:09:38.552] Smartcard socket not found, disabling    err=""stat /run/pcscd/pcscd.comm: no such file or directory""
INFO [03-26|11:09:38.554] Set global gas cap                       cap=50,000,000
INFO [03-26|11:09:38.561] Initializing the KZG library             backend=gokzg
INFO [03-26|11:09:38.572] Enabling metrics collection
INFO [03-26|11:09:38.572] Enabling stand-alone metrics HTTP endpoint address=0.0.0.0:6060
INFO [03-26|11:09:38.572] Starting metrics server                  addr=http://0.0.0.0:6060/debug/metrics
INFO [03-26|11:09:38.572] Allocated trie memory caches             clean=614.00MiB dirty=1024.00MiB
INFO [03-26|11:09:38.578] Using pebble as the backing database
INFO [03-26|11:09:38.578] Allocated cache and file handles         database=/home/user/.ethereum/geth/chaindata cache=2.00GiB handles=524,288
INFO [03-26|11:09:39.592] Opened ancient database                  database=/home/user/.ethereum/geth/chaindata/ancient/chain readonly=false
Chain metadata
  databaseVersion: 9 (0x9)
  headBlockHash: 0x9c1ded300eff7bd9888ef50efe834ae4872138c499bc0cac9237c66359575df6
  headFastBlockHash: 0x15955ca3b96163347ac361e0f5ed4f030345a95f2d66b5c0f0c7668111c22cee
  headHeaderHash: 0xa08081168d23b5505909ff2d98547b786e27753748d8787a129bd98e9c01953a
  lastPivotNumber: 22124002 (0x15195e2)
  len(snapshotSyncStatus): 282 bytes
  snapshotDisabled: false
  snapshotJournal: 0 bytes
  snapshotRecoveryNumber: 22130119 (0x151adc7)
  snapshotRoot: 0xce4bcb0e32a40ead20270594392d09540d9b881396fb9198997c337fbb5631b6
  txIndexTail: 19780311 (0x12dd2d7)
  SkeletonSyncStatus: {""Subchains"":[{""Head"":22130270,""Tail"":22129712,""Next"":""0x9c1ded300eff7bd9888ef50efe834ae4872138c499bc0cac9237c66359575df6""}],""Finalized"":22124001}


Fatal: Failed to register the Ethereum service: gap in the chain between ancients [0 - #22129824] and leveldb [#22130074 - #22130073]
```

#### Steps to reproduce the behaviour
Already happened twice killing geth early, but not sure how reproducible.
",storage: storage corruption,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a fatal error that occurs when the application is restarted after being terminated with `ctrl-c` during its initialization phase. The termination leaves the application's database in a corrupted or inconsistent state ('gap in the chain'). This prevents the application from successfully starting up again.

- **CWE-404 (Improper Resource Shutdown or Release):** This is the most accurate CWE. The database ('chaindata') is a critical resource. The `ctrl-c` signal initiates a shutdown process. This process is 'improper' because it fails to leave the database resource in a consistent state, making it unusable for the next session ('re-use'). The fatal error on restart is a direct result of the resource not being released or shut down correctly.

- **CWE-362 (Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')):** While an underlying race condition could potentially contribute to the inconsistent state, the direct cause of the bug as reported is the failure to handle the abrupt termination signal (`ctrl-c`) gracefully. The primary weakness demonstrated is the faulty shutdown logic, not necessarily a race between two normally executing threads. Therefore, CWE-404 is a more direct description of the observed problem.

- **CWE-841 (Improper Enforcement of Behavioral Workflow):** This CWE is not applicable. The issue is not about an actor (like a user) failing to follow a required sequence of operations. Instead, it's an internal failure of the software to maintain state integrity when its execution is unexpectedly halted.",closed,"The bug is caused by an improper handling of the shutdown process when the Geth client is terminated abruptly (using ctrl-c) during its initialization phase, which leads to inconsistencies in the chain state and an inability to restart the client.","The failure to restart the Geth client after an abrupt termination can lead to downtime, loss of synchronization with the Ethereum network, and potentially impact users and applications relying on the client for transactions and block validation.",2949047351,31499,"March 26, 2025 10:11 AM (GMT+8)","April 3, 2025 10:03 PM (GMT+8)",['type:bug'],
go-ethereum,concurrent map read and map write in validateAuth,https://github.com/ethereum/go-ethereum/issues/31474,Consensus,"It seems that there could have ""concurrent map read and map write"" while execute pool.all.auths[from]? pool.all.Remove & pool.all.Add has lock, but validateAuth has no lock for pool.all


https://github.com/ethereum/go-ethereum/blob/b0b2b765094ed4abc490ba26bc3be431c84c5b96/core/txpool/legacypool/legacypool.go#L621

",storage: storage corruption,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report explicitly states a ""concurrent map read and map write"" issue. The `validateAuth` function reads from a shared map (`pool.all.auths`) without acquiring a lock, while other functions (`Add`/`Remove`) write to that same map with a lock. This creates a classic race condition. 

CWE-362, 'Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')', is the most accurate choice. Its definition perfectly describes the situation: a ""concurrent code sequence"" (read vs. write) accessing a ""shared resource"" (the map) where a ""timing window exists"" due to the missing lock in the read path, allowing the resource to be modified concurrently. 

CWE-567, 'Unsynchronized Access to Shared Data in a Multithreaded Context', is also relevant as it describes the general problem. However, CWE-362 is more specific because it highlights the timing-dependent nature of the flaw, which is the core of a race condition.

CWE-662, 'Improper Synchronization', is a very broad category. While technically correct, it is less precise than CWE-362, which specifically identifies the type of synchronization flaw as a race condition. Therefore, CWE-362 is the single most accurate classification.",closed,"The code in the validateAuth function accesses the shared 'pool.all' map without proper synchronization, which leads to potential race conditions when concurrently reading from and writing to the map.","This can lead to inconsistent state or crashes in the application, as concurrent modifications can corrupt the data structure, potentially affecting transaction validation and overall network reliability.",2942338111,31474,"March 24, 2025 7:51 AM (GMT+8)","April 3, 2025 4:08 PM (GMT+8)",['type:bug'],
go-ethereum,Different EL clients have inconsistencies in applying for non-existent blockheaders,https://github.com/ethereum/go-ethereum/issues/31471,Network,"Hi, I'm working on a project to verify that five Ethereum excution clients devp2p network protocol implementations (Geth, Erigon, Nethermind, Besu and Reth) behave consistently with each other.

#### Steps to reproduce the behaviour
When we were fuzz testing the devp2p/eth68 protocol, we found that if I mutated the packets and sent them to the nodes, they would behave differently. For example, if I mutated the `Getblockheaders `data when sending it, it is likely that some abnormal values will appear (non-existent block numbers, amount, skip, etc.). In this same situation, different EL clients react differently. Geth and Erigon will not respond to this data or return an empty message, but will not disconnect from the peer. Other clients, Reth, Neth and Besu, will disconnect the peer quickly. The tolerance for this message may be (0-10), and they have very strict protocol verification. This may violate the excution-spec because there should be no difference between their implementations.

#### System information

- Geth v1.13.8
- Reth v1.1.4
- Erigon v2.60.10
- Nethermind v1.30.3
- Besu-25.2.0
",network: faulty peer management,CWE-436,Interpretation Conflict,"The bug report's central theme is the inconsistent behavior among different Ethereum client implementations when presented with the same malformed input. Specifically, Geth and Erigon handle a mutated `Getblockheaders` request differently than Reth, Nethermind, and Besu. This directly aligns with the definition of CWE-436, 'Interpretation Conflict', which states 'Product A handles inputs or steps differently than Product B'. In this case, the different client groups are 'Product A' and 'Product B', and their conflicting actions (ignoring vs. disconnecting the peer) stem from different interpretations of the protocol specification for handling invalid requests.

CWE-20, 'Improper Input Validation', is a related but less precise choice. While the root cause involves how input is validated, the specific problem highlighted in the report is not a validation failure within a single product leading to a typical vulnerability (like a crash), but the *divergence* in validation logic *between* products that are supposed to be interoperable. CWE-436 more accurately captures this interoperability problem.

CWE-693, 'Protection Mechanism Failure', is also less suitable. The report does not describe a protection mechanism that is failing. Instead, it describes different clients employing different (and conflicting) protection strategies—one being lenient, the other strict. The issue is the conflict itself, not the failure of one of the strategies.",closed,"Different Ethereum execution clients implement the devp2p/eth68 protocol inconsistently, leading to varied responses to mutated packets requesting non-existent block headers.","This inconsistency may lead to network instability or forks, as clients may fail to synchronize correctly, potentially causing disruptions in the Ethereum network.",2941823606,31471,"March 24, 2025 2:44 AM (GMT+8)","May 2, 2025 10:32 PM (GMT+8)",['type:bug'],
go-ethereum,nonce too low is not returned in eth_sendRawTransaction,https://github.com/ethereum/go-ethereum/issues/31451,API,"#### System information

Geth version: `geth version v1.15.5` 

#### Expected behaviour
When submitting a new transaction using `eth_sendRawTransaction`, if the `nonce` in transaction  is lower than the current nonce of the sender, an error message `nonce too low` should be returned.


#### Actual behaviour
In version `v1.15.5`, if a transaction with a low nonce is sent using `eth_sendRawTransaction`, no error message is returned.

#### Possible Reason
In PR #31202 , when `locals == nil`,  errors returned by `txPool.Add` are not propagated back to the caller. This prevents caller programs from executing corresponding processing logic based on the error messages.

```golang
func (b *EthAPIBackend) SendTx(ctx context.Context, signedTx *types.Transaction) error {
	locals := b.eth.localTxTracker
	if locals != nil {
		if err := locals.Track(signedTx); err != nil {
			return err
		}
	}
	// No error will be returned to user if the transaction fails stateful
	// validation (e.g., no available slot), as the locally submitted transactions
	// may be resubmitted later via the local tracker.
	err := b.eth.txPool.Add([]*types.Transaction{signedTx}, false)[0]
	if err != nil && locals == nil {
		return err
	}
	return nil
}
```",api: incorrect api output,CWE-755,Improper Handling of Exceptional Conditions,"The bug report indicates that when a transaction with a low nonce is submitted, an error is generated internally by `txPool.Add` but is not propagated back to the API caller. This means an exceptional condition (an invalid transaction due to a low nonce) is detected but not handled correctly. The API should report this failure but instead returns a success-like state (no error). This directly aligns with the definition of CWE-755, where the product incorrectly handles an exceptional condition.

CWE-20 (Improper Input Validation) is less suitable because the validation itself appears to be working; the system correctly identifies that the nonce is too low. The flaw is in the subsequent handling of this validation failure, not the validation logic itself.

CWE-394 (Unexpected Status Code or Return Value) is also not the best fit. This CWE typically applies when the *caller* of a function fails to check the return value. In this case, the bug is within the function being called (`SendTx`), which is the *provider* of the incorrect return value (it suppresses the error from an internal call), not the consumer.",closed,"The error handling logic in the `eth_sendRawTransaction` method does not propagate errors back to the caller when `locals` is nil, resulting in a failure to return a 'nonce too low' error message.","Users can submit transactions with a nonce lower than the current nonce without receiving any error feedback, which may lead to confusion and unexpected behavior in transaction processing.",2938395218,31451,"March 21, 2025 1:22 PM (GMT+8)","March 25, 2025 6:16 PM (GMT+8)",['type:bug'],
go-ethereum,Chain cutoff is not respected in the new bloomfilter,https://github.com/ethereum/go-ethereum/issues/31446,Storage,"```
ERROR[03-20|12:34:01.783] Log index head rendering failed          error=""failed to advance log iterator at 0 while rendering map 0: receipts not found for block 1""
```",storage: storage corruption,CWE-665,Improper Initialization,"The bug report's core error is `receipts not found for block 1`, which caused a subsequent operation, `failed to advance log iterator`, to fail. This sequence strongly suggests that a function was called to retrieve block receipts, it returned an error or a null value indicating the data was not found, and the calling code did not check for this failure. Instead, it proceeded as if the receipts were successfully retrieved, leading to a crash and potential storage corruption. This directly matches the definition of CWE-252, 'Unchecked Return Value'. CWE-129 is less accurate because the issue isn't an invalid array index value, but rather the failure to handle the result of a lookup using that index. CWE-662 is not applicable as there is no evidence in the report of a multi-threading or synchronization problem; the error appears to be a deterministic, logical flaw.",closed,"The bloomfilter implementation does not properly respect the chain cutoff, leading to failure in retrieving necessary receipts for block rendering.","This bug can result in incorrect log rendering and potentially cause inconsistencies in the blockchain state, impacting the reliability of the blockchain's execution environment.",2935353593,31446,"March 20, 2025 12:40 PM (GMT+8)","March 27, 2025 4:20 PM (GMT+8)",['type:bug'],
go-ethereum,NAT UPnP continuously remapping port,https://github.com/ethereum/go-ethereum/issues/31418,Network,"#### System information

Geth version: 1.15.6-unstable
CL client & version: Nimbus [v25.3.0](https://github.com/status-im/nimbus-eth2/releases/tag/v25.3.0)
OS & Version: OSX
Commit hash : 881ee4062

#### Expected behaviour
UPnP maps one port, and sticks with it

#### Actual behaviour
Port is continuously remapped to new values, also changing the ENR

```
~/go-ethereum$ grep ""New local node record\|mapp"" geth.log
INFO [03-18|12:17:36.639] New local node record                    seq=1,738,224,792,044 id=a7b302de865fa192 ip=127.0.0.1 udp=30303 tcp=30303
INFO [03-18|12:17:38.734] New local node record                    seq=1,738,224,792,045 id=a7b302de865fa192 ip=<public_ip>    udp=1027  tcp=30303
TRACE[03-18|12:17:38.836] Attempting port mapping                  proto=TCP extport=30303 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:17:38.837] New local node record                    seq=1,738,224,792,046 id=a7b302de865fa192 ip=<public_ip>    udp=30303 tcp=30303
INFO [03-18|12:17:39.246] NAT mapped port                          proto=TCP extport=30303 intport=30303 interface=""UPNP IGDv1-PPP1""
TRACE[03-18|12:17:39.246] Attempting port mapping                  proto=UDP extport=30303 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:17:39.863] NAT mapped alternative port              proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:17:39.919] New local node record                    seq=1,738,224,792,047 id=a7b302de865fa192 ip=<public_ip>    udp=55285 tcp=30303
TRACE[03-18|12:25:39.247] Attempting port mapping                  proto=TCP extport=30303 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:25:39.660] NAT mapped alternative port              proto=TCP extport=59229 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:25:39.661] New local node record                    seq=1,738,224,792,048 id=a7b302de865fa192 ip=<public_ip>     udp=55285 tcp=59229
TRACE[03-18|12:25:39.864] Attempting port mapping                  proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:25:40.076] NAT mapped port                          proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
TRACE[03-18|12:33:39.661] Attempting port mapping                  proto=TCP extport=59229 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:33:40.088] NAT mapped alternative port              proto=TCP extport=51217 intport=30303 interface=""UPNP IGDv1-PPP1""
TRACE[03-18|12:33:40.088] Attempting port mapping                  proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:33:40.236] New local node record                    seq=1,738,224,792,049 id=a7b302de865fa192 ip=<public_ip>     udp=55285 tcp=51217
INFO [03-18|12:33:40.499] NAT mapped port                          proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
TRACE[03-18|12:41:40.088] Attempting port mapping                  proto=TCP extport=51217 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:41:40.507] NAT mapped alternative port              proto=TCP extport=17009 intport=30303 interface=""UPNP IGDv1-PPP1""
TRACE[03-18|12:41:40.507] Attempting port mapping                  proto=UDP extport=55285 intport=30303 interface=""UPNP IGDv1-PPP1""
INFO [03-18|12:41:40.723] New local node record                    seq=1,738,224,792,050 id=a7b302de865fa192 ip=<public_ip>     udp=55285 tcp=17009
```

Could be related to https://github.com/ethereum/go-ethereum/pull/30265
",api: api unavailability,CWE-670,Always-Incorrect Control Flow Implementation,"The bug report describes a situation where the software's behavior deviates from the intended algorithm. The expected behavior is to map a port via UPnP and then maintain that mapping. The actual behavior, as shown in the logs, is a continuous cycle of remapping the port to new values. This indicates a flaw in the program's logic that controls the port mapping lifecycle. 

CWE-670, 'Always-Incorrect Control Flow Implementation', is the best fit because it describes a situation where 'the code contains a control flow path that does not reflect the algorithm that the path is intended to implement, leading to incorrect behavior any time this path is navigated.' The periodic remapping is precisely an incorrect control flow that is executed repeatedly.

CWE-400, 'Uncontrolled Resource Consumption', is a plausible consequence of this bug, as continuously creating new port mappings could exhaust the NAT table on the router. However, CWE-670 describes the root cause of the bug—the faulty logic—more accurately than CWE-400, which describes the potential impact.

CWE-682, 'Incorrect Calculation', is not applicable because the problem is not a mathematical miscalculation but a flaw in the sequence of operations and decision-making within the program.",closed,"The issue arises from the UPnP implementation that fails to maintain a consistent mapping of external ports, leading to continuous remapping of ports for the same internal service.","This bug can lead to instability in network connectivity for nodes, causing potential disruptions in peer-to-peer communication and affecting the overall reliability of the blockchain network.",2928296471,31418,"March 18, 2025 12:10 PM (GMT+8)","April 9, 2025 5:28 PM (GMT+8)",['type:bug'],
go-ethereum,core/filtermaps: Could not get last block of epoch,https://github.com/ethereum/go-ethereum/issues/31413,Storage,"This is just after merging #31080 and trying it out on a Sepolia node.
The indexer runs, and starts printing

```
ERROR[03-17|19:06:34.584] Could not get last block of epoch        epoch=65 error=""failed to retrieve last block of map 67583: pebble: not found""
INFO [03-17|19:06:38.317] Successful NewPayload                    number=7,922,601 hash=ee0d98..55dcd6 status=SYNCING
INFO [03-17|19:06:38.317] Forkchoice requested sync to new head    number=7,922,601 hash=ee0d98..55dcd6 finalized=unknown
INFO [03-17|19:06:38.317] Successful ForkchoiceUpdated             head=ee0d98..55dcd6 status=SYNCING
INFO [03-17|19:06:41.046] Looking for peers                        peercount=0 tried=40 static=0
ERROR[03-17|19:06:41.301] Could not get last block of epoch        epoch=65 error=""failed to retrieve last block of map 67583: pebble: not found""
ERROR[03-17|19:06:46.765] Could not get last block of epoch        epoch=65 error=""failed to retrieve last block of map 67583: pebble: not found""
```

It never gets beyond this and just keeps printing the same message.",storage: storage corruption,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a situation where the software encounters an error, specifically `""failed to retrieve last block of map 67583: pebble: not found""`. This is an exceptional condition. The software's response to this condition is to log the error and then immediately retry the same failing operation, causing it to get stuck in an infinite loop and preventing it from making any progress. This behavior directly aligns with the definition of CWE-755, 'Improper Handling of Exceptional Conditions', as the product is clearly not handling the 'not found' exception correctly, leading to a denial of service for the indexer. While CWE-665 (Improper Initialization) could be the root cause of the 'not found' error, the weakness demonstrated by the system's behavior (the infinite loop) is the failure to handle the resulting exception. CWE-362 (Race Condition) is less likely as the report does not provide any evidence of concurrency issues; the error appears to be deterministic and persistent rather than a timing-related problem.",closed,"The indexer is unable to retrieve the last block of a specific epoch due to a failure in accessing the underlying storage mechanism (pebble), which indicates that the requested resource (block data) is not found.","This issue prevents the node from syncing properly, potentially leading to inconsistencies in the blockchain state and affecting the overall functionality of the network as it fails to process new blocks and synchronize with peers.",2925984281,31413,"March 17, 2025 6:08 PM (GMT+8)","March 18, 2025 8:46 PM (GMT+8)",['type:bug'],
go-ethereum,dev.period should be clamped to max int64 / time.Second,https://github.com/ethereum/go-ethereum/issues/31401,Utilities,"#### System information

Geth
Version: 1.15.3-stable
Git Commit: 612c9e0f4ae483f180ef96ace86effec6dc9bb0e
Git Commit Date: 20250225
Architecture: arm64
Go Version: go1.24.1
Operating System: darwin

#### Expected behaviour
`--dev.period` will only accept valid values

#### Actual behaviour
If `--dev.period` is passed a value greater than `max int64 / time.Second`, go-ethereum dev mode will mine as fast as it can. The overflow happens because  although `--dev.period` is `uint64` in seconds, it backends into a `time.Timer` which takes a `time.Duration`, an `int64`.

max dev.period = 9223372036, go-ethereum works
over dev.period = 9223372037, go-ethereum mines as fast as it can

Trivial Go code to compute these values: https://go.dev/play/p/yoyue1iVsAD
",general: general improper authorization,CWE-681,Incorrect Conversion between Numeric Types,"The bug report describes a flaw where a command-line argument, `--dev.period`, is accepted as a `uint64` but is later used to initialize a `time.Timer` which requires a `time.Duration` (an `int64`). When the input `uint64` value is larger than the maximum positive value an `int64` can represent, an overflow occurs during the type conversion. This results in an unexpected behavior where the timer is set incorrectly. 

CWE-20 (Improper Input Validation) is a possible but overly general classification. While adding input validation would fix the bug, the fundamental flaw is not just a lack of validation, but the specific way the data is handled after being received.

CWE-190 (Integer Overflow or Wraparound) is relevant as an overflow does occur. However, the overflow is not the result of an arithmetic operation (like addition or multiplication) exceeding the bounds of its type, but rather a direct consequence of converting a value from one numeric type (`uint64`) to another (`int64`) with a more limited positive range.

CWE-681 (Incorrect Conversion between Numeric Types) is the most accurate and specific classification. Its description, 'When converting from one data type to another... data can be... translated in a way that produces unexpected values,' perfectly matches the root cause of the bug: the unsafe conversion from `uint64` to `int64`.",closed,"The `--dev.period` parameter is defined as a `uint64`, but it is passed to a `time.Timer` which expects an `int64`. When values greater than `max int64 / time.Second` are provided, an integer overflow occurs, causing unexpected behavior.","If `--dev.period` is set to a value greater than `9223372036`, the mining process will operate at an uncontrolled rate, potentially leading to resource exhaustion and denial of service in a development environment.",2922844120,31401,"March 16, 2025 7:38 AM (GMT+8)","April 17, 2025 8:23 PM (GMT+8)",['type:bug'],
go-ethereum,Feature request: exclude valid authorities from the `eth_createAccessList` result (EIP-7702),https://github.com/ethereum/go-ethereum/issues/31335,Consensus,"# Rationale

Using the `eth_createAccessList` method when building EIP-7702 transactions would be easier if it excluded authorities from valid authorizations, as they are automatically added to the access list during execution.
Otherwise, clients have to post-process the `eth_createAccessList` result and manually remove valid authorities to avoid overpaying for unnecessary records in the transaction’s access list.

# Implementation

All authorizations passed to the `eth_createAccessList` method should be processed as follows:
1. Validate the authorization
2. Recover the authority address
3. Mark it as excluded in `AccessListTracer`

An incomplete pull request implementing this change (lacking DoS protection) is available here:
https://github.com/ethereum/go-ethereum/pull/31336
",api: improper authorization,CWE-400,Uncontrolled Resource Consumption,"The bug report describes an issue where the `eth_createAccessList` method includes redundant entries (authorities from valid authorizations) in the access list it generates. The direct consequence, as stated in the report, is that clients 'overpay for unnecessary records in the transaction’s access list.' This directly maps to the concept of consuming more resources than necessary. In this context, the limited resources are the user's funds (gas) and the block space consumed by the transaction data. 

CWE-863 (Incorrect Authorization) is not a good fit because the authorization process itself is not flawed in a security sense; it correctly identifies the authority. The issue is what the application does with that information afterward. 

CWE-20 (Improper Input Validation) is also not suitable because the input authorization is considered valid. The problem lies not in validating the input, but in the subsequent processing logic that produces an inefficient, bloated output.

CWE-400 (Uncontrolled Resource Consumption) is the most accurate choice because the flaw leads to the unnecessary consumption of limited resources (gas and block space) by failing to control the size of the generated access list optimally. The core problem is one of economic inefficiency and waste, which is the essence of this CWE.",closed,"The `eth_createAccessList` method does not currently exclude valid authorities from its result, leading to unnecessary data being included in the access list.","Clients may overpay for transactions due to the inclusion of unnecessary records in the access list, resulting in inefficiency and increased costs.",2903695165,31335,"March 7, 2025 6:46 PM (GMT+8)","March 25, 2025 10:01 PM (GMT+8)",['type:bug'],
go-ethereum,eth_feeHistory blob gas used ratio error,https://github.com/ethereum/go-ethereum/issues/31245,API,"#### System information

Geth version: `1.15.2`
CL client & version: Teku 
OS & Version: Linux

There seems to be a bug in the `eth_feeHistory` method. The blob gas used ratio is no longer a coefficient:

```
{
  ""jsonrpc"": ""2.0"",
  ""id"": 1,
  ""result"": {
    ""oldestBlock"": ""0x76ac95"",
    ""baseFeePerGas"": [
      ""0x17a2450f4"",
      ""0x16be16dff"",
      ""0x168412aff"",
      ""0x16cd1cde6"",
      ""0x157794815""
    ],
    ""gasUsedRatio"": [
      0.34914364543796966,
      0.4601405237392908,
      0.5506862222222222,
      0.26595780555555554
    ],
    ""baseFeePerBlobGas"": [
      ""0x26609f9"",
      ""0x27ea052"",
      ""0x27ea052"",
      ""0x2ce745d"",
      ""0x30924a1""
    ],
    ""blobGasUsedRatio"": [
      87381.33333333333,
      65536,
      131072,
      109226.66666666667
    ]
  }
}
```

The regression seems to have been created [here](https://github.com/ethereum/go-ethereum/commit/e6f3ce7b168b8f346de621a8f60d2fa57c2ebfb0#diff-3357b2399699d7cf954c543cbfb02ff442eb24491e55f5e813e3cc85829b3e8dR110)",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report details an error in the `eth_feeHistory` API method where the `blobGasUsedRatio` is calculated incorrectly. The report states this is a 'ratio error' and provides output values (e.g., 87381.33) that are not the expected coefficient format, which should likely be a value between 0 and 1, similar to the `gasUsedRatio` field. This directly points to a flaw in the internal computation logic that generates the API's output. This aligns perfectly with the definition of CWE-682, which states 'The product performs a calculation that generates incorrect or unintended results'. CWE-20 (Improper Input Validation) is less appropriate because the problem is not with validating the inputs to the API call, but with the processing that occurs after valid input is received. CWE-1389 (Incorrect Parsing of Numbers with Different Radices) is incorrect as the issue is not about misinterpreting input numbers of different bases, but about generating an incorrect output value through a flawed calculation.",closed,The bug in the `eth_feeHistory` method is due to a regression introduced in a recent commit. The blob gas used ratio is incorrectly calculated as a non-coefficient value instead of a proper ratio.,"This bug can lead to incorrect gas fee estimations for blob transactions, which may cause transaction failures or increased costs for users relying on accurate fee information.",2876253171,31245,"February 24, 2025 9:58 PM (GMT+8)","February 27, 2025 2:24 AM (GMT+8)",['type:bug'],
go-ethereum,goroutine leak in new metrics loop(),https://github.com/ethereum/go-ethereum/issues/31244,Utilities,"Using go-ethereum library as depednecy in my app for some types parsing. Not running geth rtc..
When upgrading from 1.14.11 to 1.15.2 the `goleak` started screaming.

Look like this PR https://github.com/ethereum/go-ethereum/pull/30814 introduced loop() goroutine that always stay active. there is no way to stop it. Also for the code that only refers dependency library for type parsing it's unclear why whole metrics system is initialized now.
 

#### System information
go-ethereum version: ` v1.15.2`

#### Expected behaviour

metrics are not initialized and no extra goroutines spawned

#### Actual behaviour

meter.go loop() keeps running in goroutine()

#### Steps to reproduce the behaviour

```
package main

import (
	""testing""

	""github.com/ethereum/go-ethereum/rpc""
	""go.uber.org/goleak""
)

func TestLeak(t *testing.T) {
	defer goleak.VerifyNone(t)
	println(rpc.LatestBlockNumber)
}

```

#### Backtrace

````
main_test.go:18: found unexpected goroutines:
        [Goroutine 3 in state chan receive, with github.com/ethereum/go-ethereum/metrics.(*meterTicker).loop on top of the stack:
        github.com/ethereum/go-ethereum/metrics.(*meterTicker).loop(0x104783420)
                /Users/demon/.gvm/pkgsets/go1.22.10/global/pkg/mod/github.com/ethereum/go-ethereum@v1.15.2/metrics/meter.go:159 +0x50
        created by github.com/ethereum/go-ethereum/metrics.(*meterTicker).add in goroutine 1
                /Users/demon/.gvm/pkgsets/go1.22.10/global/pkg/mod/github.com/ethereum/go-ethereum@v1.15.2/metrics/meter.go:145 +0xc8
````

When submitting logs: please submit them as text and not screenshots.
",general: general performance degradation,CWE-772,Missing Release of Resource after Effective Lifetime,"The bug report describes a 'goroutine leak' where a goroutine started for a metrics loop remains active indefinitely with no way to stop it. This is detected by the `goleak` tool, which specifically finds resources (goroutines) that are not cleaned up. Analyzing the provided CWEs:

1.  **CWE-772 (Missing Release of Resource after Effective Lifetime):** This CWE is the most accurate fit. A goroutine is a resource. The report explicitly states that the goroutine 'always stay active' and is never stopped, even after the code that triggered its creation has finished executing. This is a classic example of a resource not being released after its effective lifetime has ended, which is the definition of a resource leak.

2.  **CWE-400 (Uncontrolled Resource Consumption):** While a persistent goroutine leak can lead to uncontrolled resource consumption (memory and CPU scheduler time), CWE-400 describes the broader consequence. CWE-772 is more specific because it identifies the root cause of the problem: the *failure to release* the resource. The bug report focuses on the single leaked goroutine, which is a direct instance of a missing release, making CWE-772 a more precise classification of the bug itself.

3.  **CWE-665 (Improper Initialization):** The user notes that it's 'unclear why whole metrics system is initialized now', which points to a potential initialization issue. However, the core problem demonstrated by the `goleak` backtrace and the user's complaint is the *persistence* of the goroutine, not its initial state. The failure to terminate the resource is a more severe and direct problem than the fact that it was initialized unexpectedly. Therefore, the leak (missing release) is the primary weakness.

Conclusion: CWE-772 most precisely describes the reported bug of a leaked goroutine that is not terminated after it is no longer needed.",closed,"The introduction of a new goroutine in the metrics loop() that remains active without a mechanism to stop it, causing a goroutine leak.","The goroutine leak can lead to increased memory usage and potential performance degradation of the application over time, especially in scenarios where the metrics system is not needed or utilized.",2876180570,31244,"February 24, 2025 9:21 PM (GMT+8)","March 19, 2025 2:20 PM (GMT+8)","['type:bug', 'help wanted', 'good first issue']",
go-ethereum,`simulated.NewBackend` does not support Shanghai (`invalid opcode: PUSH0`),https://github.com/ethereum/go-ethereum/issues/31203,Execution,"#### System information

Geth version: `v1.14.13`
OS & Version: MacOS 14.1.2 (23B92)

#### Expected behaviour

A contract compiled with solc >0.8.19 is deployed using the `simulated.NewBackend(...)`.

#### Actual behaviour

An error `invalid opcode: PUSH0` is received.

#### Steps to reproduce the behaviour

1. Create bindings for a contract compiled with solc v0.8.20.
2. Create a simulated backend with default settings.
3. Use this simulated backend to deploy the contract.

Also, it was confirmed that if the contract is compiled with solc v0.8.19, it IS DEPLOYED successfully.

This may be related to https://github.com/ethereum/go-ethereum/issues/28144",evm: simulation inconsistency,CWE-670,Always-Incorrect Control Flow Implementation,"The bug report describes an issue where the `simulated.NewBackend` function, when called with its default settings, creates a simulated Ethereum environment that does not support the Shanghai hard fork. This leads to an `invalid opcode: PUSH0` error when trying to deploy contracts compiled with modern tools (solc >0.8.19), which utilize opcodes introduced in Shanghai. The core of the problem is that the default configuration of the resource (the simulated backend) is outdated and no longer compatible with the current ecosystem, causing failures. 

CWE-1188, 'Initialization of a Resource with an Insecure Default', is the best fit. The 'resource' is the simulated backend. It is 'initialized with a default' configuration that specifies a pre-Shanghai EVM version. This default is 'insecure' in the sense that it is no longer a safe or correct default for users of modern tools, leading to unexpected behavior and functional failures ('simulation inconsistency'). The default setting creates a discrepancy between the simulation and the current live network, which is a failure state.

CWE-693, 'Protection Mechanism Failure', is not applicable. The simulated backend is a testing and development tool, not a security protection mechanism. The bug is a functional failure due to an outdated default configuration, not a failure to defend against a directed attack.",closed,"The `simulated.NewBackend` does not handle the new opcodes introduced in the Shanghai upgrade, specifically the `PUSH0` opcode, leading to an error when deploying contracts compiled with newer versions of the Solidity compiler.","Contracts compiled with Solidity versions greater than 0.8.19 cannot be deployed using the simulated backend, which may hinder testing and development of new features or improvements that rely on these newer compiler versions.",2860333104,31203,"February 18, 2025 12:38 PM (GMT+8)","March 22, 2025 10:48 PM (GMT+8)","['type:bug', 'need more information']",
go-ethereum,Block production failure with v1.15.1: ethash does not support withdrawals,https://github.com/ethereum/go-ethereum/issues/31190,Consensus,"#### System information

Geth version: `Geth/v1.15.1-stable-b027a90a/linux-amd64/go1.23.6`
CL client & version: teku 25.2.0
OS & Version: Linux

#### Problem

I missed a mainnet block due to geth error

```
ERROR[***] Failed to build payload                  err=""ethash does not support withdrawals""
WARN [***] Served engine_forkchoiceUpdatedV3        conn=172.21.0.5:53158 reqid=190614 duration=5.883302ms err=""Invalid payload attributes"" errdata=""{\""err\"":\""ethash does not support withdrawals\""}""
```

from teku perspective:
```
Invalid remote response from the execution client: JSON-RPC error: Internal error (-38003): Invalid payload attributes
```


#### Startup params:
```
geth:
    image: ethereum/client-go:stable
    restart: always
    stop_grace_period: 5m
    command: [""--datadir"",""/opt/geth"",
              ""--http"",
              ""--http.addr"",""0.0.0.0"",
              ""--http.corsdomain"",""*"",
              ""--http.vhosts"",""*"",
              ""--syncmode"",""snap"",
              ""--port"",""30303"",
              ""--metrics"",
              ""--metrics.addr"",""0.0.0.0"",
              ""--authrpc.addr"",""0.0.0.0"",
              ""--authrpc.port"",""8551"",
              ""--authrpc.vhosts"",""*"",
              ""--authrpc.jwtsecret"",""/etc/ee-jwt-secret.hex"",
              ""--http.api"",""eth,net,engine,web3,txpool"",
              ""--state.scheme=path"",
              ""--cache"",""8192""]
```

",consensus: consensus liveness failure,CWE-436,Interpretation Conflict,"The bug report describes a failure in a multi-component system where an execution client (Geth, Product A) and a consensus client (Teku, Product B) interact. The consensus client sends a request to build a block that includes withdrawals, which is correct for the Proof-of-Stake (PoS) Ethereum mainnet. However, the execution client incorrectly processes this request under the assumption that the consensus mechanism is Ethash (Proof-of-Work), which does not support withdrawals. This leads to the error 'ethash does not support withdrawals' and a block production failure. This perfectly matches CWE-436 'Interpretation Conflict', where 'Product A handles inputs or steps differently than Product B, which causes A to perform incorrect actions based on its perception of B's state.' Here, Geth's perception of the chain's state (PoW) conflicts with the actual state and Teku's request (PoS), causing the failure.

CWE-682 'Incorrect Calculation' is less suitable because the issue is not a mathematical or numerical miscalculation but a logical error in determining the correct operational context (PoS vs. PoW).

CWE-841 'Improper Enforcement of Behavioral Workflow' is also unsuitable. The problem is not with the sequence of interactions between the clients, but with how one of the clients handles the data within a specific step of the workflow.",closed,"The Geth client version v1.15.1 is not compatible with the ethash consensus mechanism for processing withdrawal requests, leading to a failure in block production.","The inability to process withdrawals can result in missed blocks, potential loss of rewards for validators, and a negative impact on the overall network performance and reliability.",2856193877,31190,"February 16, 2025 4:23 PM (GMT+8)","February 17, 2025 7:36 PM (GMT+8)",['type:bug'],
go-ethereum,dumpconfig produces invalid NAT toml,https://github.com/ethereum/go-ethereum/issues/31183,Utilities,"#### System information
Geth version: `v1.15.1`

#### Expected behaviour
v1.15.0 added support to configuring `Node.P2P.NAT` in `config.toml`. 

Given a `config.toml` with a NAT value configured, one expects that `geth dumpconfig` would produce valid toml with the same NAT configured. 

#### Actual behaviour
It produces invalid toml that cannot be used a config.

#### Steps to reproduce the behaviour
config.toml:
```
[Node.P2P]
NAT = ""extip:1.2.3.4""
```

Run dumpconfig:
```
docker run --volume=./config.toml:/tmp/config.toml ethereum/client-go:v1.15.1 dumpconfig --config=/tmp/config.toml
```

Produces invalid toml that contains:
```

[Node.P2P.NAT]
Interface = ""extip:1.2.3.4""

```

Note that running dumpconfig with legacy `--nat=expip:1.2.3.4` cli flag the output is correct.",general: incorrect tooling output,CWE-116,Improper Encoding or Escaping of Output,"The bug report describes a situation where the `geth dumpconfig` command reads a valid TOML configuration file but produces an invalid TOML output. Specifically, a simple key-value pair `NAT = ""extip:1.2.3.4""` under the `[Node.P2P]` table is transformed into a new, incorrect table structure `[Node.P2P.NAT]` with a different key `Interface = ""extip:1.2.3.4""`. This output is described as 'invalid toml that cannot be used a config'. The core issue is the incorrect generation of a structured output format (TOML).

Let's evaluate the given CWEs:
- **CWE-704 (Incorrect Type Conversion or Cast):** This is a plausible but less precise fit. The root cause might involve an incorrect conversion of an internal configuration object back to its TOML representation. However, the primary manifestation of the bug is not just a type mismatch (like int to string) but a fundamental error in the output's structure.

- **CWE-436 (Interpretation Conflict):** This CWE is not suitable. It describes a conflict in how two different products interpret data. The bug here is internal to a single product (`geth`) and its `dumpconfig` utility. There is no interaction or misinterpretation between two separate products.

- **CWE-116 (Improper Encoding or Escaping of Output):** This is the most accurate CWE. The `dumpconfig` command is preparing a 'structured message' (the TOML output). The process of converting the in-memory configuration into a TOML string is a form of 'encoding'. This encoding is 'done incorrectly', which directly leads to the outcome that 'the intended structure of the message is not preserved'. The original structure of a key-value pair is lost and replaced by an incorrect and invalid table structure. This description perfectly matches the bug report.",closed,"The `dumpconfig` functionality in Geth fails to correctly validate or handle the NAT configuration in the provided `config.toml`, resulting in an incorrect output format.","The invalid output from `dumpconfig` prevents users from generating a valid configuration file, which could lead to misconfiguration of network settings and potential connectivity issues.",2853717342,31183,"February 14, 2025 1:23 PM (GMT+8)","February 17, 2025 4:47 PM (GMT+8)",['type:bug'],
go-ethereum,Valid peers dropped due to blob tx validation failure from another peer,https://github.com/ethereum/go-ethereum/issues/31162,Consensus,"#### System information

Geth version: 1.13.14-stable-c18a9e54
CL client: prysm
OS & Version: Amazon Linux 2

#### Expected behaviour
When multiple peers send transaction **announcements** (for a blob transaction with a sidecar), and then another peer later sends the **full transaction** but **without the sidecar**, leading to validation failure, **only the peer that sent the invalid full transaction should be dropped**.

#### Actual behaviour
Instead of only dropping the peer who sent the invalid full transaction, **all peers who previously announced the transaction (with the correct size) are also dropped** due to `Announced transaction size mismatch`.

#### Code Analysis
- In `tx_fetcher.go`, when an **announcement** arrives, it is stored in:
  - `f.waitslots`
  - `f.announced`
  - `f.waitlist`
  
- When the **full transaction** arrives via `Enqueue()`, it iterates over `f.addTxs()`, where it fails validation (`missing sidecar in blob transaction`).
- However, **despite the validation failure, the full transaction still proceeds to `f.cleanup`**.
- In `cleanup`, the **size check is applied to all peers** who previously announced the transaction, leading to their disconnection, **even though they never sent the invalid full transaction**.

#### Backtrace
```
TRACE[02-10|15:41:45.617] Transaction validation failed            hash=b0e4bf..d948a1 err=""missing sidecar in blob transaction""
WARN [02-10|15:41:45.617] Announced transaction size mismatch      peer=fe907eef61226eb98ffc181c2bb95b39881301efee838e8d4b4caf85ab7b1088 tx=b0e4bf..d948a1 size=221  ann=393,755
WARN [02-10|15:41:45.617] Announced transaction size mismatch      peer=3864397c93fd2efded8163377cc6d83090613df9443c70c93c1b6c70b302023f tx=b0e4bf..d948a1 size=221  ann=393,755
WARN [02-10|15:41:45.617] Announced transaction size mismatch      peer=2db63adf0aee55da89afd2004acf1e0324a90abed53084b87cc3da29bc84927b tx=b0e4bf..d948a1 size=221  ann=393,755
WARN [02-10|15:41:45.617] Announced transaction size mismatch      peer=9c111c7cd78469794e36786c3a5edaf3f1e0e4c008b55166ffdf086c5a18352b tx=b0e4bf..d948a1 size=221  ann=393,755
WARN [02-10|15:41:45.617] Announced transaction size mismatch      peer=b2825db6dbdb29807bfb405dad3fe887f1a60a0889ebfec0c575df3b9de08d31 tx=b0e4bf..d948a1 size=221  ann=393,755
```
````
",network: faulty peer management,CWE-755,Improper Handling of Exceptional Conditions,"The bug report describes a scenario where the system detects a transaction validation failure, which is an exceptional condition. The report explicitly states, 'Transaction validation failed... err=""missing sidecar in blob transaction""'. However, the code then proceeds incorrectly. As noted in the analysis, 'despite the validation failure, the full transaction still proceeds to f.cleanup'. This incorrect continuation of the logic path after an error is detected leads to the unintended consequence of dropping valid peers. This is a textbook example of improperly handling an exceptional condition. The system identifies the error but fails to manage the program's state and execution flow correctly in response. 

CWE-284 (Improper Access Control) is not applicable because the issue is not about an unauthorized actor accessing a resource; all peers are authorized participants in the network. The problem lies in the logic processing the data, not in access permissions.

CWE-400 (Uncontrolled Resource Consumption) is less accurate. While the outcome is a depletion of a resource (peer connections), this is a secondary effect. The root cause is not a failure to control resource allocation but the faulty error-handling logic that leads to the incorrect release of these resources. Therefore, CWE-755 is the most direct and accurate classification of the fundamental flaw.",closed,"The system incorrectly handles transaction validation failures by dropping all peers who announced a transaction, regardless of whether they sent an invalid transaction or not. This is because the cleanup process applies size checks to all peers involved in the announcement.","This bug can lead to unnecessary disconnections of valid peers, causing network instability and reducing the overall efficiency of the transaction propagation in the blockchain network.",2847565710,31162,"February 12, 2025 8:50 AM (GMT+8)","March 1, 2025 9:10 PM (GMT+8)",['type:bug'],
go-ethereum,simulated.Backend leaks goroutines,https://github.com/ethereum/go-ethereum/issues/31022,Others,"#### System information

Geth version: `v1.14.12`
OS & Version: MacOS

#### Expected behaviour

I'm in the process of writing tests that use the simulated backend and I want to make sure that _my_ code does not leak goroutines, so I'm using uber/goleak.

I noticed that uber/goleak reports that the simulated backend leaks goroutines. 

Given this test:

```go
package main

import (
        ""testing""

        ""github.com/ethereum/go-ethereum/core/types""
        ""github.com/ethereum/go-ethereum/ethclient/simulated""
        ""go.uber.org/goleak""
)

func TestSimulatedBackendLeak(t *testing.T) {
        defer goleak.VerifyNone(t)
        genesisData := types.GenesisAlloc{}
        simulatedBackend := simulated.NewBackend(genesisData)
        defer simulatedBackend.Close()
}
```

and the latest stable versions of go-ethereum and goleak at the time of writing:

```go
go 1.23.2

require (
        github.com/ethereum/go-ethereum v1.14.12
        go.uber.org/goleak v1.3.0
)
```

I expected no leaked goroutines to be reported by `goleak`.

#### Actual behaviour

I'm getting an error from goleak.
I expected that when `Close()` returns, all the goroutines started by the simulated backend are terminated. Instead I get this stacktrace:

```bash
✗ go test main_test.go
--- FAIL: TestSimulatedBackendLeak (0.45s)
    main_test.go:16: found unexpected goroutines:
        [Goroutine 3 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 4 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 5 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 6 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 7 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 8 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 9 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 10 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 11 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 12 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 13 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 14 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 15 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 16 in state chan receive, with github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache on top of the stack:
        github.com/ethereum/go-ethereum/core.(*txSenderCacher).cache(0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:63 +0x34
        created by github.com/ethereum/go-ethereum/core.newTxSenderCacher in goroutine 1
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/core/sender_cacher.go:55 +0x78
         Goroutine 29 in state chan receive, with github.com/ethereum/go-ethereum/eth/gasprice.NewOracle.func1 on top of the stack:
        github.com/ethereum/go-ethereum/eth/gasprice.NewOracle.func1()
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/eth/gasprice/gasprice.go:126 +0x78
        created by github.com/ethereum/go-ethereum/eth/gasprice.NewOracle in goroutine 51
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/eth/gasprice/gasprice.go:124 +0x8f0
         Goroutine 33 in state chan receive, with github.com/ethereum/go-ethereum/eth/filters.(*FilterAPI).timeoutLoop on top of the stack:
        github.com/ethereum/go-ethereum/eth/filters.(*FilterAPI).timeoutLoop(0x14000624750, 0x0?)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/eth/filters/api.go:93 +0x70
        created by github.com/ethereum/go-ethereum/eth/filters.NewFilterAPI in goroutine 51
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/ethereum/go-ethereum@v1.14.12/eth/filters/api.go:81 +0xe0
         Goroutine 99 in state select, with github.com/syndtr/goleveldb/leveldb.(*DB).mpoolDrain on top of the stack:
        github.com/syndtr/goleveldb/leveldb.(*DB).mpoolDrain(0x14000603180)
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20210819022825-2ae1ddf74ef7/leveldb/db_state.go:110 +0xe8
        created by github.com/syndtr/goleveldb/leveldb.openDB in goroutine 51
        	/Users/alexandrutopliceanu/go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20210819022825-2ae1ddf74ef7/leveldb/db.go:149 +0x3cc
        ]
FAIL
FAIL	command-line-arguments	0.875s
FAIL
```

#### Steps to reproduce the behaviour

I prepared a small repo showcasing the issue, https://github.com/topliceanu/simulatedbackendleak.
Run it with `go test main_test.go`.

#### Backtrace

See above 🆙 

When submitting logs: please submit them as text and not screenshots.
",general: general performance degradation,CWE-772,Missing Release of Resource after Effective Lifetime,"The bug report describes a situation where goroutines, which are a type of resource, are created by the `simulated.Backend`. These goroutines are expected to be terminated when the `simulatedBackend.Close()` method is called, which marks the end of the backend's useful life. However, the `goleak` tool demonstrates that these goroutines persist even after `Close()` has returned. This is a classic resource leak. 

Comparing this to the provided CWEs:
- CWE-400 (Uncontrolled Resource Consumption) is less accurate. While leaking goroutines does consume resources, the core issue described is not about an uncontrolled *rate* of allocation (like in a loop without limits), but rather a failure to deallocate a specific set of resources at the end of their lifecycle. The problem is the cleanup, not the allocation process itself.
- CWE-404 (Improper Resource Shutdown or Release) is a plausible candidate. The `Close()` function is performing an 'improper' shutdown because it doesn't successfully release all associated resources. 
- CWE-772 (Missing Release of Resource after Effective Lifetime) is the most precise fit. The 'resource' is the set of goroutines. Their 'effective lifetime' is the period during which the `simulatedBackend` is active. This lifetime ends when `Close()` is called. The bug is that the release of these goroutines is 'missing' after this point. This definition perfectly encapsulates the problem of a resource not being cleaned up when it is no longer needed.

Therefore, CWE-772 is the single most accurate classification because it specifically describes the failure to release a resource after its intended period of use has concluded.",closed,"The simulated backend in the Ethereum `go-ethereum` library does not properly clean up all goroutines when the `Close()` method is called, leading to leaks of goroutines.","Goroutine leaks can lead to increased memory usage, potential application slowdowns, and ultimately, server crashes if left unchecked, particularly under high-load scenarios.",2784821039,31022,"January 13, 2025 6:03 PM (GMT+8)","February 25, 2025 7:21 PM (GMT+8)",['type:bug'],
go-ethereum,`engine_newPayloadV3` RPC Method call,https://github.com/ethereum/go-ethereum/issues/31011,Execution,"#### System information

Geth version: `geth version`
CL client & version: e.g. lighthouse/nimbus/prysm@v1.0.0
OS & Version: Linux
Commit hash : (if `develop`)

#### Expected behaviour
RPC call should not break `geth` node running.

#### Actual behaviour
The issue occurred on `op-sepolia` running the [firehose](https://github.com/streamingfast/firehose-core/) tracer. It occurred randomly and it doesn't occur on each new block. It would break the firehose tracer if the method `engine_newPayloadV3` is called outside of the normal flow between EL <> CL.

#### Steps to reproduce the behaviour
Kinda hard to reproduce, it occurred randomly after weeks of running a node that had run as expected.
Also, once the node is restarted, it would work as expected without any issues. A hypothesis, would be that the issue could come from https://github.com/ethereum/go-ethereum/blob/master/beacon/blsync/engineclient.go#L95-L119 where there is an async go func running. 

#### Backtrace

```bash
""RPC method engine_newPayloadV3 crashed: caller expected to not be in transaction state but we were, this is a bug at block #22064228 (f15fe758377e046d2755bd92da341a86ca1e96f83667b2d8613f929c1798d14e) in transaction b03d74a6fd894daf8deae16893a4b2a0e00aed1d9066f167c50334442b2b54e8 (caller=github.com/ethereum/go-ethereum/eth/tracers/firehose.go:413, init=true, inBlock=true, inTransaction=true, inCall=false)\ngoroutine 210911285 [running]:\ngithub.com/ethereum/go-ethereum/rpc.(*callback).call.func1()\n\tgithub.com/ethereum/go-ethereum/rpc/service.go:199 +0x85\npanic({0x18858e0?, 0xc0a1b10e40?})\n\truntime/panic.go:770 +0x132\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).panicInvalidState(0xc0224a8000, {0x1bb3fa3, 0x49}, 0xc0a1b10de0?)\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:1488 +0x51d\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).ensureInBlockAndNotInTrx(0xc0224a8000)\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:1430 +0x45\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).OnBlockEnd(0xc0224a8000, {0x0, 0x0?})\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:413 +0x10c\ngithub.com/ethereum/go-ethereum/core.(*BlockChain).processBlock.func1()\n\tgithub.com/ethereum/go-ethereum/core/blockchain.go:1899 +0x2d\npanic({0x18858e0?, 0xc0a1b10dd0?})\n\truntime/panic.go:770 +0x132\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).panicInvalidState(0xc0224a8000, {0x1bb3fa3, 0x49}, 0x7f03e8609648?)\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:1488 +0x51d\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).ensureInBlockAndNotInTrx(0xc0224a8000)\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:1430 +0x45\ngithub.com/ethereum/go-ethereum/eth/tracers.(*Firehose).OnBeaconBlockRootStart(0xc0224a8000)\n\tgithub.com/ethereum/go-ethereum/eth/tracers/firehose.go:515 +0xa5\ngithub.com/ethereum/go-ethereum/core.ProcessBeaconBlockRoot({0x66, 0x3, 0x6b, 0x45, 0x9b, 0x4, 0x67, 0x49, 0x46, 0xbc, ...}, ...)\n\tgithub.com/ethereum/go-ethereum/core/state_processor.go:240 +0x94\ngithub.com/ethereum/go-ethereum/core.(*StateProcessor).Process(0xc0224900c0, 0xc063fc3600, 0xc0143f9500, {0xc018c65680, 0x0, 0x0, {0x0, 0x0, 0x0}, 0x0, ...})\n\tgithub.com/ethereum/go-ethereum/core/state_processor.go:80 +0x67a\ngithub.com/ethereum/go-ethereum/core.(*BlockChain).processBlock(0xc01da4c488, 0xc063fc3600, 0xc0143f9500, {0x0?, 0x28e7598?, 0x37560e0?}, 0x0)\n\tgithub.com/ethereum/go-ethereum/core/blockchain.go:1905 +0x2ce\ngithub.com/ethereum/go-ethereum/core.(*BlockChain).insertChain(0xc01da4c488, {0xc05d1c5680, 0x1, 0x1}, 0x0, 0x0)\n\tgithub.com/ethereum/go-ethereum/core/blockchain.go:1824 +0x1e57\ngithub.com/ethereum/go-ethereum/core.(*BlockChain).InsertBlockWithoutSetHead(0xc01da4c488, 0xc063fc3600, 0x0)\n\tgithub.com/ethereum/go-ethereum/core/blockchain.go:2379 +0xdb\ngithub.com/ethereum/go-ethereum/eth/catalyst.(*ConsensusAPI).newPayload(_, {{0x23, 0x42, 0xa9, 0xa5, 0x10, 0xd8, 0x55, 0xe7, 0x79, ...}, ...}, ...)\n\tgithub.com/ethereum/go-ethereum/eth/catalyst/api.go:946 +0x1ab7\ngithub.com/ethereum/go-ethereum/eth/catalyst.(*ConsensusAPI).NewPayloadV3(_, {{0x23, 0x42, 0xa9, 0xa5, 0x10, 0xd8, 0x55, 0xe7, 0x79, ...}, ...}, ...)\n\tgithub.com/ethereum/go-ethereum/eth/catalyst/api.go:622 +0x225\nreflect.Value.call({0xc0231a3e30?, 0xc023502110?, 0x80?}, {0x1b47329, 0x4}, {0xc087e14180, 0x4, 0xc087e14180?})\n\treflect/value.go:596 +0xca6\nreflect.Value.Call({0xc0231a3e30?, 0xc023502110?, 0x3?}, {0xc087e14180?, 0x16?, 0x16?})\n\treflect/value.go:380 +0xb9\ngithub.com/ethereum/go-ethereum/rpc.(*callback).call(0xc023504960, {0x28de358, 0xc091f70eb0}, {0xc0ae0a6e10, 0x13}, {0xc091f70f00, 0x3, 0x4e14cf?})\n\tgithub.com/ethereum/go-ethereum/rpc/service.go:205 +0x36d\ngithub.com/ethereum/go-ethereum/rpc.(*handler).runMethod(0xc01c444000?, {0x28de358?, 0xc091f70eb0?}, 0xc093b604d0, 0x3?, {0xc091f70f00?, 0x7f02c7a04998?, 0xc0a1b10cf0?})\n\tgithub.com/ethereum/go-ethereum/rpc/handler.go:568 +0x3c\ngithub.com/ethereum/go-ethereum/rpc.(*handler).handl ... bytes: 866
```

Could there be any issue with the `updateLoop` which would call `engine_newPayloadV3` on a fork or something which could cause the node to panic?
",api: api unavailability,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a crash that occurs randomly in a concurrent environment. The backtrace explicitly states the cause: 'caller expected to not be in transaction state but we were'. This indicates that two or more concurrent operations (goroutines, as mentioned in the report and seen in the stack trace) are accessing and modifying a shared state (the 'transaction state') without proper coordination. The random and intermittent nature of the bug is a classic symptom of a race condition, where the outcome depends on the non-deterministic timing of the concurrent operations. CWE-362, 'Race Condition', perfectly captures this scenario: there is a 'concurrent code sequence' accessing a 'shared resource' (the system state) with a 'timing window' that allows for inconsistent or unexpected modifications. CWE-662, 'Improper Synchronization', is a broader category; while technically correct, CWE-362 is more specific and accurately describes the root cause as a race. CWE-404 is incorrect as the issue is not related to the shutdown or release of a resource like memory or a file handle, but rather an inconsistent state due to concurrent access.",closed,"The bug arises from the `engine_newPayloadV3` RPC method being invoked while the node is in an unexpected transaction state, likely due to an asynchronous function not properly handling state transitions.","The panic caused by this bug can lead to the Geth node crashing, disrupting normal operations and potentially causing data inconsistencies or requiring a restart to restore functionality.",2778134305,31011,"January 9, 2025 3:29 PM (GMT+8)","January 20, 2025 4:46 PM (GMT+8)",['type:bug'],
go-ethereum,Incorrect recursive encoding of nested bytes arrays (`bytes[]`) in apitypes,https://github.com/ethereum/go-ethereum/issues/30979,Utilities,"#### System information

Geth version: v1.14.12
CL client & version: Not related
OS & Version: OSX
Commit hash : (if `develop`)

#### Expected behaviour

Encode successfully


#### Actual behaviour

Get error:
```
failed to pack and hash typedData primary type: provided data '65' doesn't match type 'bytes'
```


#### Steps to reproduce the behaviour

1. Consider a message with a field `sigs` of type `bytes[]` in Solidity. In Go, this is represented as `[][]uint8`.

2. The `func (typedData *TypedData) EncodeData(primaryType string, data map[string]interface{}, depth int)` method recursively encodes each field. When it encounters the `sigs` array, it correctly identifies it as an array due to the trailing ""]"" in the type string.
<img width=""619"" alt=""image"" src=""https://github.com/user-attachments/assets/d6b7749d-5b39-44cd-beca-771d12b0d532"" />

3. `encodeArrayValue` is called, receiving the `[][]uint8` as `arrayValue` and `bytes` as `parsedType` (correctly parsed from `bytes[]`).
<img width=""859"" alt=""image"" src=""https://github.com/user-attachments/assets/8ebd2e37-0af8-44ca-bd2a-b81a34f7bc35"" />

4. The problem arises within the loop of `encodeArrayValue`. Each item in `arrayValue` (which is a `[]uint8` representing a Solidity `bytes`) is incorrectly treated as another array. This triggers a recursive call to `encodeArrayValue`.
<img width=""616"" alt=""image"" src=""https://github.com/user-attachments/assets/be2e75f2-9403-428e-8f5a-4b45314f7eef"" />

5. In the second, erroneous `encodeArrayValue` call, the `[]uint8` is further split into individual `uint8` values. The `parsedType` remains `bytes` (because `strings.Split(""bytes"", ""["")[0]` is still `bytes`). This leads to an error because a single `uint8` cannot be parsed as `bytes`.

#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them as text and not screenshots.
",general: incorrect tooling output,CWE-704,Incorrect Type Conversion or Cast,"The bug report describes a flaw in a recursive encoding function. The function `encodeArrayValue` is designed to process arrays. When given an array of byte arrays (`bytes[]` in Solidity, `[][]uint8` in Go), it correctly processes the outer array. However, for each element of the outer array (which is a `[]uint8`, representing a single `bytes` value), the code incorrectly treats it as another array and makes a recursive call. This second, erroneous recursive call then attempts to process individual bytes (`uint8`) as if they were byte arrays (`bytes`). The error `provided data '65' doesn't match type 'bytes'` explicitly shows the system trying to handle a value of one type (`uint8`) as if it were another (`bytes`). This is a direct match for CWE-704's definition: 'The product does not correctly convert an object, resource, or structure from one type to a different type.' The core issue is the misinterpretation of the data's type during processing. CWE-20 is less suitable because the initial input data is valid for its type; the error is in the processing logic, not in the validation of the input. CWE-436 is not applicable as the bug is an internal logic error within a single software component, not an interpretation conflict between two different products.",closed,"The encoding function incorrectly treats elements of a nested `bytes[]` array as separate arrays during recursion, leading to failures when attempting to encode individual bytes as if they were still arrays.","This bug could prevent the successful encoding of data structures that include nested byte arrays, resulting in application errors and potential failures in data transmission or contract interactions.",2767076342,30979,"January 3, 2025 6:57 AM (GMT+8)","February 21, 2025 4:48 PM (GMT+8)",['type:bug'],
go-ethereum,Continuously changing configurations and restarting the node caused the node to panic during runtime.,https://github.com/ethereum/go-ethereum/issues/30968,Utilities,"#### System information

Geth
Version: 1.13.15-stable
Git Commit: c5ba367eb6232e3eddd7d6226bfd374449c63164
Git Commit Date: 20240417
Architecture: amd64
Go Version: go1.22.3
Operating System: linux
OS & Version: Ubuntu 22.04.3 LTS

#### Expected behaviour
After changing configurations, the node should not panic; at the very least, it should provide a friendly message to the user before panicking.

#### Actual behaviour
I repeatedly modified the configuration file and restarted the node. During one of the restarts, the node panicked at runtime. Below are the logs and error code from the node when the panic occurred.
![1735471549306](https://github.com/user-attachments/assets/3805f1f4-caee-4aa4-b777-0923dadde591)

#### Steps to reproduce the behaviour
I saved the node configuration file from when the panic occurred and attempted to reproduce the issue, but was unable to do so. However, the panic did indeed happen.
```
[Eth]
NetworkId = 123454321
SyncMode = ""snap""
EthDiscoveryURLs = []
SnapDiscoveryURLs = []
NoPruning = false
NoPrefetch = false
TxLookupLimit = 2350000
TransactionHistory = 2350000
LightPeers = 100
DatabaseFreezer = ""geth""
TrieCleanCache = 154
TrieDirtyCache = 256
TrieTimeout = 3600000000000
SnapshotCache = 102
Preimages = false
EnablePreimageRecording = false
RPCGasCap = 50000000
RPCEVMTimeout = 5000000000

[Eth.Miner]
GasFloor = 0
GasCeil = 30000000
GasPrice = 1000000000
Recommit = 2000000000
NewPayloadTimeout = 2000000000

[Eth.TxPool]
Locals = []
NoLocals = false
Journal = ""transactions.rlp""
Rejournal = 3600000000000
PriceLimit = 2684354560
PriceBump = 10
AccountSlots = 16
GlobalSlots = 1024
AccountQueue = 64
GlobalQueue = 1024
Lifetime = 10800000000000

[Eth.BlobPool]
Datadir = ""blobpool""
Datacap = 2684354560
PriceBump = 100

[Eth.GPO]
Blocks = 20
Percentile = 60
MaxHeaderHistory = 1024
MaxBlockHistory = 2000000000
MaxPrice = 500000000000
IgnorePrice = 2

[Node]
DataDir = ""node2""
IPCPath = ""geth.ipc""
HTTPHost = """"
HTTPPort = 8545
HTTPVirtualHosts = [""localhost""]
HTTPModules = [""net"", ""web3"", ""eth""]
AuthAddr = ""localhost""
AuthPort = 8552
AuthVirtualHosts = [""localhost""]
WSHost = """"
WSPort = 8546
WSModules = [""net"", ""web3"", ""eth""]
GraphQLVirtualHosts = [""localhost""]
BatchRequestLimit = 1000
BatchResponseMaxSize = 25000000

[Node.P2P]
MaxPeers = 50
NoDiscovery = false
DiscoveryV4 = true
BootstrapNodes = [""enode://736e6c1b287d08e0508cec7ef0bbcf307dd1ce96018c5fc368b2f20c30231135877d79f286c08c8f3ed53122064e9b972ccb58e789572eca5281597190cd2258@127.0.0.1:0?discport=30305""]
BootstrapNodesV5 = [""enode://736e6c1b287d08e0508cec7ef0bbcf307dd1ce96018c5fc368b2f20c30231135877d79f286c08c8f3ed53122064e9b972ccb58e789572eca5281597190cd2258@127.0.0.1:0?discport=30305""]
StaticNodes = []
TrustedNodes = []
ListenAddr = "":30307""
DiscAddr = """"

[Node.HTTPTimeouts]
ReadTimeout = 30000000000
ReadHeaderTimeout = 30000000000
WriteTimeout = 30000000000
IdleTimeout = 120000000000

[Metrics]
HTTP = ""127.0.0.1""
Port = 6060
InfluxDBDatabase = ""geth""
InfluxDBUsername = ""test""
InfluxDBPassword = ""test""
InfluxDBTags = ""host=localhost""
InfluxDBToken = ""test""
InfluxDBBucket = ""geth""
InfluxDBOrganization = ""geth""
```

#### Backtrace

````
INFO [10-24|20:27:14.910] Starting Geth on Ethereum mainnet...
INFO [10-24|20:27:14.911] Bumping default cache on mainnet         provided=1024 updated=4096
INFO [10-24|20:27:14.912] Maximum peer count                       ETH=50 total=50
INFO [10-24|20:27:14.914] Smartcard socket not found, disabling    err=""stat /run/pcscd/pcscd.comm: no such file or directory""
INFO [10-24|20:27:14.920] Set global gas cap                       cap=50,000,000
INFO [10-24|20:27:14.920] Initializing the KZG library             backend=gokzg
INFO [10-24|20:27:14.958] Allocated trie memory caches             clean=614.00MiB dirty=1024.00MiB
INFO [10-24|20:27:14.958] Using pebble as the backing database
INFO [10-24|20:27:14.958] Allocated cache and file handles         database=/root/test/fuzznode/node2/geth/chaindata cache=2.00GiB handles=524,288
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0xc70911]

goroutine 1 [running]:
github.com/ethereum/go-ethereum/core/rawdb.NewFreezer({0xc001266300, 0x29}, {0x195bf96, 0x11}, 0x0, 0x77359400, 0xc000693e90)
	github.com/ethereum/go-ethereum/core/rawdb/freezer.go:99 +0x231
github.com/ethereum/go-ethereum/core/rawdb.NewChainFreezer(...)
	github.com/ethereum/go-ethereum/core/rawdb/freezer.go:82
github.com/ethereum/go-ethereum/core/rawdb.newChainFreezer({0xc001266300?, 0x23?}, {0x195bf96?, 0x10?}, 0x10?)
	github.com/ethereum/go-ethereum/core/rawdb/chain_freezer.go:56 +0x2f
github.com/ethereum/go-ethereum/core/rawdb.NewDatabaseWithFreezer({0x7f53ad68efa0, 0xc0003217d0}, {0xc001266120, 0x23}, {0x195bf96, 0x11}, 0x0)
	github.com/ethereum/go-ethereum/core/rawdb/database.go:203 +0x85
github.com/ethereum/go-ethereum/core/rawdb.Open({{0x0, 0x0}, {0xc0012660f0, 0x28}, {0xc001266120, 0x23}, {0x195bf96, 0x11}, 0x800, 0x80000, ...})
	github.com/ethereum/go-ethereum/core/rawdb/database.go:414 +0xbe
github.com/ethereum/go-ethereum/node.(*Node).OpenDatabaseWithFreezer(0xc0003382a0, {0x1951146, 0x9}, 0x800, 0x80000, {0xc000577601, 0x4}, {0x195bf96, 0x11}, 0x0)
	github.com/ethereum/go-ethereum/node/node.go:760 +0x338
github.com/ethereum/go-ethereum/eth.New(0xc0003382a0, 0xc0001dc708)
	github.com/ethereum/go-ethereum/eth/backend.go:132 +0x505
github.com/ethereum/go-ethereum/cmd/utils.RegisterEthService(0xc0003382a0, 0x1958a2e?)
	github.com/ethereum/go-ethereum/cmd/utils/flags.go:1863 +0x25
main.makeFullNode(0xc0007cc040)
	github.com/ethereum/go-ethereum/cmd/geth/config.go:180 +0x212
main.geth(0xc0007cc040)
	github.com/ethereum/go-ethereum/cmd/geth/main.go:340 +0x125
github.com/urfave/cli/v2.(*Command).Run(0xc0006906e0, 0xc0007cc040, {0xc000290330, 0x3, 0x3})
	github.com/urfave/cli/v2@v2.25.7/command.go:274 +0x93f
github.com/urfave/cli/v2.(*App).RunContext(0xc000016b40, {0x1ebe4b8, 0x2c51580}, {0xc000290330, 0x3, 0x3})
	github.com/urfave/cli/v2@v2.25.7/app.go:332 +0x566
github.com/urfave/cli/v2.(*App).Run(...)
	github.com/urfave/cli/v2@v2.25.7/app.go:309
main.main()
	github.com/ethereum/go-ethereum/cmd/geth/main.go:270 +0x45

````

When submitting logs: please submit them as text and not screenshots.
",storage: storage persistence failure,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a panic that occurs intermittently when the node is repeatedly restarted with configuration changes. The final error is a `panic: runtime error: invalid memory address or nil pointer dereference`, which directly corresponds to the definition of CWE-476. However, CWE-476 describes the symptom (the crash) rather than the root cause. The conditions required to trigger the bug—repeated restarts and an inability to reproduce it consistently—strongly suggest a timing-related issue. This scenario points to a race condition where the new node process starts and attempts to access a shared resource (such as the database, as indicated by the stack trace) before the previous process has fully shut down and released it. This contention between the concurrent shutdown and startup operations over a shared resource is the definition of CWE-362. CWE-404 (Improper Resource Shutdown or Release) is also plausible, as it could be the mechanism that enables the race condition, but CWE-362 ('Race Condition') more accurately captures the overall weakness, including the concurrency and timing aspects that make the bug intermittent. Therefore, CWE-362 is the most accurate classification of the underlying vulnerability.",closed,The node panicked due to a runtime error caused by a null pointer dereference during the initialization of the database after continuously changing configurations and restarting the node.,"This bug may lead to unexpected crashes in the node during runtime, which could interrupt service availability and potentially cause data inconsistencies or loss if not handled gracefully.",2762210508,30968,"December 29, 2024 11:26 AM (GMT+8)","January 6, 2025 2:52 PM (GMT+8)",['type:bug'],
go-ethereum,Bug in `eth_simulateV1` JSON-RPC: Can not simulate historical transaction as expected.,https://github.com/ethereum/go-ethereum/issues/30950,API,"#### System information

Geth version: `Version: 1.14.13-unstable
CL client & version: e.g. lighthouse/
OS & Version: Linux

#### Expected behaviour

I am trying to use `eth_simulateV1 ` api to simulate historical transactions and I meet unexpected revert. Here is my code:

```typescript

import axios from ""axios"";
import { parseUnits } from ""viem"";

async function main() {
  const response = await axios.post(
    'http://localhost:8545',
    {
      'jsonrpc': '2.0',
      'method': 'eth_simulateV1',
      'params': [
        {
          'blockStateCalls': [
            {

              'calls': [
                {
                  'from': '0x8e90675E889fcf027d47B04D859aA537f7052626',
                  'to': '0x00000688768803Bbd44095770895ad27ad6b0d95',
                  'maxFeePerGas': '0x' + parseUnits('7.725034766', 9).toString(16),
                  'data': '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'
                },
              ]
            }
          ],
          ""traceTransfers"":true,
        },
        '0x' + (21457054).toString(16)
      ],
      'id': 1
    },
    {
      headers: {
        'Content-Type': 'application/json'
      }
    }
  );
  console.log('get response:', response)
  console.log('result:', JSON.stringify(response.data.result, null, 4))
  let txStatus = parseInt(response.data.result[0].calls[0].status, 16)
  if (txStatus) {
    console.log('success !')
    console.log('gas used:', response.data.result[0].gasUsed)
  }
  else {
    console.log('failed')
  }
}
main()

```

This transaction is a [trx to fill 1inch order](https://etherscan.io/tx/0xf7810b64e2030592428849a2d4c9006923224d3ac0225feaaa5c34272480b6da) and has been included in block 21457055. 
The simulation result is below and this error is caused by the price slippage. I guess this may be caused by uncorrect setting of block timestamp environment variable.
```json
    {
        ""baseFeePerGas"": ""0x0"",
        ""blobGasUsed"": ""0x0"",
        ""calls"": [
            {
                ""returnData"": ""0x"",
                ""logs"": [],
                ""gasUsed"": ""0xe89d"",
                ""status"": ""0x0"",
                ""error"": {
                    ""message"": ""execution reverted"",
                    ""code"": -32000,
                    ""data"": ""0xfb8ae129""
                }
            }
        ],
        ""difficulty"": ""0x0"",
        ""excessBlobGas"": ""0x1f20000"",
        ""extraData"": ""0x"",
        ""gasLimit"": ""0x1c9c380"",
        ""gasUsed"": ""0xe89d"",
        ""hash"": ""0x1b3a217ed483cc9cfecc737756fed458763a3aaffb9266f04484fd22e6a9453b"",
        ""logsBloom"": ""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
        ""miner"": ""0x4838b106fce9647bdf1e7877bf73ce8b0bad5f97"",
        ""mixHash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        ""nonce"": ""0x0000000000000000"",
        ""number"": ""0x147689f"",
        ""parentBeaconBlockRoot"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        ""parentHash"": ""0xc8d4bcd2f1558f9c7a4648644969348f31aae36fc048be1b4d984e89ef51d9c5"",
        ""receiptsRoot"": ""0x482f6b57b3028ec19a3effce63f4d43ee181ff999fd4a026a118dbd672b8e8e4"",
        ""sha3Uncles"": ""0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347"",
        ""size"": ""0x8e7"",
        ""stateRoot"": ""0x87bb2cb73962353c90f6c75b75df6ca2025a4cdcd94bd7eca365c9a7b3bd1b0f"",
        ""timestamp"": ""0x6767d780"",
        ""transactions"": [
            ""0x5c839cd87d99b65d1fb4b48128868b1ecfcd9cba283c9929fe66f71d9027c87f""
        ],
        ""transactionsRoot"": ""0x5653fefe5c891487778f72908f50c1d51ff3435214010fcd376adf62df3161a6"",
        ""uncles"": [],
        ""withdrawals"": [],
        ""withdrawalsRoot"": ""0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421""
    }
```

#### Actual behaviour
The transaction has been included in block. Therefore, the simulation result should be successful.

#### Steps to reproduce the behaviour

You can use my code to test, if the state is expired, please use archive node.

",api: incorrect api output,CWE-20,Improper Input Validation,"The user is reporting a bug in the `eth_simulateV1` API where simulating a historical transaction yields a failure, contrary to the user's expectation that it should succeed because the transaction was eventually included in the blockchain. The user suspects an incorrect environmental setup for the simulation, specifically mentioning the block timestamp. The core of the issue is that the API, given a set of inputs (transaction data and a historical block number), is allegedly not processing them correctly to produce the right output. 

Let's evaluate the provided CWEs:
- CWE-693 (Protection Mechanism Failure): This is incorrect. The bug report describes a functional issue with an API's output, not a failure of a security control like authentication, authorization, or encryption.
- CWE-1389 (Incorrect Parsing of Numbers with Different Radices): This is too specific and unlikely. The user provides a block number in hexadecimal format. While a parsing error is possible, the user's suspicion points to a broader issue with setting up the simulation environment (the timestamp), not just a simple number parsing error. There is no direct evidence of a radix-related misinterpretation.
- CWE-20 (Improper Input Validation): This is the best fit. The definition states that the product 'does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' In this context, the input is the block number and transaction details. The system is allegedly failing to use this input to 'correctly' process the simulation. It's not setting up the historical state accurately (as per the user's claim about the timestamp), leading to an incorrect result. This is a failure to correctly process the input to ensure correct program behavior, which is the essence of CWE-20.",closed,"The `eth_simulateV1` API fails to accurately simulate historical transactions, likely due to incorrect environmental settings, such as block timestamps, which affects state conditions during simulation.","This bug can lead to developers receiving misleading results when simulating transactions, causing them to misinterpret transaction behavior and potentially leading to the execution of faulty or unintended transactions in a live environment.",2754583965,30950,"December 22, 2024 10:09 AM (GMT+8)","January 9, 2025 5:37 PM (GMT+8)",['type:bug'],
go-ethereum,block import is broken with verkle,https://github.com/ethereum/go-ethereum/issues/30878,Storage,"Following a successful `geth init` with a custom genesis block, `geth import` will fail.

It goes off the rails, checking if the triedb has been `Initialized` at https://github.com/ethereum/go-ethereum/blob/master/core/genesis.go#L295

`Initialized` will go over the layers, and what happens is that there is only one layer, and it's keyed with `types.EmptyRootHash`, which is not a valid node value for verkle. In fact, the tree itself shouldn't be empty to begin with, so this value should not show up, regardless of whether or not verkle is supported:

```
(dlv) print tree.layers
map[github.com/ethereum/go-ethereum/common.Hash]github.com/ethereum/go-ethereum/triedb/pathdb.layer [
	[86,232,31,23,27,204,85,166,255,131,69,230,146,192,248,110,91,72,224,27,153,108,173,192,1,98,47,181,227,99,180,33]: *github.com/ethereum/go-ethereum/triedb/pathdb.diskLayer {
		root: github.com/ethereum/go-ethereum/common.Hash [86,232,31,23,27,204,85,166,255,131,69,230,146,192,248,110,91,72,224,27,153,108,173,192,1,98,47,181,227,99,180,33],
		id: 0,
		db: *(*""github.com/ethereum/go-ethereum/triedb/pathdb.Database"")(0xc0001c7590),
		nodes: *(*""github.com/VictoriaMetrics/fastcache.Cache"")(0xc00046e000),
		buffer: *(*""github.com/ethereum/go-ethereum/triedb/pathdb.buffer"")(0xc0004de860),
		stale: false,
		lock: (*sync.RWMutex)(0xc000333844),}, 
]
```

The culprit is `loadLayers()`, which will call `ReadAccountTrieNode`, which will in turn return `nil`. As a result, it will create a new empty layer using `EmptyRootHash` as a root.",storage: storage persistence failure,CWE-665,Improper Initialization,"The bug report describes a failure in `geth import` that originates from an incorrect state of the `triedb`. The root cause is identified in the `loadLayers` function. When this function calls `ReadAccountTrieNode` and receives a `nil` return value, it proceeds to incorrectly initialize a new, empty layer using `EmptyRootHash`. This action leaves the `triedb` resource in an invalid and unexpected state for a verkle tree, causing subsequent operations to fail. This sequence of events directly matches the definition of CWE-665, where a resource is incorrectly initialized, leaving it in an unexpected state.

CWE-252 (Unchecked Return Value) is less appropriate because the code does not ignore the return value of `ReadAccountTrieNode`. Instead, it reacts to the `nil` value, but the reaction itself is flawed, leading to the improper initialization. The value is checked, but handled incorrectly.

CWE-20 (Improper Input Validation) is too general. While the `nil` return could be considered an 'input' to the next stage of logic, the fundamental problem described is the resulting incorrect state of a critical resource during its setup phase. CWE-665 is more specific to the problem's manifestation as a faulty initialization.",closed,"The issue arises from the `loadLayers()` function which calls `ReadAccountTrieNode`, returning `nil` when it encounters an empty Verkle tree. This leads to the creation of a new empty layer with `EmptyRootHash`, which is not a valid state.","This bug prevents successful block imports when using a custom genesis block with Verkle support, potentially halting blockchain operations and leading to data inconsistencies or failures in node synchronization.",2726637348,30878,"December 9, 2024 10:33 AM (GMT+8)","February 6, 2025 5:47 PM (GMT+8)",['type:bug'],
go-ethereum,SimulatedBackend: Transaction after rollback requires empty block commit,https://github.com/ethereum/go-ethereum/issues/30842,Consensus,"#### System information

Geth version: v1.14.12 (Gei Hinnom)
OS & Version: OSX

#### Expected behaviour
After rolling back a transaction in the simulated backend, subsequent transactions should be processed normally without requiring an empty block commit.

#### Actual behaviour
In [v1.14.12](https://github.com/ethereum/go-ethereum/releases/tag/v1.14.12), after rolling back a transaction, subsequent transactions require an empty block commit to be processed successfully. Without the empty block commit, the transaction receipt cannot be obtained. This behavior does not occur in v1.14.11, where transactions after rollback work normally.

#### Steps to reproduce the behaviour
1. This issue is present in v1.14.12 but not in v1.14.11
2. The test below demonstrates the issue. Run the test with `go test`:

**Test code**
`ethclient/simulated/rollback_test.go`

```go
package simulated

import (
	""context""
	""testing""
	""time""

	""github.com/ethereum/go-ethereum/core/types""
)

// TestTransactionRollbackBehavior verifies the behavior of transactions
// in the simulated backend after rollback operations.
//
// The test demonstrates that after a rollback:
//  1. The first test shows normal transaction processing without rollback
//  2. The second test shows that transactions immediately after rollback fail
//  3. The third test shows a workaround: committing an empty block after rollback
//     makes subsequent transactions succeed
func TestTransactionRollbackBehavior(t *testing.T) {
	sim := simTestBackend(testAddr)
	defer sim.Close()
	client := sim.Client()

	t.Run(""Case 1: Basic Transaction (Control Case)"", func(t *testing.T) {
		// Demonstrates normal transaction processing works as expected
		tx := testSendSignedTx(t, sim)
		sim.Commit()
		assertSuccessfulReceipt(t, client, tx)
	})

	t.Run(""Case 2: Transaction After Rollback (Shows Issue)"", func(t *testing.T) {
		// First transaction gets rolled back
		_ = testSendSignedTx(t, sim)
		sim.Rollback()

		// Attempting to process a new transaction immediately after rollback
		// Currently, this case fails to get a valid receipt
		tx := testSendSignedTx(t, sim)
		sim.Commit()
		assertSuccessfulReceipt(t, client, tx)
	})

	t.Run(""Case 3: Transaction After Rollback with Empty Block (Workaround)"", func(t *testing.T) {
		// First transaction gets rolled back
		_ = testSendSignedTx(t, sim)
		sim.Rollback()

		// Workaround: Commit an empty block after rollback
		sim.Commit()

		// Now the new transaction succeeds
		tx := testSendSignedTx(t, sim)
		sim.Commit()
		assertSuccessfulReceipt(t, client, tx)
	})
}

// testSendSignedTx sends a signed transaction to the simulated backend.
// It does not commit the block.
func testSendSignedTx(t *testing.T, sim *Backend) *types.Transaction {
	t.Helper()
	client := sim.Client()
	ctx := context.Background()

	signedTx, err := newTx(sim, testKey)
	if err != nil {
		t.Fatalf(""failed to create transaction: %v"", err)
	}

	if err = client.SendTransaction(ctx, signedTx); err != nil {
		t.Fatalf(""failed to send transaction: %v"", err)
	}

	return signedTx
}

// assertSuccessfulReceipt verifies that a transaction was successfully processed
// by checking its receipt status.
func assertSuccessfulReceipt(t *testing.T, client Client, tx *types.Transaction) {
	t.Helper()
	ctx := context.Background()

	var (
		receipt *types.Receipt
		err     error
	)

	// Poll for receipt with timeout
	deadline := time.Now().Add(2 * time.Second)
	for time.Now().Before(deadline) {
		receipt, err = client.TransactionReceipt(ctx, tx.Hash())
		if err == nil && receipt != nil {
			break
		}
		time.Sleep(100 * time.Millisecond)
	}

	if err != nil {
		t.Fatalf(""failed to get transaction receipt: %v"", err)
	}
	if receipt == nil {
		t.Fatal(""transaction receipt is nil"")
	}
	if receipt.Status != types.ReceiptStatusSuccessful {
		t.Fatalf(""transaction failed with status: %v"", receipt.Status)
	}
}
```

**Output:**
```sh
Running tool: /opt/homebrew/bin/go test -timeout 30s -run ^TestTransactionRollbackBehavior$ github.com/ethereum/go-ethereum/ethclient/simulated

--- FAIL: TestTransactionRollbackBehavior (2.04s)
    --- FAIL: TestTransactionRollbackBehavior/Case_2:_Transaction_After_Rollback_(Shows_Issue) (2.02s)
        /Users/geth-dev/go-ethereum/ethclient/simulated/issue_test.go:40: failed to get transaction receipt: not found
FAIL
FAIL	github.com/ethereum/go-ethereum/ethclient/simulated	2.438s
FAIL
```

#### Backtrace

N/A - This is a test behavior issue, not a crash.",consensus: consensus inefficiency,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a failure in the `Rollback()` function of a `SimulatedBackend`. This function is intended to revert the state of the simulated blockchain, effectively discarding recent changes. After the rollback, the backend is left in an inconsistent state, preventing new transactions from being processed correctly. This requires a workaround (committing an empty block) to clean up the state and make the backend usable again.

Let's analyze the provided CWEs:
- **CWE-665 (Improper Initialization):** This CWE concerns the initial state of a resource. The problem here is not with the initial creation of the `SimulatedBackend`, but with its state *after* a `Rollback()` operation. While the rollback leads to an improperly configured state for the *next* operation, the root cause is the failure of the rollback process itself, not the initial setup. Therefore, this is not the best fit.
- **CWE-682 (Incorrect Calculation):** This CWE applies to bugs where a calculation produces a wrong numerical or logical result. The described bug is a failure in state management and process flow, not a specific calculation error. This CWE is not applicable.
- **CWE-404 (Improper Resource Shutdown or Release):** This is the most accurate CWE. The state of the `SimulatedBackend` can be considered a resource. The `Rollback()` operation is analogous to releasing or resetting this resource (the state changes from the last transaction) to make it available for re-use by subsequent transactions. The bug report clearly shows that this 'release' process is improper. The resource is not correctly reset, leaving it in a state where it cannot be re-used until an extra cleanup step is performed. This perfectly aligns with the definition of not releasing a resource correctly before it is made available for re-use.",closed,"The simulated backend does not properly handle the state after a transaction rollback, requiring an empty block commit for subsequent transactions to be processed successfully.","Subsequent transactions after a rollback fail to obtain receipts unless an empty block is committed, leading to potential inconsistencies in transaction processing and user experience issues in applications relying on the simulated backend.",2710357035,30842,"December 2, 2024 3:33 AM (GMT+8)","January 16, 2025 9:40 PM (GMT+8)",['type:bug'],
go-ethereum,"`evm run --bench` segfaults in `Fatalf` ",https://github.com/ethereum/go-ethereum/issues/30778,Execution,"The following command: 

`evm run --bench --nomemory=false --noreturndata=false --codefile - --prestate /tmp/genesis.json --sender 0000000000000000000000000000000000000000 --input cde4efa9`

`/tmp/genesis.json`:
```
{
    ""config"": {
        ""chainId"": 420420420,
        ""homesteadBlock"": 0,
        ""eip150Block"": 0,
        ""eip155Block"": 0,
        ""eip158Block"": 0,
        ""byzantiumBlock"": 0,
        ""constantinopleBlock"": 0,
        ""petersburgBlock"": 0,
        ""istanbulBlock"": 0,
        ""berlinBlock"": 0,
        ""londonBlock"": 0,
        ""arrowGlacierBlock"": 0,
        ""grayGlacierBlock"": 0,
        ""shanghaiTime"": 0,
        ""cancunTime"": 0,
        ""terminalTotalDifficulty"": 0,
        ""terminalTotalDifficultyPassed"": true
    },
    ""coinbase"": ""0x0000000000000000000000000000000000000000"",
    ""difficulty"": ""0x20000"",
    ""extraData"": """",
    ""gasLimit"": ""0xffffffff"",
    ""nonce"": ""0x0000000000000042"",
    ""mixhash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
    ""parentHash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
    ""timestamp"": ""0x00"",
    ""alloc"": {
        ""0101010101010101010101010101010101010101"": {
            ""balance"": ""1000000000""
        },
        ""0202020202020202020202020202020202020202"": {
            ""balance"": ""1000000000""
        },
        ""0303030303030303030303030303030303030303"": {
            ""balance"": ""1000000000""
        }
    }
}
```
Fixture:
`6080604052348015600e575f80fd5b50600436106026575f3560e01c8063cde4efa914602a575b5f80fd5b60306032565b005b5f8054906101000a900460ff16155f806101000a81548160ff02191690831515021790555056fea264697066735822122046c92dd2fd612b1ed93d184dad4c49f61c44690722c4a6c7c746ebeb0aadeb4a64736f6c63430008190033`

Results in:
```
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xd205a0]

goroutine 59 [running]:
testing.(*common).decorate(0x20?, {0xc0002d0080, 0x20}, 0xc000300008?)
	testing/testing.go:775 +0xa0
testing.(*common).logDepth(0xc00036f408, {0xc0002d0080, 0x20}, 0x3)
	testing/testing.go:1042 +0x1dc
testing.(*common).log(...)
	testing/testing.go:1011
testing.(*common).Fatalf(0xc00036f408, {0x140c196?, 0x140aa06?}, {0xc00002ff20?, 0xc00002ff00?, 0x2?})
	testing/testing.go:1089 +0x54
main.timedExec.func1(0xc00036f408)
	github.com/ethereum/go-ethereum/cmd/evm/runner.go:97 +0x2ea
testing.(*B).runN(0xc00036f408, 0x1)
	testing/benchmark.go:193 +0xf0
testing.(*B).run1.func1()
	testing/benchmark.go:215 +0x48
created by testing.(*B).run1 in goroutine 1
	testing/benchmark.go:208 +0x90
```

The bug is introduced with this PR: https://github.com/ethereum/go-ethereum/pull/30442/files#diff-48d6c3d5b7c9c1d0bd83fa0d5ac8fe38ce3ce34aaf39f22d00e84fcf61b249b4

The lines in the stack trace do seem off too.",evm: simulation inconsistency,CWE-476,NULL Pointer Dereference,"The bug report's stack trace provides the most critical piece of evidence for classification. The panic message explicitly states: `panic: runtime error: invalid memory address or nil pointer dereference`. This is a direct and unambiguous description of the fault. Furthermore, the signal `[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xd205a0]` confirms a segmentation fault, with the address `0x0` being the canonical address for a NULL pointer.

Comparing this evidence to the provided CWEs:
- **CWE-476 (NULL Pointer Dereference):** The official description is ""The product dereferences a pointer that it expects to be valid but is NULL."" This perfectly matches the panic message from the bug report. The evidence is direct and requires no inference.
- **CWE-665 (Improper Initialization):** While a NULL pointer dereference is often a *symptom* of improper initialization, classifying it as such would be an inference about the root cause. The bug report itself only provides evidence of the dereference, not the reason the pointer was NULL. Therefore, CWE-476 is a more direct and accurate classification of the observable fault.
- **CWE-703 (Improper Check or Handling of Exceptional Conditions):** The crash occurs within the `Fatalf` function, which is used to handle fatal errors. This indicates a failure within the exception handling logic. However, CWE-476 describes the *specific* programming error that caused this failure. When a more specific CWE accurately describes the fault, it is preferred over a more general one. The specific fault here is the NULL pointer dereference.

Therefore, CWE-476 is the single most accurate classification as it precisely describes the immediate technical cause of the crash as documented in the bug report.",closed,"The bug is caused by a nil pointer dereference in the `Fatalf` function of the testing package, likely due to improper handling of a struct or variable that was expected to be initialized but is instead nil.","This issue can lead to a segmentation fault (segfault), causing the application to crash when the command `evm run --bench` is executed. This impacts the reliability and stability of the EVM (Ethereum Virtual Machine) execution environment.",2678881720,30778,"November 21, 2024 10:16 AM (GMT+8)","November 26, 2024 11:12 PM (GMT+8)",['type:bug'],
go-ethereum,The `prestateTracer` under `diffMode` does not return all the storage diffs.,https://github.com/ethereum/go-ethereum/issues/30774,API,"#### System information

Geth version: 1.14.12
OS & Version: Linux

#### Expected behavior

Hi! I'm trying to debug the transaction using `debug_traceTransaction`. I use the built-in `prestateTracer` and enable `diffMode`. I notice in the `post` section of the returned result, an address that should have been modified was ignored.

The following modifications occurred after executing the transaction `setRational(-34342247582603709930262480515100532418408549587488298634819624648327228197968,54)`

```
0x0000000000000000000000000000000000000000000000000000000000000000 
 -> 0xb412fa0861bb1532171e2f7e6d88df75e8bb79d4ba10674f506b1d13a2d973b0
0x0000000000000000000000000000000000000000000000000000000000000001
 -> 0x0000000000000000000000000000000000000000000000000000000000000036
```

The `debug_traceTransaction` RPC call returned the correct result. However, if I continue to execute the transaction `setRational(0,-3686082785242131774829242764878224605745458421934561058325782450253198843211)`. The state modification should be:

```
0x0000000000000000000000000000000000000000000000000000000000000000
 -> 0x0000000000000000000000000000000000000000000000000000000000000000
0x0000000000000000000000000000000000000000000000000000000000000001 
 -> 0xf7d9c0469c411e6b7d7863011ce7f3f258685e4ce99f5467f28c3598787722b5
```

However, `debug_traceTransaction` only returned one modification in the post section: `{'0x0000000000000000000000000000000000000000000000000000000000000001': '0xf7d9c0469c411e6b7d7863011ce7f3f258685e4ce99f5467f28c3598787722b5'}`. It ignored the modification of `0x0000000000000000000000000000000000000000000000000000000000000000`.

```solidity
pragma  abicoder v2;

contract TestRational {
  struct Rational { int256 numerator; int256 denominator;  }

  Rational r;

  function getRational() public returns(Rational memory) {
    return r;
  }

  function setRational(int256 num, int256 denom) public {
    require(denom != 0, hex""44656e6f6d696e61746f722063616e6e6f74206265207a65726f"");
    r.numerator = num;
    assembly  { { if 0x10000000001 { } } }
    bytes32 v_69452 = keccak256(abi.encodePacked(msg.sender));
    r.denominator = denom;
  }

  constructor () {
    r.numerator = -1;
    r.denominator = 2;
  }

}
```

```python
trace = w3.manager.request_blocking('debug_traceTransaction', [tx_hash, {'tracer':'prestateTracer','tracerConfig': {'diffMode': True}}])
```

Result:

```
AttributeDict({'post': AttributeDict({'0x0000000000000000000000000000000000000000': AttributeDict({'balance': '0x355dacaa5c6e'}), '0x5c9776deac45c8b416239604cd8850d5dc81d3fb': AttributeDict({'storage': AttributeDict({'0x0000000000000000000000000000000000000000000000000000000000000001': '0xf7d9c0469c411e6b7d7863011ce7f3f258685e4ce99f5467f28c3598787722b5'})}), '0xbe931d46286d4e27217d57d1a4672b4d536e46fd': AttributeDict({'balance': '0xfffffffffffffffffffffffffffffffffffffffffffffffffffe84c17977809d', 'nonce': 3})}), 'pre': AttributeDict({'0x0000000000000000000000000000000000000000': AttributeDict({'balance': '0x2f9aa6ccc4bb'}), '0x5c9776deac45c8b416239604cd8850d5dc81d3fb': AttributeDict({'balance': '0x0', 'code': '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', 'nonce': 1, 'storage': AttributeDict({'0x0000000000000000000000000000000000000000000000000000000000000000': '0xb412fa0861bb1532171e2f7e6d88df75e8bb79d4ba10674f506b1d13a2d973b0', '0x0000000000000000000000000000000000000000000000000000000000000001': '0x0000000000000000000000000000000000000000000000000000000000000036'})}), '0xbe931d46286d4e27217d57d1a4672b4d536e46fd': AttributeDict({'balance': '0xfffffffffffffffffffffffffffffffffffffffffffffffffffe9c276179cd9e', 'nonce': 2})})})
```",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report describes a situation where the `prestateTracer` in `diffMode` fails to report all state changes that occurred during a transaction. Specifically, it omits a storage slot modification. This component's purpose is to calculate the difference between the state before and after a transaction. The reported bug shows that this calculation is flawed, leading to an incomplete and therefore incorrect result. This directly aligns with CWE-682, which describes a product performing a calculation that generates incorrect or unintended results. The tracer's output is a calculated result, and in this case, it is demonstrably wrong. CWE-436 is not applicable as the issue is internal to a single component (Geth's tracer) and not an interpretation conflict between two different products. CWE-754 is less fitting because the core issue is not a failure to check for an exceptional condition, but rather the incorrectness of the primary calculation itself. The bug doesn't cause a crash or an unhandled exception; it silently produces incorrect data, which is the essence of an 'Incorrect Calculation' weakness.",closed,"The `prestateTracer` is not correctly capturing all state changes occurring during the execution of the transaction in `diffMode`, particularly ignoring certain storage modifications.","This bug can lead to incomplete debugging information, making it difficult for developers to trace state changes accurately. It could hinder the debugging process and potentially allow undetected state modifications, leading to issues in smart contract execution and integrity.",2677841331,30774,"November 21, 2024 3:19 AM (GMT+8)","December 17, 2024 4:12 PM (GMT+8)",['type:bug'],
go-ethereum,cmd/abigen:  either `--abi` or `--combined-json` should be required.,https://github.com/ethereum/go-ethereum/issues/30768,Utilities,"Opening this to remind myself to ensure it's fixed.

Running `cmd/abigen/abigen --pkg my_package example.json` (erroneously omitting the `--abi` flag) generates an empty binding.  If `abigen` is run without specifying `--combined-json` or `--abi`, it should fail explicitly.",general: incorrect tooling output,CWE-20,Improper Input Validation,"The bug report describes a scenario where the `abigen` command-line tool produces incorrect output (an empty binding) because it is run with an invalid combination of arguments. The report explicitly states that the tool should fail if neither the `--abi` nor the `--combined-json` flag is provided. This is a classic case of improper input validation. The command-line flags and arguments are the 'input' to the program. The program fails to 'validate' that this input has the 'properties that are required to process the data safely and correctly'—namely, the presence of one of the two required flags. 

CWE-20 (Improper Input Validation) is the most accurate fit because the core issue is the failure to check the provided command-line arguments before proceeding with execution. 

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is less suitable. While an invalid argument set could be considered an 'exceptional condition,' CWE-20 is more specific to the root cause, which is the validation of data received from an upstream component (the user via the command line). 

CWE-252 (Unchecked Return Value) is not applicable as the bug report does not mention any function or method whose return value is being ignored. The failure occurs at the argument parsing and validation stage.",closed,The `abigen` command does not enforce required parameters (`--abi` or `--combined-json`) leading to the generation of an empty binding when they are omitted.,"Users may unintentionally create invalid or unusable bindings, leading to confusion and potential issues in application development.",2671399111,30768,"November 19, 2024 9:14 AM (GMT+8)","January 21, 2025 2:12 PM (GMT+8)",['type:bug'],
go-ethereum,Etherscan inconsistent,https://github.com/ethereum/go-ethereum/issues/30593,API,"This might not be a problem with go-ethereum, but I'm raising it here because issues are a pretty good discussion format. Also because it may turn out to be related to geth anyway, if geth is used under the hood. 

Is an internal transfer `0.1 ETH` or `0.01 ETH`?

The transaction [`0x96dfd56413baf7ee53483d5d6788ea5faa621ee6bb7d4b8808408d1f07f72bf8`](https://etherscan.io/tx/0x96dfd56413baf7ee53483d5d6788ea5faa621ee6bb7d4b8808408d1f07f72bf8) to contract [`0x897a96deb94291b785faff64088f7202a019f38e`](https://etherscan.io/address/0x897a96deb94291b785faff64088f7202a019f38e), shows on etherscan as if it makes an internal tx to ""MevRefunder"" of `0.01 ETH`. 

![Screenshot 2024-10-14 at 08-25-39 Ethereum Transaction Hash (Txhash) Details Etherscan](https://github.com/user-attachments/assets/4469c705-e123-4e62-bac8-99c96e187895)
 
Also the ""internal transactions"" show the same

![Screenshot 2024-10-14 at 08-27-35 Ethereum Transaction Hash (Txhash) Details Etherscan](https://github.com/user-attachments/assets/b1ceb2fe-4bb8-4340-a430-34fad2740fda)

-----------


However, looking at the state changes, it becomes clear that `0.1` has been transferred: 

![Screenshot 2024-10-14 at 08-27-03 Ethereum Transaction Hash (Txhash) Details Etherscan](https://github.com/user-attachments/assets/b98dbe04-b220-487d-a116-d02778ef2da7)

Also, checking the parity-style trace shows `0.1`.: 

![Screenshot 2024-10-14 at 08-28-45 Etherscan Transaction VMTrace And Debug](https://github.com/user-attachments/assets/5eb29cd1-a5ad-4025-8b1c-96eb7e391625)

",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report highlights a discrepancy where different parts of the Etherscan interface display conflicting values for the same internal transaction. The main transaction view shows a transfer of `0.01 ETH`, while the state change view and the trace view show the correct value of `0.1 ETH`. This is a classic example of an 'Interpretation Conflict' as defined by CWE-436, where one component (the main UI) handles or interprets the underlying blockchain data differently from other components (the state trace/debug view), leading to an incorrect representation. While an 'Incorrect Calculation' (CWE-682) has occurred to produce the wrong value, the fundamental issue described is the *conflict* between different interpretations within the system. CWE-193 is incorrect because the error is a factor of 10, not an off-by-one error.",closed,"The discrepancy between the reported transaction amount on Etherscan and the actual amount transferred suggests a potential issue in how internal transactions are recorded or displayed, possibly related to the handling of Ethereum's state changes or API responses.","This inconsistency could lead to confusion among users about the actual amount transferred, potentially resulting in financial misunderstandings or mistrust in the platform's reliability.",2584928373,30593,"October 14, 2024 6:32 AM (GMT+8)","October 25, 2024 11:32 AM (GMT+8)",['type:bug'],
go-ethereum,eth_getLogs fails to get logs,https://github.com/ethereum/go-ethereum/issues/30516,API,"#### System information

Geth version: `v1.14.9-amd64`
CL client & version: `prysm@v5.0.4`
OS & Version: Linux
Commit hash : N/A

#### Expected behaviour
This request should return an empty array
```
curl --location 'localhost:8545' --header 'Content-Type: application/json' --data '{
    ""method"": ""eth_getLogs"",
    ""params"": [
        {
            ""blockHash"": ""0x2acd4a70f418203eb43b3731a4fe96927e1c109a6a8e2c3d8d21d6d9af8f66db""
        }
    ],
    ""id"": 1,
    ""jsonrpc"": ""2.0""
}'
```

#### Actual behaviour
It returns
```
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32000,""message"":""failed to get logs for block #1022389 (0x2acd4a..8f66db)""}}
```

#### Steps to reproduce the behaviour
Issue this request to geth
```
curl --location 'localhost:8545' --header 'Content-Type: application/json' --data '{
    ""method"": ""eth_getLogs"",
    ""params"": [
        {
            ""blockHash"": ""0x2acd4a70f418203eb43b3731a4fe96927e1c109a6a8e2c3d8d21d6d9af8f66db""
        }
    ],
    ""id"": 1,
    ""jsonrpc"": ""2.0""
}'
```

#### Backtrace

````
ERROR[09-19|17:53:52.290] Invalid receipt array RLP                hash=2acd4a..8f66db err=""rlp: expected input list for []*types.Log, decoding into ([]*rawdb.receiptLogs)[0](rawdb.storedReceiptRLP).Logs""
WARN [09-19|17:53:52.290] Served eth_getLogs                       conn=127.0.0.1:57742 reqid=1 duration=""261.545µs"" err=""failed to get logs for block #1022389 (0x2acd4a..8f66db)""
````

When submitting logs: please submit them as text and not screenshots.
",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The user's bug report describes a scenario where a valid API request to `eth_getLogs` results in an unexpected server error instead of the expected empty array. The provided backtrace pinpoints the cause: `Invalid receipt array RLP ... err=""rlp: expected input list...""`. This indicates that the server encountered malformed data while trying to deserialize a block receipt from its internal storage. This deserialization failure is an exceptional condition.

Let's evaluate the provided CWEs:
- **CWE-1286 (Improper Validation of Syntactic Correctness of Input):** This is not the best fit. The user's input (the JSON-RPC request) is syntactically correct and is processed by the server. The error occurs when the server processes pre-existing, internal data, not the direct user input.
- **CWE-502 (Deserialization of Untrusted Data):** This is a strong candidate because a deserialization error is the trigger. However, the deserialization function itself appears to be working correctly by identifying the malformed data and throwing an error. The weakness is not that the deserializer accepts bad data, but rather how the application code reacts to this error.
- **CWE-703 (Improper Check or Handling of Exceptional Conditions):** This is the most accurate CWE. The deserialization error is a classic 'exceptional condition'. The bug report's 'Expected behaviour' (return an empty array) versus 'Actual behaviour' (return a server error) clearly demonstrates that the application fails to handle this exception gracefully. Instead of catching the error and returning a valid, albeit empty, response, the application lets the error propagate, causing the API call to fail. This is a direct example of improper handling of an exceptional condition.",closed,"The API call to `eth_getLogs` fails due to an invalid receipt array, indicating an issue with the data structure expected during the decoding process.","This bug can lead to applications that depend on log retrieval for specific blocks to malfunction, potentially causing data inconsistencies or failures in transaction tracking and event handling.",2551768178,30516,"September 27, 2024 12:35 AM (GMT+8)","October 2, 2024 2:09 AM (GMT+8)",['type:bug'],
go-ethereum,err: gas limit reached (supplied gas 9223372036854775807),https://github.com/ethereum/go-ethereum/issues/30467,API,"#### System information

Geth version: `1.14.9`
CL client & version: `Prysm@v5.1.0`
OS & Version: `Linux`

#### Expected behaviour
eth_call returns the response normally

#### Actual behaviour
```bash
INFO [09-19|20:29:30.936] rpc response                             method=eth_call logId=5 err=""err: gas limit reached (supplied gas 9223372036854775807)"" result=""\""0x\"""" attempt=0 args=""[{\""from\"":\""0x0000000000000000000000000000000000000000\"",\""input\"":\""0xe8eb1dc3\"",\""to\"":\""0x211e1c4c7f1bf5351ac850ed10fd68cffcf6c21b\""}, \""latest\""]"" errorData=null
ERROR[09-19|20:29:30.936] error fetching MaxDataSize from sequencer inbox err=""err: gas limit reached (supplied gas 9223372036854775807)""
```

#### Steps to reproduce the behaviour
Prysm Command:
```bash
/opt/ethmain/core/beacon-chain --mainnet --chain-id=1 --network-id=1 --checkpoint-sync-url=https://sync-mainnet
.beaconcha.in --execution-endpoint=http://127.0.0.1:8551 --jwt-secret=/mnt/ethmain/node/jwt.hex --datadir=/mnt/ethmain/node/prysm/beacon --enable-historical-state-representation
--suggested-fee-recipient=0xcDA9D71bdfAe59b89Cee131eD3079f8AC4c77062 --http-mev-relay=http://127.0.0.1:18550 --rpc-host=0.0.0.0 --rpc-port=4000 --rpc-max-page-size=200000 --http-
modules=prysm,eth --grpc-gateway-host=0.0.0.0 --grpc-gateway-port=3500 --grpc-gateway-corsdomain=* --grpc-max-msg-size=268435456 --p2p-tcp-port=13000 --p2p-udp-port=12000 --disab
le-monitoring --accept-terms-of-use
```

Geth Command:
```bash
/opt/ethmain/core/geth --config=/mnt/ethmain/conf/config.toml --rpc.gascap=0 --rpc.txfeecap=0
```
The version of Geth before we upgraded was 1.14.5，When I remove the `--rpc.gascap=0 --rpc.txfeecap=0` parameter, the node responds normally, but the 0 value is unlimited in meaning ah!

",api: api unavailability,CWE-20,Improper Input Validation,"The bug report describes a scenario where setting a configuration parameter, `--rpc.gascap`, to `0` causes unexpected behavior. The user intends for `0` to mean 'unlimited', but the application fails, returning a 'gas limit reached' error for a very large supplied gas value (`9223372036854775807`, which is the maximum signed 64-bit integer). The issue is resolved by removing the parameter, which implies the application's default handling is correct, but its handling of the explicit `0` input is flawed. This is a classic example of CWE-20 (Improper Input Validation), as the software receives an input (`0`) but does not correctly process it according to its special, intended meaning ('unlimited'), leading to an incorrect and unsafe state. While CWE-190 (Integer Overflow or Wraparound) might be involved due to the large number, the root cause described is the system's failure to correctly interpret the configuration input, which is an input validation problem. CWE-704 (Incorrect Type Conversion or Cast) is less likely as there is no direct evidence of a faulty cast; the issue stems from the program's logic based on the input value.",closed,"The gas limit for RPC calls is set to an excessively high value (9223372036854775807), which is not handled correctly by the system, leading to the error when the limit is reached.","This bug can cause failures in transaction execution and retrieval of results from the RPC interface, potentially leading to denial of service for users attempting to make calls that exceed the gas limit.",2536450623,30467,"September 19, 2024 2:03 PM (GMT+8)","September 23, 2024 7:31 PM (GMT+8)",['type:bug'],
go-ethereum,Simulated backend `Fork` & blockchain `SetHead` don't emit removed logs event,https://github.com/ethereum/go-ethereum/issues/30448,Consensus,"#### System information

Geth version: `1.14.8`

#### Expected behaviour

When the simulated backend `Fork(parentHash common.Hash)` is called, the necessary removed logs event should be emitted has it would on non-simulated backend.

On the old simulated backend (before #28202 was merged) we were using `(bc *BlockChain) InsertChain(chain types.Blocks)` to simulate chain reorgs under similar conditions, and did not face this issue. However, in the new simulated backend we don't have access anymore to the `blockchain` (it's not exported) and can only use the `Fork` function.

Note that the `Fork` function call the `BlockChain.SetHead(head uint64)` function which may be the source of the issue.

#### Actual behaviour

Removed logs event are not emitted.

#### Steps to reproduce the behaviour

Create a simulated backend
Deploy a contract that can emit logs
Subscribe to logs
Call a function that emit logs
Call the `Fork(parentHash common.Hash)` to the block before the last event was emitted
The logs subscription will not yield any removed logs event.
",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report describes a discrepancy between how a simulated environment and a real environment handle the same operation. Specifically, the simulated backend's `Fork` function, which simulates a chain reorg, does not emit a 'removed logs event', whereas a real, non-simulated backend would. This perfectly aligns with the definition of CWE-436: Interpretation Conflict. In this context, 'Product A' is the simulated backend, and 'Product B' is the real (non-simulated) backend. The simulated backend (A) handles the reorg step differently than the real backend (B), causing an incorrect outcome for the user who expects the simulation to mirror reality. CWE-703 is less suitable because while a reorg is an exceptional condition, the core of the issue is the *difference* in behavior between two systems, not just a generic failure to handle an exception. CWE-682 is incorrect as the bug is not related to an incorrect mathematical calculation but rather a failure to trigger a required event.",closed,"The new simulated backend does not emit removed logs events when using the Fork function, as it does not have access to the blockchain to handle log removal correctly.","This issue can lead to inconsistencies in event handling, as clients relying on log subscriptions will not be notified about removed logs, potentially causing confusion or incorrect state representation in applications using the blockchain.",2530702688,30448,"September 17, 2024 10:09 AM (GMT+8)","September 30, 2024 8:46 PM (GMT+8)",['type:bug'],
go-ethereum,Simulated backend Rollback() function should set gas tip back to the parameter passed by config,https://github.com/ethereum/go-ethereum/issues/30429,Consensus,"#### System information

Geth version: `1.14.8`
OS & Version: OSX

#### Expected behaviour

Calling the `Rollback()` function on the simulated backend should set gas tip back to parameter passed by config as it was the case before https://github.com/ethereum/go-ethereum/pull/28202 was merged.

#### Actual behaviour

Currently the gas tip is arbitrary set to 1 Gwei after calling the `Rollback()` function, which is not even the default config parameter (1 wei). 

There is a TODO in the code left by @MariusVanDerWijden here:
https://github.com/ethereum/go-ethereum/blob/a9523b6428238a762e1a1e55e46ead47630c3a23/eth/catalyst/simulated_beacon.go#L276-L277

#### Steps to reproduce the behaviour

1) Create a new simulated client with the default values. 
2) Call Rollback()
3) Make a TX using the suggested gas tip.

You will get the error `transaction underpriced: gas tip cap 1000000, minimum needed 1000000000`.

",evm: incorrect gas calculation,CWE-682,Incorrect Calculation,"The bug report describes a function, `Rollback()`, that incorrectly sets the `gas tip` to a hardcoded value (1 Gwei) instead of restoring it to the value specified in the configuration. This action is a form of calculation or state assignment. The resulting incorrect `gas tip` value is then used in subsequent transaction processing, which is a form of resource management (gas pricing). This leads to transaction failures due to an 'underpriced' error. This scenario directly matches the definition of CWE-682, where the product 'performs a calculation that generates incorrect or unintended results that are later used in... resource management.' The bug report's own symptom, 'incorrect gas calculation,' further reinforces this choice.

CWE-453 (Insecure Default Variable Initialization) is less accurate because the issue is not with the initial default value of the variable when the system starts, but with an incorrect state change performed by a specific function (`Rollback()`) during runtime.

CWE-20 (Improper Input Validation) is not applicable as the `Rollback()` function's flaw is in its internal logic, not in how it processes external input.",closed,The Rollback() function in the simulated backend incorrectly sets the gas tip to a hardcoded value of 1 Gwei instead of reverting it back to the configuration parameter specified by the user.,"This bug can lead to transaction failures due to the gas tip being set incorrectly, causing transactions to be underpriced and preventing users from successfully executing transactions in the simulated environment.",2524036141,30429,"September 13, 2024 7:06 AM (GMT+8)","November 25, 2024 12:02 PM (GMT+8)",['type:bug'],
go-ethereum,blsync does not expand tilde for home,https://github.com/ethereum/go-ethereum/issues/30304,Utilities,"I think the following should work:

```console
$ go run ./cmd/blsync --sepolia --beacon.api=https://xxx.io --beacon.checkpoint=$(curl -X 'GET' -H 'accept: application/json' 'https://xxx.io/eth/v1/beacon/headers/finalized' | jq -r "".data.root"") --blsync.engine.api=http://localhost:8551 --blsync.jwtsecret=~/.ethereum/sepolia/geth/jwtsecret
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   667  100   667    0     0   1400      0 --:--:-- --:--:-- --:--:--  1398
Fatal: Error loading or generating JWT secret: open ~/.ethereum/sepolia/geth/jwtsecret: no such file or directory
exit status 1
```",general: general improper authorization,CWE-436,Interpretation Conflict,"The bug report describes a program, `blsync`, that fails when given a file path starting with a tilde (`~`). The program attempts to open the path literally (e.g., `./~/.ethereum/...`) instead of expanding the tilde to the user's home directory (e.g., `/home/user/.ethereum/...`). This leads to a 'no such file or directory' error. The core of the issue is a discrepancy in how the path string is interpreted.

- **CWE-73 (External Control of File Name or Path)** is not the best fit. The problem is not that the user can control the path—that is the intended functionality of the command-line flag. The weakness is in the program's *processing* of a specific, conventional path format, not the external control itself.

- **CWE-20 (Improper Input Validation)** is a possible but overly general classification. The failure to expand the tilde can be seen as a failure to correctly process or validate the input. However, a more specific CWE is available.

- **CWE-436 (Interpretation Conflict)** is the most accurate choice. The definition states, 'Product A handles inputs or steps differently than Product B'. In this case, the `blsync` program (Product A) interprets the `~` character literally, which is different from how a standard command-line shell (Product B) or the user would interpret it. This conflict in interpretation is the direct cause of the bug, as the program performs an incorrect action (trying to open a non-existent file) based on its misinterpretation of the input string's meaning.",closed,"The application does not correctly expand the tilde (~) character to the user's home directory, which results in a file path that the program cannot locate.","This bug prevents users from successfully loading their JWT secret file, which could lead to authentication failures and hinder the normal operation of the application.",2468000296,30304,"August 15, 2024 12:55 PM (GMT+8)","November 7, 2024 1:24 AM (GMT+8)",['type:bug'],
go-ethereum,abi.JSON ERROR:unsupported arg type: INameService,https://github.com/ethereum/go-ethereum/issues/30266,Utilities,"#### System information

github.com/ethereum/go-ethereum v1.13.14

#### Expected behaviour
Success to unmarshal the ABI

#### Actual behaviour
ERROR: unsupported arg type: INameService

#### Steps to reproduce the behaviour
You could find this ABI from [Etherscan](https://etherscan.io/address/0x7ab6E3B49769c330caE585c6C3d298F327769920#code)
```go
func TestUnmarshalABI(t *testing.T){
	jsonData := `[{""inputs"":[{""components"":[{""internalType"":""uint256"",""name"":""dailyLimit"",""type"":""uint256""},{""internalType"":""uint256"",""name"":""txLimit"",""type"":""uint256""},{""internalType"":""uint256"",""name"":""accountDailyLimit"",""type"":""uint256""},{""internalType"":""uint256"",""name"":""minAmount"",""type"":""uint256""},{""internalType"":""bool"",""name"":""onlyWhitelisted"",""type"":""bool""}],""internalType"":""struct IMessagePassingBridge.BridgeLimits"",""name"":""bridgeLimits"",""type"":""tuple""},{""components"":[{""internalType"":""uint256"",""name"":""lastTransferReset"",""type"":""uint256""},{""internalType"":""uint256"",""name"":""bridged24Hours"",""type"":""uint256""}],""internalType"":""struct IMessagePassingBridge.AccountLimit"",""name"":""accountDailyLimit"",""type"":""tuple""},{""components"":[{""internalType"":""uint256"",""name"":""lastTransferReset"",""type"":""uint256""},{""internalType"":""uint256"",""name"":""bridged24Hours"",""type"":""uint256""}],""internalType"":""struct IMessagePassingBridge.BridgeDailyLimit"",""name"":""bridgeDailyLimit"",""type"":""tuple""},{""internalType"":""contract INameService"",""name"":""nameService"",""type"":""INameService""},{""internalType"":""bool"",""name"":""isClosed"",""type"":""bool""},{""internalType"":""address"",""name"":""from"",""type"":""address""},{""internalType"":""uint256"",""name"":""amount"",""type"":""uint256""}],""name"":""canBridge"",""outputs"":[{""internalType"":""bool"",""name"":""isWithinLimit"",""type"":""bool""},{""internalType"":""string"",""name"":""error"",""type"":""string""}],""stateMutability"":""view"",""type"":""function""},{""inputs"":[{""internalType"":""uint256"",""name"":""amount"",""type"":""uint256""},{""internalType"":""uint8"",""name"":""decimals"",""type"":""uint8""}],""name"":""normalizeFrom18ToTokenDecimals"",""outputs"":[{""internalType"":""uint256"",""name"":""normalized"",""type"":""uint256""}],""stateMutability"":""pure"",""type"":""function""},{""inputs"":[{""internalType"":""uint256"",""name"":""amount"",""type"":""uint256""},{""internalType"":""uint8"",""name"":""decimals"",""type"":""uint8""}],""name"":""normalizeFromTokenTo18Decimals"",""outputs"":[{""internalType"":""uint256"",""name"":""normalized"",""type"":""uint256""}],""stateMutability"":""pure"",""type"":""function""}]`
	result, err := abi.JSON(strings.NewReader(jsonData))
	if err != nil {
		t.Fatal(""ERROR:"", err)
	}
	fmt.Println(""result:"", result)
}
```

Is there a way to directly deserialize this kind of ABI from Etherscan? It seems that the ABI obtained from Etherscan is missing some information.
Related PR: #24572, #27551
",general: incorrect tooling output,CWE-20,Improper Input Validation,"The bug report describes a failure in the `abi.JSON` function when it attempts to parse a JSON string representing a contract's Application Binary Interface (ABI). The function throws an error, `unsupported arg type: INameService`, indicating that it encountered a type value (`INameService`) within the input JSON that it does not recognize or know how to process. This is a direct example of CWE-20 (Improper Input Validation). The software receives input, but its validation logic is not sufficient to correctly handle all possible valid data from its operational ecosystem (in this case, an ABI provided by Etherscan). The program's parser incorrectly deems the input invalid because its set of supported types is incomplete.

CWE-754 (Improper Check for Unusual or Exceptional Conditions) is not the best fit because the code *does* check for the unsupported type and handles it by throwing an error. The issue is not a failure to check, but rather the strictness of the check itself.

CWE-436 (Interpretation Conflict) is a possible candidate, as there is a difference in how `go-ethereum` and the source of the ABI (Etherscan/Solidity) represent custom types. However, CWE-20 is more fundamental and direct. The immediate cause of the bug is the failure of the input validation/parsing routine within the `go-ethereum` library. The interpretation conflict is the underlying reason for the validation failure, but the bug itself manifests as a validation problem.",closed,"The issue arises from the inability of the ABI unmarshalling process to recognize the 'INameService' contract type specified in the ABI, which is not well-defined or supported in the ABI standard used by the code.","This bug can lead to a failure in contract interaction, preventing the successful unmarshalling of the ABI and thus hindering functionality that relies on the 'INameService' type. This could potentially cause applications to crash or behave unexpectedly when trying to use this ABI.",2447636312,30266,"August 5, 2024 5:32 AM (GMT+8)","August 20, 2024 6:26 PM (GMT+8)","['type:bug', 'help wanted', 'good first issue']",
go-ethereum,`cmd/evm` returns incorrect value for sender address when executing opcode `BALANCE`,https://github.com/ethereum/go-ethereum/issues/30254,Execution,"#### System information

Geth version: `evm version 1.14.5-stable-0dd173a7 ` and ` evm version 1.14.8-unstable-de6d5976 `
CL client & version: Nope
OS & Version: Ubuntu 20.04
Commit hash : Nope

#### Expected behaviour

Hello developers,

I'm currently testing EVM implementations and have encountered a peculiar issue. When executing the `BALANCE` opcode (0x31), if the address specified by `--sender` is the same as the address at the top of the stack, the EVM appears to return a balance of 0 instead of the actual balance from `genesis.json`.

#### Steps to reproduce the behaviour

I used the latest version of geth image pulled from dockerhub to reproduce this bug. 

```
docker pull ethereum/client-go:alltools-latest
docker run ethereum/client-go:alltools-latest tail -f /dev/null
docker exec -it containerid /bin/sh
```

This is the `genesis.json` file for `--prestate`, which sets the balance of address `0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f` to `0xffffffffffffffffffffffffffffffffffffffff`.

```json
{
  ""config"": {
    ""chainId"": 9599,
    ""homesteadBlock"": 0,
    ""eip150Block"": 0,
    ""eip155Block"": 0,
    ""eip158Block"": 0,
    ""byzantiumBlock"": 0,
    ""constantinopleBlock"": 0,
    ""petersburgBlock"": 0,
    ""istanbulBlock"": 0,
    ""berlinBlock"": 0,
    ""londonBlock"": 0,
    ""shanghaiBlock"": 0,
    ""shanghaiTime"":0
  },
  ""alloc"": {
    ""0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f"": {
     ""balance"": ""0x1234""
    }
  },
  ""coinbase"": ""0x000000000000000000000000000000000000abcd"",
  ""difficulty"": ""0x0"",
  ""extraData"": """",
  ""gasLimit"": ""0xffffff"",
  ""nonce"": ""0x0000000000000042"",
  ""mixhash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
  ""parentHash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
  ""timestamp"": ""0x00""
}
```

Use evm to run the bytecode `731c7cd2d37ffd63856a5bd56a9af1643f2bcf545f3160005260406000f3` and set the `--sender` to the address in stack.

```
evm --debug --sender 0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f --gas 0xffffff --nomemory=false --json --code 731c7cd2d37ffd63856a5bd56a9af1643f2bcf545f3160005260406000f3 --prestate ./genesis.json run
```

The mnemonics of the bytecode here are as follows.

```
PUSH20 1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f
BALANCE 31
PUSH1 00
MSTORE
PUSH1 40
PUSH1 00
RETURN 
```

The result from evm's output, the stack output of `BALANCE ` is 0x0.

```json
{""pc"":0,""op"":115,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH20""}
{""pc"":21,""op"":49,""gas"":""0xfffffc"",""gasCost"":""0x64"",""memSize"":0,""stack"":[""0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f""],""depth"":1,""refund"":0,""opName"":""BALANCE""}
{""pc"":22,""op"":96,""gas"":""0xffff98"",""gasCost"":""0x3"",""memSize"":0,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":24,""op"":82,""gas"":""0xffff95"",""gasCost"":""0x6"",""memSize"":0,""stack"":[""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""MSTORE""}
{""pc"":25,""op"":96,""gas"":""0xffff8f"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000000000"",""memSize"":32,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":27,""op"":96,""gas"":""0xffff8c"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000000000"",""memSize"":32,""stack"":[""0x40""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":29,""op"":243,""gas"":""0xffff89"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000000000"",""memSize"":32,""stack"":[""0x40"",""0x0""],""depth"":1,""refund"":0,""opName"":""RETURN""}
{""output"":""00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",""gasUsed"":""0x79""}
```

#### Backtrace

I checked in `evm version 1.14.8-unstable-de6d5976` and `evm version 1.14.5-stable-0dd173a7`, the problem occured in both versions. 

If the `--sender` parameter is not the same with address in the stack, the opcode `BALANCE` works fine.

````shell
evm --debug --gas 0xffffff --nomemory=false --json --code 731c7cd2d37ffd63856a5bd56a9af1643f2bcf545f3160005260406000f3 --prestate ./genesis.json run
````

````json
{""pc"":0,""op"":115,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH20""}
{""pc"":21,""op"":49,""gas"":""0xfffffc"",""gasCost"":""0xa28"",""memSize"":0,""stack"":[""0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f""],""depth"":1,""refund"":0,""opName"":""BALANCE""}
{""pc"":22,""op"":96,""gas"":""0xfff5d4"",""gasCost"":""0x3"",""memSize"":0,""stack"":[""0x1234""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":24,""op"":82,""gas"":""0xfff5d1"",""gasCost"":""0x6"",""memSize"":0,""stack"":[""0x1234"",""0x0""],""depth"":1,""refund"":0,""opName"":""MSTORE""}
{""pc"":25,""op"":96,""gas"":""0xfff5cb"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000001234"",""memSize"":32,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":27,""op"":96,""gas"":""0xfff5c8"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000001234"",""memSize"":32,""stack"":[""0x40""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":29,""op"":243,""gas"":""0xfff5c5"",""gasCost"":""0x3"",""memory"":""0x0000000000000000000000000000000000000000000000000000000000001234"",""memSize"":32,""stack"":[""0x40"",""0x0""],""depth"":1,""refund"":0,""opName"":""RETURN""}
{""output"":""00000000000000000000000000000000000000000000000000000000000012340000000000000000000000000000000000000000000000000000000000000000"",""gasUsed"":""0xa3d""}
````



",evm: simulation inconsistency,CWE-665,Improper Initialization,"The bug report describes a scenario where the Ethereum Virtual Machine (EVM) `BALANCE` opcode produces an incorrect result. Specifically, when the address being queried for its balance is the same as the transaction's sender address, the opcode returns 0 instead of the correct balance defined in the pre-state (genesis file). This is a classic example of a flawed computation. The process of retrieving the balance is a form of calculation, and under a specific logical condition, it yields an incorrect value. 

CWE-682 (Incorrect Calculation) is the most fitting choice because the software performs an operation (retrieving a balance) that generates an incorrect result. This incorrect result (`0x0`) is then pushed to the stack for subsequent use, matching the CWE description perfectly.

CWE-665 (Improper Initialization) is less suitable because the resource (the account's balance) appears to be initialized correctly in the `genesis.json` file. The bug is not in the initial state of the resource but in the logic that accesses or processes it during runtime.

CWE-1188 (Initialization of a Resource with an Insecure Default) is incorrect because the issue is not related to an insecure default value. The initial balance is explicitly set by the user, and the problem is a runtime logic error, not an insecure default configuration.",closed,"The EVM incorrectly handles the case where the sender address is the same as the address on the stack during the execution of the BALANCE opcode, leading to a zero balance being returned regardless of the actual balance set in genesis.json.","This bug can result in incorrect balance checks within smart contracts, potentially causing failures in transactions and smart contract logic that rely on accurate account balances, which can lead to loss of funds or unintended behavior.",2442609529,30254,"August 1, 2024 2:21 PM (GMT+8)","August 2, 2024 11:49 PM (GMT+8)",['type:bug'],
go-ethereum,State corruption after unexpected terminations during snap sync,https://github.com/ethereum/go-ethereum/issues/30229,Storage,"This issue was discovered by [greg](https://github.com/greg7mdp)(kudos for the debugging assistance!). 

Specifically, the Geth node panic'd during the snap sync, and a few missing nodes were detected during the snapshot generation. The missing nodes are all in the storage tries, particularly the topmost trie nodes in one or two trie paths.

Incomplete storage tries are quite common due to storage chunkification. The strange part is that the shortNode containing the associated account data exists in the account trie, which prevents the state from healing the missing storage trie nodes.

After debugging it for a while, I realized that it's caused by redoing the state sync after the unexpected termination.

Specifically, in sync cycle A, the storage trie of account X was fully synchronized and properly persisted on the disk. The associated account data was also inserted into the account trie and flushed to the disk, indicating that the storage trie was complete and no healing was required. However, a panic occurred, causing the process to terminate without saving the state snap progress indicator.

In sync cycle B, after relaunching, the storage retrieval of account X was redone using the old sync progress indicator. In this new cycle, the storage was chunkified into several pieces, and several trie nodes on the boundary path were deleted from the disk. Since the storage trie in this new cycle was incomplete, account X was tagged as ""needHeal,"" and the account data itself was discarded. Theoretically, this mechanism ensures that a healing operation will be conducted, refilling all missing trie nodes within the account trie and storage trie. However, in cycle A, the account data was already persisted on the disk and not deleted in cycle B. This leftover trie node with account data prevents the state healing, as it assumes the storage trie is complete.


---

![Untitled (Draft)-6](https://github.com/user-attachments/assets/250e8c67-610d-4de7-8c83-e8fe7b84debe)

The leftover node of account X in cycle B breaks the state healing.

---

Originally bug report https://github.com/ethereum/go-ethereum/issues/30149
",storage: storage corruption,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a state corruption issue that occurs after an unexpected process termination (a panic). The core of the problem lies in how the system handles its state upon this abnormal shutdown. Specifically, in 'sync cycle A', the process writes some data (an account trie node) to disk but then panics before it can update a related piece of data (the 'state snap progress indicator'). This failure to atomically update all related state components during a crash constitutes an 'Improper Resource Shutdown'. The 'resource' in this context is the persistent state on disk. When the process restarts for 'sync cycle B', it attempts to 're-use' this resource. However, because the resource was left in an inconsistent state by the improper shutdown, the system's logic fails. It reads the old progress indicator but also sees the leftover data from cycle A, leading it to incorrectly skip a necessary 'healing' operation, resulting in state corruption. 

CWE-367 (TOCTOU) is less accurate because the issue is not a race condition where a resource's state changes between a check and a use in a concurrent environment. Instead, the state is already inconsistent at the start of the operation due to a prior crash. 

CWE-20 (Improper Input Validation) is also less fitting. While one could argue the system fails to validate its own inconsistent state upon restart, the root cause is not the validation logic itself, but the fact that an improper shutdown *created* an invalid state that the system was not prepared to handle. Therefore, CWE-404, which focuses on the failure during shutdown and release of resources, is the most direct and accurate description of the root cause.",closed,"The state sync process fails to properly handle unexpected terminations, leading to incomplete storage tries and preventing state healing due to a mismatch in stored account data and the state expectations.","This bug can result in state corruption, where some account data may be lost or inaccessible, potentially leading to inconsistencies in account balances and affecting user transactions.",2431611438,30229,"July 26, 2024 7:30 AM (GMT+8)","August 12, 2024 4:43 PM (GMT+8)",['type:bug'],
go-ethereum,EIP-712 typed data validation does not support fixed size arrays,https://github.com/ethereum/go-ethereum/issues/30183,Utilities,"#### System information

Geth version: `latest (1.14.7)`

#### Expected behaviour

Encoding a typed data struct should support fixed size arrays as EIP-712 specifies, _Arrays are either fixed size or dynamic and denoted by Type[n] or Type[] respectively_.

#### Actual behaviour

Encoding a typed data struct fails validation if a fixed size array is referenced

#### Steps to reproduce the behaviour

declare a `TypedData` variable:
```
typedData := TypedData{
		Types: Types{
			""BulkOrder"": []Type{
				{Name: ""tree"", Type: ""OrderComponents[2][2]""},
			},
			""OrderComponents"": []Type{
				{Name: ""offerer"", Type: ""address""},
				{Name: ""amount"", Type: ""uint8""},
			},
			""EIP712Domain"": []Type{
				{Name: ""name"", Type: ""string""},
				{Name: ""version"", Type: ""string""},
				{Name: ""chainId"", Type: ""uint8""},
				{Name: ""verifyingContract"", Type: ""address""},
			},
		},
		PrimaryType: ""BulkOrder"",
		Domain: TypedDataDomain{
			VerifyingContract: ""0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC"",
		},
		Message: TypedDataMessage{},
}
```

call `EncodeData` method on the variable:
```
typedData.EncodeData(""EIP712Domain"", typedData.Domain.Map(), 1)
```
",api: api unavailability,CWE-20,Improper Input Validation,"The bug report explicitly states that the system 'fails validation' for a specific input type (fixed-size arrays) that is part of the EIP-712 specification. The software receives input data but its validation logic is flawed, as it incorrectly rejects a valid data structure. This directly aligns with the definition of CWE-20: 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' CWE-754 is not a good fit because a fixed-size array is a standard, expected part of the EIP-712 specification, not an 'unusual or exceptional condition'. CWE-400 is irrelevant as the bug report describes a validation failure leading to API unavailability, not an issue with uncontrolled resource consumption.",closed,"The EIP-712 implementation does not properly handle fixed size arrays in its validation logic, leading to failures when such arrays are referenced.","This bug prevents users from using fixed size arrays in typed data encoding, which could limit the functionality of applications relying on EIP-712 for data validation and signing, potentially leading to user frustration or incorrect data handling.",2414994768,30183,"July 18, 2024 1:45 AM (GMT+8)","August 28, 2024 8:12 PM (GMT+8)",['type:bug'],
go-ethereum,rpc.ClientSubscription.Unsubscribe() never returns,https://github.com/ethereum/go-ethereum/issues/30156,API,"When calling `Unsubscribe` on an `rpc.ClientSubscription`, if there is no response, the function will never return.
Maybe `CallContext` with a timeout should be used instead of `Call` in `requestUnsubscribe` here:
https://github.com/ethereum/go-ethereum/blob/cf0378499f1bcae65c093c58cd6ca8225e91b125/rpc/subscription.go#L372",api: incorrect api output,CWE-400,Uncontrolled Resource Consumption,"The bug report describes a function, `Unsubscribe`, that can block indefinitely if it does not receive a response. This causes the thread or goroutine executing the function to hang, making it unavailable for any other work. This is a form of resource exhaustion or denial of service.

Let's analyze the provided CWE options:
- **CWE-835 (Loop with Unreachable Exit Condition 'Infinite Loop')**: This is a plausible but less accurate choice. While the effect is similar to an infinite loop (the thread of execution is stuck), the root cause described is a blocking function call (`Call`) waiting for I/O, not an explicit `for` or `while` loop with a flawed exit condition in the application code. The problem is the lack of a termination condition for a *wait state*, not a computational loop.
- **CWE-770 (Allocation of Resources Without Limits or Throttling)**: This CWE focuses on the *allocation* of an unrestricted *number* or *size* of resources. The bug report does not describe allocating too many resources, but rather holding onto a single resource (the execution thread) for an indefinite amount of time. Therefore, this CWE is not a good fit.
- **CWE-400 (Uncontrolled Resource Consumption)**: This is the most accurate CWE. An execution thread (or goroutine in this case) is a limited resource. The function's failure to use a timeout means it does not properly control the 'maintenance' of this resource, as it can be held indefinitely. This directly leads to the consumption of the resource, preventing it from being reused. The suggestion in the bug report to add a timeout is a direct mitigation for this type of uncontrolled resource consumption.",closed,"The `Unsubscribe` method on `rpc.ClientSubscription` does not handle the case where a response is not received, leading to a blocking call that never returns.","This bug can lead to application hangs or unresponsiveness, as the client will be stuck waiting indefinitely for a response that may never come.",2407400320,30156,"July 14, 2024 11:54 AM (GMT+8)","August 20, 2024 9:54 PM (GMT+8)",['type:bug'],
go-ethereum,"`snap` sync in `path` mode not working. ",https://github.com/ethereum/go-ethereum/issues/30149,Storage,"#### System information

Geth version: `geth version`: `geth version 1.14.7-stable-aa55f5ea`
CL client & version: `Lighthouse v5.2.1-9e12c21`
OS & Version: `#117~20.04.1-Ubuntu SMP Tue Apr 30 10:35:57 UTC 2024`
Commit hash : (if `develop`)

#### Expected behaviour

Should be able to sync from scratch. 

#### Actual behaviour

I tried to sync from scratch 3 times, after blowing the database every time using:
 `sudo geth --datadir /var/lib/goethereum removedb`

First time keeping the `ancient`, next two times blowing everything.

System seems fine. using nvme ssd (Samsung 970 Plus 2TB) with no issues reported with `smartctl -a`. 

#### Steps to reproduce the behaviour

Use `removedb` to blow database and run geth with:

`geth --mainnet --http --http.addr 0.0.0.0 --datadir /var/lib/goethereum --authrpc.jwtsecret /var/lib/lighthouse/secret/jwt.hex --cache 10704 --maxpeers 35 --metrics --pprof --pprof.addr 0.0.0.0`


#### Note

Previously I used `hash` mode, but I starting having errors, so I decided to resync in `path` mode.
On my first resync attempt, I specified `path` mode explicitly, but then I removed it since it is the default with geth 1.14.

#### Partial log (seems to repeat the following):

```
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.758] Unexpected trienode heal packet          peer=d32e6ab2 reqid=7,062,910,621,028,475,407
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.774] Unexpected trienode heal packet          peer=141f8901 reqid=5,921,614,888,348,237,967
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.795] Unexpected trienode heal packet          peer=0ebdc58c reqid=4,864,759,534,782,202,732
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.880] Unexpected trienode heal packet          peer=edcdb9d9 reqid=2,192,217,697,858,156,755
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.921] Unexpected trienode heal packet          peer=1ff4414c reqid=6,030,783,751,269,227,388
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.959] Unexpected trienode heal packet          peer=55522f26 reqid=6,072,072,301,071,529,713
Jul 13 09:03:57 gp-nuc-staker geth[128070]: WARN [07-13|09:03:57.972] Unexpected trienode heal packet          peer=d6161cca reqid=2,271,209,749,937,513,820
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.085] Unexpected trienode heal packet          peer=0f098f11 reqid=1,138,651,193,010,756,505
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.141] Unexpected trienode heal packet          peer=936db72d reqid=4,437,056,338,323,220,388
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.142] Unexpected trienode heal packet          peer=c966be1b reqid=7,099,670,709,689,758,184
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.187] Unexpected trienode heal packet          peer=d6469ba0 reqid=3,762,804,802,417,240,180
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.246] Unexpected trienode heal packet          peer=38d7692b reqid=7,502,169,550,455,053,468
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.451] Unexpected trienode heal packet          peer=84fabfcb reqid=7,547,774,593,759,638,446
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.455] Unexpected trienode heal packet          peer=48382872 reqid=8,242,958,486,812,907,649
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.582] Unexpected trienode heal packet          peer=8d6c20c7 reqid=3,239,138,954,101,181,394
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.817] Unexpected trienode heal packet          peer=4dca7c2d reqid=1,258,313,712,087,304,831
Jul 13 09:03:58 gp-nuc-staker geth[128070]: WARN [07-13|09:03:58.962] Unexpected trienode heal packet          peer=93abd245 reqid=247,484,856,798,019,426
Jul 13 09:03:59 gp-nuc-staker geth[128070]: WARN [07-13|09:03:59.164] Unexpected trienode heal packet          peer=fe409484 reqid=1,940,029,955,041,506,237
Jul 13 09:03:59 gp-nuc-staker geth[128070]: WARN [07-13|09:03:59.761] Unexpected trienode heal packet          peer=676aa5ea reqid=7,948,375,599,722,888,431
Jul 13 09:03:59 gp-nuc-staker geth[128070]: WARN [07-13|09:03:59.818] Unexpected trienode heal packet          peer=6b36f791 reqid=8,237,650,123,766,752,191
Jul 13 09:04:01 gp-nuc-staker geth[128070]: ERROR[07-13|09:04:01.080] Reject duplicated disable operation
Jul 13 09:04:01 gp-nuc-staker geth[128070]: WARN [07-13|09:04:01.083] Rewinding blockchain to block            target=17,236,615
Jul 13 09:04:01 gp-nuc-staker geth[128070]: INFO [07-13|09:04:01.179] Forkchoice requested sync to new head    number=20,297,763 hash=5a9e28..601654 finalized=20,297,671
Jul 13 09:04:01 gp-nuc-staker geth[128070]: WARN [07-13|09:04:01.624] Unexpected trienode heal packet          peer=0ad80bd5 reqid=6,054,871,301,206,217,589
Jul 13 09:04:06 gp-nuc-staker geth[128070]: WARN [07-13|09:04:06.589] Unexpected trienode heal packet          peer=507c0ba1 reqid=728,961,722,073,398,230
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Loaded most recent local header          number=17,236,615 hash=d45fec..85641c td=58,750,003,716,598,352,816,469 age=1y2mo1w
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Loaded most recent local block           number=0          hash=d4e567..cb8fa3 td=17,179,869,184                 age=55y3mo3w
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Loaded most recent local snap block      number=17,236,615 hash=d45fec..85641c td=58,750,003,716,598,352,816,469 age=1y2mo1w
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Loaded last snap-sync pivot marker       number=20,297,699
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Truncated excess ancient chain segment   oldhead=17,236,616 newhead=17,236,615
Jul 13 09:04:09 gp-nuc-staker geth[128070]: ERROR[07-13|09:04:09.189] Failed to reset txpool state             err=""missing trie node d7f8974fb5ac78d9ac099b9ad5018bedc2ce0a72dad1827a1709da30580f0544 (path ) state 0xd7f8974fb5ac78d9ac099b9ad5018bedc2ce0a72dad1827a1709da30580f0544 is not available""
Jul 13 09:04:09 gp-nuc-staker geth[128070]: ERROR[07-13|09:04:09.189] Failed to reset blobpool state           err=""missing trie node d7f8974fb5ac78d9ac099b9ad5018bedc2ce0a72dad1827a1709da30580f0544 (path ) state 0xd7f8974fb5ac78d9ac099b9ad5018bedc2ce0a72dad1827a1709da30580f0544 is not available""
Jul 13 09:04:09 gp-nuc-staker geth[128070]: INFO [07-13|09:04:09.189] Syncing: state healing in progress       accounts=171,363@9.40MiB      slots=370,618@27.58MiB        codes=158@1.12MiB       nodes=2,200,693@656.42MiB pending=1
Jul 13 09:04:09 gp-nuc-staker geth[128070]: WARN [07-13|09:04:09.827] Invalid header encountered               number=17,243,765 hash=c4b4d5..d4945e parent=92b4d0..33efde err=""invalid baseFee: have 22538549297790339279734171310165035945408590406000924764119485189068901105624426301855089982168153411550498537209217831373027898239413607943974690469634015283818785048852579179651325625259832894695691515525064791337815595940419550393589714109246997359284111805124879034697899525295424341491246035168509628172907509521129100362692207788162713961236095039939262974933566853686299190485776674002268522718733250330593316091256945728471735413084714797754924980549384657782392683361214171005136784521456234054143342537901317065719284303058998029664626932578749925783310255654602479250539161990713166752302906809618288152821109898175669726923372552932536418724458948591326277142444161014876627458004662477650951029823838076828953776090732435403021715630746282681766320038663990963863852006267626214767200889504219768527718466717599099673892659859747365971796601170232460197088684606947870095176023335886794457625217602318152542483681965612179634372317826117336376706664089136712108120539547072718335031282627884301573763383449753105875635176913668461331617296072190938190526500434189888042032668278466203146748502295460457919420557961151890312586941301685218753984111290634306131555279265117573532777913708143062960102358953157436884943568174397316890473488245341580691877538876333527638155271626960537872257996469475505696009811210694279688449941315777979150651683299594288562164573620993270979364061657267653116985337506911004796992217772550036279419192875689594008383627196837462401804415246919936897110242353211888958661242023396784607186863132104101093978127746661391508350906343553995523079838337620692354697754370659373286798752309446844868917142884687732336736106214013904046225386595485661424895532510789607493673002702294575915846343976854757147949897233351135099562589593960168076464541062114481669309255008626350861489862968951017692232832369610770811526170395193613236954597927339198555463805832396877366460174937946550299762393528183504184829255548931568247797978797698122775750837402059968504890632969755949713801874510659189797681534203834724833542922628924172096649715714933133664760700349802232640176378784747313415596869345694405077811290322872837740144797064793869828958750188797336611549304802973970815744243072656692321830436116720560350562611392607112503995726393941746852893742767968203856460429444405513620304709782148486901400985839227050371933464865642262684847203032680591231981971790053580359745217196362027067715245263969569264816750521399977049809850423836008190534031242180390126993908121391345920351855849672111288942046519830185399162269823142357490591601940496845313896652130813920258398024023864948279013652115209210524184901118105943910519657495808408974705677668889667324737912578343789547619101314453291528004409239157496746318282841982409899622307774904465599023316587147121347226756095841106292951889112374026667957519790443674340532222718581359676004068762525633351700751657061154148314381661758789258835487117136795585595442846800971509309285376590095051444389244418646637476206829622395612729248627562852550708573501632504536658692339721478231465835258703243602227956263104651808811557823793675559266493433031125107420711670304328626278768351106518166557460756077753012934399879810313615911564602930969408935562135392975365833594355072251943553877536528002820602112874398776819430612454097678199901195300499686226872833230564100265381898087034060865955603133024459604314075698003210185351116392881661247932596571948983865799057110238885927353070404513705621908169202947435378822318135735395541772183011209182979340159966101493021975253406651362012295623277622220637911529973882505507491600241970011671105101863576791614706247352366749420756300031579892891800803202128875032061150202897249022414322415792542142132123645705447488557348565012959663775943123272534092697796396730954751952819158937486841446217937796604185991305586482736895794390116493190982628951737798611247576602623517798182227534992536532884926412286889305812423218512846017869970608451529611101277040498093100250948795502654731359139541931018992055031180434158212550193554128097627346699531252111573201395249643466759104980299108950799853927502712942301472125217333447539171249405406154409779006906066767229907588282374638056288934943218495483030683245112081221644756545771856379535451123182694050771235633545583838683046677019114459013754336940937623309785970236084554815111321263295212309725357798156819477692545504976104651526167637649933334657280776159544715326286751840556053774656056250527231403759976888063734388633729988591882948843180969262720464923139975108702710748435947831824654937585838947578122885472741518582292155415480494642379882985920042731354615491505736694291445338432971597711041710693229427704368511526176051145418505610842435081983864072098349745753618841101886078954234010627116528579626158904530215517557455851958406991465039494116985781078897176745948035605111414940577428877851770159805516510167355389325051404440938015558666774899936640456780949170159139924798181017614446901266602573962832382628356502433165709009069524593612175960383639330735471289819000495156825673148828729717439543236554555375029265477580259514206254601206896661502603682039131634740032680040486096665578813216794654362423796808641893231822788600034277588015129665964440572374331617367504335874113054596452484687908059558432681308848248641647339373675604765875284160683589661240529819527885625206402452885307419551084895344114690416027507411612978060775501613948884395999224922726215834543343084188147852114463871770134480714628043841189983625840043915978444481084336657298061135385263569903458810612349253486579664786598310718132148704849393200096712371791354310642662858980065383365000887200423253498297480104472193039990270849406580083580071027733995559899530259554886674946120813857872865756488785961541765659086567324705100129339640686412394367089160335144425346493190544323575752345741477096327845067676741680730581763937970870359316396659007877992474508203634620112774713943502323685431497396359039141087576614250634078577427838915796955509799601406035266013743180122717744959431016608976898726171450706352259672017935243685609388788398073287123132263157978072451214784777966722604861993208864636519533186342144099068469264181341911612342890535308059055144696465460935796920888088018381253171642294343904559331864934282141399384498963704752951189768259253751404279594240075412589273935231603966181701361603039453111217624544139621971072919010061898493056251074652695999945971741157358537326478320214069114952125721341271647936200938242519759840937168141657575299772081229640863674505748087518690425045505562509503298198893955464221317136303930191096192783195254085355732467681978969033417553358870683956487994693988502719153683956024684576269462580078763136591908678537669917807760807589054160911904096188134960796080069684999193723081282378887533181241637759794565448230440934941914803178038665709175590382920562763471279293562004967000198054368950259272285038666321063746832140881719852270857160093311365185589523645330207227400400810945242577183183807149033888542060056133956803922485194160898354198360853648506422386350798916611601377078730503623738596460780379219692971096196234254184332278116480901741008018013774304287181715291000848050261584399167788825095626389571230627628545546406827376827516696776759983729838763600093595313390310119609454116065822554454039090736993414632531919403169344983848924012266507871323222919639880352984425272340675212207736635759022798742627069031323696685095645419088378153263505273864800626560286985482483828031758934547670669492557872769536491224542865437296816542426797430571752859142158551356704317837010781226845425497668115405682284960675788509615496006657389386677671624203580368354009835774684159697208462048187868293876668325937737563141561060766857669780696838610193537628735620012256938268504746812212228521608028112489603037054595237804583645279899221553272365021981877064408570923212135981799119017738098513291430233633187485435445483352391356084355661378855589920459973955254443416139846013687460508535417565238866309160643199019682037892493640916775238827674489760838020166416209951564359217865909318972910644073135833358951946945964179745874104460376118918078909109704477943526967049900849213459464054454446647004903034456499945945552085199776150756221088677015113227766481743408310553049528747323284923225807577722663289819576905202520484718599405380485302711039216266722062844179049177805320752386002855781295241696066909919781828359061372943099760115135605171419599639104985220642203337552416286184170129155427282051634483214038001914197384107119894019533332213883754568411852429071763015175524100517363110473558675059436875634170987102210784565091685517745297504484573553434013166451929621317858511865370529365610450317290970061740208313474977153173808865598272648188688309934010440095153142525483435129775101873799554572182533368296650441998163297761203935013001743050718323108708507729260220297573852947479432742862711824287944684547185469275781287516176468719867974162954924645299850469732880716039729660317821393654130833427128645065571166313044867461001169432213629025809630317351847400927088838363292642271448549705858721761403015675598662076782037617787670265267049759629561618540362765517033097560498607976483732948263957978038489014408163681914858338127416898483506533562244646787622119108230323851490956288387370740264471020284092737309937762712394342900078140873155620747478277541757824910511519635107524240679739178587912507666508865536637196721870375000457682877247942935190605546934192815996876024225981138363104922752138160235552317146168300647262202794153067382766487760590620186475961425910454838854496649711376617219958839654846270960150193146144215686164639790443339053458547398610052752809870728403365260885566253024551499563901330984196385617546026127007839934045208161187654165172451450623260957644353144772299504956773845119656386478972479529664951924351490994287098253538375405759898981774858283236421697224267672086217310734087686582395261571201721204740467642110908005644185802109982932288187382045694635607071172963828687080086511862466859926294055761105232483513423639434510371791850804290728033909853343551767360009983470285113131641320228020860830231472478332844212270656876014684750120238287667637076583100314825598242905561140050102148504003359545748849876872572165065136804160919757760886670344882257258293451847445330803998104682008746644592026687750575506582234425838289249019295770993281878252160339462546220514623497902548613635021185750095020896371732023005020136427157157277706878043819275715379566599047960923073323648206223618822828069180800708728891853706741542070050127020476954637258971954365346576289978381965777076715297116599055282683345549502892862982068875667803120194808174275103244278660640203695523896640682266405958090565636293946266160173395282276345177636419481007250763085620777603507940719279076367811541083258789582050452474394442116093432009558195095864630749067306479193897117918577873573965555856991577383023566939006433413006110388702546519644183577248876780680534258879506936645158542033055941207626623638729891261255765658703387137559817966669787563379590699328733218785408605544881086212963164436065292485114283282722042733326637470137796676754931325916034721988264685374924748346193979201404489929679342234812333883786650771556303211614919314194117210245130540382708281304125209496379699872060534831323227716378730782170988527019058061326022776294664699164142237922854738525089961116345364658991074224236460959059755110309470872422733146636931646884118308437456589194321631401802941631875260016396944991740104702836351536976774126466142957448198449032508315873354002943938770247645221386250480190776733415228773702340956282207676188203960506677598698079949230627457007219801018585820129488809136247292654209319437899990024569869912434455787304670542502736427583055555681863030344310750864281402485917705828515227896732209313304087804291336220377701620215039816210501614289538449817862093043551072878620288692646067443702070859160390143143733103936986742605322566976695594340150850770710065817295073081741013117017260468414616723451289824075052625791196985476598001791389384557621199487281335190084648763782679259011027062474049660317413162541902740729235106013075306209550931732584594091604606106336628819718382486430959853409413416348036335846638276992757538069278978866664626666531936433545030974401544795047806333726073801627740900954671279221351758633489189591012427996726776328201549581935196565701198478773067217809619798897928568619770445011387030511906634675357615164903001098694421016925336498039692011432329326703669465252077441472097084949987162542536887132874780239697254421388458198406926485983367776179426109261470993269908611366304666342699415577365512087507732756182993297573901090432049391423989269139536557005163620014176582278184839374992376541126848445239983635335588168148023194687889500537255266022647964092738414090818764513644082402703084443029700879171177796549314164584467129780409304675941220749695114253664556886757007323363912032577151917592242363550278986022173604345971127363452932138863807393507611124773803264031249614909125395308487019187287446090820736593591836123867946391559164212462570076382615779630599293042407059722104996465995090273803100713014684652180088788852841094841855547006285545135112073677039521565873982339695695742980828603523816364507943095340932261402463850726454016996547921631926647951198837494103219593162943115016440192437353873452151098315751616520138857971378270213114299727853035547873833008477952266467507703371252872030873287805699467828359885619803581436868405006691494059778438294203449183478176050090703085483304975015292700527716266148691492086151613839132802494869962557474683171860648422985867991531875860261385314291545123218368906274989932686373919353464762659655016962046512359716564667226488632914033161886631817912653913269862951908057681055781943879370702861470851931733915340692756036688215783086576770650293782651180782872683925038977967418881006410844153893956485142720921733367134355963132663605192298245791358765691964317141106241112974267597940562264760963669593474568647740857248607287171958356752741388300659584614909842113715105541603815305532473126341052003422476377175553605217471986107825056136506359396614776205005017013676530189175458521882406184485036967988832910112751326823548394249393238859940820585932163510405382545659550507775795961157456776364096861988353358978973554428189134281588603794101221655616845264035056533511262472757574432263331414385421592048242057867896006075450228883455179995393624090945564123697599798800447699113848302116767892141602110579138149167755302371429090736009980826053423284175193341917264192367586665538557712279213068873573415716538838781136916765996087936878201654168239748567267335144372005278089679073214970312741869144382250132828859183027774292060221582819032972789013355003068449562042619195517423064563284474048589392767526487691570265362975977670679159049764158869600678627826517305728605523296953883902703077589248509882009657460708028052972829174186860181533369658159933581477667602850617354426163320667037262211274030875693383535536537864298177176491529674675414520528887206978207035020719800419551318831207028589803968917539250324960147460172066636663234141262622204953432231547497022836386713676237777538259145401324245230930309813990391405981578436772445449551701418333379757144730035449419276631037890904290817957260562261030987304934745619485959697734490593356354054276519220173215867028642043271959625945343650137567176667132173721109608413045437454260569109621842138298670540639970710636982968871934454773211082958647150508295384767804908518731738030560871366612792820311204020967774686522851210875190039935872725408165439562429952367102903613381913635019358816758703815569189591517366457768096288940140495971449191462499550718717976856733386072415766009402492047185992777100854234798066600103053470531696148052425886359510573024391209096803890651930218124386751141770351988775487166352818848087212456285833983445855085853137903532085404649424599126569198950669284686907836727391071617995641481256922647449013864333009158050759807515420717101178291692981213071124554364553445789703281641603928058785805873475752595370727709186518218030668127100188359145066600059644422866488804970870967625643449690824995913702868792894921846891091101655748458539640589774746910526532198779727582415897730306586770298090317203913940658351738017709488726160382962211572444753121047164767720968106138210533703037945553742501316614106324724185493877288670976350583248543724986807455750531505661192684007367145113435999722197645021563079838839849392149679552985855836108049128786545796401197730379585040771382934371029959202018521774112348378726132381448376203552449028892530186534228720896537180664643511526900933993160991622552588484512243432256212825831277949732502040740768201324550891617009325196898811918771006141612223102541503169424552255745007959172200031775642288972959862932836410070894196184179576242551358422250095870281140449535719668836099058554065395451726820796352345540105141318770994602344139509996330002080083462952317931140108132471837833842617308742172817003248670884816005465407025614241886946447677744209602532211254726254810303637813460136852442796615805954958830072567729453977535223945349808392633163095857213002111746482014071238864745217192739102773426225277405829502623503052106954389578132123982105143123083888300827888213660230519771626152663780084248256786023985201956789598185991644767079777146827874536087257654974226999355374270071811886962130909716830072366803266692988769178853068486426463667535543828697141175401286750576783443583685835809280891741704241204916443717514652678749332554678136405098846028076375759655485267903470815448322708622304204676758750155020259521890745354267306426703364440400032477535979637847949630575165256464478405322300899648028204236141593024198445271656056109481089219245451289543688573499567605331314576274138013644757236950841233824566813408296807753110022528680681664306658257298042307506582456620218930128304491459440980657564994926268653386629638210152292164949205066126376279250309083355401174134175921580109425436887956517462893518235029633048849383976613085451458204860306773539860440865101833686077709510935654171976516332874829226370335748405797350265015530242026063481452270998142163733410330091188015629486022300287665686437126151988321987727803898440922881616354310229833606308881184806494959714710981790761294330926281462278350782032312759511645566323491082403202863946844999365276051847867917483586376806306637357499674398062386165202362049653194190642671326295560000511159024810359781773947775187523014890123127311686969933194542774298416033026104499680852505311969534690801129279317263275626244463226827734106140006907551762393907438470795512792666126248366442414526759957167333572517908781348808722013762042234755689143608719487607797221222690152493190637291731548433246295813515176128815878325418886417901064157065466911798517853187880029133422071569443984754403582118176542960659718279255883854907159187610678981091423803098446812925761619857842173023150670059209920432836302662991951246973638923530578980704858513783837887522868341022426802415257464341370430348861613690872565338707658092377419400507713317407966423057881684629684774397027542702447320722970969104506947447593737185309232581203974268132379558941758360048387039113245499416720031670364684060989377651674760209149378480441705472105506251432320247280260404469483373771127602384289556085157974223456333594569776742812330735624997332889267934412127852930831426999751031550689489661224833801334200917740103128971496812156874093259248012607871177524617084041312695695771603050685679768282272906355842422107474159655342860312025599788562947744256148555032238197300301595316992909497856200004639284380589826940203574321685796570524023850090491916699595863881336254166410315658307822924234083961809120599528826643269101461129000466588792461807574033270223012554199271587701916075732029199962728821627166676833110287289821524066498453409887404326412401465557547485720870961905547460396519134039564102866680434751165561743782551548738834543841538732333816368270517207231016717727739556943825083762852874968887780118509185962794512704686160145007605272779112149906511715721694702916310456761351094639751770603599244244669848612956170709047485725257947209793377869034557314662825734003961556120414118651068588606246428917101359054761244821133381340569078012929923750119234209055538332923942831649186107452535416789970246109768179230104738913155319321525099340638765078060842476945751767827851363485414610033219722998578822398082711369410059807288410737918135139601966976313003541894486404033040304612797209808166657814816640890561106849529570709414862868791922565134448028943567624552811661650668398278505402802196456101682571943314576702713494303358474583211610868320854376602599251297876459454704228156024205442820531229072572783259009908467299637908471841455845648162488000187654791733348053969755194446137995912806755352792193783594427670222512824856316967738394342164886793417085326209617218428162950623401162621129904245784081836506946175293592006818519833587777065702343197637874080432960135864844208086111480419872647546794641506338722305348470433422313112483173635980514235661454691007537213277877981149359671897227494248332154433484545870270863041705237748496786677969430016208681538724873145718220279598630649115087514987016708799405886381041471699511164389102831071317487630341273077283193645459429909316684884112829972820344924775402768032019142317372232918157563289015460408373587503239906942775260415567537195711582725352212388274657751820853826283198067944047459672523311560291310952294940581709892638895240806732495661494202209219272032216818741886764313891220342208620720162644725168629624901503392278028729497544810514298628620562090609563339907603508673242598087368828699065793809901858710051888832456029904869686044467164845953277942368933173007979071723696654615176350552158081413831208760092555825654985469980689533052154329236854832842035642991980214288091499780677151243384954756158585532608348381954361793807568623038728451179933885887277218016097200693335593981729625212894204565514685356863362129051847926164594607564129445015727196941231325775049708774285362257494772630444608428222298891930657582746439054287927512938561231488189618880361229762679206943858650024603971902428274285674094321061845072210420561770346555286094663606946736411862280000264299138326619425258151760358148854451459340549305993423551606923582791503987063338612142426435820474237909849091672862290427494789480366896467902533636228330545415438918664936450113391927052515516820432872600317205368296858860260852097500535214587072362814705442698366794258210247488360866850277315620868423763792958401176487375304979461009527385273858163042343412456226061681209549995078457317559407236413308715571942263540527970952447198479482469744759466468327651999945654726731361231194909978585895235354693148833199196069138575703812138652699917048927443164751130170217074017926636652836016669330454324385846532699015281130750527849786820131840216681889106019418152723275131741180380469725139448467166331073529443312589091843734659126225906550213514390985515382415700189864256563543143382308109173491945637428008209649306167623709516409284865006946759504345596296673367191238870255626125645012011251116474330249729724950122862057845507914838372107606951603480935265321388303979034362390212688615023075306138223515491409909768190488879749164390278328227827485825820737864041813975818073490562185284924719684762209990925421801394975166057049840866106850655572904462411116691853434247564685840094564368744502855045930207244520127114284329124563369739952107549977243254432012005486282533471606782694020270124038239606721094221637046470133583902871408515366695470754067759342257940550670009350142150632963344213949666658415156805862748720145471682527466162229698932576094495137543034585463551907149077139475630411617461545132561541022894653198710799264298592403321937236013311331003443596563916196213444662047411527040375041720772984630860233357262593222594161960151233380276577338467002473108991130696391983142940376299311151487448432066517071778621559266101508197629628012334453585437908666602271368320298660322118967967403237790321875916528542373129959902484932244992736889073267160579316161005643777163232799343031122269518646714354287403119909149723380180249016823627530857459954929389265473899494847443462017694427961770678716120681020868855843122535244122006073020664053099874434288070759566709738100543724846323270621385500674361260301802938900549733723359975845615469394377010698849334447102667827903212309916172735443332384641824601370435017562472833675643891179023495432079331699081877931650559417237686741664883067023362946215847810602825299023419624787572077899449607328136517839508909333123181139691568793109790053870055714639043359758470860139969948892138001836788814089750005393362010386188353393739976134797296669253991054943122421803642086000002734722174210409747530420918080581841941912666787845382393902683077613198740849355965301686923747566274452130388439349942776751018911992791933451372884425127632572434867189000251963121746683049816914440909882936285765373758037395968104103142886498640921377680016489895813359056877356186889400147348367916441764424001735277516154435996655933986950904297588470077527863350063782815246923527836408215514278969688339848715696853300579984888507274898030163199222646621512633496273561365257921707442912384601867533985647237341106650632929260005685018205686765116133315607086227605544261645613120760086843092366941473587621631152165903297112758378912293878275669489501203876627805537208143737139327929896863631315402317555414208119985666902349946538237832769733910330907064240210870383421990238001086831479088459722914769467692443954474685788679257231705414480603129134720241373137962376478622643276809779830157862618704472449266755747881398195549842074438251764405703055333898406465397308805565030895968939697539387280867858359721448712333016159075792585309167170627096875066723676725825099551561261700159368145211805057236293625790227800735537807886351296758064368857362979822455285500937590555078060278505677744290843755629331034613509477950393059557548770928716621336587991684507450449673371501869336969632439687254438679415819630514848584245777308577065740473977965660439153508437542955905854841337436829716944045811358831805513410466492590212572579472386826679338130142970101244379751772674527330943861703326989298111588586419591347760460961359563643690315596643977317559791532364827687741785065531518878446392807962238560466769252568364264877612588968408122708114168434747806426949976825567638958138757249352279612894391253327318557580506986960241728683213568566724631180237264047848649020607930430791007256770069913460084881179829310599469283613396827888548749336676617562527081139131078284413532042679018757572161226425424775103275723894319384568828736882363548101044909565494570680986235652683146757672012320506255999006907779246770180104810061461136781978704042635366697496985036708476069191852255001694934953237409996716776478949374552455761423106103791697409775459889406869427410893097984006305901360796712835720635495343840027421055947636481426326745032092644204007683679667728079302738904173806689404794226822842824448068328621371109333988124224578012306473047159027590557537990002747345596092083288113266551712774285423643381867949807877716031829874033460116832432294806815443248816323080714702929949680893455165288548835737469703000807502322209965496085290502868140753595732161255301608456069582286370364127637426159301112361192655425900859288501183196854622659963773024009259654328464114327299667635418578271748279156779508277603915772771063262008539243194257499252174646899515888370051081931060959885161886168583013055881003772713552348725978560587286914184861302635234843018990597926401518038560230173881351284274829252277126104238430947717254841623191022667356714128444332313818111444777478805156721138571581612084503474277721363766868577038209515077618356745064291670912826875664141764917092145924688390671645948453530293357416417569838364047880414411823244451380225698794964316318127505368556651285873397423969866449745946958423689676402971574961204815486785636200489503684893343464157650421417214812974232796630571439632113000858080117029866898837517047192894961203817873645967354468437205115414075918972512343122911111734852438610229332418669461967014957066143452196804922410474072701383971707440636806138856963662675427673444803470150096723019095691980500720743146345036883585183789779113054778307047933766733647239303534597790677211152515977147580568592565257698532479613529575482736474980240783412355187711179254826107344192677773241981157460865984759508261563825645532641095235137543721493612949699742408771065976027081482336082882316661519162720312172490425164616631309526009865508052912584864674442090694335847635253963546636917164503258366121536105434293552953587091154271316414713292792482310968268463439347395956603157504178828372615771642242741613146949666728593140973176668185737762089374836071967642776118049303372596814885293330230124764881512282484009062684050063331125666270360747024553451504116327953530010263586351805190010781850423744281521819360509112662642121595318277532544143911313897950616213167576838396542008908113340293280590222590173072690599306794023755953097678416887533883242769347128346339837552845456146619153276116281326028417067911007572417074225522784214672642613979254423409429288759845592114841435041861833872523341730013612000043760957763275429291638789708588077497571340074392507202969877449875019715123585799054553063001340865605237169398336154176775207270397413305336206007861464788771859264474580222963232315825993928870652676736518714153493396294613566777239034847925339578510010405706224747379728276182706802881484680688823375700279261387931366662882719439179195073424414981735391941452178036764598945161888708455864491137269059355063858737272758285824703117492449058416065921383173706690546633230726815209475145748302856642514671849233343961433181168749497619723263950826745789373201150641766343278383657064656100104958782338945397598291854666126394949299901987256664498675576487689566334338235393750018813224783982380302940269310286553036950452768624775312677354258362317980232480599655892601737971605214456689414625051143149583130430015777666932278413376366490444799481994730937670144444108706475876364867963715493055413139989009064332461144764401332913216114174835230286790328260273776855482704763567420189045069407995458463148790202419905616663365656255145301923609398584304583918834530019737490919615364187160782624001064879131472384015496287137598952224982310537785032007424936093489750862005252362603204138959347827955672274570807193086354620031722701875656998897737063594680668907646074012561293335044071573346709693735604568080452486460946535926076900625312900620799812534942557108232365892232921373309006833256770623478329419960641573465365285085930346317204591531337595194296258358931619650781611883034923888677066494130909123967531964639015465489399954805452250081399179580422177728395024063649584361180211424821672571510538673078243326894153426539296503386005913561633619244503280032749612994689847604046760098267840290277779632563725197765582344044468580510393108259060611626151721642021336650816442168451954816239219383099487465904449076674353377619878310333633264084662106546205663984365029944691649507940407106264014744868439601525014119208450339353813430803710878871445151854431531193239966846583532506895172996798365496868037054342157210707692083852869985652403632390916617647050093190636328271114557529896734110149888963440411456255869187808421240179852328052416007345531539555207094898569484845379959096599350094013425458676859043118116423603610266960361888952320659686828927137809867399132935379414412279057432193276025556820953224776831664615670725665696425549414420084849718150349250844799823559130874187536675245390009975985346003296443074111161948986828130608030605974878642867774677559871211173628529334970477879235465718384914491913151356216440732481872899194438635359954572597351561435884828561408726857951049768224226271609357650351778333671977966629668934989066861460185349422445432557309970272764873129529277781563035392740559945844320598372421088027214115916544693422762329960005549998672437920421535304781232151152039529540045010598348189026056025370971058181636568298149047666035395482194443221046488062640359270202086635748784221683969780711367699880454568235836730472782858533457553463574196742403481290557721606527522688935188791305882626070750510960863348052239733068953435691594646139078026813286096486291844251776902325749710117240903095985924242332530656222227250240585259686722760013101711050251625633714023906837923193350531448113294155286689967029409927740886823664317399652214479270178344408773382913862695533899521553611724396716126160628228518313740596163337171105415708101979140357785084231877131493434358970639796528290015640237905802395520627080259329157046098136785443473949668933910031509536363803774582888195285042902418188261325170993829432147584257896792560949246081531272359515471296910372130039801428392043046951563752050729189275897400521949463269388073629522792587020447520100725563446835140874705849997426089662261671694936948098865531366264377932080369572448260847687072809990085863797457844692924098639628384584656404624514870766397811490409087043656055980390832392484773016020668436187699794242111888328986273380851650263817152496285057132446203198983647282759391899532263830686606813314361403667442338908245262527772570962918784692397218046878895019438361303959406705382471599747901470743014338818298194551694866087821845114169580232888277089058428781404664752303978461351789947740783482130440023346471156745212169438390794970572061653831447416945231622998933830469624432379015382451072316333122314761918546817666641724975915713942441184842738858664264987444177949286755849393149124567487216895621181759985776391095308565589036151178335698523619105096871666261908553086777362285580950571213245745172850775424593197772037309984828385132236524248654499284645135738025243511590143079775750053536816186436146795382998161433845157614312882542240718604615892079290727879653588179591671175639247734428338407893641753780166923093328041112342517356866510773925150448037351070348511397459690808952247741970475917955685299996204560341798129211119162188990370045633736990609811052156594519112188114558864570074664536642410881392342494665592614134258903540188283305969030700654116962504469101721652881896770418057056062113257207982005921457992424494909931179424012536222512492587398106680314616895156479473160626553473687058365533605681862818437677643715337356463376921522910030762661313903438423593640887591734945420491761832756294738128223390145771673025896624009184335620502407008565177673536133896057390562808098750293930099539336949778636990362397778262487240590580039952801898811619948974711981232653251962315101502511381979681449423203989003387201575497206044583190747154225267734561961607743076363516161592206562734594375725614966966824955714068025627478144329338557905801231778155431262906085035852372596017582518599335172636301833475834366033060186075298770927810001346471372332694454405934569624535174487599439107084807817861427183086446162201093954527360687523384804540288890004516031696376053647353081079155165144196987761879441538741482783261642749116566239615300526453831195179869974214512260225433962993645735454352518782721548114849568195362503832113145325561684994063899775154407614663724460063999180806170606988587532089521596151124691658547673803669268791976322768588039976615327660191174113702075923769412287969027117984430316426254425700118110403637865678872891910544613427459812729261229511758671524758105774081108674357657041824366291972172844877556355797856466823012260001167005390625764099118818877905934827486205393319945396562591166131217217448288590329045176360136799640239318157723013719500129097594879100130472824334674194752801794016524784346115585715792583355829682250295904870376491981140473819049985219396444962401618855869957555407201699621118207508526795672329573485679416412381753875953769592906257749540015632941023867717422189242233744977715217067028116628844804723395383536933268909372943130543033137929166320847699517505481112272191965571337120337694948958586784617946739560764256797834996238658675348015919553367760709771821246879151053100775525951678185936789646137105194353168806531391247738226816351631612706726011189949319336032566860017633474840776935176897680182614820961596122465995226339910201952274946194020798563825704926641004458431525360824337677375429491777753531960564821769400845471377360988874763295227957864310578682727415824923976553746712797750878145552890825540377931440648312471540066867453984182923596957910747560411087058569224079633585317099143551118039254561463156930983023505299224398910177848871403561878744754385511336553421839997331835055606684982227935564532236701187091781793633455583742425035248630979229636231868467923052437898362505975739547632988654143165943296459320967698111024110111721088590928764506975415994314459328073495224996574978895033116460709876182709866490745155944560946583194369063903257481281311755714779754244502487704711168934729207629355588251570133955818043551265551492660949841270073390021541882183693510632332777473522125876353570648213844714310969031729010428404707725886351284419474110976600907991764108959796648706675972598967200081081704579959524656771713333559555360007164241205385980464807752090893118321681423903861857420630127061695353050158746343700136648026731603383121777621789643813842455954937880501254234180098040248190581426435097913336982622730611863437664484423599147997008308223137560655369017160720465545883832227771132753055798029561485388466701315186594723130769270354036524080275997234681481784319020849550557392658011543661211141193378556081014085776128053522875014362453397657628861202407037539035385178164063301989936056314751335154927262621644846336441703646083060784970859328590859954989442846931349720689361608846645262140260989157737684761098920659772590942328886762414911681715226706393255734474101562239756101747917240081502327977397071836922359181375537907052920039994287300541999049450409336334886225164681110496150394157030652285248572823761749674924001312870405629993031147364526138939550818104087955946166214815654495609133317889302978367721188368019326183634100590665867366051426829473180341575959205410727603593331847854156318316221431841125605847960824180514408231542270712988490313049025889147029924809567955171853889632150833851333349369485497795741078284011424514043801041495230853869748519466011558578505600463485694841159413394821195314995630570701408491362818313067536869704328600957968818875236246987190670814464009765478658340509386527755460268245387616823341589644670146312421238197365903986865284236971688666844549942550606457462580954009397258975671631222293330717405598436034115691963325428241761380022595676578028648456410766444866610975897030008156826071943687760173703527023235821497529151288274406269592691831238170880561675066910780639540336777387479130732789626421821444446358907014148673072099809001016460851950039177173002386685993883086798872374600398134403217638257601369269803262299418843687078269800161432358562328561178524096550257648669872469813209569659020206967782786349903894010856532275665237444376804616572987170628994700810549627023967089991077835590297799471797066735057426995306428035569928427111511947638268151852327388528107804446920457785118558951598127855302203300352459673386895899738648470366590272286619723986347160769391334576920407329103334001256878039704203676907929022506235600421997740508380269689527741574068824087529532719318029591573145692761216963196029036470727139941004003794438406712118233001741921674868242418595830748710622303009518972752914859917623042518701154367349709955573369811860157720680294591375224277935651022428897693377803137515272128489417292944730435448933377005334397710836129178709244960460251145476143758867093292439997564476382954270875945385266448073936243081692719243848012645075214316811213090924730048717706312639779369514512115277106071250610210938340772431729296529960336998572250307484371562958393958645280954372049431199916998188234226047248318895890805550280131527404708360820806121091326401091255121266127299988484109427598488174518496352217959453887222805449754234774047406311190062972867885690337545333241386734824428876595665052730649905438345563755265861552615708879073437575797453583866199963533337412419089655435953207588606278641778796962170113331127330723122473077105157026267033312534656873858029968662447492960990575130231610431505986032191932375986686665729462550074494973895482180866966158871400124560225289463329023158003203107865717692583785722489383582575310485236122345806031170295638219693775725557021395246075440355125182037397932832904906787058458446293665093571394831608228058196856430523943870079872547354630490377779609711239461902213158940243327690712517523949956634958329915667517456561235136264084941567554439241028939457675360665666461435787589523871394662223952554044934516626440096639545618439269571176122084581232485332971012945738452980646590113679635551523851664704244871758716787384234898779560387661249783782828540432505380381386634647402449528848484665911942019101670896495402929284429402780740203023602704687255371136943651372297882768726938003723139881121187286195952230317862099766781825262812603008372419794602922929937898747599900620966720244472569152643576636689820381284142236836196959569023351962642371510071605756169037638070079623744107246519590752269155128567582183956223303512152904913047565142591748719342370033442053753508453610866869872396427794527005625653697420388066918628949402733804694132268212373557711813476959828289826946702076456908260438602358939869273814579996992877963466252645279399558151797086836426507662176650622101091765863038365485729670180796453580683300470520332849095474630492918463590893542982052276468848930296601101148807798164517316001564440748861266913121974321388293545295451773369847571695987548978286874939719896092884993594170191855069466364212505889247892116095830416033601231622767481887088344356841750382688789425686747649964440245827707772041963522514814709937272370531966327995797570767921536896762709263621282760796901763788002110751033796373667296011010090301117749957282543953832418176805255359271417587487729757794050272183267805512738817321338151519351073145906597581150147105290256677168294512857123815871553810395414696290885831639140000017539634748908816554433343737614172324610275274683392083260771550016522608531965843360496808501095006926611557096770426301576687854534977811291878948948408512866952207175828691381005826058089704996618035267070823511406394082342566663127874435994182693228367519969700281286372257203292695958541105666356242435649879854087255780911046270473966908641345197373245619931216360081403715345364307240863018415650977777055012491764833232374649089758909188160042345029275972259069074339266811895845111807797962745773882070712359053234594457346762816540016199275257887862812674528915489273193116046421352415741086621644568565259757043925255675413934473068651554902739873396969327584010700037340127168533830007987247425120861438845415803757465819518124260515185934826322031284057677437216850861663452241522153326157018711538732940716725184988568196564831492924283633263276513226362697899319271458766692079400390992471720867261907023373944555918677484045126341380571544109434846211711363779340033354359166948748886080467755524897551844457106673690160370758577181864979421394685653644686979036146728006305619445349804822159051415184860975932526243528366699949492017584956033845028804291251568545967668643487353983285781728293515659554129862171482132983083118158927218361515984877392780491882244076796924249063554281083400521572192804204423336654988356230863649791993984937218808541487652438509160227279532377507091487281161853957315564309384495805351759826276673863781330209869498414639560605616322592174259773960905711242339462610205342987382612995499472831445261312934827033362929332202230500522419419466689723584029332620597440691109665198073523265531248309561045211740489496741281201245777158059218975787707875252856170589517974291344892386962665601316498266074704018444136491934695315918581382398696220515293438043279672435083897853875802508770856317868860071869945542561447522066117576473715466197351613948896085822488873212889729916925636057407625640027639439977625871673342275714520739387902148206883682137642291242788351636172153269713587215629404738311294261657322783414637344240511488283786128207661564326725003350839555269952609524886532029422165309933333666783383432634352505934359817715569078486137377986381924133644538962141784385366488037234450740061542191803331557364200123155188084049522040831357518712035765213314972012006132326357393965961480653715068071824352510256230422104207485432817019022751907553087438302832049784312462309307900430726005555046933289250805242439264769242386213509333199311730123758798591353831242190106316093583103086890572486640158560516828096784715008029987131082059166670066520955945775634714077887607435444254993090775020519164359604263719726516700033876472242274355629189587560127606928112196943147177232587433972872174097551833117281349285277018402888163282481701813873111290814359718997412915858269468985293331964894251353195352344775676777746315273188163631731694061224296380190502887339265421949782229948442342632747707610426257714288232056973262149353207144094015975073511463473085414023611090631552477664933719990814324258017549263537660205157459432774288039854326693764174038449040441878183282640556785984056709556298147590312358012663694167966318140615072040800472566521307797330993825700450931534198570896305883528962126102232646741363356427706592146539524972674123078061880505149647979669647783000961973849188034364027295786543019825290392125511775945095676362111981558227533626811303158218777770252136867544861144547801245880123585055459889336908274472713328292147242620375159297516001664735496378853987735339770050637852928895715350696620172600305954928756127683697719488520528822548981465501955556580692543980514678740910646476458400407145869533204918406948436080508914943513821652770742678116032287035460610382518538224691140849591057377425507824271582383852803766372944038455478233802172190824846794399277876292846742550120799088566169383156021999098742342805432361728558796361599878920400816068717368767878887784342253056754424670350979659029596568343694523633359997585106001918773616851953950723276979853081265106332598156024469826026074679481628147013369898034120768488751952432966760276336758866693811237319066300116142706282163881826161325158625920638178489959639420924591866818149444124730489342144237640757144427859659035711106302101535035521593963756440029523789617893748632604930608099596441314851275097035783406781828037736828511085139276156579398497859386966836873506638029437020474005376759822222318654969646649170890775811465785888237428529766179161204348395483807983301595448822390859901840639950924463460826420973746060327371792764998492019121604629835863004003459535411598514649296365381986205462761231579484246766044506630243611290336467123753377595970487941475346556874607176890626351390629835329443105880985435642035021888506652340769853281241437979094305258812116097514009849478476478431645734011778585558408142210947668261599182723413780291165621810086833152363317901379957702188388519220959084625869093196405873357988902539297953528473498339052976096866848190554590630310448199200852255578314587469811079587528769390555211280895863459474670623444429951154557605802173773852614453202570794815606686538241026497769134446374802559145776757608520678607366043079999465729544104790474046534844654168181540301220819008381480817638513097542392882143844907763680242655017291885953945546558037071075263671824690099916993344483060236884934283020396100772379608856700328757903539841639070807420502536941712720007193226288927064000287025062034765556938255673500167633473536576117718449196222545728223780117403613907335829523913072435692051719272948281814751532405678270901083230841139274588154004883140969666863785647317156157057281649374433999960472743657580786946031623660895208758484397445248568368626234909299413194078570691962876581280838521891910064781575921752433844152042135027266777659670061256295488804164932412588956852668345726015156632908933425085879542907720258747215579379762406257541569142542134954986264315685914857836257668959967717000926081706318541107443030832121474901612266181141156680201564243345623304100429527781747861809650556262969855182118383398594103068502841628665452576207013149774625999640517060562
```",storage: storage corruption,CWE-665,Improper Initialization,"The bug report describes a failure during the process of synchronizing a `geth` node from scratch. This synchronization is a form of resource initialization, where the resource is the blockchain database. The log shows multiple errors, such as `Failed to reset txpool state err=""missing trie node...""` and `Invalid header encountered`, which indicate that the database is in a corrupted or inconsistent state. The user's explicit action is to `removedb` and start over, which is a direct attempt at initialization. The failure of this process, leading to a resource (the database) being in an unusable, unexpected state, aligns perfectly with the definition of CWE-665: 'The product does not initialize or incorrectly initializes a resource, which might leave the resource in an unexpected state.'

CWE-20 (Improper Input Validation) is a plausible candidate because the node receives an 'Invalid header' from a peer. However, the log shows this as a `WARN`, suggesting some level of validation did occur. More importantly, this is just one symptom of a larger problem. The core issue is not just accepting one piece of bad data, but the entire initialization process failing, resulting in a corrupted state.

CWE-436 (Interpretation Conflict) is less suitable because the bug report does not provide evidence that the issue stems from a difference in how two distinct products (e.g., `geth` vs. another client type) handle data. The errors appear to be internal to the `geth` client's own state management and database construction during the sync (initialization) phase.

Therefore, CWE-665 is the most accurate and encompassing classification for the described problem.",closed,"The issue arises from the Geth client's inability to properly handle certain synchronization modes, particularly 'path' mode, leading to unexpected behavior during the syncing process. The logs indicate repeated warnings about unexpected trienode heal packets and errors related to missing trie nodes, suggesting that the state and blockchain data may not be correctly validated or processed.","This bug can prevent the Geth client from successfully syncing from scratch, causing disruptions in the operation of Ethereum nodes. As a consequence, users may experience delays in accessing updated blockchain data, reduced reliability of the node, and potential issues with network participation or transaction processing.",2406916219,30149,"July 13, 2024 1:18 PM (GMT+8)","August 13, 2024 10:31 AM (GMT+8)",['type:bug'],
go-ethereum,`eth_createAccessList` fails when using block_hash and not setting txn fees,https://github.com/ethereum/go-ethereum/issues/30145,API,"#### System information

Geth version: current master (also happens in releases)
Commit hash : cf0378499f1bcae65c093c58cd6ca8225e91b125

#### Expected behaviour
`eth_createAccessList` to succeed when given a block hash (that wasn't pruned) and a basic transaction (only `to` and `input`) that does not revert.

#### Actual behaviour
Returns the following error:
```
code: -32000
message: ""failed to apply transaction: 0x3e983326c3827cf62805f3dab45de2d23ce3c839310d823feac120f538a1a286 err: max fee per gas less than block base fee: address 0x0000000000000000000000000000000000000000, maxFeePerGas: 27907986728, baseFee: 28235336045"", data: None
```

Note that this does not always happen:

#### Relevant files
- The call to `set_defaults` that doesn't get the block that was requested: https://github.com/ethereum/go-ethereum/blob/bcaf3747f8443c6f8042f4f058f74404bb8c0a22/internal/ethapi/api.go#L1506-L1515
- The part of the implementation that sets this: https://github.com/ethereum/go-ethereum/blob/bcaf3747f8443c6f8042f4f058f74404bb8c0a22/internal/ethapi/transaction_args.go#L186-L187
- Where the field is set: https://github.com/ethereum/go-ethereum/blob/bcaf3747f8443c6f8042f4f058f74404bb8c0a22/internal/ethapi/transaction_args.go#L268-L272

#### The cause of this bug:
When requesting the access list for anything but the most recent block and not specifying fee details, Go-Ethereum automatically adds the fee values **using the most recent block** (rather than the specified one). When the block base-fee changed durin gthat time the resulting `maxFeePerGas` can (and does often enough to be a problem) be below the `baseFee` of the block we're actually executing against, thus causing this error.

#### Additional Information
Potentially related (but I think it's a different issue/cause): https://github.com/ethereum/go-ethereum/issues/25319",api: api unavailability,CWE-436,Interpretation Conflict,"The root cause of the bug is a discrepancy in how the system sources its data for a single operation. The user provides a `block_hash` to define the context (a specific past block) for the `eth_createAccessList` call. However, when transaction fee details are omitted, the system's `set_defaults` function incorrectly uses the context of the *latest* block to populate these missing values. This leads to an internal state where the transaction is being evaluated against the target block, but with fee parameters derived from the latest block. This is a classic example of an 'Interpretation Conflict' as defined by CWE-436, where the system handles one input (the `block_hash`) correctly but misinterprets the context for another part of the operation (defaulting fees), leading to an incorrect action (the transaction failure). CWE-1188 is not a good fit because the default value is not inherently 'insecure,' but rather contextually incorrect. CWE-20 is also unsuitable because the issue is not a failure to validate input, but a logical error in processing that leads to a failed internal check.",closed,"The bug occurs because when `eth_createAccessList` is called with a block hash, the system defaults to using the most recent block's fee values instead of the specified block's fee values. This leads to situations where `maxFeePerGas` is set below the `baseFee` of the block being executed against.","This bug can cause the `eth_createAccessList` call to fail, resulting in failed transactions when the block base fee has changed. This can lead to unexpected behavior in applications relying on this API, potentially causing a denial of service for functionality that requires access list creation.",2403355524,30145,"July 11, 2024 2:38 PM (GMT+8)","November 8, 2024 8:33 PM (GMT+8)",['type:bug'],
go-ethereum,--dev mode restart error with --datadir,https://github.com/ethereum/go-ethereum/issues/29955,Storage,"#### System information

Geth version: `geth version`
CL client & version: e.g. lighthouse/nimbus/prysm@v1.0.0
OS & Version: Linux
Commit hash : 68c0ec08158c

#### Expected behaviour
geth successfully starts

#### Actual behaviour
geth canot start, error: Fatal: Could not read genesis from database: could not unmarshal genesis state json: missing required field 'balance' for Account


#### Steps to reproduce the behaviour
```bash
./build/bin/geth --dev --datadir ./data --http --http.api personal,eth,net,web3,debug --allow-insecure-unlock
```
run this command, ctrl+c to quit it, then run this command again, the error occurs.

#### Backtrace

````
INFO [06-07|16:24:29.422] Starting Geth in ephemeral dev mode...
WARN [06-07|16:24:29.422] You are running Geth in --dev mode. Please note the following:

  1. This mode is only intended for fast, iterative development without assumptions on
     security or persistence.
  2. The database is created in memory unless specified otherwise. Therefore, shutting down
     your computer or losing power will wipe your entire block data and chain state for
     your dev environment.
  3. A random, pre-allocated developer account will be available and unlocked as
     eth.coinbase, which can be used for testing. The random dev account is temporary,
     stored on a ramdisk, and will be lost if your machine is restarted.
  4. Mining is enabled by default. However, the client will only seal blocks if transactions
     are pending in the mempool. The miner's minimum accepted gas price is 1.
  5. Networking is disabled; there is no listen-address, the maximum number of peers is set
     to 0, and discovery is disabled.

INFO [06-07|16:24:29.424] Maximum peer count                       ETH=50 total=50
INFO [06-07|16:24:29.425] Smartcard socket not found, disabling    err=""stat /run/pcscd/pcscd.comm: no such file or directory""
INFO [06-07|16:24:29.428] Set global gas cap                       cap=50,000,000
INFO [06-07|16:24:29.494] Using developer account                  address=0x958dd2c08650fF154d0030923790250eFd06EffB
INFO [06-07|16:24:29.495] Using pebble as the backing database
INFO [06-07|16:24:29.495] Allocated cache and file handles         database=/home/tmp/geth_node/data/geth/chaindata cache=512.00MiB handles=524,288
INFO [06-07|16:24:29.496] Opened ancient database                  database=/home/tmp/geth_node/data/geth/chaindata/ancient/chain readonly=true
Fatal: Could not read genesis from database: could not unmarshal genesis state json: missing required field 'balance' for Account

````

When submitting logs: please submit them as text and not screenshots.
",general: initialization failure,CWE-404,Improper Resource Shutdown or Release,"The bug report describes a failure that occurs when the application is started for a second time after being terminated with `ctrl+c`. The error message, `Fatal: Could not read genesis from database: could not unmarshal genesis state json: missing required field 'balance' for Account`, indicates that the application fails during its initialization phase because the data it's trying to read from its persistent storage (`--datadir`) is malformed or incomplete. This malformed state is a result of the previous instance of the application being terminated abruptly. Analyzing the provided CWEs: 

1. **CWE-502 (Deserialization of Untrusted Data)** is considered but dismissed. While the failure is technically a deserialization (`unmarshal`) error, the data is not 'untrusted' in the typical sense of being supplied by a malicious external actor. The data was written by the application itself in the previous session and is merely corrupted, making this CWE a poor fit for the root cause.

2. **CWE-665 (Improper Initialization)** accurately describes the symptom observed during the second run. The application is indeed failing to initialize correctly because a resource (the database) is in an unexpected state. 

3. **CWE-404 (Improper Resource Shutdown or Release)** points to the root cause more accurately than CWE-665. The problem originates from the first session's termination. The `ctrl+c` signal leads to an improper shutdown, where the application does not correctly finalize or 'release' the database resource, leaving it in an inconsistent state. This improperly released resource is then 'made available for re-use' on the next startup, leading to the observed initialization failure. 

Therefore, CWE-404 is the single most accurate classification because the fundamental weakness lies in the shutdown/termination process, which corrupts the resource, directly causing the subsequent initialization failure.",closed,The issue arises from the inability of the Geth client to properly read the genesis state from the database after a restart in development mode. The genesis state JSON is missing a required field ('balance') for an account.,"This bug can prevent users from successfully starting the Geth client in development mode, hindering development processes and testing efforts.",2341557950,29955,"June 8, 2024 8:55 AM (GMT+8)","June 10, 2024 1:58 PM (GMT+8)",['type:bug'],
go-ethereum,"Error tracing old block/txs with ""contract creation code storage out of gas""",https://github.com/ethereum/go-ethereum/issues/29812,API,"#### System information

Geth version: `Geth/v1.13.15-stable-c5ba367e/linux-amd64/go1.22.2`
OS & Version: Linux
Network: Ethereum Mainnet

#### Expected behaviour

Successful transaction:

```
{
  ""jsonrpc"": ""2.0"",
  ""id"": 1,
  ""result"": [
    {
      ""txHash"": ""0x0bd55bbf4dfb4e7b15bfed296be3330d5c1116b1bc399a75d3f849edc0d5ac45"",
      ""result"": {
        ""from"": ""0x326be8f71bfb0379f989aab1cc1fe37f0a771f60"",
        ""gas"": ""0x493e0"",
        ""gasUsed"": ""0x2ac58"",
        ""to"": ""0xd8253352f6044cfe55bcc0748c3fa37b7df81f98"",
        ""input"": ""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"",
        ""output"": ""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"",
        ""value"": ""0xde0b6b3a7640000"",
        ""type"": ""CREATE""
      }
    }
  ]
}
```

#### Actual behaviour

We expect a successful transaction result, but getting an error in the traces for old blocks:
`contract creation code storage out of gas`

```
{
  ""jsonrpc"": ""2.0"",
  ""id"": 1,
  ""result"": [
    {
      ""txHash"": ""0x0bd55bbf4dfb4e7b15bfed296be3330d5c1116b1bc399a75d3f849edc0d5ac45"",
      ""result"": {
        ""from"": ""0x326be8f71bfb0379f989aab1cc1fe37f0a771f60"",
        ""gas"": ""0x493e0"",
        ""gasUsed"": ""0x2ac58"",
        ""input"": ""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"",
        ""error"": ""contract creation code storage out of gas"",
        ""value"": ""0xde0b6b3a7640000"",
        ""type"": ""CREATE""
      }
    }
  ]
}
```

#### Steps to reproduce the behaviour

```
curl http://127.0.0.1:8545/ \
  -H ""Content-Type: application/json"" \
  --data '{""method"":""debug_traceBlockByNumber"",""params"":[""0x11ba5"", {""tracer"": ""callTracer""}],""id"":1,""jsonrpc"":""2.0""}' | jq
```

It also happens when tracing transactions:

```
curl http://127.0.0.1:8545/ \
    -H ""Content-Type: application/json"" \
    --data '{""method"":""debug_traceTransaction"",""params"":[""0x967def72c4d687b4bf07dec6aeafd764b6f29a659cb655c82afdbe8cb0e2bcdb"", {""tracer"": ""callTracer""}],""id"":1,""jsonrpc"":""2.0""}' | jq
```

And others transactions like:
* `0x427ea3fd3e0123284acc734f11fa17b13de070553993d26b0eec3331be26ff9b`
* `0xaff43d4d212ac145e11ff29ad4c071e9f19af0f6f88c43fd10b896fba72df014`
* `0x0f4353e7cfd2d2afd9cc456609f34f76ad58142ecf1957124c4f28592168379a`",api: incorrect api output,CWE-436,Interpretation Conflict,"The bug report describes a situation where the Geth `debug_trace...` API incorrectly re-simulates a historical transaction. While the transaction was successful on the blockchain, the tracer API returns an ""out of gas"" error. This indicates a flaw in the re-execution logic. The core of the issue is that the gas cost, a critical resource, is being calculated incorrectly for these historical transactions, leading to an erroneous and misleading result. 

CWE-682, 'Incorrect Calculation', is the most accurate fit. The official description states, 'The product performs a calculation that generates incorrect or unintended results that are later used in security-critical decisions or resource management.' The Geth tracer is performing a gas calculation (resource management) that yields an incorrect result (an error instead of a successful trace). This directly matches the bug's symptoms.

CWE-20, 'Improper Input Validation', is not the best fit. The input to the API (the block number or transaction hash) is valid and correct. The failure is not in validating this input but in the subsequent internal processing and calculation based on that input.

CWE-1302, 'Missing Source Identifier in Entity Transactions on a System-On-Chip (SOC)', is entirely irrelevant as the bug relates to blockchain software, not System-on-a-Chip hardware.",closed,"The error occurs during contract creation when the gas required for storage operations exceeds the available gas limit, leading to a failure in tracing transactions for old blocks that involve contract creation.","This bug can cause issues with contract creation transactions, leading to failed transactions and potentially preventing users from deploying contracts properly. It may also affect the ability to trace and audit past transactions, impacting trust and transparency in the blockchain network.",2308528133,29812,"May 21, 2024 3:07 PM (GMT+8)","May 28, 2024 7:12 PM (GMT+8)",['type:bug'],
go-ethereum,"Debug_traceBlockByHash returning ""insufficient funds"" error on block 19888327",https://github.com/ethereum/go-ethereum/issues/29800,API,"#### System information

Geth version: geth.exe version 1.14.3-stable-ab48ba42
CL client & version: beacon-chain version Prysm/v5.0.3/38f208d70dc95b12c08403f5c72009aaa10dfe2f. Built at: 2024-04-04 18:48:31+00:00
OS & Version: Windows

#### Expected behaviour
Debug_traceBlockByHash should return the trace dump for block 19888327

#### Actual behaviour
A tracing failed message was returned instead

```
C:\Users\Administrator>curl http://localhost:8545 -m 300 -X POST --header ""Content-type: application/json"" --data ""{\""jsonrpc\"":\""2.0\"", \""method\"":\""debug_traceBlockByHash\"", \""params\"":[\""0xcc1d35533ea26392bfa91944b3f6d1f446581b05f5f4b35dea93d558b08d353c\"", {\""tracer\"":\""callTracer\""}], \""id\"":1}""
{""jsonrpc"":""2.0"",""id"":1,""error"":{""code"":-32000,""message"":""tracing failed: insufficient funds for gas * price + value: address 0xc79d40C897FbD912a7cD29E318a0D41F579793f6 have 2469004274997060 want 3963014826093176""}}
```

If I independently trace the two ""out"" transactions on this block for the address [0xc79d40C897FbD912a7cD29E318a0D41F579793f6 ](https://etherscan.io/address/0xc79d40C897FbD912a7cD29E318a0D41F579793f6), it seems to return results correctly.

```
C:\Users\Administrator>curl http://localhost:8545 -m 300 -X POST --header ""Content-type: application/json"" --data ""{\""jsonrpc\"":\""2.0\"", \""method\"":\""debug_traceTransaction\"", \""params\"":[\""0xefa4345e670ef386c0c1e076625c1a7627df192adf5ed8b7f5a8ec27c14ccdfd\"", {\""tracer\"":\""callTracer\""}], \""id\"":1}""
{""jsonrpc"":""2.0"",""id"":1,""result"":{""from"":""0xc79d40c897fbd912a7cd29e318a0d41f579793f6"",""gas"":""0x927c0"",""gasUsed"":""0x60126"",""to"":""0x5f6ae08b8aeb7078cf2f96afb089d7c9f51da47d"",""input"":""0xba1f77e80000000000000000000000000000000000000000000000000000000000000000"",""calls"":[{... etc
```

```
C:\Users\Administrator>curl http://localhost:8545 -m 300 -X POST --header ""Content-type: application/json"" --data ""{\""jsonrpc\"":\""2.0\"", \""method\"":\""debug_traceTransaction\"", \""params\"":[\""0xb3552b1f6e4c97349ca45ae34bb831c04c571fd4fa2110481d4aae851e8a0331\"", {\""tracer\"":\""callTracer\""}], \""id\"":1}""
{""jsonrpc"":""2.0"",""id"":1,""result"":{""from"":""0xc79d40c897fbd912a7cd29e318a0d41f579793f6"",""gas"":""0xa410"",""gasUsed"":""0x5208"",""to"":""0x742c5ce550ec2e1a78b338904978ec9004eb065f"",""input"":""0x"",""value"":""0xc8ed706a30328"",""type"":""CALL""}}
```

Seems to be affecting more than 1 of our nodes, potentially other blocks as well as we received some reports about indexed traces showing a transaction failing, however when the tx is traced individually with debug_traceTransaction, no execution reverted seemed to be found.",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes an issue where the `debug_traceBlockByHash` API call fails with an 'insufficient funds' error. The error message explicitly shows a discrepancy between the funds an account has and the funds it needs: '...have 2469004274997060 want 3963014826093176'. This indicates a failed calculation. The fact that tracing individual transactions within the same block works correctly suggests that the state (specifically, the account balance) is not being calculated and updated correctly when processing the sequence of transactions within the entire block. This leads to an incorrect result for the balance check, which is a form of resource management. Therefore, CWE-682 (Incorrect Calculation) is the most accurate description, as the software performs a calculation related to account funds that generates an incorrect result, causing the API call to fail. CWE-665 (Improper Initialization) is less precise; while the state for a subsequent transaction might be considered 'improperly initialized', the root cause is the flawed calculation of that state based on prior transactions in the block. CWE-1191 is irrelevant as it pertains to hardware debug interfaces, not a software API.",closed,"The debug_traceBlockByHash method is failing to provide the expected trace dump due to insufficient funds error on one of the transactions within the block, despite successful tracing of individual transactions.","This bug may lead to incorrect or incomplete transaction tracing results, potentially causing confusion and hindering debugging efforts for developers relying on accurate trace information.",2302517425,29800,"May 17, 2024 11:44 AM (GMT+8)","May 29, 2024 3:00 AM (GMT+8)",['type:bug'],
go-ethereum,"`cmd/evm` can't invoke post-merge opcodes correctly ",https://github.com/ethereum/go-ethereum/issues/29782,Execution,"#### System information

Geth version: `geth & Tools 1.14.4`
CL client & version: Nope
OS & Version: Linux
Commit hash : d2f00cb5

#### Expected behaviour
`cmd/evm` should support opcodes introduced in shanghai fork.

#### Actual behaviour
`cmd/evm`  raised ""error"":""invalid opcode: PUSH0"" in the json file.

#### Steps to reproduce the behaviour
Hello guys, I think the problem that cmd/evm can't support for post-merge opcodes(like PUSH0) at #28690 is not fixed yet. 
1. I downloaded several recent binary archives of geth & Tools 1.14.0, 1.14.2 1.14.4 from https://geth.ethereum.org/downloads
2. Create a genesis.json file that enables shanghai opcodes by setting `shanghaiTime=0`
```json
{
    ""config"": {
      ""chainId"": 9599,
      ""homesteadBlock"": 0,
      ""eip150Block"": 0,
      ""eip155Block"": 0,
      ""eip158Block"": 0,
      ""byzantiumBlock"": 0,
      ""constantinopleBlock"": 0,
      ""petersburgBlock"": 0,
      ""istanbulBlock"": 0,
      ""berlinBlock"": 0,
      ""londonBlock"": 0,
      ""shanghaiBlock"": 0,
      ""shanghaiTime"":0
    },
    ""alloc"": {
      ""0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f"": {
        ""balance"": ""0xffffffffffffffffffffffffffffffffffffffff""
      }
    },
    ""coinbase"": ""0x000000000000000000000000000000000000abcd"",
    ""difficulty"": ""0x0"",
    ""extraData"": """",
    ""gasLimit"": ""0xffffff"",
    ""nonce"": ""0x0000000000000042"",
    ""mixhash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
    ""parentHash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
    ""timestamp"": ""0x00""
}
```
3. Run the `evm` directly with the commands:
```shell
./evm --debug --verbosity 1 --gas 0xffffff --nomemory=false --json --sender 0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f --receiver 0x000000000000000000000000636F6E7472616374 --code 6080604052348015600e575f80fd5b50600436106026575f3560e01c8063b349cb3214602a575b5f80fd5b60406004803603810190603c919060b2565b6042565b005b8073ffffffffffffffffffffffffffffffffffffffff16ff5b5f80fd5b5f73ffffffffffffffffffffffffffffffffffffffff82169050919050565b5f608682605f565b9050919050565b609481607e565b8114609d575f80fd5b50565b5f8135905060ac81608d565b92915050565b5f6020828403121560c45760c3605b565b5b5f60cf8482850160a0565b9150509291505056fea2646970667358221220802b048b24208868e10a279d062a61966de4d4410bf3b21674deb80178cc524964736f6c63430008170033 --input b349cb320000000000000000000000009957acb0b63afca54257b634bc605ec639f8165c --prestate ./genesis.json run 
```

#### Backtrace
The json outputs are 
```json
{""pc"":0,""op"":96,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":2,""op"":96,""gas"":""0xfffffc"",""gasCost"":""0x3"",""memSize"":0,""stack"":[""0x80""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":4,""op"":82,""gas"":""0xfffff9"",""gasCost"":""0xc"",""memSize"":0,""stack"":[""0x80"",""0x40""],""depth"":1,""refund"":0,""opName"":""MSTORE""}
{""pc"":5,""op"":52,""gas"":""0xffffed"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""CALLVALUE""}
{""pc"":6,""op"":128,""gas"":""0xffffeb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":7,""op"":21,""gas"":""0xffffe8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""ISZERO""}
{""pc"":8,""op"":96,""gas"":""0xffffe5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":10,""op"":87,""gas"":""0xffffe2"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1"",""0xe""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":14,""op"":91,""gas"":""0xffffd8"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":15,""op"":80,""gas"":""0xffffd7"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":16,""op"":96,""gas"":""0xffffd5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":18,""op"":54,""gas"":""0xffffd2"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4""],""depth"":1,""refund"":0,""opName"":""CALLDATASIZE""}
{""pc"":19,""op"":16,""gas"":""0xffffd0"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""LT""}
{""pc"":20,""op"":96,""gas"":""0xffffcd"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":22,""op"":87,""gas"":""0xffffca"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x26""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":23,""op"":95,""gas"":""0xffffc0"",""gasCost"":""0x0"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":23,""op"":95,""gas"":""0xffffc0"",""gasCost"":""0x0"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH0"",""error"":""invalid opcode: PUSH0""}
{""output"":"""",""gasUsed"":""0xffffff"",""error"":""invalid opcode: PUSH0""}
#### LOGS ####
```
The same commands and genesis.json work fine in geth 1.13.4-stable-3f907d6a but fail in geth 1.14.0-stable-87246f3c. The expected output from geth 1.13.4 is
```json
{""pc"":0,""op"":96,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":2,""op"":96,""gas"":""0xfffffc"",""gasCost"":""0x3"",""memSize"":0,""stack"":[""0x80""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":4,""op"":82,""gas"":""0xfffff9"",""gasCost"":""0xc"",""memSize"":0,""stack"":[""0x80"",""0x40""],""depth"":1,""refund"":0,""opName"":""MSTORE""}
{""pc"":5,""op"":52,""gas"":""0xffffed"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""CALLVALUE""}
{""pc"":6,""op"":128,""gas"":""0xffffeb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":7,""op"":21,""gas"":""0xffffe8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""ISZERO""}
{""pc"":8,""op"":96,""gas"":""0xffffe5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":10,""op"":87,""gas"":""0xffffe2"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1"",""0xe""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":14,""op"":91,""gas"":""0xffffd8"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":15,""op"":80,""gas"":""0xffffd7"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":16,""op"":96,""gas"":""0xffffd5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":18,""op"":54,""gas"":""0xffffd2"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4""],""depth"":1,""refund"":0,""opName"":""CALLDATASIZE""}
{""pc"":19,""op"":16,""gas"":""0xffffd0"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""LT""}
{""pc"":20,""op"":96,""gas"":""0xffffcd"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":22,""op"":87,""gas"":""0xffffca"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x26""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":23,""op"":95,""gas"":""0xffffc0"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":24,""op"":53,""gas"":""0xffffbe"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""CALLDATALOAD""}
{""pc"":25,""op"":96,""gas"":""0xffffbb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb320000000000000000000000009957acb0b63afca54257b634bc605ec6""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":27,""op"":28,""gas"":""0xffffb8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb320000000000000000000000009957acb0b63afca54257b634bc605ec6"",""0xe0""],""depth"":1,""refund"":0,""opName"":""SHR""}
{""pc"":28,""op"":128,""gas"":""0xffffb5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":29,""op"":99,""gas"":""0xffffb2"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0xb349cb32""],""depth"":1,""refund"":0,""opName"":""PUSH4""}
{""pc"":34,""op"":20,""gas"":""0xffffaf"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0xb349cb32"",""0xb349cb32""],""depth"":1,""refund"":0,""opName"":""EQ""}
{""pc"":35,""op"":96,""gas"":""0xffffac"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":37,""op"":87,""gas"":""0xffffa9"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x1"",""0x2a""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":42,""op"":91,""gas"":""0xffff9f"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":43,""op"":96,""gas"":""0xffff9e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":45,""op"":96,""gas"":""0xffff9b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":47,""op"":128,""gas"":""0xffff98"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":48,""op"":54,""gas"":""0xffff95"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4"",""0x4""],""depth"":1,""refund"":0,""opName"":""CALLDATASIZE""}
{""pc"":49,""op"":3,""gas"":""0xffff93"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""SUB""}
{""pc"":50,""op"":129,""gas"":""0xffff90"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4"",""0x20""],""depth"":1,""refund"":0,""opName"":""DUP2""}
{""pc"":51,""op"":1,""gas"":""0xffff8d"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4"",""0x20"",""0x4""],""depth"":1,""refund"":0,""opName"":""ADD""}
{""pc"":52,""op"":144,""gas"":""0xffff8a"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":53,""op"":96,""gas"":""0xffff87"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":55,""op"":145,""gas"":""0xffff84"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x24"",""0x4"",""0x3c""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":56,""op"":144,""gas"":""0xffff81"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":57,""op"":96,""gas"":""0xffff7e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":59,""op"":86,""gas"":""0xffff7b"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0xb2""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":178,""op"":91,""gas"":""0xffff73"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":179,""op"":95,""gas"":""0xffff72"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":180,""op"":96,""gas"":""0xffff70"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":182,""op"":130,""gas"":""0xffff6d"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x20""],""depth"":1,""refund"":0,""opName"":""DUP3""}
{""pc"":183,""op"":132,""gas"":""0xffff6a"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x20"",""0x4""],""depth"":1,""refund"":0,""opName"":""DUP5""}
{""pc"":184,""op"":3,""gas"":""0xffff67"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x20"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""SUB""}
{""pc"":185,""op"":18,""gas"":""0xffff64"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x20"",""0x20""],""depth"":1,""refund"":0,""opName"":""SLT""}
{""pc"":186,""op"":21,""gas"":""0xffff61"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""ISZERO""}
{""pc"":187,""op"":96,""gas"":""0xffff5e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":189,""op"":87,""gas"":""0xffff5b"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x1"",""0xc4""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":196,""op"":91,""gas"":""0xffff51"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":197,""op"":95,""gas"":""0xffff50"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":198,""op"":96,""gas"":""0xffff4e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":200,""op"":132,""gas"":""0xffff4b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf""],""depth"":1,""refund"":0,""opName"":""DUP5""}
{""pc"":201,""op"":130,""gas"":""0xffff48"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24""],""depth"":1,""refund"":0,""opName"":""DUP3""}
{""pc"":202,""op"":133,""gas"":""0xffff45"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x0""],""depth"":1,""refund"":0,""opName"":""DUP6""}
{""pc"":203,""op"":1,""gas"":""0xffff42"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x0"",""0x4""],""depth"":1,""refund"":0,""opName"":""ADD""}
{""pc"":204,""op"":96,""gas"":""0xffff3f"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":206,""op"":86,""gas"":""0xffff3c"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0xa0""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":160,""op"":91,""gas"":""0xffff34"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":161,""op"":95,""gas"":""0xffff33"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":162,""op"":129,""gas"":""0xffff31"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x0""],""depth"":1,""refund"":0,""opName"":""DUP2""}
{""pc"":163,""op"":53,""gas"":""0xffff2e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x0"",""0x4""],""depth"":1,""refund"":0,""opName"":""CALLDATALOAD""}
{""pc"":164,""op"":144,""gas"":""0xffff2b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":165,""op"":80,""gas"":""0xffff28"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":166,""op"":96,""gas"":""0xffff26"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":168,""op"":129,""gas"":""0xffff23"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac""],""depth"":1,""refund"":0,""opName"":""DUP2""}
{""pc"":169,""op"":96,""gas"":""0xffff20"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":171,""op"":86,""gas"":""0xffff1d"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x8d""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":141,""op"":91,""gas"":""0xffff15"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":142,""op"":96,""gas"":""0xffff14"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":144,""op"":129,""gas"":""0xffff11"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94""],""depth"":1,""refund"":0,""opName"":""DUP2""}
{""pc"":145,""op"":96,""gas"":""0xffff0e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":147,""op"":86,""gas"":""0xffff0b"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x7e""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":126,""op"":91,""gas"":""0xffff03"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":127,""op"":95,""gas"":""0xffff02"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":128,""op"":96,""gas"":""0xffff00"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":130,""op"":130,""gas"":""0xfffefd"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86""],""depth"":1,""refund"":0,""opName"":""DUP3""}
{""pc"":131,""op"":96,""gas"":""0xfffefa"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":133,""op"":86,""gas"":""0xfffef7"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x5f""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":95,""op"":91,""gas"":""0xfffeef"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":96,""op"":95,""gas"":""0xfffeee"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":97,""op"":115,""gas"":""0xfffeec"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH20""}
{""pc"":118,""op"":130,""gas"":""0xfffee9"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0xffffffffffffffffffffffffffffffffffffffff""],""depth"":1,""refund"":0,""opName"":""DUP3""}
{""pc"":119,""op"":22,""gas"":""0xfffee6"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0xffffffffffffffffffffffffffffffffffffffff"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""AND""}
{""pc"":120,""op"":144,""gas"":""0xfffee3"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":121,""op"":80,""gas"":""0xfffee0"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":122,""op"":145,""gas"":""0xfffede"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":123,""op"":144,""gas"":""0xfffedb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x86""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":124,""op"":80,""gas"":""0xfffed8"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x86"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":125,""op"":86,""gas"":""0xfffed6"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x86""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":134,""op"":91,""gas"":""0xfffece"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":135,""op"":144,""gas"":""0xfffecd"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":136,""op"":80,""gas"":""0xfffeca"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":137,""op"":145,""gas"":""0xfffec8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":138,""op"":144,""gas"":""0xfffec5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94""],""depth"":1,""refund"":0,""opName"":""SWAP1""}
{""pc"":139,""op"":80,""gas"":""0xfffec2"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":140,""op"":86,""gas"":""0xfffec0"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x94""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":148,""op"":91,""gas"":""0xfffeb8"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":149,""op"":129,""gas"":""0xfffeb7"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""DUP2""}
{""pc"":150,""op"":20,""gas"":""0xfffeb4"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""EQ""}
{""pc"":151,""op"":96,""gas"":""0xfffeb1"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":153,""op"":87,""gas"":""0xfffeae"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x1"",""0x9d""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":157,""op"":91,""gas"":""0xfffea4"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":158,""op"":80,""gas"":""0xfffea3"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":159,""op"":86,""gas"":""0xfffea1"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xac""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":172,""op"":91,""gas"":""0xfffe99"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":173,""op"":146,""gas"":""0xfffe98"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0xcf"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP3""}
{""pc"":174,""op"":145,""gas"":""0xfffe95"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x24"",""0x4"",""0xcf""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":175,""op"":80,""gas"":""0xfffe92"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xcf"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":176,""op"":80,""gas"":""0xfffe90"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xcf"",""0x4""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":177,""op"":86,""gas"":""0xfffe8e"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xcf""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":207,""op"":91,""gas"":""0xfffe86"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":208,""op"":145,""gas"":""0xfffe85"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x0"",""0x0"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":209,""op"":80,""gas"":""0xfffe82"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":210,""op"":80,""gas"":""0xfffe80"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":211,""op"":146,""gas"":""0xfffe7e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x3c"",""0x24"",""0x4"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SWAP3""}
{""pc"":212,""op"":145,""gas"":""0xfffe7b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x24"",""0x4"",""0x3c""],""depth"":1,""refund"":0,""opName"":""SWAP2""}
{""pc"":213,""op"":80,""gas"":""0xfffe78"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x3c"",""0x4"",""0x24""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":214,""op"":80,""gas"":""0xfffe76"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x3c"",""0x4""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":215,""op"":86,""gas"":""0xfffe74"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x3c""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":60,""op"":91,""gas"":""0xfffe6c"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":61,""op"":96,""gas"":""0xfffe6b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":63,""op"":86,""gas"":""0xfffe68"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x42""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":66,""op"":91,""gas"":""0xfffe60"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":67,""op"":128,""gas"":""0xfffe5f"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":68,""op"":115,""gas"":""0xfffe5c"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""PUSH20""}
{""pc"":89,""op"":22,""gas"":""0xfffe59"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0xffffffffffffffffffffffffffffffffffffffff""],""depth"":1,""refund"":0,""opName"":""AND""}
{""pc"":90,""op"":255,""gas"":""0xfffe56"",""gasCost"":""0x1db0"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0xb349cb32"",""0x40"",""0x9957acb0b63afca54257b634bc605ec639f8165c"",""0x9957acb0b63afca54257b634bc605ec639f8165c""],""depth"":1,""refund"":0,""opName"":""SELFDESTRUCT""}
{""output"":"""",""gasUsed"":""0x1f59""}
```
I want to know whether this is a bug or the way to set evm genesis has changed. As I'm fuzzing evm implementations, to let geth/evm support new opcodes is important to me. 
Thanks for your time :)  
",evm: simulation inconsistency,CWE-665,Improper Initialization,"The bug report describes a situation where the `cmd/evm` tool fails to recognize a valid opcode (`PUSH0`) for the Shanghai fork, despite being explicitly configured to use that fork via a `genesis.json` file (`shanghaiTime=0`). The core issue is that the mechanism responsible for selecting and applying the correct EVM ruleset based on the configuration is not functioning correctly. This EVM ruleset selection is a form of protection, as it ensures that only opcodes valid for a specific network state are executed. The tool is incorrectly using an older ruleset, leading to the rejection of valid bytecode.

- **CWE-693 (Protection Mechanism Failure):** This is the most accurate fit. The fork scheduling system is a protection mechanism designed to ensure the EVM operates under the correct set of rules. The bug shows this mechanism is failing to activate the Shanghai ruleset as configured, thus it 'incorrectly uses a protection mechanism'.

- **CWE-1188 (Initialization of a Resource with an Insecure Default):** This is not a good fit. The problem is not with a default setting. The user is providing a specific, non-default configuration to enable the Shanghai fork, but this configuration is being ignored or mishandled. The failure is in applying an explicit setting, not in the nature of the default.

- **CWE-20 (Improper Input Validation):** This is less precise. The issue is not that the input (`genesis.json` or the bytecode) is being validated incorrectly. The `genesis.json` is likely parsed correctly, and the `PUSH0` opcode is correctly identified as invalid *under the wrong ruleset*. The root cause is the failure to use the input configuration to switch to the *correct* ruleset (the protection mechanism) before validation occurs.",closed,"The `cmd/evm` module does not correctly handle the new opcodes introduced in the Shanghai fork, leading to an 'invalid opcode' error for the PUSH0 instruction.","The inability to invoke post-merge opcodes like PUSH0 could lead to failures in executing smart contracts that utilize these opcodes, resulting in potential loss of functionality and financial impact for users relying on these contracts.",2297412100,29782,"May 15, 2024 9:56 AM (GMT+8)","May 28, 2024 7:45 PM (GMT+8)",['type:bug'],
go-ethereum,"Debug_traceBlockByHash shows output for tx hash as ""Execution Reverted"" falsely",https://github.com/ethereum/go-ethereum/issues/29778,API,"#### System information

Geth version: `1.14.2`
CL client & version: `lighthouse, but N/A`
OS & Version: `Ubuntu 22`
Commit hash : N/A

Example: 
blockHash: `0xa8f23b3c94c8c5156dac46b93f1575f2c3ff7bc35d07276056fb5745d550875f`
txHash: `0x54ee3181242a78fb55c484f6de1c58aacb2e7abc08c8a4e25f799ae47dcd964d`

#### Expected behaviour

This tx is successful according to etherscan and other clients (Erigon, Nethermind, and older Geth)
https://etherscan.io/tx/0x54ee3181242a78fb55c484f6de1c58aacb2e7abc08c8a4e25f799ae47dcd964d

Geth 1.13.15
```
    {
      ""txHash"": ""0x54ee3181242a78fb55c484f6de1c58aacb2e7abc08c8a4e25f799ae47dcd964d"",
      ""result"": {
        ""from"": ""0xc252ceec3ad24c47657638c323d96249a9f1b42a"",
        ""gas"": ""0xa1284"",
        ""gasUsed"": ""0x28061"",
        ""to"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
        ""input"": ""0x05f497df75e26b9977ebb3a4d68a155e846020979f11b30ad133b381c78f24c469c46dfc970000000000000000000000007635831f45dc9c9d0d0b81d29ef725fb5dcabf4e000000000000000000000000000000000000000000000000000000000000000000000
0000000000000000000a0b86991c6218b36c1d19d4a2e9eb0ce3606eb48000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2000000000000000000000000000000000000000000000000000000000204583d0000000000000000000000000000000000000000
0000000000206e9f2b26bfb08a8000000000000000000000b8f81bb640006643c29500000000000000000000b69c88fc9fca744e7f0aaba70e988204f9bdc9a15ba061ece073affdc2b67bb3c6bb074ae9430585ff71d4c78d8e07d39d5b6289a24d8253194032e78758c3ca00000000000
0000000000000000000000000000000000000000000000204583da80000e100004000000000000000000000000000000000000022634d94f7fa8200000000000000000000000000000000000000000000000000000000000001a00000000000000000000000000000000000000000000000
000000000000000135a263f4e84902997eff4537d4d0aaefbb4ca5ac95000000c1000000540000005400000054000000540000002a0000000000000000fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6
b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8406643c1bdb09498030ae3416b66dc000080af6840355608efd9a900000c989d73cf0bd5f83b660000d18bd45f0b94f54a968f0000d61b892b2ad6249011850000a59ca88d5813e693528f0000299aad897099c9fc85ce000038d42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66010101a263f4e84902997eff4537d4d0aaefbb4ca5ac9500130500002100000000000000002935426dcb0c0e0000000000000000000000"",
        ""calls"": [
          {
            ""from"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
            ""gas"": ""0x965d4"",
            ""gasUsed"": ""0x25a34"",
            ""to"": ""0x5b93d80da1a359340d1f339fb574bdc56763f995"",
            ""input"": ""0x05f497df75e26b9977ebb3a4d68a155e846020979f11b30ad133b381c78f24c469c46dfc970000000000000000000000007635831f45dc9c9d0d0b81d29ef725fb5dcabf4e0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000a0b86991c6218b36c1d19d4a2e9eb0ce3606eb48000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2000000000000000000000000000000000000000000000000000000000204583d00000000000000000000000000000000000000000000000000206e9f2b26bfb08a8000000000000000000000b8f81bb640006643c29500000000000000000000b69c88fc9fca744e7f0aaba70e988204f9bdc9a15ba061ece073affdc2b67bb3c6bb074ae9430585ff71d4c78d8e07d39d5b6289a24d8253194032e78758c3ca000000000000000000000000000000000000000000000000000000000204583da80000e100004000000000000000000000000000000000000022634d94f7fa8200000000000000000000000000000000000000000000000000000000000001a0000000000000000000000000000000000000000000
0000000000000000000135a263f4e84902997eff4537d4d0aaefbb4ca5ac95000000c1000000540000005400000054000000540000002a0000000000000000fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8406643c1bdb09498030ae3416b66dc000080af6840355608efd9a900000c989d73cf0bd5f83b660000d18bd45f0b94f54a968f0000d61b892b2ad62490
11850000a59ca88d5813e693528f0000299aad897099c9fc85ce000038d42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66010101a263f4e84902997eff4537d4d0aaefbb4ca5ac9500130500002100000000000000002935426dcb0c0e0000000000000000000000"",
            ""calls"": [
              {
                ""from"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
                ""gas"": ""0x9338e"",
                ""gasUsed"": ""0x24d18"",
                ""to"": ""0x111111125421ca6dc452d289314280a0f8842a65"",
                ""input"": ""0xf497df75e26b9977ebb3a4d68a155e846020979f11b30ad133b381c78f24c469c46dfc970000000000000000000000007635831f45dc9c9d0d0b81d29ef725fb5dcabf4e000000000000000000000000000000000000000000000000000000000000000
//...
```

#### Actual behaviour
Geth, as of 1.14.2, shows in 
```
    {
      ""txHash"": ""0x54ee3181242a78fb55c484f6de1c58aacb2e7abc08c8a4e25f799ae47dcd964d"",
      ""result"": {
        ""from"": ""0xc252ceec3ad24c47657638c323d96249a9f1b42a"",
        ""gas"": ""0xa1284"",
        ""gasUsed"": ""0xd44a"",
        ""to"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
        ""input"": ""0x05f497df75e26b9977ebb3a4d68a155e846020979f11b30ad133b381c78f24c469c46dfc970000000000000000000000007635831f45dc9c9d0d0b81d29ef725fb5dcabf4e0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000a0b86991c6218b36c1d19d4a2e9eb0ce3606eb48000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2000000000000000000000000000000000000000000000000000000000204583d00000000000000000000000000000000000000000000000000206e9f2b26bfb08a8000000000000000000000b8f81bb640006643c29500000000000000000000b69c88fc9fca744e7f0aaba70e988204f9bdc9a15ba061ece073affdc2b67bb3c6bb074ae9430585ff71d4c78d8e07d39d5b6289a24d8253194032e78758c3ca000000000000000000000000000000000000000000000000000000000204583da80000e100004000000000000000000000000000000000000022634d94f7fa8200000000000000000000000000000000000000000000000000000000000001a00000000000000000000000000000000000000000000000000000000000000135a263f4e84902997eff4537d4d0aaefbb4ca5ac95000000c1000000540000005400000054000000540000002a0000000000000000fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8406643c1bdb09498030ae3416b66dc000080af6840355608efd9a900000c989d73cf0bd5f83b660000d18bd45f0b94f54a968f0000d61b892b2ad6249011850000a59ca88d5813e693528f0000299aad897099c9fc85ce000038d42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66010101a263f4e84902997eff4537d4d0aaefbb4ca5ac9500130500002100000000000000002935426dcb0c0e0000000000000000000000"",
        ""output"": ""0xfb8ae129"",
        ""error"": ""execution reverted"",
        ""calls"": [
          {
            ""from"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
            ""gas"": ""0x965d4"",
            ""gasUsed"": ""0x4d9d"",
            ""to"": ""0x5b93d80da1a359340d1f339fb574bdc56763f995"",
            ""input"": ""0x05f497df75e26b9977ebb3a4d68a155e846020979f11b30ad133b381c78f24c469c46dfc970000000000000000000000007635831f45dc9c9d0d0b81d29ef725fb5dcabf4e0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000a0b86991c6218b36c1d19d4a2e9eb0ce3606eb48000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc2000000000000000000000000000000000000000000000000000000000204583d00000000000000000000000000000000000000000000000000206e9f2b26bfb08a8000000000000000000000b8f81bb640006643c29500000000000000000000b69c88fc9fca744e7f0aaba70e988204f9bdc9a15ba061ece073affdc2b67bb3c6bb074ae9430585ff71d4c78d8e07d39d5b6289a24d8253194032e78758c3ca000000000000000000000000000000000000000000000000000000000204583da80000e100004000000000000000000000000000000000000022634d94f7fa8200000000000000000000000000000000000000000000000000000000000001a00000000000000000000000000000000000000000000000000000000000000135a263f4e84902997eff4537d4d0aaefbb4ca5ac95000000c1000000540000005400000054000000540000002a0000000000000000fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8402024b700001e806643c1d50000b42ae51d2024b700b4fb2809a5314473e1165f6b58018e20ed8f07b8406643c1bdb09498030ae3416b66dc000080af6840355608efd9a900000c989d73cf0bd5f83b660000d18bd45f0b94f54a968f0000d61b892b2ad6249011850000a59ca88d5813e693528f0000299aad897099c9fc85ce000038d42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66010101a263f4e84902997eff4537d4d0aaefbb4ca5ac9500130500002100000000000000002935426dcb0c0e0000000000000000000000"",
            ""output"": ""0xfb8ae129"",
            ""error"": ""execution reverted"",
            ""calls"": [
              {
                ""from"": ""0xd42b0ecf8a9f8ba9db7b0c989d73cf0bd5f83b66"",
                ""gas"": ""0x9338e"",
//...
```
#### Steps to reproduce the behaviour

Simply request this block hash in a `debug_traceBlockByHash` and check the txhash mentioned above.
```""jsonrpc"": ""2.0"", ""id"": 1, ""method"": ""debug_traceBlockByHash"", ""params"": [""0xa8f23b3c94c8c5156dac46b93f1575f2c3ff7bc35d07276056fb5745d550875f"",{""Tracer"": ""callTracer""}]}```


",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a situation where a specific version of the Geth software (1.14.2) produces a different output for the same input (a specific block hash) compared to other blockchain clients (Erigon, Nethermind) and even a previous version of itself (1.13.15). The newer Geth version incorrectly reports a successful transaction as 'execution reverted'. This perfectly matches the definition of CWE-436, 'Interpretation Conflict', where 'Product A handles inputs or steps differently than Product B, which causes A to perform incorrect actions'. Here, Product A is Geth 1.14.2 and Product B represents the other clients and the older Geth version. 

CWE-682, 'Incorrect Calculation', is a plausible but less precise fit. While an incorrect calculation (of gas or status) is occurring, the fundamental issue highlighted by the bug report is the discrepancy between different systems' outputs for the same data. The incorrectness is established *by comparison* to the correct interpretation of other systems, making CWE-436 the more accurate, higher-level classification. 

CWE-670, 'Always-Incorrect Control Flow Implementation', is too specific about the code-level cause. The bug report describes the external symptom (conflicting output) and does not provide enough information to confirm a specific control flow error is the root cause.",closed,"The Geth client incorrectly reports the execution status of a transaction that has successfully completed, falsely indicating a revert due to a potential issue in how it handles transaction outcomes in version 1.14.2.","This bug may lead to confusion and incorrect state reporting in the blockchain, causing developers and users to misunderstand the success of transactions, potentially leading to erroneous decisions or actions based on faulty execution feedback.",2296619799,29778,"May 15, 2024 12:20 AM (GMT+8)","May 22, 2024 12:31 AM (GMT+8)",['type:bug'],
go-ethereum,geth is underfilling mainnet blocks,https://github.com/ethereum/go-ethereum/issues/29771,Consensus,"Starting with [Edolus (v1.13.12)](https://github.com/ethereum/go-ethereum/releases/tag/v1.13.12), a couple weeks before Deneb, geth blocks began to use significantly less gas than other builders/engines when the network isn't over capacity. Currently the median block built by geth is using less than 3 million gas and carries [less than 50 transactions](https://dune.com/queries/3718742/6256673).

![gas-usage](https://github.com/ethereum/go-ethereum/assets/96306976/4a1ce7eb-2981-4792-b5d1-b234706280a4)
> [Figure 1](https://dune.com/queries/3718742/6256571): average gas usage of blocks separated by builder.

Transactions on the network tend to be heavily skewed toward low priority fees, with over 40% of transactions using less than 1.5% of their tips in gas (over 50% in locally built blocks).

![ethereum-fee-distribution](https://github.com/ethereum/go-ethereum/assets/96306976/67064f0a-4623-47d7-a243-d115f22eee2b)
> [Figure 2](https://dune.com/queries/2793955/4652794): the distribution of priority fee share of gas price for transactions on the Ethereum Network.

As can be seen in Figure 3, in blocks built by geth the majority of the left spike is missing, accounting for approximately 50% of transactions. Because these transactions contain little-to-no tips, the value of geth blocks is relatively unaffected and [remains competitive](https://dune.com/queries/3718650/6256512) with Nethermind blocks.

![geth-fee-distribution](https://github.com/ethereum/go-ethereum/assets/96306976/f3ac1011-d5c0-4954-a535-903e6761b56a)
> [Figure 3](https://dune.com/queries/3718897/6256829): the distribution of priority fee share of gas price for transactions in blocks built by geth.

",consensus: consensus inefficiency,CWE-682,Incorrect Calculation,"The bug report details that the `geth` software is creating blocks that use significantly less gas than their capacity allows, a phenomenon described as 'underfilling'. This is happening because a large number of transactions with low priority fees are being excluded. The selection of transactions to include in a block is a resource management task, where the block's gas limit is the resource. This selection process relies on calculations to determine which transactions are profitable or otherwise desirable to include. The observed behavior—systematically excluding a whole class of valid transactions—points to a flaw in these calculations. This aligns perfectly with the definition of CWE-682, 'Incorrect Calculation', which describes a product performing a calculation that yields 'incorrect or unintended results that are later used in... resource management.' The incorrect calculation is within the transaction selection logic, and the result is inefficient management of the block space resource. CWE-670, 'Always-Incorrect Control Flow Implementation', is less fitting. While an incorrect calculation could lead to a wrong turn in control flow, the root cause described by the symptoms is the calculation itself, not a structurally flawed logical path that is always incorrect regardless of the input values.",closed,"The geth implementation is underfilling blocks with gas due to a change in transaction selection logic, which results in blocks containing fewer transactions and lower gas usage compared to other builders.","This bug can lead to inefficient block utilization, causing potential revenue loss for miners and affecting overall network performance and transaction throughput.",2294652926,29771,"May 14, 2024 7:31 AM (GMT+8)","May 14, 2024 5:29 PM (GMT+8)",['type:bug'],
go-ethereum,Geth/evm raises runtime error when executing opcode `prevrandao`,https://github.com/ethereum/go-ethereum/issues/29722,Execution,"#### System information

Geth version: `1.13.4`
CL client & version: Nope
OS & Version: Linux
Commit hash : 3f907d6a

#### Expected behaviour
According to [EVM opcodes](https://www.evm.codes/?fork=cancun), when execuing opcode `0X44`, EVM should return previous block's [RANDAO mix](https://eips.ethereum.org/EIPS/eip-4399).  Comparing with Besu/evmtools, Py-evm and EthereumJS, all other 3 evms are fine, only Geth/evm came to an error.

#### Actual behaviour
When executing any Ethereum smart contract bytecodes that includes opcode `0X44`, the Geth/evm will raise an error and abort its execution, causing Ethereum execution node or other applications built upon Geth/evm fail.

#### Steps to reproduce the behaviour

1. Download `Geth & Tools 1.13.4-3f907d6a` from https://gethstore.blob.core.windows.net/builds/geth-alltools-linux-amd64-1.13.4-3f907d6a.tar.gz
2. Unzip the file and you can see executable evm at `geth-alltools-linux-amd64-1.13.4-3f907d6a/evm`
3. Create a new `genesis.json` file in dir geth-alltools-linux-amd64-1.13.4-3f907d6a/ to let evm support shanghai opcodes.
```json
{
  ""config"": {
    ""chainId"": 9599,
    ""homesteadBlock"": 0,
    ""eip150Block"": 0,
    ""eip155Block"": 0,
    ""eip158Block"": 0,
    ""byzantiumBlock"": 0,
    ""constantinopleBlock"": 0,
    ""petersburgBlock"": 0,
    ""istanbulBlock"": 0,
    ""berlinBlock"": 0,
    ""londonBlock"": 0,
    ""shanghaiBlock"": 0,
    ""shanghaiTime"":0
  },
  ""alloc"": {
    ""0x1c7cd2d37ffd63856a5bd56a9af1643f2bcf545f"": {
      ""balance"": ""0xffffffffffffffffffffffffffffffffffffffff""
    }
  },
  ""coinbase"": ""0x000000000000000000000000000000000000abcd"",
  ""difficulty"": ""0x0"",
  ""extraData"": """",
  ""gasLimit"": ""0xffffff"",
  ""nonce"": ""0x0000000000000042"",
  ""mixhash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
  ""parentHash"": ""0x0000000000000000000000000000000000000000000000000000000000000000"",
  ""timestamp"": ""0x00""
}
```
4. Run the commands to let geth/evm execute 0x44
```shell
$  ./evm --debug --gas 0xffffff --nomemory=false --json --code 6080604052348015600e575f80fd5b50600436106026575f3560e01c80639ceee80c14602a575b5f80fd5b60306044565b604051603b91906061565b60405180910390f35b5f44905090565b5f819050919050565b605b81604b565b82525050565b5f60208201905060725f8301846054565b9291505056fea264697066735822122097f788bd78037d47c3e87ca3ee039171808cf9ea275785553c6ccd08d982424464736f6c63430008170033 --input 9ceee80c --prestate ./genesis.json run  
```
5. You can see that terminal outputs error messages.
```
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xb7d05b]

goroutine 1 [running]:
github.com/ethereum/go-ethereum/core/vm.opRandom(0x1?, 0x0?, 0xc000534318)
        github.com/ethereum/go-ethereum/core/vm/instructions.go:480 +0x3b
github.com/ethereum/go-ethereum/core/vm.(*EVMInterpreter).Run(0xc000300540, 0xc000172480, {0xc00051dd08, 0x4, 0x8}, 0x0)
        github.com/ethereum/go-ethereum/core/vm/interpreter.go:230 +0x9c7
github.com/ethereum/go-ethereum/core/vm.(*EVM).Call(0xc000176000, {0x12e3640, 0xc000174700}, {0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...}, ...)
        github.com/ethereum/go-ethereum/core/vm/evm.go:236 +0xbb1
github.com/ethereum/go-ethereum/core/vm/runtime.Call({0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...}, ...)
        github.com/ethereum/go-ethereum/core/vm/runtime/runtime.go:191 +0x2cb
main.runCmd.func2()
        github.com/ethereum/go-ethereum/cmd/evm/runner.go:266 +0x34
main.timedExec(0x0, 0xc0004e6800)
        github.com/ethereum/go-ethereum/cmd/evm/runner.go:99 +0x372
main.runCmd(0xc0004e6f00)
        github.com/ethereum/go-ethereum/cmd/evm/runner.go:271 +0x120e
github.com/ethereum/go-ethereum/internal/flags.MigrateGlobalFlags.func2.1(0x1b50e80?)
        github.com/ethereum/go-ethereum/internal/flags/helpers.go:100 +0x34
github.com/urfave/cli/v2.(*Command).Run(0x1b50e80, 0xc0004e6f00, {0xc0004f45a0, 0x1, 0x1})
        github.com/urfave/cli/v2@v2.25.7/command.go:274 +0x998
github.com/urfave/cli/v2.(*Command).Run(0xc00045e9a0, 0xc000426e00, {0xc000134270, 0xd, 0xd})
        github.com/urfave/cli/v2@v2.25.7/command.go:267 +0xbe5
github.com/urfave/cli/v2.(*App).RunContext(0xc0003de780, {0x12eaba0?, 0x1bdd400}, {0xc000134270, 0xd, 0xd})
        github.com/urfave/cli/v2@v2.25.7/app.go:332 +0x5b7
github.com/urfave/cli/v2.(*App).Run(...)
        github.com/urfave/cli/v2@v2.25.7/app.go:309
main.main()
        github.com/ethereum/go-ethereum/cmd/evm/main.go:248 +0x45
```

6. Comparing with Besu/evmtools Py-evm EthereumJS, all other 3 evms are fine, only Geth/evm came to this error.

#### Backtrace

````
{""pc"":0,""op"":96,""gas"":""0xffffff"",""gasCost"":""0x3"",""memSize"":0,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":2,""op"":96,""gas"":""0xfffffc"",""gasCost"":""0x3"",""memSize"":0,""stack"":[""0x80""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":4,""op"":82,""gas"":""0xfffff9"",""gasCost"":""0xc"",""memSize"":0,""stack"":[""0x80"",""0x40""],""depth"":1,""refund"":0,""opName"":""MSTORE""}
{""pc"":5,""op"":52,""gas"":""0xffffed"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""CALLVALUE""}
{""pc"":6,""op"":128,""gas"":""0xffffeb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":7,""op"":21,""gas"":""0xffffe8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x0""],""depth"":1,""refund"":0,""opName"":""ISZERO""}
{""pc"":8,""op"":96,""gas"":""0xffffe5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":10,""op"":87,""gas"":""0xffffe2"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x1"",""0xe""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":14,""op"":91,""gas"":""0xffffd8"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":15,""op"":80,""gas"":""0xffffd7"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""POP""}
{""pc"":16,""op"":96,""gas"":""0xffffd5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":18,""op"":54,""gas"":""0xffffd2"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4""],""depth"":1,""refund"":0,""opName"":""CALLDATASIZE""}
{""pc"":19,""op"":16,""gas"":""0xffffd0"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x4"",""0x4""],""depth"":1,""refund"":0,""opName"":""LT""}
{""pc"":20,""op"":96,""gas"":""0xffffcd"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":22,""op"":87,""gas"":""0xffffca"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0"",""0x26""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":23,""op"":95,""gas"":""0xffffc0"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":24,""op"":53,""gas"":""0xffffbe"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x0""],""depth"":1,""refund"":0,""opName"":""CALLDATALOAD""}
{""pc"":25,""op"":96,""gas"":""0xffffbb"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c00000000000000000000000000000000000000000000000000000000""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":27,""op"":28,""gas"":""0xffffb8"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c00000000000000000000000000000000000000000000000000000000"",""0xe0""],""depth"":1,""refund"":0,""opName"":""SHR""}
{""pc"":28,""op"":128,""gas"":""0xffffb5"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c""],""depth"":1,""refund"":0,""opName"":""DUP1""}
{""pc"":29,""op"":99,""gas"":""0xffffb2"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x9ceee80c""],""depth"":1,""refund"":0,""opName"":""PUSH4""}
{""pc"":34,""op"":20,""gas"":""0xffffaf"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x9ceee80c"",""0x9ceee80c""],""depth"":1,""refund"":0,""opName"":""EQ""}
{""pc"":35,""op"":96,""gas"":""0xffffac"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x1""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":37,""op"":87,""gas"":""0xffffa9"",""gasCost"":""0xa"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x1"",""0x2a""],""depth"":1,""refund"":0,""opName"":""JUMPI""}
{""pc"":42,""op"":91,""gas"":""0xffff9f"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":43,""op"":96,""gas"":""0xffff9e"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":45,""op"":96,""gas"":""0xffff9b"",""gasCost"":""0x3"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x30""],""depth"":1,""refund"":0,""opName"":""PUSH1""}
{""pc"":47,""op"":86,""gas"":""0xffff98"",""gasCost"":""0x8"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x30"",""0x44""],""depth"":1,""refund"":0,""opName"":""JUMP""}
{""pc"":68,""op"":91,""gas"":""0xffff90"",""gasCost"":""0x1"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x30""],""depth"":1,""refund"":0,""opName"":""JUMPDEST""}
{""pc"":69,""op"":95,""gas"":""0xffff8f"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x30""],""depth"":1,""refund"":0,""opName"":""PUSH0""}
{""pc"":70,""op"":68,""gas"":""0xffff8d"",""gasCost"":""0x2"",""memory"":""0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000080"",""memSize"":96,""stack"":[""0x9ceee80c"",""0x30"",""0x0""],""depth"":1,""refund"":0,""opName"":""DIFFICULTY""}
{""output"":"""",""gasUsed"":""0x0""}

````

Thanks for your attention :)",evm: simulation inconsistency,CWE-476,NULL Pointer Dereference,"The bug report's 'Actual behaviour' section and the provided backtrace contain explicit evidence of the specific error. The panic message is 'panic: runtime error: invalid memory address or nil pointer dereference', and the signal is 'SIGSEGV: segmentation violation code=0x1 addr=0x0'. This directly corresponds to the definition of CWE-476, 'NULL Pointer Dereference', which states that the product dereferences a pointer that it expects to be valid but is NULL. The error occurs within the `opRandom` function, indicating a pointer was used without being properly initialized. While this could be seen as an 'Improper Check or Handling of Exceptional Conditions' (CWE-703), CWE-476 is far more specific and accurately describes the technical root cause of the crash. CWE-20, 'Improper Input Validation', is less fitting because the issue is not with validating external input but with an internal state error leading to a specific type of crash during the execution of a valid opcode. The most accurate and precise classification based on the provided technical details is the NULL pointer dereference.",closed,The Geth/EVM implementation raises a runtime error due to a nil pointer dereference when executing the opcode `0x44` (prevrandao) because it does not properly handle the case where expected data is not available.,"This bug causes the Geth/EVM execution environment to crash when encountering the `prevrandao` opcode, which can lead to failures in Ethereum smart contract execution, affecting applications built on Geth and potentially disrupting the Ethereum network.",2283209667,29722,"May 7, 2024 12:48 PM (GMT+8)","May 29, 2024 8:53 AM (GMT+8)",['type:bug'],
go-ethereum,internal/ethapi: crash casued by no limits for rewardPercentiles at interface FeeHistory,https://github.com/ethereum/go-ethereum/issues/29709,API,"there is no number limit for rewardPercentiles
when `maxBlockHistory` set to 1024,
then set 600k element(limited by rpc requtest size)  in rewardPercentiles to call FeeHistory
the node will crash, for too many memory need.

maybe only a few nodes set `maxBlockHistory` such a big number,
but I think It's better to limit the number of rewardPercentiles to defend attack.
so, please check this PR [eth/gasprice: add query limit for FeeHistory to defend DDOS attack](https://github.com/ethereum/go-ethereum/pull/29644) again, thx.",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report details a crash that occurs when a user provides a very large array for the `rewardPercentiles` parameter in the `FeeHistory` API call. The report explicitly states this leads to a crash because of 'too many memory need'. This directly aligns with the definition of CWE-789, where a product allocates memory based on an untrusted, large size value without ensuring the size is within expected limits. The number of elements in the `rewardPercentiles` array is the 'untrusted, large size value' that dictates the memory allocation. While CWE-20 (Improper Input Validation) is technically true, it is too general. The specific type of validation that is missing is a size check for a memory allocation, which CWE-789 describes precisely. CWE-400 (Uncontrolled Resource Consumption) describes the consequence (exhaustion of memory), but CWE-789 describes the specific cause of that consumption, making it a more accurate and specific choice for this bug.",closed,"The absence of limits for the rewardPercentiles parameter in the FeeHistory interface allows excessively large input values, which can lead to memory exhaustion and subsequent crashes when high values are set for maxBlockHistory.","This bug can result in node crashes due to high memory consumption, potentially leading to denial of service (DoS) for affected nodes. If exploited, it could allow an attacker to overload the node with large requests, impacting network stability.",2279913618,29709,"May 6, 2024 2:44 AM (GMT+8)","May 7, 2024 3:25 PM (GMT+8)",['type:bug'],
go-ethereum,eth_estimateGas with blobs fails when capped by limited funds,https://github.com/ethereum/go-ethereum/issues/29702,API,"#### System information

Geth version: 1.14.1-unstable-86a1f0c3-20240502
CL client & version: e.g. prysm@v5.0.3
OS & Version: Ubuntu 23.04
Commit hash : 86a1f0c39494c8f5caddf6bd9fbddd4bdfa944fd

#### Expected behaviour

When doing an eth_estimateGas call of an eip4844 tx with blobs, with the account holding enough ETH but not too much (not multiple of what is necessary), it should work.

The call includes maxFeePerBlobGas, maxFeePerGas, maxPriorityFeePerGas.

```
{""jsonrpc"":""2.0"",""id"":5,""method"":""eth_estimateGas"",""params"":[{""blobVersionedHashes"":[""0x01728b8444295cdd28e4dde23e352a4dc5aefa1a5a2cfec522fb3fe04af56732""],""blobs"":[""0x0068656c6c6f20776f726c642066726f6d20657468657265756d20737461746500800000...""],""data"":""0xdb93dcef00000000000000000000000000000000...."",""from"":""0x79E374Babb092590eD82f9A7cA5631aEAd710dea"",""maxFeePerBlobGas"":""0xb44997e62"",""maxFeePerGas"":""0x62fc7c875"",""maxPriorityFeePerGas"":""0x3b9aca00"",""nonce"":""0x3"",""to"":""0xbe78dc6a57dfd9f8898C8C8edd5Bc1C9571E391E"",""value"":""0x0""}]}
```

#### Actual behaviour

The call fails with `Failed with XXX gas: insufficient funds for gas * price + value: address 0x79E374Babb092590eD82f9A7cA5631aEAd710dea have YYY want ZZZ`, with XXX looking random and way above the necessary gas, ZZZ being always a bit above YYY.

In the above example, the message was `Failed with 2853958 gas: insufficient funds for gas * price + value: address 0x79E374Babb092590eD82f9A7cA5631aEAd710dea have 75833739893214239 want 82177035114105854`

#### Steps to reproduce the behaviour

Calling eth_estimateGas with blobs with the account holding enough ETH, but not too much (not multiple of what is necessary), will trigger the bug.

#### Reason

I think I have identified the bug. In the gasestimator.go code, when computing the highest gas limit with the account available balance, it does not take into account the gas used to pay for blobs.

It can be seen with the example above : account has 75833739893214239 wei, maxFeePerGas is 26571425909 wei, the code compute an allowance (max gas limit) of 75833739893214239 / 26571425909 = 2853958 gas (which match the error message). 

But then it tries to execute the code with a gas fee of 2853958 * 26571425909 + 131072 (blob gas) * 48395550306 (blog gas fee) = 82177035114105854 wei, which match the error message.

A PR will follow shortly.",api: api unavailability,CWE-682,Incorrect Calculation,"The bug report explicitly identifies a flawed calculation as the root cause. The `gasestimator.go` code calculates the maximum possible gas limit by dividing the user's balance by the gas price. However, it fails to subtract the cost of 'blobs' from the total balance before performing this division. This leads to an incorrectly high gas limit estimate. When the system then attempts to validate this estimate, the total cost (gas + blobs) exceeds the user's funds, causing the estimation to fail. This perfectly matches the definition of CWE-682 'Incorrect Calculation', as the product performs a calculation that generates an incorrect result (the gas limit), which is then used in resource management (transaction cost estimation). CWE-400 is less suitable because the issue is not uncontrolled consumption, but rather a failure to perform a transaction due to a calculation error. CWE-754 is also unsuitable as the condition of having limited funds is a normal operational state, not an unusual or exceptional one that requires a special check.",closed,The gas estimator does not account for the additional gas required to pay for blob transactions when calculating the maximum allowable gas limit based on the account's available balance.,"This bug can lead to incorrect gas estimation, causing transactions to fail due to insufficient funds, which may frustrate users and hinder the execution of valid transactions.",2278262092,29702,"May 3, 2024 7:07 PM (GMT+8)","May 7, 2024 8:27 PM (GMT+8)",['type:bug'],
go-ethereum,eth_estimateGas uses global gas cap as the high watermwark,https://github.com/ethereum/go-ethereum/issues/29695,API,"Tracker for https://github.com/ethereum/go-ethereum/pull/29509.

Gas estimation should cap itself to the block gas limit if none is given, currently it caps itself to the configured call gas cap. This is bad because it wastes estimation cycles.

Interestingly, the gas estimator itself works correctly, but is called bad (the gas is set *before* estimation to the global gas cap, so the poor estimator works with what it's given). The cause is a long stream of refactors and abstractions which gradually bubbles setting the gas value of a transaction in ToMessage, which sounds counterintuitive.

Fixing it is not *super* obvious, because changing ToMessage to not set the gas might have other implications. We should look through the call sites and see how to best fix without adding workarounds.",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report describes an issue where a gas estimation process uses an unnecessarily high upper limit (a global gas cap) instead of a more appropriate, lower one (the block gas limit). This leads to wasted computational resources, described as 'wastes estimation cycles' and resulting in 'general performance degradation'. This is a classic resource management problem.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions)** is not a good fit. The bug does not concern a rare or exceptional event; gas estimation is a normal, expected operation. The flaw is in how this normal operation is configured, not in how an error or exception is handled.

- **CWE-1188 (Initialization of a Resource with an Insecure Default)** is a plausible but less accurate choice. While a value (the gas cap) is initialized with a 'bad' default, the CWE specifies an 'insecure' default. The bug report frames the problem as one of performance and inefficiency ('wastes estimation cycles'), not a direct security vulnerability like allowing an attack. The primary impact is resource waste, not a security compromise.

- **CWE-400 (Uncontrolled Resource Consumption)** is the most accurate fit. The limited resource is computational time/CPU cycles. The system fails to 'properly control' the allocation of this resource for the estimation task by setting an overly generous cap. This leads directly to the described symptoms of wasted cycles and performance degradation. The core of the problem is the inefficient and excessive use of a resource, which is the exact definition of CWE-400.",closed,The gas estimation is incorrectly capped to the configured call gas cap instead of the block gas limit due to a series of refactors that altered how the gas value is set before estimation.,"This bug could lead to inefficient gas estimation, resulting in wasted estimation cycles and potentially unnecessary transaction failures or higher costs for users due to inaccurate gas predictions.",2275037015,29695,"May 2, 2024 9:28 AM (GMT+8)","August 29, 2024 4:37 PM (GMT+8)",['type:bug'],
go-ethereum,Unexpected response  in case of method debug_traceBlockByHash after upgrade to go-ethereum: v1.14.0,https://github.com/ethereum/go-ethereum/issues/29676,API,"#### System information

Geth version: ` `go-ethereum: v1.14.0
CL client & version: prysm@v5.0.2
OS & Version: Linux/
Commit hash : (if `develop`)

#### Expected behaviour





#### Actual behaviour
```json
{
    ""jsonrpc"": ""2.0"",
    ""id"": 1,
    ""error"": {
        ""code"": -32000,
        ""message"": ""tracing failed: insufficient funds for gas * price + value: address 0xdf99A0839818B3f120EBAC9B73f82B617Dc6A555 have 61122619715444668 want 74363312441006965""
    }
}
```

#### Steps to reproduce the behaviour

Make a call (example below):
```json
{
    ""jsonrpc"": ""2.0"",
    ""method"": ""debug_traceBlockByHash"",
    ""params"": [
        ""0x683b2d38f36806709da5f925adac285bd2cbed10e58669dc8ef5ac2164d3f58a"",
        {
            ""tracer"": ""callTracer"",
            ""tracerConfig"": {
                ""onlyTopCall"": false,
                ""withLog"": false
            },
            ""disableStorage"": true,
            ""disableStack"": true
        }
    ],
    ""id"": 1
}
```

The issue is only observed when tracing  below blocks:
height: 19755425, hash: '0xdd0ac10044f0254bdb4a2d6ddb314cc7825dfb07474fc7f3dfc94f31c4616d5e'
height: 19755134, hash: '0x683b2d38f36806709da5f925adac285bd2cbed10e58669dc8ef5ac2164d3f58a'


Downgrade to previous version fixed the issue:

geth --version
geth version 1.13.15-stable-c5ba367e

So the issue is only observed in v1.14.0 for specific blocks.

#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them as text and not screenshots.
",api: incorrect api output,CWE-682,Incorrect Calculation,"The bug report details an error that occurs when tracing a specific block in a new version of go-ethereum (v1.14.0) that did not occur in a previous version (v1.13.15). The error message, `""tracing failed: insufficient funds for gas * price + value""`, explicitly points to a financial calculation being performed by the software. Since the block being traced is historical and was valid at the time of its creation, the tracing logic in the new version must be performing this calculation incorrectly, leading to the erroneous 'insufficient funds' failure. This directly aligns with the definition of CWE-682, where a product performs a calculation that generates incorrect results, which are then used in resource management (in this case, determining if the trace can proceed). CWE-841 is not applicable as the issue is not related to the sequence of actions in a workflow. CWE-436 is less suitable because the problem is a regression within a single product, not an interpretation conflict between two different products interacting with each other. The root cause is a faulty calculation, making CWE-682 the most accurate choice.",closed,"The upgrade to go-ethereum v1.14.0 introduces a change in how the `debug_traceBlockByHash` method handles tracing requests, resulting in insufficient funds errors due to gas calculations for specific blocks.","Users attempting to trace specific blocks will receive errors indicating insufficient funds, which could disrupt debugging processes and adversely affect developers relying on accurate tracing functionality.",2268263326,29676,"April 29, 2024 6:53 AM (GMT+8)","May 22, 2024 12:32 AM (GMT+8)",['type:bug'],
go-ethereum,Miner deadlock in dev mode with period 0,https://github.com/ethereum/go-ethereum/issues/29656,Consensus,"#### System information

Geth version: `1.13.11`, `1.13.15`, `1.14.0`
OS & Version: OSX

#### Expected behaviour

In dev mode, when the client sends transactions from two different addresses, it could be mined.

#### Actual behaviour

After version `1.13.11` if I send two transactions from two different addresses concurrently, the miner deadlock on txpool sync, and could not produce new blocks.

The simulated beacon API hang in the `api.eth.TxPool().Sync()` [at this line](https://github.com/ethereum/go-ethereum/blob/c1f59b98f6b0351339767d71953eb4eb5d19c496/eth/catalyst/api.go#L397). In the `Sync()`, it will trigger more new transaction events and the subscriber could not handle it, so it deadlocked. If I changed the chan size in `eth/catalyst/simulated_beacon_api.go`, it could allow more concurrent transactions.

```
  newTxs = make(chan core.NewTxsEvent, 10)
```

#### Steps to reproduce the behaviour

geth command to start in the dev mode
```
../build/bin/geth \
  --dev --dev.period 0 \
  --keystore $KEYSTORE \
  --http --http.addr ""127.0.0.1"" --http.port 8545 --http.api eth,net,web3,debug,personal,txpool \
  --rpc.txfeecap 0 \
  --verbosity 5
```

And the client is written by ethers.js
```
const ethers = require(""ethers"");
const provider = new ethers.JsonRpcProvider(""http://localhost:8545"", undefined, { cacheTimeout: -1 });

const faucet = new ethers.Wallet(`${KEY_FROM_THE_KEYSTORE}`, provider);
console.log(""faucet"", faucet.address);

(async () => {
  const wallets = Array(2).fill(0).map((x, i) => new ethers.Wallet(
    ethers.zeroPadBytes(`0x${(i + 132).toString(16)}`, 32), provider));

  // Sequential transactions should be fine.
  for (let w of wallets) {
    const tx = await faucet.sendTransaction({
      to: w.address,
      value: ethers.parseEther(""3""),
    });
    const receipt = await tx.wait();
    console.log(""init"", w.address, receipt.blockNumber);
  }

  // Concurrent transactions from two different address.
  await Promise.all(wallets.map((w) => (async () => {
    for (let i = 0; i < 3; i++) {
      const tx = await w.sendTransaction({
        to: faucet.address,
        value: ""1"",
      });
      const receipt = await tx.wait();
      console.log(w.address, receipt.blockNumber);
    }
  })()));
})();
```",consensus: consensus liveness failure,CWE-833,Deadlock,"The bug report explicitly and repeatedly uses the term 'deadlock' to describe the system's behavior. The details confirm this: concurrent transactions cause the miner to hang and cease producing new blocks. The report states, 'the miner deadlock on txpool sync'. This describes a state where different processes or threads are stuck, waiting for each other or for an event that cannot occur, which is the definition of a deadlock. 

CWE-662 (Improper Synchronization) is a possible cause, as the issue involves concurrent operations and a channel, which is a synchronization primitive. However, 'deadlock' is a more specific and severe outcome of improper synchronization, making CWE-833 a more precise classification of the actual weakness.

CWE-400 (Uncontrolled Resource Consumption) is also related, as the deadlock is triggered by a small, fixed-size channel buffer being exhausted. The fix involves increasing the size of this resource. However, the critical failure mode is not just resource exhaustion leading to a denial of service, but a complete halt in processing due to a circular wait condition—a deadlock. 

Therefore, CWE-833 is the single most accurate choice because it directly describes the specific, critical failure state reported, which is a deadlock.",closed,"The miner deadlock occurs due to a race condition in transaction pool synchronization when multiple transactions are triggered concurrently, causing the system to become unable to process new blocks.","The bug can lead to a complete halt in block production in development mode, which can disrupt testing and development activities, potentially causing delays and hindering the development process.",2263973923,29656,"April 25, 2024 4:04 PM (GMT+8)","April 26, 2024 8:50 AM (GMT+8)",['type:bug'],
go-ethereum,flatCallTracer returns wrong result instead of error at timeout,https://github.com/ethereum/go-ethereum/issues/29622,API,"#### System information

Geth version: geth-1.13.4
CL client & version: lighhouse@lighthouse-5.1.3
OS & Version: Ubuntu 22.04.4 LTS

#### Expected behaviour

When `debug_traceBlockByNumber` with `flatCallTracer` times out, RPC should return an error.


#### Actual behaviour

Currently `debug_traceBlockByNumber` with `flatCallTracer` returns an incorrect trace.

#### Steps to reproduce the behaviour

* Perform request with very low timeout to force the issue:
```json
{""method"":""debug_traceBlockByNumber"",""params"":[""0x12cdbd2"",{""timeout"":""1ms"",""tracer"":""flatCallTracer""}],""id"":0,""jsonrpc"":""2.0""}
```

* Perform request with very high timeout to obtain the correct trace:
```json
{""method"":""debug_traceBlockByNumber"",""params"":[""0x12cdbd2"",{""timeout"":""20s"",""tracer"":""flatCallTracer""}],""id"":0,""jsonrpc"":""2.0""}
```

* compare the outputs


Credit to https://github.com/tsahee for identifying the issue.
",api: incorrect api output,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a scenario where an API call, `debug_traceBlockByNumber`, encounters a timeout. A timeout is an exceptional condition that is not part of the normal execution flow. The expected behavior is for the system to handle this condition by returning an error. However, the actual behavior is that it returns an incorrect result. This directly aligns with the definition of CWE-703, 'Improper Check or Handling of Exceptional Conditions', as the product is not properly handling an exceptional condition (the timeout). CWE-440, 'Expected Behavior Violation', is also technically true but is too general; the specific reason for the violation is the improper exception handling, making CWE-703 a more precise fit. CWE-252, 'Unchecked Return Value', speculates on a potential implementation cause, but the bug report itself only describes the failure to handle the exceptional state, which is the primary characteristic of CWE-703.",closed,"The `flatCallTracer` does not handle timeout scenarios properly, resulting in incorrect trace outputs instead of returning an appropriate error message.","This bug can lead to confusion and incorrect assumptions about the state of the blockchain, as users may receive misleading trace results when they expect an error due to timeout. It can affect debugging and analysis tasks, potentially leading to incorrect decisions based on faulty data.",2258370920,29622,"April 23, 2024 9:18 AM (GMT+8)","May 3, 2024 5:52 AM (GMT+8)",['type:bug'],
go-ethereum,Geth `--dev` does not work with `CancunTime`,https://github.com/ethereum/go-ethereum/issues/29564,Consensus,"#### System information

Geth version: `1.13.11` - `1.13.15`
CL client & version: `--dev` (simulated beacon)
OS & Version: OSX Ventura 13.5.2
Commit hash : (if `develop`)

#### Expected behaviour

I wouldn't expect `Invalid parameters` when performing sealing work and for transaction indexing to not get stuck.

#### Actual behaviour

Logs that differ from Shanghai rules:

```
WARN [04-17|09:09:38.382] Error performing sealing work            err=""Invalid parameters""
```

Indefinite indexing:

```
WARN [04-17|09:09:38.397] Served eth_getTransactionReceipt         reqid=9 duration=""129.591µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.508] Served eth_getTransactionReceipt         reqid=10 duration=""147.688µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.612] Served eth_getTransactionReceipt         reqid=11 duration=""182.516µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.716] Served eth_getTransactionReceipt         reqid=12 duration=""151.324µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.822] Served eth_getTransactionReceipt         reqid=13 duration=""145.97µs""  err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.926] Served eth_getTransactionReceipt         reqid=14 duration=""109.269µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
...
```

#### Steps to reproduce the behaviour

At the present moment, I need to set `terminalTotalDifficulty` in genesis to `-1` and `difficulty` to `0` in order to trick it to even trigger Shanghai rules. Nothing else seems to work. Since there's a check for `difficulty > terminalTotalDifficulty` and difficulty seems to need to be `0` at the genesis for the rules to trigger, I had to try to set `terminalTotalDifficulty` to `-1` and that somehow seems to work.

All other fork rules are set as expected, as you can see from the logs below they are picked up. I just don't believe they are being triggered.

I am using `dev.period` == `1`. Sending any transaction and attempting to get the receipt does not work as it gets stuck indexing forever. But the `invalid parameters` when performing sealing work also aren't present under the working Shanghai rules. Turning on Cancun time seems to trigger all of this.

#### Backtrace

````
WARN [04-17|09:09:36.006] Unknown config environment variable      envvar=GETH_BINARY
WARN [04-17|09:09:36.006] Unknown config environment variable      envvar=GETH_BINARY_LOCAL
INFO [04-17|09:09:36.017] Starting Geth in ephemeral dev mode...
WARN [04-17|09:09:36.017] You are running Geth in --dev mode. Please note the following:

  1. This mode is only intended for fast, iterative development without assumptions on
     security or persistence.
  2. The database is created in memory unless specified otherwise. Therefore, shutting down
     your computer or losing power will wipe your entire block data and chain state for
     your dev environment.
  3. A random, pre-allocated developer account will be available and unlocked as
     eth.coinbase, which can be used for testing. The random dev account is temporary,
     stored on a ramdisk, and will be lost if your machine is restarted.
  4. Mining is enabled by default. However, the client will only seal blocks if transactions
     are pending in the mempool. The miner's minimum accepted gas price is 1.
  5. Networking is disabled; there is no listen-address, the maximum number of peers is set
     to 0, and discovery is disabled.

INFO [04-17|09:09:36.020] Maximum peer count                       ETH=50 total=50
DEBUG[04-17|09:09:36.025] FS scan times                            list=""122.635µs"" set=""39.359µs"" diff=""5.676µs""
DEBUG[04-17|09:09:36.025] Failed to decode keystore key            path=/tmp/tmp1xsd44so/keystore/pw.txt err=""invalid character 'w' looking for beginning of value""
TRACE[04-17|09:09:36.025] Handled keystore changes                 time=""172.866µs""
TRACE[04-17|09:09:36.025] Started watching keystore folder         path=/tmp/tmp1xsd44so/keystore folder=/tmp/tmp1xsd44so/keystore
DEBUG[04-17|09:09:36.027] Sanitizing Go's GC trigger               percent=100
INFO [04-17|09:09:36.028] Set global gas cap                       cap=50,000,000
INFO [04-17|09:09:37.164] Using developer account                  address=0xdC544d1AA88Ff8bbd2F2AeC754B1F1e99e1812fd
INFO [04-17|09:09:37.165] Using pebble as the backing database
INFO [04-17|09:09:37.165] Allocated cache and file handles         database=/tmp/tmp1xsd44so/geth/chaindata cache=512.00MiB handles=5120
DEBUG[04-17|09:09:37.169] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=bodies items=0 size=0.00B
DEBUG[04-17|09:09:37.170] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=receipts items=0 size=0.00B
DEBUG[04-17|09:09:37.171] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=diffs items=0 size=0.00B
DEBUG[04-17|09:09:37.172] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=headers items=0 size=0.00B
DEBUG[04-17|09:09:37.174] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=hashes items=0 size=0.00B
INFO [04-17|09:09:37.174] Opened ancient database                  database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain readonly=true
INFO [04-17|09:09:37.174] Initializing the KZG library             backend=gokzg
INFO [04-17|09:09:37.202] Allocated trie memory caches             clean=154.00MiB dirty=256.00MiB
INFO [04-17|09:09:37.202] Using pebble as the backing database
INFO [04-17|09:09:37.202] Allocated cache and file handles         database=/tmp/tmp1xsd44so/geth/chaindata cache=512.00MiB handles=5120
DEBUG[04-17|09:09:37.404] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=receipts items=0 size=0.00B
DEBUG[04-17|09:09:37.405] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=diffs items=0 size=0.00B
DEBUG[04-17|09:09:37.406] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=headers items=0 size=0.00B
DEBUG[04-17|09:09:37.406] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=hashes items=0 size=0.00B
DEBUG[04-17|09:09:37.406] Chain freezer table opened               database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain table=bodies items=0 size=0.00B
INFO [04-17|09:09:37.406] Opened ancient database                  database=/tmp/tmp1xsd44so/geth/chaindata/ancient/chain readonly=false
INFO [04-17|09:09:37.408] State scheme set to already existing     scheme=hash
DEBUG[04-17|09:09:37.408] Current full block not old enough to freeze number=0 hash=db8524..5b0379 delay=90000
INFO [04-17|09:09:37.411] Initialising Ethereum protocol           network=1337 dbversion=<nil>
INFO [04-17|09:09:37.433] 
INFO [04-17|09:09:37.433] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [04-17|09:09:37.433] Chain ID:  131277322940537 (unknown)
INFO [04-17|09:09:37.433] Consensus: Beacon (proof-of-stake), merged from Ethash (proof-of-work)
INFO [04-17|09:09:37.433] 
INFO [04-17|09:09:37.433] Pre-Merge hard forks (block based):
INFO [04-17|09:09:37.433]  - Homestead:                   #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/homestead.md)
INFO [04-17|09:09:37.433]  - Tangerine Whistle (EIP 150): #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/tangerine-whistle.md)
INFO [04-17|09:09:37.433]  - Spurious Dragon/1 (EIP 155): #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [04-17|09:09:37.433]  - Spurious Dragon/2 (EIP 158): #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [04-17|09:09:37.433]  - Byzantium:                   #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/byzantium.md)
INFO [04-17|09:09:37.433]  - Constantinople:              #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/constantinople.md)
INFO [04-17|09:09:37.433]  - Petersburg:                  #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/petersburg.md)
INFO [04-17|09:09:37.433]  - Istanbul:                    #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/istanbul.md)
INFO [04-17|09:09:37.433]  - Berlin:                      #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/berlin.md)
INFO [04-17|09:09:37.434]  - London:                      #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/london.md)
INFO [04-17|09:09:37.434]  - Arrow Glacier:               #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/arrow-glacier.md)
INFO [04-17|09:09:37.434]  - Gray Glacier:                #0        (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/gray-glacier.md)
INFO [04-17|09:09:37.434] 
INFO [04-17|09:09:37.434] Merge configured:
INFO [04-17|09:09:37.434]  - Hard-fork specification:    https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/paris.md
INFO [04-17|09:09:37.434]  - Network known to be merged: true
INFO [04-17|09:09:37.434]  - Total terminal difficulty:  -1
INFO [04-17|09:09:37.434] 
INFO [04-17|09:09:37.435] Post-Merge hard forks (timestamp based):
INFO [04-17|09:09:37.435]  - Shanghai:                    @0          (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/shanghai.md)
INFO [04-17|09:09:37.435]  - Cancun:                      @0          (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/cancun.md)
INFO [04-17|09:09:37.435] 
INFO [04-17|09:09:37.435] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [04-17|09:09:37.435] 
INFO [04-17|09:09:37.435] Loaded most recent local block           number=0 hash=db8524..5b0379 td=0 age=55y1mo15h
WARN [04-17|09:09:37.435] Failed to load snapshot                  err=""missing or corrupted snapshot""
INFO [04-17|09:09:37.479] Rebuilding state snapshot
DEBUG[04-17|09:09:37.479] Journalled generator progress            progress=empty
DEBUG[04-17|09:09:37.501] Start snapshot generation                root=149cc3..2373b3
INFO [04-17|09:09:37.501] Initialized transaction indexer          range=""last 2350000 blocks""
INFO [04-17|09:09:37.501] Resuming state snapshot generation       root=149cc3..2373b3 accounts=0 slots=0 storage=0.00B dangling=0 elapsed=21.900ms
TRACE[04-17|09:09:37.501] Detected outdated state range            kind=account prefix=0x61 last=0x err=""wrong root: have 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421 want 0x149cc3a1f5296e04547fd60cd867c8c0a300862684af92520a656910f12373b3""
DEBUG[04-17|09:09:37.502] Regenerated state range                  kind=account prefix=0x61 root=149cc3..2373b3 last=0x count=9 created=9 updated=0 untouched=0 deleted=0
DEBUG[04-17|09:09:37.502] Journalled generator progress            progress=done
DEBUG[04-17|09:09:37.502] Regenerated local transaction journal    transactions=0 accounts=0
INFO [04-17|09:09:37.523] Generated state snapshot                 accounts=9 slots=0 storage=378.00B dangling=0 elapsed=43.849ms
DEBUG[04-17|09:09:38.201] Blobpool tip threshold updated           tip=1
INFO [04-17|09:09:38.202] Chain post-merge, sync via beacon client
INFO [04-17|09:09:38.202] Gasprice oracle is ignoring threshold set threshold=2
TRACE[04-17|09:09:38.202] Decrease miner recommit interval         from=2s to=2s
TRACE[04-17|09:09:38.224] Engine API request received              method=ForkchoiceUpdated head=db8524..5b0379 finalized=db8524..5b0379 safe=db8524..5b0379
INFO [04-17|09:09:38.246] Entered PoS stage
INFO [04-17|09:09:38.268] Starting peer-to-peer node               instance=Geth/v1.13.15-stable/darwin-amd64/go1.22.1
WARN [04-17|09:09:38.268] P2P server will be useless, neither dialing nor listening
INFO [04-17|09:09:38.360] New local node record                    seq=1,713,366,578,359 id=238274fb68b719e6 ip=127.0.0.1 udp=0 tcp=0
DEBUG[04-17|09:09:38.360] IPCs registered                          namespaces=admin,debug,web3,eth,txpool,miner,net,dev
INFO [04-17|09:09:38.360] Started P2P networking                   self=enode://39661e4edcb7527bb67a0c33459869f4c77574575c329345391252d470a53503dd3950f6c2deac4ee394a891be39199d713ef6fe26f16bb248e67466e3b08c7c@127.0.0.1:0
INFO [04-17|09:09:38.360] IPC endpoint opened                      url=/tmp/tmp1xsd44so/geth.ipc
TRACE[04-17|09:09:38.360] Engine API request received              method=ForkchoiceUpdated head=db8524..5b0379 finalized=db8524..5b0379 safe=db8524..5b0379
TRACE[04-17|09:09:38.368] Accepted RPC connection                  conn=
DEBUG[04-17|09:09:38.368] RPC connection read error                err=EOF
DEBUG[04-17|09:09:38.382] Reinjecting stale transactions           count=0
INFO [04-17|09:09:38.382] Starting work on payload                 id=0x02a949a8cf438792
TRACE[04-17|09:09:38.382] Engine API request received              method=GetPayload        id=0x02a949a8cf438792
INFO [04-17|09:09:38.382] Updated payload                          id=0x02a949a8cf438792 number=1 hash=7820a0..299db8 txs=0 withdrawals=0 gas=0 fees=0 root=149cc3..2373b3 elapsed=""144.297µs""
INFO [04-17|09:09:38.382] Stopping work on payload                 id=0x02a949a8cf438792 reason=delivery
WARN [04-17|09:09:38.382] Error performing sealing work            err=""Invalid parameters""
TRACE[04-17|09:09:38.386] Accepted RPC connection                  conn=
DEBUG[04-17|09:09:38.386] Served eth_getBlockByNumber              reqid=0 duration=""254.279µs""
DEBUG[04-17|09:09:38.388] Served eth_chainId                       reqid=1 duration=""64.904µs""
DEBUG[04-17|09:09:38.390] Served eth_chainId                       reqid=2 duration=""61.759µs""
DEBUG[04-17|09:09:38.392] Served eth_estimateGas                   reqid=3 duration=""545.784µs""
DEBUG[04-17|09:09:38.392] Served eth_chainId                       reqid=4 duration=""30.44µs""
DEBUG[04-17|09:09:38.393] Served eth_blockNumber                   reqid=5 duration=""31.58µs""
DEBUG[04-17|09:09:38.393] Served eth_getBlockByNumber              reqid=6 duration=""144.219µs""
INFO [04-17|09:09:38.395] Setting new local account                address=0xdC544d1AA88Ff8bbd2F2AeC754B1F1e99e1812fd
TRACE[04-17|09:09:38.395] Pooled new future transaction            hash=ca171b..03e088 from=0xdC544d1AA88Ff8bbd2F2AeC754B1F1e99e1812fd to=<nil>
TRACE[04-17|09:09:38.395] Removed old queued transactions          count=0
TRACE[04-17|09:09:38.395] Removed unpayable queued transactions    count=0
TRACE[04-17|09:09:38.395] Promoted queued transactions             count=1
INFO [04-17|09:09:38.395] Submitted contract creation              hash=0xca171ba87b2eaf383b4afbede13e76d0ae43506c98d908b1fa7a181edf03e088 from=0xdC544d1AA88Ff8bbd2F2AeC754B1F1e99e1812fd nonce=0 contract=0xd794C821fCCFF5D96F5Db44af7e29977630A9dc2 value=0
DEBUG[04-17|09:09:38.395] Distributed transactions                 plaintxs=1 blobtxs=0 largetxs=0 bcastpeers=0 bcastcount=0 annpeers=0 anncount=0
DEBUG[04-17|09:09:38.395] Served eth_sendTransaction               reqid=7 duration=1.236518ms
DEBUG[04-17|09:09:38.396] Served eth_chainId                       reqid=8 duration=""26.193µs""
MATH_CONTRACT_DEPLOY_HASH: b'\xca\x17\x1b\xa8{.\xaf8;J\xfb\xed\xe1>v\xd0\xaeCPl\x98\xd9\x08\xb1\xfaz\x18\x1e\xdf\x03\xe0\x88'
WARN [04-17|09:09:38.397] Served eth_getTransactionReceipt         reqid=9 duration=""129.591µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.508] Served eth_getTransactionReceipt         reqid=10 duration=""147.688µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.612] Served eth_getTransactionReceipt         reqid=11 duration=""182.516µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.716] Served eth_getTransactionReceipt         reqid=12 duration=""151.324µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.822] Served eth_getTransactionReceipt         reqid=13 duration=""145.97µs""  err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:38.926] Served eth_getTransactionReceipt         reqid=14 duration=""109.269µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.036] Served eth_getTransactionReceipt         reqid=15 duration=""139.673µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.142] Served eth_getTransactionReceipt         reqid=16 duration=""131.598µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.248] Served eth_getTransactionReceipt         reqid=17 duration=""139.038µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.351] Served eth_getTransactionReceipt         reqid=18 duration=""132.846µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.459] Served eth_getTransactionReceipt         reqid=19 duration=""139.372µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
WARN [04-17|09:09:39.563] Served eth_getTransactionReceipt         reqid=20 duration=""147.151µs"" err=""transaction indexing is in progress"" errdata=""transaction indexing is in progress""
...
...
...
````
... polling `eth_getTransactionReceipt` never leaves indexing status",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a situation where the system enters a state from which it cannot recover. Specifically, the logs show repeated messages of `err=""transaction indexing is in progress""`, and the user states that polling for a transaction receipt ""never leaves indexing status"" and ""gets stuck indexing forever."" This behavior directly aligns with the definition of CWE-835, which describes a loop with an unreachable exit condition, colloquially an 'infinite loop'. The system is stuck in a perpetual state of indexing. While CWE-755 ('Improper Handling of Exceptional Conditions') is plausible because the loop appears to be triggered by an `err=""Invalid parameters""` during sealing, CWE-835 is more specific and accurately describes the primary, user-impacting failure mode, which is the endless loop itself. CWE-436 ('Interpretation Conflict') is less applicable because the issue is an internal logic failure within a single product (Geth) under a specific configuration, not a misinterpretation of state between two different products.",closed,"The Geth client in `--dev` mode fails to validate parameters correctly when handling the Cancun time, leading to an `Invalid parameters` error and indefinite transaction indexing.","This bug can result in the Geth client being unable to process transactions effectively, causing the developer environment to become unusable, thereby impacting development workflows and testing of new features.",2248563433,29564,"April 17, 2024 3:22 PM (GMT+8)","April 18, 2024 4:42 PM (GMT+8)",['type:bug'],
go-ethereum,Incorrect receipt for the tx 0x8b21c385f137ce75b3f2b0ee84040b629208d5037d0101d23c8bd2ce98e3a89b,https://github.com/ethereum/go-ethereum/issues/29550,API,"Ethereum sepolia

#### System information

Geth version: v1.13.11
CL client & version: nimbus amd64-v24.2.0
OS & Version: linux

#### Expected behaviour
when requesting  eth_getTransactionReceipt for 0x8b21c385f137ce75b3f2b0ee84040b629208d5037d0101d23c8bd2ce98e3a89b
expected transactionIndex is 0x26

#### Actual behaviour
transactionIndex in response is 0x14
full response:
```
{""jsonrpc"":""2.0"",""id"":1,""result"":{""blockHash"":""0x5b9878a504a93085ae7b240d511d7b7eb64058925fb42dd6470bed9f61341973"",""blockNumber"":""0x56b2d0"",""contractAddress"":null,""cumulativeGasUsed"":""0xadc32"",""effectiveGasPrice"":""0xee9ab034"",""from"":""0x3c352ea32dfbb757ccdf4b457e52daf6ecc21917"",""gasUsed"":""0x5208"",""logs"":[],""logsBloom"":""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",""status"":""0x1"",""to"":""0xe078fca4af16626da5f71875f87d891f1b932ad4"",""transactionHash"":""0x7cb724246409190caa7789a29a652948a920ab4d9ed1e0df5aaa9fe615f20564"",""transactionIndex"":""0x14"",""type"":""0x0""}}
```
We cannot reproduce this issue right now, because it was fixed by restarting the node, but the problem has arisen not for the first time, and we want to understand what is causing it

#### Backtrace

````
[backtrace]
````

When submitting logs: please submit them as text and not screenshots.
",api: incorrect api output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes an intermittent issue where an API returns incorrect data. The problem is not consistently reproducible and is temporarily fixed by restarting the node. This pattern is a classic symptom of a state corruption issue. In a complex, multi-process system like an Ethereum node (Geth execution client + Nimbus consensus client), multiple threads or processes operate concurrently on shared data, such as the blockchain state or transaction caches. The reported behavior—an incorrect `transactionIndex` being returned—strongly suggests that a timing window exists where this shared data is read while it's in an inconsistent state, or is updated incorrectly due to improper synchronization between concurrent operations. This aligns perfectly with the definition of CWE-362, a 'Race Condition'.

CWE-703 (Improper Check or Handling of Exceptional Conditions) is less suitable. While the bug might be triggered by a rare event, the core problem isn't a failure to catch an exception but rather the resulting data inconsistency. The system continues to operate, but with incorrect data, which points more to a race condition than an unhandled exception.

CWE-416 (Use After Free) is a specific type of memory corruption bug. While it could potentially lead to such symptoms, there is no evidence in the bug report (like a crash or memory-specific errors) to point specifically to a use-after-free. The intermittent nature in a highly concurrent environment makes CWE-362 a more direct and probable explanation based on the provided information.",closed,"The discrepancy in the transaction index returned by the eth_getTransactionReceipt API indicates a potential issue in the state synchronization or caching mechanism within the node software, which may lead to inconsistent state representation.","This bug can lead to incorrect transaction receipts being returned to users, causing confusion and potential loss of trust in the system. It may also affect applications relying on accurate transaction data, leading to erroneous applications behavior or unintended consequences in smart contract interactions.",2245400168,29550,"April 16, 2024 8:06 AM (GMT+8)","April 18, 2024 4:46 PM (GMT+8)",['type:bug'],
go-ethereum,Beacon root contract in dev mode and private chains,https://github.com/ethereum/go-ethereum/issues/29539,Storage,"[EIP-4788](https://eips.ethereum.org/EIPS/eip-4788) introduces a system contract which is deployed as a normal contract to the state. However it is required for networks which have the Cancun fork enabled. It is a bug when a dev chain or private chain with Cancun enabled is deployed and it is missing the beacon root contract.

For dev-mode, we should add the beacon root contract to the [genesis alloc](https://github.com/ethereum/go-ethereum/blob/3705acd1a97b2cc9bbb092b326a9d8cfbc42037a/core/genesis.go#L576). As for private chain, IMO the least we should do is refuse `geth init` in case Cancun is enabled and the genesis alloc is missing the beacon root code at the correct address.",storage: missing data,CWE-665,Improper Initialization,"The bug report describes a situation where a required system contract (the beacon root contract) is missing when a new blockchain is created under specific conditions (dev mode or private chain with Cancun fork enabled). The creation of a new chain involves setting up its initial state, known as the 'genesis alloc'. The failure to include this necessary contract in the genesis allocation is a direct instance of 'Improper Initialization'. The definition of CWE-665, 'The product does not initialize or incorrectly initializes a resource,' perfectly describes this problem, where the resource is the blockchain's state, and it is initialized incorrectly by omitting a required component. The proposed solutions, such as adding the contract to the default genesis or refusing to initialize a chain with an invalid genesis file, both center on correcting the initialization process. 

CWE-20 (Improper Input Validation) is a plausible but less precise fit. While one proposed solution involves validating the genesis file (an input) during initialization, the core issue also affects dev mode where the default configuration itself is wrong, not just user-provided input. CWE-665 is more fundamental as it describes the resulting state of the system, which is an improperly initialized chain, regardless of the cause. 

CWE-755 (Improper Handling of Exceptional Conditions) is not suitable because the bug is a setup and configuration error, not a failure to handle a runtime exception. The system is built incorrectly from the start, rather than failing to handle an unexpected event during its operation.",closed,The absence of the beacon root contract in the genesis allocation for development or private chains when the Cancun fork is enabled.,"If the beacon root contract is missing, it can lead to inconsistencies or failures in executing transactions that rely on this contract, potentially disrupting the functionality of the network and its ability to process blocks correctly.",2243552658,29539,"April 15, 2024 12:27 PM (GMT+8)","May 14, 2024 9:04 PM (GMT+8)","['type:bug', 'help wanted', 'good first issue']",
go-ethereum,ipv6 address used as extip results in `127.0.0.1` being used,https://github.com/ethereum/go-ethereum/issues/29495,Network,"#### System information

Geth version: `1.13.14`
CL client & version: e.g. nimbus@v24.3.0
OS & Version: Linux

#### Expected behaviour
Sync mainnet state and chaindata after startup.

#### Actual behaviour
```
INFO [04-09|11:51:38.790] Logging configured                       rotate=true format=terminal location=/home/leo_h/eth/geth.log
INFO [04-09|11:51:38.801] Starting Geth on Ethereum mainnet...
INFO [04-09|11:51:38.802] Bumping default cache on mainnet         provided=1024 updated=4096
INFO [04-09|11:51:38.803] Maximum peer count                       ETH=50 total=50
INFO [04-09|11:51:38.805] Smartcard socket not found, disabling    err=""stat /run/pcscd/pcscd.comm: no such file or directory""
INFO [04-09|11:51:38.811] Set global gas cap                       cap=50,000,000
INFO [04-09|11:51:38.811] Initializing the KZG library             backend=gokzg
INFO [04-09|11:51:38.867] Allocated trie memory caches             clean=614.00MiB dirty=1024.00MiB
INFO [04-09|11:51:38.867] Using pebble as the backing database
INFO [04-09|11:51:38.867] Allocated cache and file handles         database=/home/leo_h/eth/geth-data/geth/chaindata cache=2.00GiB handles=524,288
INFO [04-09|11:51:38.944] Opened ancient database                  database=/home/leo_h/eth/geth-data/geth/chaindata/ancient/chain readonly=false
INFO [04-09|11:51:38.944] State scheme set by user                 scheme=path
INFO [04-09|11:51:38.946] Initialising Ethereum protocol           network=1 dbversion=8
WARN [04-09|11:51:38.946] Sanitizing invalid node buffer size      provided=1024.00MiB updated=256.00MiB
INFO [04-09|11:51:38.967] Opened ancient database                  database=/home/leo_h/eth/geth-data/geth/chaindata/ancient/state readonly=false
WARN [04-09|11:51:38.967] Path-based state scheme is an experimental feature
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [04-09|11:51:38.969] Chain ID:  1 (mainnet)
INFO [04-09|11:51:38.969] Consensus: Beacon (proof-of-stake), merged from Ethash (proof-of-work)
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] Pre-Merge hard forks (block based):
INFO [04-09|11:51:38.969]  - Homestead:                   #1150000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/homestead.md)
INFO [04-09|11:51:38.969]  - DAO Fork:                    #1920000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/dao-fork.md)
INFO [04-09|11:51:38.969]  - Tangerine Whistle (EIP 150): #2463000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/tangerine-whistle.md)
INFO [04-09|11:51:38.969]  - Spurious Dragon/1 (EIP 155): #2675000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [04-09|11:51:38.969]  - Spurious Dragon/2 (EIP 158): #2675000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [04-09|11:51:38.969]  - Byzantium:                   #4370000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/byzantium.md)
INFO [04-09|11:51:38.969]  - Constantinople:              #7280000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/constantinople.md)
INFO [04-09|11:51:38.969]  - Petersburg:                  #7280000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/petersburg.md)
INFO [04-09|11:51:38.969]  - Istanbul:                    #9069000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/istanbul.md)
INFO [04-09|11:51:38.969]  - Muir Glacier:                #9200000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/muir-glacier.md)
INFO [04-09|11:51:38.969]  - Berlin:                      #12244000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/berlin.md)
INFO [04-09|11:51:38.969]  - London:                      #12965000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/london.md)
INFO [04-09|11:51:38.969]  - Arrow Glacier:               #13773000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/arrow-glacier.md)
INFO [04-09|11:51:38.969]  - Gray Glacier:                #15050000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/gray-glacier.md)
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] Merge configured:
INFO [04-09|11:51:38.969]  - Hard-fork specification:    https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/paris.md
INFO [04-09|11:51:38.969]  - Network known to be merged: true
INFO [04-09|11:51:38.969]  - Total terminal difficulty:  58750000000000000000000
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] Post-Merge hard forks (timestamp based):
INFO [04-09|11:51:38.969]  - Shanghai:                    @1681338455 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/shanghai.md)
INFO [04-09|11:51:38.969]  - Cancun:                      @1710338135 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/cancun.md)
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [04-09|11:51:38.969]
INFO [04-09|11:51:38.969] Loaded most recent local block           number=0 hash=d4e567..cb8fa3 td=17,179,869,184 age=55y3w1d
INFO [04-09|11:51:38.970] Initialized transaction indexer          range=""last 2350000 blocks""
INFO [04-09|11:51:38.971] Loaded local transaction journal         transactions=0 dropped=0
INFO [04-09|11:51:39.062] Enabled snap sync                        head=0 hash=d4e567..cb8fa3
INFO [04-09|11:51:39.063] Chain post-merge, sync via beacon client
INFO [04-09|11:51:39.063] Gasprice oracle is ignoring threshold set threshold=2
WARN [04-09|11:51:39.068] Engine API enabled                       protocol=eth
INFO [04-09|11:51:39.068] Starting peer-to-peer node               instance=Geth/v1.13.14-stable-2bd6bd01/linux-amd64/go1.21.6
INFO [04-09|11:51:39.088] New local node record                    seq=1,712,633,593,960 id=da0a4563386118c2 ip=127.0.0.1 udp=30303 tcp=30303
INFO [04-09|11:51:39.089] Started P2P networking                   self=enode://e44055b1a9dc317006443ea3ad938d039434a995b47c2f200b4c060c1e35aa708217330030b1674a95e1c88547e7dd47d71785ca90d6f18f5cbbda4fbb88611a@127.0.0.1:30303
INFO [04-09|11:51:39.090] IPC endpoint opened                      url=/home/leo_h/eth/geth-data/geth.ipc
INFO [04-09|11:51:39.091] Loaded JWT secret file                   path=/home/leo_h/eth/jwtsecret.hex crc32=0x5050dcd5
INFO [04-09|11:51:39.093] HTTP server started                      endpoint=127.0.0.1:8545 auth=false prefix= cors= vhosts=localhost
INFO [04-09|11:51:39.093] WebSocket enabled                        url=ws://127.0.0.1:8551
INFO [04-09|11:51:39.094] HTTP server started                      endpoint=127.0.0.1:8551 auth=true  prefix= cors=localhost vhosts=localhost
INFO [04-09|11:51:49.605] Looking for peers                        peercount=0 tried=1 static=0
WARN [04-09|11:52:14.069] Post-merge network, but no beacon client seen. Please launch one to follow the chain!
INFO [04-09|11:52:14.090] Looking for peers                        peercount=0 tried=3 static=0
WARN [04-09|11:52:36.702] Ignoring payload while snap syncing      number=19,615,500 hash=2cc775..e0b643 reason=""forced head needed for startup""
INFO [04-09|11:52:36.909] Forkchoice requested sync to new head    number=19,615,500 hash=2cc775..e0b643 finalized=unknown
INFO [04-09|11:53:37.082] Forkchoice requested sync to new head    number=19,615,501 hash=5761bf..5f95a8 finalized=unknown
INFO [04-09|11:53:37.324] Forkchoice requested sync to new head    number=19,615,502 hash=e0be89..a5a842 finalized=unknown
INFO [04-09|11:53:37.602] Forkchoice requested sync to new head    number=19,615,503 hash=4dfad7..40d86c finalized=unknown
INFO [04-09|11:53:38.784] Forkchoice requested sync to new head    number=19,615,504 hash=775f64..505b63 finalized=unknown
INFO [04-09|11:53:39.167] Forkchoice requested sync to new head    number=19,615,505 hash=5f7cfb..5d26c6 finalized=unknown
INFO [04-09|11:53:39.425] Forkchoice requested sync to new head    number=19,615,506 hash=354bd3..dd86e6 finalized=unknown
INFO [04-09|11:53:39.694] Forkchoice requested sync to new head    number=19,615,507 hash=d8dd88..1e5a5b finalized=unknown
INFO [04-09|11:53:39.955] Forkchoice requested sync to new head    number=19,615,508 hash=e4a8d6..133af3 finalized=unknown
INFO [04-09|11:53:40.238] Forkchoice requested sync to new head    number=19,615,509 hash=fa9ecc..45671a finalized=unknown
INFO [04-09|11:53:40.604] Forkchoice requested sync to new head    number=19,615,510 hash=6cbdb0..4889b3 finalized=unknown
INFO [04-09|11:53:40.904] Forkchoice requested sync to new head    number=19,615,511 hash=f4e9d4..928c45 finalized=unknown
INFO [04-09|11:53:41.163] Forkchoice requested sync to new head    number=19,615,512 hash=e5c39f..8fe807 finalized=unknown
INFO [04-09|11:53:41.423] Forkchoice requested sync to new head    number=19,615,513 hash=7c8d0f..445ff1 finalized=unknown
INFO [04-09|11:53:41.698] Forkchoice requested sync to new head    number=19,615,514 hash=5ae518..535c58 finalized=unknown
INFO [04-09|11:53:41.966] Forkchoice requested sync to new head    number=19,615,515 hash=899ec3..8389f8 finalized=unknown
INFO [04-09|11:53:42.230] Forkchoice requested sync to new head    number=19,615,516 hash=900940..b62ed8 finalized=unknown
INFO [04-09|11:53:42.506] Forkchoice requested sync to new head    number=19,615,517 hash=897d10..7a4da4 finalized=unknown
INFO [04-09|11:53:42.712] Forkchoice requested sync to new head    number=19,615,518 hash=883ad8..f38a5a finalized=unknown
INFO [04-09|11:53:42.945] Forkchoice requested sync to new head    number=19,615,519 hash=1eb1da..181578 finalized=unknown
INFO [04-09|11:53:43.175] Forkchoice requested sync to new head    number=19,615,520 hash=0dca13..41cf5a finalized=unknown
INFO [04-09|11:53:43.395] Forkchoice requested sync to new head    number=19,615,521 hash=61a34a..2e9ab4 finalized=unknown
INFO [04-09|11:53:43.666] Forkchoice requested sync to new head    number=19,615,522 hash=68d7e3..a5cc4b finalized=unknown
INFO [04-09|11:53:43.967] Forkchoice requested sync to new head    number=19,615,523 hash=56bc35..fdd1e4 finalized=unknown
INFO [04-09|11:53:44.193] Forkchoice requested sync to new head    number=19,615,524 hash=955670..87a068 finalized=unknown
```

Not syncing state and chain data, even after nimbus has synced and backfilled itself.

One line in the log says ""forced head needed for startup"".

#### Steps to reproduce the behaviour
Sync a nimbus CL using checkpoint with `--backfill=false`, then launch both geth and nimbus.

",network: p2p protocol error,CWE-665,Improper Initialization,"The bug report indicates that when an IPv6 address is provided as input for the external IP (`extip`) parameter, the software fails to process it correctly and defaults to using `127.0.0.1`. This leads to a failure in the node's primary function of syncing with the network. This is a direct consequence of the software not handling a specific type of valid input. 

Let's evaluate the given CWEs:
- CWE-1389 (Incorrect Parsing of Numbers with Different Radices) is not a good fit. While an IPv6 address contains hexadecimal characters, the problem is not a misinterpretation of the number's base (e.g., treating a hex number as decimal). The issue is the failure to parse the entire IPv6 address format, which is a broader parsing problem.
- CWE-444 (Inconsistent Interpretation of HTTP Requests) is irrelevant. The bug is related to the configuration of a peer-to-peer node's network address, not the interpretation of HTTP requests by a proxy or intermediary.
- CWE-20 (Improper Input Validation) is the most accurate fit. The official description states, 'The product receives input or data, but it does not validate or incorrectly validates that the input has the properties that are required to process the data safely and correctly.' In this case, the software received an IPv6 address as input but failed to process it correctly, demonstrating a flaw in its input handling logic. This failure to handle a valid, expected format for an IP address falls directly under the scope of improper input validation or processing.",closed,"The issue stems from the incorrect handling of IPv6 addresses when setting the external IP address, which defaults to '127.0.0.1' instead of the intended IPv6 address.","This can lead to connectivity issues as the node may not be able to interact with the network properly, preventing it from syncing with other peers and potentially isolating the node from the Ethereum network.",2232557363,29495,"April 9, 2024 4:03 AM (GMT+8)","August 29, 2024 4:40 PM (GMT+8)",['type:bug'],
go-ethereum,Transactions stuck in pending in dev-mode,https://github.com/ethereum/go-ethereum/issues/29475,Consensus,"#### System information

* Geth version
    ```
    Geth
    Version: 1.13.14-stable
    Git Commit: 2bd6bd01d2e8561dd7fc21b631f4a34ac16627a1
    Git Commit Date: 20240227
    Architecture: arm64
    Go Version: go1.21.0
    Operating System: darwin
    GOPATH=
    GOROOT=/Users/gashkov/.asdf/installs/golang/1.22.0/go
    ```
* CL client & version: none (dev-mode)
* OS & Version: macOS Sonoma 14.4.1 (23E224)
* Commit hash: not applicable

#### Steps to reproduce the behaviour

1. Run `go-ethereum` in a dev-mode with block generation on demand
2. Send a batch of transactions concurrently

<details>
<summary>Stress-testing script I used for reproducing this behavior.</summary>

```go
package main

import (
	""fmt""
	""github.com/ethereum/go-ethereum/common""
	""github.com/ethereum/go-ethereum/common/hexutil""
	""github.com/ethereum/go-ethereum/core/types""
	""github.com/ethereum/go-ethereum/rpc""
	""log""
	""sync""
	""time""
)

func getCoinbase(c *rpc.Client) common.Address {
	var coinbase common.Address

	if err := c.Call(&coinbase, ""eth_coinbase""); err != nil {
		log.Fatalln(""error obtaining coinbase"", err)
	} else {
		log.Printf(""coinbase=%v"", coinbase)
	}

	return coinbase
}

func getTransactionCount(c *rpc.Client, address common.Address) hexutil.Uint {
	var nonce hexutil.Uint

	if err := c.Call(&nonce, ""eth_getTransactionCount"", address, ""latest""); err != nil {
		log.Fatalln(""error obtaining coinbase's initial nonce"", err)
	} else {
		log.Printf(""nonce=%v"", nonce)
	}

	return nonce
}

func sendTransactionToSelf(c *rpc.Client, address common.Address, nonce hexutil.Uint) (common.Hash, error) {
	txObject := map[string]any{""from"": address, ""to"": address, ""nonce"": nonce}

	var txHash common.Hash
	if err := c.Call(&txHash, ""eth_sendTransaction"", txObject); err != nil {
		return common.Hash{}, err
	}

	return txHash, nil
}

func waitTransactionReceipt(c *rpc.Client, txHash common.Hash) (*types.Receipt, error) {
	for i := 0; i < 10; i++ {
		var txReceipt *types.Receipt
		if err := c.Call(&txReceipt, ""eth_getTransactionReceipt"", txHash); err != nil {
			if fmt.Sprint(err) == ""transaction indexing is in progress"" {
				// `transaction indexing is in progress` is returned when
				// `eth_getTransactionCount` is called with no previously mined
				// blocks.
				time.Sleep(1 * time.Second)
			} else {
				return nil, err
			}
		}

		if txReceipt != nil {
			return txReceipt, nil
		}

		time.Sleep(100 * time.Millisecond)
	}

	return nil, fmt.Errorf(""timeout waiting tx hash=%v to be mined"", txHash)
}

func main() {
	c, err := rpc.Dial(""http://localhost:8545"")

	if err != nil {
		log.Fatal(""error dialing server"", ""url"", ""http://localhost:8545"")
	}

	coinbase := getCoinbase(c)
	startingNonce := getTransactionCount(c, coinbase)

	var (
		wg  sync.WaitGroup
		sem = make(chan struct{}, 5)
	)

	for nonce := startingNonce; nonce <= startingNonce+15; nonce++ {
		nonce := nonce
		sem <- struct{}{}
		wg.Add(1)

		go func() {
			defer func() { <-sem }()
			defer wg.Done()

			if txHash, err := sendTransactionToSelf(c, coinbase, nonce); err != nil {
				log.Printf(""error sending tx nonce=%v err=%v"", uint64(nonce), err)
			} else if receipt, err := waitTransactionReceipt(c, txHash); err != nil {
				log.Printf(""error waiting tx nonce=%v err=%v"", uint64(nonce), err)
			} else {
				log.Printf(""sent tx hash=%v nonce=%v blockNumber=%v"", receipt.TxHash, uint64(nonce), receipt.BlockNumber)
			}
		}()
	}

	wg.Wait()
}
```
</details>
</details>
<details>
<summary>Stress-testing output</summary>

```
% go run main.go
2024/04/06 20:13:14 coinbase=0xfb8c69691E914275e19Eb9d42735844A120067aD
2024/04/06 20:13:14 nonce=0x0
2024/04/06 20:13:15 sent tx hash=0xad155b491b06bffa28d2e0ebd4cf4f85a8e5bec108428cb2492b0048395fc3b7 nonce=2 blockNumber=1
2024/04/06 20:13:15 sent tx hash=0x7c7d61049a6118838cb0babd50aa05d5f8feece647637313d2e432dc2448e6e4 nonce=1 blockNumber=1
2024/04/06 20:13:15 sent tx hash=0xa53f94890c86c1d20f6c6398c8cd07d8c91bad816c91b7119c525f597ae7237a nonce=0 blockNumber=1
2024/04/06 20:13:15 sent tx hash=0x06bbb3c89850442f73ac53fff35b42a529dac62dde0167480455dda21e4b54e4 nonce=4 blockNumber=1
2024/04/06 20:13:15 sent tx hash=0xb55986ad438a261b8225e6384eba83a3dd710f196a5105526f149d0c8f85c0a8 nonce=3 blockNumber=1
2024/04/06 20:13:15 sent tx hash=0xc2f5aa3063d679fd39d9f2495577cb204519e9b8ecd68065155083f9c13a9aae nonce=7 blockNumber=2
2024/04/06 20:13:15 sent tx hash=0xedb2c69e889019102540da5800c4717aa3e9178fa9f8a8e4ac260235827b122d nonce=5 blockNumber=2
2024/04/06 20:13:15 sent tx hash=0xcc36386a360e4c35ccf7da2cd6d87ec4509f619f6f1620a3a9e3c43d0a050f71 nonce=6 blockNumber=2
2024/04/06 20:13:15 sent tx hash=0xf7f8a37a85beb5d366c989295cd46961a9e2bb59fac54b58fcb69fd93c7caa25 nonce=8 blockNumber=2
2024/04/06 20:13:16 error waiting tx nonce=9 err=timeout waiting tx hash=0x9b54d66bb30c77334f95e2931ca4ab6f11f61b139af1a6fc517b3fb4fe8b5e93 to be mined
2024/04/06 20:13:16 error waiting tx nonce=11 err=timeout waiting tx hash=0x6bd2490d9e4539f37ef2493389cd1066a25b32b4b2f50076e2824437335ead8f to be mined
2024/04/06 20:13:16 error waiting tx nonce=13 err=timeout waiting tx hash=0x2298fea2beeae800aa07c9e1751de1a4995d3fc506e0af3fc9039d77e89309e9 to be mined
2024/04/06 20:13:16 error waiting tx nonce=10 err=timeout waiting tx hash=0x034b4941ac6c1de3fd8e32b5c9d9976fb5896c6dbd6f37e9bb019db9e136d825 to be mined
2024/04/06 20:13:16 error waiting tx nonce=12 err=timeout waiting tx hash=0x24ca4ec05d745c4271e7b4a70d7a74d403daa38306ef7a6f6ae01a8394db7964 to be mined
2024/04/06 20:13:17 error waiting tx nonce=14 err=timeout waiting tx hash=0x2120f1d967a28ba0c467fd6c638db89959d64a92872569e7e0869ba0f3abad43 to be mined
2024/04/06 20:13:17 error waiting tx nonce=15 err=timeout waiting tx hash=0xb0e0165e29eb44545cd852da79937ad50c5933bead69cf54fbc122b5b50163e6 to be mined
```

</details>

#### Expected behaviour

`geth --dev` accepts and executes transactions concurrently.

#### Actual behaviour

Transactions are accepted but stuck in the pool:

```
% curl \
  -s \
  -X POST http://localhost:8545/ \
  -H 'content-type: application/json' \
  -H 'accept: application/json, */*;q=0.5' \
  -d '{""jsonrpc"":""2.0"",""id"":""1"",""method"":""txpool_inspect"",""params"":[]}' | jq

{
  ""jsonrpc"": ""2.0"",
  ""id"": ""1"",
  ""result"": {
    ""pending"": {
      ""0xfb8c69691E914275e19Eb9d42735844A120067aD"": {
        ""9"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1750000001 wei""
      }
    },
    ""queued"": {
      ""0xfb8c69691E914275e19Eb9d42735844A120067aD"": {
        ""10"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei"",
        ""11"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei"",
        ""12"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei"",
        ""13"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei"",
        ""14"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei"",
        ""15"": ""0xfb8c69691E914275e19Eb9d42735844A120067aD: 0 wei + 21000 gas × 1535240671 wei""
      }
    }
  }
}
```

Looks like the root cause is the deadlock between `SimulatedBeacon` and
`TxPool` waiting each other. Overall, the following happens:

```
SimulatedBeacon.loop():
  case <-newTxs:
    SimulatedBeacon.SealBlock()
      TxPool.Sync()  // Runs pool reorg and waits until done
        LegacyPool.runReorg()
```

and at the same time

```
SubmitTransaction(newTx)
  EthAPIBackend.SendTx(newTx)
    LegacyPool.add(newTx)
      LegacyPool.runReorg()
        txFeed.send(newTx)
          newTxs <- newTx // Waits until SimulatedBeacon.loop will be ready
```

So, when new TXs are sent concurrently, `LegacyPool` waits `SimulatedBeacon`
to react to the new TX but the `SimulatedBeacon` itself waits `LegacyPool` to
sync itself.

#### Backtrace

Nothing too suspicious in logs, but stacktraces contain two goroutines
indirectly waiting each other though:

```
goroutine 4279 [chan receive, 1 minutes]:
github.com/ethereum/go-ethereum/core/txpool.(*TxPool).Sync(0xc000513e60)
        /Users/gashkov/dev/go-ethereum/core/txpool/txpool.go:478 +0x148
github.com/ethereum/go-ethereum/eth/catalyst.(*ConsensusAPI).forkchoiceUpdated(0xc000178be0, {{0xc9, 0x10, 0x26, 0x77, 0xa1, 0x3, 0x24, 0x7, 0xab, ...}, ...}, ...)
        /Users/gashkov/dev/go-ethereum/eth/catalyst/api.go:397 +0x28d0
github.com/ethereum/go-ethereum/eth/catalyst.(*SimulatedBeacon).sealBlock(0xc0006626e0, {0x108c0da00, 0x0, 0x0}, 0x661190bc)
        /Users/gashkov/dev/go-ethereum/eth/catalyst/simulated_beacon.go:159 +0x4f4
github.com/ethereum/go-ethereum/eth/catalyst.(*SimulatedBeacon).Commit(0xc0006626e0)
        /Users/gashkov/dev/go-ethereum/eth/catalyst/simulated_beacon.go:249 +0xc4
github.com/ethereum/go-ethereum/eth/catalyst.(*api).loop(0xc0001b6980)
        /Users/gashkov/dev/go-ethereum/eth/catalyst/simulated_beacon_api.go:50 +0x2d8
created by github.com/ethereum/go-ethereum/eth/catalyst.RegisterSimulatedBeaconAPIs in goroutine 1
        /Users/gashkov/dev/go-ethereum/eth/catalyst/simulated_beacon.go:294 +0x14c
```
```
goroutine 4369 [select, 1 minutes]:
reflect.rselect({0xc00001d148, 0x2, 0x99?})
        /Users/gashkov/.asdf/installs/golang/1.21.0/go/src/runtime/select.go:589 +0x2d0
reflect.Select({0xc000000b40, 0x2, 0x5})
        /Users/gashkov/.asdf/installs/golang/1.21.0/go/src/reflect/value.go:3104 +0xa00
github.com/ethereum/go-ethereum/event.(*Feed).Send(0xc0003b9c90, {0x106d49200, 0xc000b78078})
        /Users/gashkov/dev/go-ethereum/event/feed.go:160 +0x758
github.com/ethereum/go-ethereum/core/txpool/legacypool.(*LegacyPool).runReorg(0xc0003b9c00, 0xc0005e8fc0, 0xc000488ed0, 0xc000458ce0, 0xc00089d290)
        /Users/gashkov/dev/go-ethereum/core/txpool/legacypool/legacypool.go:1336 +0xbf0
created by github.com/ethereum/go-ethereum/core/txpool/legacypool.(*LegacyPool).scheduleReorgLoop in goroutine 46
        /Users/gashkov/dev/go-ethereum/core/txpool/legacypool/legacypool.go:1205 +0x37c
```

* [All logs](https://raw.githubusercontent.com/nikitagashkov/go-ethereum-1-13-4-dev-mode-deadlock-report/70ef96998d9d3a1b37dd6f1065b20b539a84a122/logs.txt)
* [All stacktraces](https://raw.githubusercontent.com/nikitagashkov/go-ethereum-1-13-4-dev-mode-deadlock-report/70ef96998d9d3a1b37dd6f1065b20b539a84a122/stacktrace.txt)


Thank you for reviewing this report!",consensus: consensus liveness failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report explicitly identifies the root cause as a 'deadlock between `SimulatedBeacon` and `TxPool` waiting each other'. The detailed analysis confirms this: one process, `SimulatedBeacon`, calls `TxPool.Sync()` and waits for it to complete. Simultaneously, another process, `LegacyPool.runReorg` (part of the TxPool logic), tries to send a notification (`newTxs <- newTx`) which the `SimulatedBeacon` process is supposed to receive. However, `SimulatedBeacon` is blocked waiting for `TxPool.Sync()` and cannot receive the notification. This creates a circular dependency where two executable segments are waiting for each other to proceed, which is the exact definition of a deadlock. The provided stack traces for the two goroutines further confirm this state of mutual waiting. 

CWE-833 (Deadlock) is the most accurate classification because its definition, 'multiple threads or executable segments that are waiting for each other to release a necessary lock, resulting in deadlock,' perfectly describes the situation. The 'lock' in this context is the synchronization mechanism (waiting for a function return and a channel send).

CWE-362 (Race Condition) is less suitable. A race condition implies a timing window where concurrent operations can lead to an incorrect or unpredictable state. Here, the issue is not an unpredictable outcome but a predictable and complete halt of progress (a deadlock).

CWE-662 (Improper Synchronization) is a broader, more generic category. While a deadlock is a form of improper synchronization, CWE-833 is a more specific and precise description of the failure mode observed in the report. Therefore, CWE-833 is the single most accurate choice.",closed,"The root cause of the bug is a deadlock situation between the SimulatedBeacon and TxPool modules. The SimulatedBeacon is waiting for the TxPool to synchronize after a new transaction is sent, while the TxPool is simultaneously waiting for the SimulatedBeacon to process the new transaction. This circular dependency causes the transactions to get stuck in the pending state.","The consequence of this bug is that transactions sent in a concurrent manner can become stuck in the transaction pool without being processed. This can lead to a failure in transaction execution, causing delays and potential loss of funds for users who depend on timely transaction confirmations. In a production environment, this could severely impact the reliability and usability of the blockchain application.",2229367527,29475,"April 6, 2024 7:03 PM (GMT+8)","August 20, 2024 5:32 AM (GMT+8)",['type:bug'],
go-ethereum,"Pending Log Subscription emits logs at extremely slow rate ( roughly 1 pending transaction per second ) ",https://github.com/ethereum/go-ethereum/issues/29415,API,"#### System information

CL client & version: e.g. prsym@v5.0.2
OS & Version: LINUX
Commit hash : a3829178af6cec64d6def9131b9340a3328cc4fc


Running this minimal snippet to subscribe to logs emitted by pending transactions.


```

func GetProvider(conn string) *ethclient.Client {

	provider, err := ethclient.Dial(conn)
	if err != nil {
		fmt.Printf(""faied to connect to geth node via ws. err=%v conn=%v\n"", err, conn)
		return nil
	}
	return provider
}

func MinimumLoop() {

	localCh := make(chan types.Log)

	provider = GetProvider(LOCAL_GETH_WS_CONN)

	localSub, err := provider.SubscribeFilterLogs(
		context.Background(),
		ethereum.FilterQuery{
			FromBlock: big.NewInt(-1),
			ToBlock:   big.NewInt(-1),
		},
		localCh,
	)
	if err != nil {
		log.Fatalln(err)
	}
	for {
		select {
		case logLocal := <-localCh:
			fmt.Println(logLocal.TxHash)
		case err := <-localSub.Err():
			log.Fatalln(err)
		}
	}
}

func main() {
	MinimumLoop()
}
```

#### Expected behaviour

Volume of logs being printed from the loop should match number of actual transaction entering the mempool.

#### Actual behaviour

Pending logs are printed out very very slowly. At a rate of roughly 1 unique transaction per second. Something is definitely wrong,



",api: api performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report's core issue is a severe performance problem, described as an 'extremely slow rate' of processing and categorized as 'api performance degradation'. This indicates that the system is unable to handle the workload of incoming pending transactions. This aligns directly with CWE-400 (Uncontrolled Resource Consumption), which deals with the improper control of limited resources, leading to issues like performance degradation or denial of service. The system's inability to process logs at the expected rate suggests a bottleneck caused by inefficient management of a resource, such as CPU cycles, memory, or internal queues. CWE-362 (Race Condition) is less appropriate because the report does not describe symptoms of a classic race condition, like data corruption or unpredictable outcomes based on timing, but rather a consistent slowdown. CWE-835 (Infinite Loop) is incorrect because the program is making progress, just very slowly; the `for-select` loop is a standard event-handling pattern and is not unintentionally stuck.",closed,"The log subscription mechanism is not processing pending transactions efficiently, leading to a bottleneck in the rate at which logs are emitted.","This bug results in a significant delay in the ability to monitor pending transactions, which can hinder real-time applications that rely on timely updates from the blockchain.",2217041008,29415,"March 31, 2024 3:11 PM (GMT+8)","April 24, 2024 3:19 PM (GMT+8)",['type:bug'],
go-ethereum,"Why this command can cause a ""trie is already committed""",https://github.com/ethereum/go-ethereum/issues/29410,Execution,"#### System information

Geth version: `geth version`
CL client & version: e.g. lighthouse/nimbus/prysm@v1.0.0
OS & Version: Windows/Linux/OSX
Commit hash : (if `develop`)

```bash
root@ser7:~# geth version 
Geth
Version: 1.13.14-stable
Architecture: amd64
Go Version: go1.22.0
Operating System: linux
GOPATH=
GOROOT=
```

```bash
root@ser7:~# evm --version 
evm version 1.13.14-stable
```

#### Expected behaviour

The trie should not be commited

#### Actual behaviour

""trie is already committed""

#### Steps to reproduce the behaviour

```bash
evm  --prestate /tmp/a.json --gas 10000 --sender 0x0dfa72de72f96cf5b127b070e90d68ec9710797c --receiver 0x0ad62f08b3b9f0ecc7251befbeff80c9bb488fe9 --value 0x00 --input e9ca826c000000 --json --dump run
```

#### Backtrace

```bash
root@ser7:~# evm  --prestate /tmp/a.json --gas 10000 --sender 0x0dfa72de72f96cf5b127b070e90d68ec9710797c --receiver 0x0ad62f08b3b9f0ecc7251befbeff80c9bb488fe9 --value 0x00 --input e9ca826c000000 --json --dump run
{""output"":"""",""gasUsed"":""0x0""}
INFO [03-31|14:32:56.029] Trie dumping started                     root=56e81f..63b421
ERROR[03-31|14:32:56.029] Trie dumping error                       err=""trie is already committed""
{
    ""root"": ""56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421"",
    ""accounts"": {}
}
```

here is my `a.json`:
```bash
root@ser7:~# cat /tmp/a.json 
{""difficulty"":""0x01"",""coinbase"":""0x0000000000000000000000000000000000000000"",""timestamp"":""0x00"",""number"":""0x00"",""gasLimit"":""0x3d0900"",""extraData"":""0x00"",""mixhash"":""0x0000000000000000000000000000000000000000000000000000000000000000"",""parentHash"":""0x0000000000000000000000000000000000000000000000000000000000000000"",""nonce"":""0x00"",""alloc"":{},""config"":{""eip150Block"":0,""eip155Block"":0,""eip158Block"":0,""homesteadBlock"":0,""daoForkBlock"":0,""byzantiumBlock"":2000,""constantinopleBlock"":2000}}
```

",evm: simulation inconsistency,CWE-672,Operation on a Resource after Expiration or Release,"The bug report describes an error, ""trie is already committed"", that occurs when the `evm` tool attempts to dump a trie. In this context, the 'trie' is a data resource. The process of 'committing' the trie finalizes its state, making it immutable. This is analogous to releasing or expiring a resource. The error occurs because the program attempts to perform an operation ('dumping') on the trie after it has entered this committed/released state. This sequence of events directly matches the definition of CWE-672: 'Operation on a Resource after Expiration or Release'. The resource is the trie, and 'committed' is its expired/released state. CWE-703 is less suitable because the issue is not just a generic failure to handle an exception (an error is indeed logged), but a specific type of logical error related to resource state. CWE-394 is incorrect as there is no evidence of an unchecked return value; rather, an explicit error condition is being reported.",closed,"The error 'trie is already committed' indicates that the trie state is being accessed or modified after it has already been finalized, which suggests improper handling of state transitions or function calls within the execution module.","This bug can lead to unexpected behavior in the execution of smart contracts, potentially causing failures in transaction processing or incorrect state updates, which can compromise the reliability and correctness of the blockchain.",2216807124,29410,"March 31, 2024 6:35 AM (GMT+8)","April 2, 2024 8:25 PM (GMT+8)",['type:bug'],
go-ethereum,Estimate gas chooses wrong instruction set at genesis,https://github.com/ethereum/go-ethereum/issues/29404,Consensus,"## Bug
```console
$ geth --dev dumpgenesis > genesis.json
$ geth --dev --datadir=data init genesis.json
$ geth --dev --datadir=data console
> eth.estimateGas({from: ""0xd67dC7d443C902bd6ABfBc91C9E2E6906f55Ca46"", data: ""0x5959f3""})
Error: invalid opcode: PUSH0
        at web3.js:6382:9(39)
        at send (web3.js:5116:62(29))
        at <eval>:1:16(7)
```

## Culprit

We determine `random` value based on if `difficulty` is set:
https://github.com/ethereum/go-ethereum/blob/a3829178af6cec64d6def9131b9340a3328cc4fc/core/evm.go#L62-L64

But then here we use it as `isMerge` for creating the chain rules.
https://github.com/ethereum/go-ethereum/blob/a3829178af6cec64d6def9131b9340a3328cc4fc/core/vm/evm.go#L148

The chain rules then dictate the instruction set, so we choose London instructions instead of Shanghai.

## Resolution

I guess the main question is should we support this behavior. Is the genesis block technically considered post-merge? A simple fix would be to change the value that goes into `Rules(..)` to be `blockCtx.Random != nil || chainConfig.TerminalTotalDifficultyPassed`. But this doesn't feel too great either.
",evm: simulation inconsistency,CWE-682,Incorrect Calculation,"The bug report describes a situation where the system incorrectly determines the state of the blockchain (pre-merge vs. post-merge) at the genesis block. This determination is based on the presence of the `difficulty` field, which is then used to set a flag (`isMerge`). This flag, in turn, is used to select the chain rules, which dictate the EVM instruction set. The incorrect logic leads to the selection of the 'London' instruction set instead of the correct 'Shanghai' set, causing an 'invalid opcode' error when a Shanghai-specific opcode is encountered. 

CWE-682 (Incorrect Calculation) is the most accurate fit. The logical determination of the `isMerge` flag is a 'calculation' that produces an incorrect result for the genesis block scenario. This incorrect result is then used in a critical decision: selecting the EVM instruction set, which is fundamental to the correct and consistent execution of smart contracts on the chain. 

CWE-703 (Improper Check or Handling of Exceptional Conditions) is less suitable because the genesis state is a specific, defined state, not a rare or unexpected exceptional condition. The bug is not a failure to handle an error, but a flaw in the primary logic path for configuration.

CWE-436 (Interpretation Conflict) is not applicable because the issue is an internal logic flaw within a single product (go-ethereum), not a disagreement in interpretation between two separate products or components.",closed,"The incorrect instruction set is chosen at genesis due to the misinterpretation of the chain's difficulty value, leading to the use of outdated London instructions instead of the expected Shanghai instructions.","This bug can result in invalid opcode errors when executing certain transactions, potentially disrupting the functionality of the Ethereum network and leading to transaction failures for users.",2215783668,29404,"March 29, 2024 6:04 PM (GMT+8)","April 18, 2024 8:53 AM (GMT+8)",['type:bug'],
go-ethereum,Fatal: Failed to register the Ethereum service: content truncated,https://github.com/ethereum/go-ethereum/issues/29303,Storage,"#### System information

Geth version: `1.13.14-stable-2bd6bd01`
CL client & version: `Lighthouse/v5.1.0-10a38a8`
OS & Version: Linux (Ubuntu 23.10) on Raspberry Pi 5

#### Expected behaviour

Node starts normally and geths starts catching up the current chain head.

#### Actual behaviour

Client starts, but almost immediately fails with `Fatal: Failed to register the Ethereum service: content truncated, size:802805, slot:266240` message. Logs:

```
INFO [03-20|16:31:00.032] Starting Geth on Ethereum mainnet...
INFO [03-20|16:31:00.032] Bumping default cache on mainnet         provided=1024 updated=4096
INFO [03-20|16:31:00.036] Maximum peer count                       ETH=50 total=50
INFO [03-20|16:31:00.037] Smartcard socket not found, disabling    err=""stat /run/pcscd/pcscd.comm: no such file or directory""
WARN [03-20|16:31:00.039] Sanitizing cache to Go's GC limits       provided=4096 updated=2647
INFO [03-20|16:31:00.040] Set global gas cap                       cap=50,000,000
INFO [03-20|16:31:00.041] Initializing the KZG library             backend=gokzg
INFO [03-20|16:31:00.146] Allocated trie memory caches             clean=397.00MiB dirty=661.00MiB
INFO [03-20|16:31:00.148] Using pebble as the backing database
INFO [03-20|16:31:00.148] Allocated cache and file handles         database=/home/ethereum/.ethereum/geth/chaindata cache=1.29GiB handles=524,288
INFO [03-20|16:31:00.213] Opened ancient database                  database=/home/ethereum/.ethereum/geth/chaindata/ancient/chain readonly=false
INFO [03-20|16:31:00.215] State scheme set by user                 scheme=path
INFO [03-20|16:31:00.219] Initialising Ethereum protocol           network=1 dbversion=8
WARN [03-20|16:31:00.219] Sanitizing invalid node buffer size      provided=661.00MiB updated=256.00MiB
INFO [03-20|16:31:00.219] Failed to load journal, discard it       err=""journal not found""
INFO [03-20|16:31:00.221] Opened ancient database                  database=/home/ethereum/.ethereum/geth/chaindata/ancient/state readonly=false
WARN [03-20|16:31:00.221] Path-based state scheme is an experimental feature
INFO [03-20|16:31:00.221]
INFO [03-20|16:31:00.221] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [03-20|16:31:00.222] Chain ID:  1 (mainnet)
INFO [03-20|16:31:00.222] Consensus: Beacon (proof-of-stake), merged from Ethash (proof-of-work)
INFO [03-20|16:31:00.222]
INFO [03-20|16:31:00.222] Pre-Merge hard forks (block based):
INFO [03-20|16:31:00.222]  - Homestead:                   #1150000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/homestead.md)
INFO [03-20|16:31:00.222]  - DAO Fork:                    #1920000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/dao-fork.md)
INFO [03-20|16:31:00.222]  - Tangerine Whistle (EIP 150): #2463000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/tangerine-whistle.md)
INFO [03-20|16:31:00.222]  - Spurious Dragon/1 (EIP 155): #2675000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [03-20|16:31:00.222]  - Spurious Dragon/2 (EIP 158): #2675000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/spurious-dragon.md)
INFO [03-20|16:31:00.222]  - Byzantium:                   #4370000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/byzantium.md)
INFO [03-20|16:31:00.222]  - Constantinople:              #7280000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/constantinople.md)
INFO [03-20|16:31:00.222]  - Petersburg:                  #7280000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/petersburg.md)
INFO [03-20|16:31:00.222]  - Istanbul:                    #9069000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/istanbul.md)
INFO [03-20|16:31:00.222]  - Muir Glacier:                #9200000  (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/muir-glacier.md)
INFO [03-20|16:31:00.222]  - Berlin:                      #12244000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/berlin.md)
INFO [03-20|16:31:00.222]  - London:                      #12965000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/london.md)
INFO [03-20|16:31:00.222]  - Arrow Glacier:               #13773000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/arrow-glacier.md)
INFO [03-20|16:31:00.222]  - Gray Glacier:                #15050000 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/gray-glacier.md)
INFO [03-20|16:31:00.222]
INFO [03-20|16:31:00.222] Merge configured:
INFO [03-20|16:31:00.222]  - Hard-fork specification:    https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/paris.md
INFO [03-20|16:31:00.222]  - Network known to be merged: true
INFO [03-20|16:31:00.222]  - Total terminal difficulty:  58750000000000000000000
INFO [03-20|16:31:00.222]
INFO [03-20|16:31:00.222] Post-Merge hard forks (timestamp based):
INFO [03-20|16:31:00.222]  - Shanghai:                    @1681338455 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/shanghai.md)
INFO [03-20|16:31:00.222]  - Cancun:                      @1710338135 (https://github.com/ethereum/execution-specs/blob/master/network-upgrades/mainnet-upgrades/cancun.md)
INFO [03-20|16:31:00.222]
INFO [03-20|16:31:00.222] ---------------------------------------------------------------------------------------------------------------------------------------------------------
INFO [03-20|16:31:00.222]
INFO [03-20|16:31:00.224] Loaded most recent local header          number=19,386,952 hash=4868c9..228db3 td=58,750,003,716,598,352,816,469 age=1w5d15h
INFO [03-20|16:31:00.225] Loaded most recent local block           number=0          hash=d4e567..cb8fa3 td=17,179,869,184                 age=55y2d16h
INFO [03-20|16:31:00.225] Loaded most recent local snap block      number=19,386,952 hash=4868c9..228db3 td=58,750,003,716,598,352,816,469 age=1w5d15h
WARN [03-20|16:31:00.226] Loaded snapshot journal                  diffs=missing
INFO [03-20|16:31:00.226] Initialized transaction indexer          range=""last 2350000 blocks""
INFO [03-20|16:31:00.226] Loaded local transaction journal         transactions=0 dropped=0
INFO [03-20|16:31:00.227] Upgrading chain index                    type=bloombits percentage=0
INFO [03-20|16:31:00.228] Resuming state snapshot generation       root=d7f897..0f0544 accounts=0 slots=0 storage=0.00B dangling=0 elapsed=""382.113µs""
INFO [03-20|16:31:00.237] Transaction pool stopped
Fatal: Failed to register the Ethereum service: content truncated, size:802805, slot:266240
```

#### Steps to reproduce the behaviour

0. Used device: single Raspberry Pi 5 device (2TB SSD connected via USB3, with a 16 GB swap file stored on the SSD)
1. Run geth on the device (in a screen session):
`geth --authrpc.addr=0.0.0.0 --authrpc.port 8551 --authrpc.vhosts=* --authrpc.jwtsecret SECRET_LOCATION --http --http.addr 0.0.0.0 --http.vhosts=* --http.api eth,net,web3 --state.scheme=path`
2. Run lighthouse on the same device (in a screen session):
`lighthouse bn --network mainnet --execution-endpoint http://localhost:8551 --execution-jwt SECRET_LOCATION --checkpoint-sync-url https://mainnet.checkpoint.sigp.io --disable-deposit-contract-sync`
3. Wait until it is fully synced, then make it lose sync (e.g., by running some heavy processes on the device or stopping the lighthouse for a few minutes). 
4. Restart the Ligthhouse and wait till it is up and running, and make sure that geth is around 3-4 minutes behind (at least this is what logs showed)
5. Hard-kill the device by unplugging it from the power source
6. Restart the device 
7. Run `geth removedb` and remove the state database, but keep the ancient state
8. Restart both clients (although geth should be enough as lighthouse does not fully start before geth is stopped)

Remarks:
- I tried to reproduce this behavior with a fully synced node, and this problem did not happen when the device was hard killed in a fully synced state
- Unfortunately, it is not a vanilla state due to the `geth removedb` step, which I ran to check if that would fix the issue on my end
- Even though the device may be partially responsible for this behavior, it seems more due to the ""catching up"" state, as I could not reproduce it with fully synced devices (despite multiple attempts). Hard-killing the device almost guaranteed database corruption before the new database model (path)",general: initialization failure,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a fatal crash that occurs when the application attempts to start after an improper shutdown (a hard power-off). The key trigger is an exceptional event: the device is unplugged while the database is in a write-intensive 'catching up' state. This leads to data corruption, as evidenced by the 'content truncated' error message. The application's inability to recover from this state and instead crashing fatally is a clear instance of failing to handle an exceptional condition.

- **CWE-703 (Improper Check or Handling of Exceptional Conditions)** is the most accurate fit. A sudden power loss is a classic exceptional condition. The software fails to anticipate or handle the resulting inconsistent state of its data files on disk, leading to a startup failure. The entire scenario described in the reproduction steps revolves around creating and then failing to handle this exceptional state.

- **CWE-404 (Improper Resource Shutdown or Release)** is not suitable. This CWE pertains to the software's own shutdown logic failing to release resources correctly. In this case, the software did not execute its shutdown logic at all; it was terminated abruptly by an external event (power loss). The problem is not how it shuts down, but how it handles the aftermath of being killed unexpectedly.

- **CWE-228 (Improper Handling of Syntactically Invalid Structure)** is a plausible but less precise choice. The 'content truncated' error does indicate the application is encountering a syntactically invalid data structure (the corrupted file). However, this invalid structure is a *symptom* of the root cause, which is the exceptional condition (the power loss). CWE-703 addresses the failure to handle the overarching situation, which is more fundamental than just the failure to parse a resulting malformed file.",closed,"The bug occurs due to content truncation in the Ethereum service registration process, likely caused by database corruption after an improper shutdown of the device while in a catching up state.","This bug prevents the Geth client from properly registering the Ethereum service, leading to a failure in node startup and synchronization, which can disrupt the functioning of the Ethereum network on the affected device.",2198094415,29303,"March 20, 2024 5:16 PM (GMT+8)","April 4, 2024 9:51 PM (GMT+8)",['type:bug'],
go-ethereum,eth_getTransactionReceipt returning reorged block data instead of the canonical block's data,https://github.com/ethereum/go-ethereum/issues/29261,Consensus,"#### System information

Geth version: `geth-windows-amd64-1.13.14-2bd6bd01`
CL client & version: `Prysm v5.0.0`
OS & Version: `Windows`

We were indexing blocks and having issues indexing this receipt: 0xddf1c0d3366ec51b0d8a75ef3e0c5c22c8c4c34b3ddc914776a34a0c4248d359

#### Expected behaviour
eth_getTransactionReceipt to return the correct block details as below:

```
""jsonrpc"": ""2.0"",
""id"": 1,
""result"": {
	""blobGasPrice"": ""0x1"",
	""blockHash"": ""0x3fb5bb2b9efa2f44b91de93c23313ede0bf1e9debe893854646f6350498b6d47"",
	""blockNumber"": ""0x1288297"",
	""contractAddress"": null,
	""cumulativeGasUsed"": ""0x174c0e0"",
	""effectiveGasPrice"": ""0xa111dcbb3"",
	""from"": ""0xa108edf3c6ce15a9674d65be73338116af6e0f06"",
	""gasUsed"": ""0x5208"",
	""logs"": [],
	""logsBloom"": ""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
	""status"": ""0x1"",
	""to"": ""0xb20aac3ed8fa7a7fbae81b622b1b554cc58b8b1d"",
	""transactionHash"": ""0xddf1c0d3366ec51b0d8a75ef3e0c5c22c8c4c34b3ddc914776a34a0c4248d359"",
	""transactionIndex"": ""0xd7"",
	""type"": ""0x2""
}
```

#### Actual behaviour
Curl calling eth_getTransactionReceipt returns the below details - Which this block is a reorged block (the correct blockHash for block 0x1288296 is 0x3fb5bb2b9efa2f44b91de93c23313ede0bf1e9debe893854646f6350498b6d47)

```
""jsonrpc"": ""2.0"",
""id"": 1,
""result"": {
	""blockHash"": ""0x19fb25e3d5ea1c8bff76c5d4e84c764d5d5d150e43566f68dbd3fc4a92b47a41"",
	""blockNumber"": ""0x1288296"",
	""contractAddress"": null,
	""cumulativeGasUsed"": ""0x305ba6"",
	""effectiveGasPrice"": ""0xa7620bcc9"",
	""from"": ""0xa108edf3c6ce15a9674d65be73338116af6e0f06"",
	""gasUsed"": ""0x5208"",
	""logs"": [],
	""logsBloom"": ""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
	""status"": ""0x1"",
	""to"": ""0xb20aac3ed8fa7a7fbae81b622b1b554cc58b8b1d"",
	""transactionHash"": ""0xddf1c0d3366ec51b0d8a75ef3e0c5c22c8c4c34b3ddc914776a34a0c4248d359"",
	""transactionIndex"": ""0x51"",
	""type"": ""0x2""
}

```

Restarting the node will allow us to correctly query 0xddf1c0d3366ec51b0d8a75ef3e0c5c22c8c4c34b3ddc914776a34a0c4248d359 from the canonical block, however does trip our reorg checks. Any idea what might be the case?

Am aware of another issue prior to this https://github.com/ethereum/go-ethereum/issues/28885 which should have resolve this issue, but seems to still be happening for us.
",api: incorrect api output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a situation where an API call (`eth_getTransactionReceipt`) returns data from a non-canonical (reorged) block instead of the correct, canonical block. This occurs in a highly concurrent environment, a blockchain node, which is constantly processing new blocks, handling API requests, and managing chain state changes like reorganizations.

A reorganization is a complex operation that modifies a shared resource: the node's view of the canonical chain and its associated transaction indexes. An API request to fetch a transaction receipt concurrently reads from this shared resource. The bug's symptom—retrieving stale data from a now-invalid fork—strongly suggests that the process handling the API request is accessing the chain state while it is being modified by the reorganization process, without proper synchronization. This creates a timing window, or race condition, where the API can read an inconsistent or outdated state.

CWE-665 (Improper Initialization) is less likely. Although restarting the node (which involves re-initialization) fixes the problem, the error doesn't occur at startup but during runtime after a specific event (a reorg). This indicates the state becomes corrupted during operation, not that it was initialized incorrectly.

CWE-193 (Off-by-one Error) is also a poor fit. While the block numbers in the report happen to differ by one, this is a symptom of being on a different fork, not the root cause. The fundamental issue is accessing the wrong block entirely (as shown by the different `blockHash`), not a simple off-by-one calculation error when accessing an array or buffer.

Therefore, CWE-362 is the most accurate classification, as the issue stems from two concurrent operations (reorg processing and API handling) accessing a shared resource (the chain state) without proper synchronization, leading to the retrieval of incorrect data.",closed,The `eth_getTransactionReceipt` API is returning transaction data from a reorged block instead of the canonical block data. This issue arises due to improper handling of block confirmations or state management in the indexing process.,"This bug can lead to inconsistency in the transaction data returned by the API, causing applications relying on accurate blockchain data to behave incorrectly, potentially leading to financial losses or operational failures in decentralized applications.",2186004083,29261,"March 14, 2024 10:33 AM (GMT+8)","April 9, 2024 2:37 PM (GMT+8)","['type:bug', 'status:triage']",
go-ethereum,`devp2p enrdump`: 1 extra prefix byte added for hex representation.,https://github.com/ethereum/go-ethereum/issues/29252,Utilities,"#### System information

```
./devp2p --version
devp2p version 1.14.0-unstable-d8e0807d-20240306
```
OS & Version: OSX
Commit hash : `d8e0807`

#### Expected behaviour
Test vector: https://eips.ethereum.org/EIPS/eip-778#test-vectors

```
./devp2p enrdump enr:-IS4QHCYrYZbAKWCBRlAy5zzaDZXJBGkcnh4MHcBFZntXNFrdvJjX04jRzjzCBOonrkTfj499SZuOh8R33Ls8RRcy5wBgmlkgnY0gmlwhH8AAAGJc2VjcDI1NmsxoQPKY0yuDUmstAHYpMa2_oxVtw0RW_QAdpzBQA8yWM0xOIN1ZHCCdl8
```

should produce

```
...
  ""secp256k1"" 03ca634cae0d49acb401d8a4c6b6fe8c55b70d115bf400769cc1400f3258cd3138
...
```
#### Actual behaviour

```
...
  ""secp256k1"" a103ca634cae0d49acb401d8a4c6b6fe8c55b70d115bf400769cc1400f3258cd3138
...
```

Notice the extra `a1` at the beginning.
The  produced `secp256k1` is 34 bytes long, whereas 33 bytes are expected - [Source](https://eips.ethereum.org/EIPS/eip-778#specification)

It seems all hex data are displayed with 1 extra prefix byte.

Example with:

```
./devp2p enrdump ""enr:-Ku4QImhMc1z8yCiNJ1TyUxdcfNucje3BGwEHzodEZUan8PherEo4sF7pPHPSIB1NNuSg5fZy7qFsjmUKs2ea1Whi0EBh2F0dG5ldHOIAAAAAAAAAACEZXRoMpD1pf1CAAAAAP__________gmlkgnY0gmlwhBLf22SJc2VjcDI1NmsxoQOVphkDqal4QzPMksc5wnpuC3gvSC8AfbFOnZY_On34wIN1ZHCCIyg""
Node ID: 191bbf49632da5393590a33d54421e79e8e5c96ade72f0ba69e1803095de6b04
URLv4:   enode://95a61903a9a9784333cc92c739c27a6e0b782f482f007db14e9d963f3a7df8c01ad6a387e8021f13e684e576ca9e5d8759b3116df521b280a887a0bdc72e457f@18.223.219.100:0?discport=9000
Record has sequence number 1 and 6 key/value pairs.
  ""attnets""   880000000000000000
  ""eth2""      90f5a5fd4200000000ffffffffffffffff
  ""id""        ""v4""
  ""ip""        18.223.219.100
  ""secp256k1"" a10395a61903a9a9784333cc92c739c27a6e0b782f482f007db14e9d963f3a7df8c0
  ""udp""       9000
```

- `secp256k1` has 1 extra bytes (expected: 33 - actual 34) - [Source](https://eips.ethereum.org/EIPS/eip-778#specification)
- `eth2` has 1 extra bytes (expected: 16 - actual 17) - [Source](https://github.com/ethereum/consensus-specs/blob/dev/specs/phase0/p2p-interface.md#eth2-field)
- `attnets` seems to have extra prefix `88`
",general: incorrect tooling output,CWE-704,Incorrect Type Conversion or Cast,"The bug report describes an issue where the `devp2p enrdump` utility produces incorrect hexadecimal output for several data fields. Specifically, it adds an extra, erroneous prefix byte to the hex string representation of binary data (e.g., `a1` is prepended to the `secp256k1` key). This indicates a flaw in the process of converting the internal binary data into its final hexadecimal string representation for display. 

Let's evaluate the provided CWEs:
- **CWE-436 (Interpretation Conflict)**: This CWE is not suitable because the issue is not an interoperability problem between two different products. It's a bug within a single tool (`devp2p enrdump`) that fails to correctly represent data according to a specification.
- **CWE-116 (Improper Encoding or Escaping of Output)**: While this seems plausible because it involves incorrect 'encoding' (hex encoding), the primary focus of CWE-116 is on preserving the structure of a message intended for another component, often to prevent injection attacks. The output here is a human-readable dump, and the issue is a misrepresentation of a data value, not a corruption of the overall message structure for machine parsing.
- **CWE-704 (Incorrect Type Conversion or Cast)**: This is the most accurate CWE. The root cause of the bug is the incorrect conversion of a data structure (a byte array) into a different type (a hexadecimal string). The function responsible for formatting the binary data into a hex string is performing the conversion incorrectly, leading to the extra byte in the output. This directly matches the CWE's description of a product not correctly converting a structure from one type to another.",closed,"The API responsible for generating the hex representation of certain byte sequences incorrectly adds an extra prefix byte, leading to an invalid hex output.","This bug can cause misinterpretation of data, leading to potential failures in data processing, compatibility issues with other systems expecting valid hex formats, and could affect overall consensus and network communication.",2184867446,29252,"March 13, 2024 8:53 PM (GMT+8)","March 14, 2024 5:32 PM (GMT+8)",['type:bug'],
go-ethereum,"Geth is stuck at `Head state missing, repairing`",https://github.com/ethereum/go-ethereum/issues/29156,Storage,"Geth has a mechanism to recover from the potential unclean shutdown. Specifically, the associated chain head state might be unreachable due to the data loss caused by unclean shutdown. Therefore, a recovery mechanism is necessary to rewind the chain head until a reachable state is found. Besides, in order to avoid rebuilding the state snapshot completely, an additional trick is added that **the rewound state must below the state snapshot disk layer**. If so, once the chain is synced up, the leftover state snapshot can be picked up again.

During the whole rewinding, an assumption is held the starting point must above the state snapshot disk layer. Usually it's always held but can't be not true under some circumstances. For instance:

The chain is rewound to a block below the state snapshot disk layer, and snapshot is waiting for picking up. If we kill the geth node before the chain is fully recovered, then the chain head will below the state snapshot. In this case Geth will be stuck at state rewinding in the next startup as the state corresponds to state snapshot disk layer will never be found.

---





",storage: storage persistence failure,CWE-835,Loop with Unreachable Exit Condition ('Infinite Loop'),"The bug report describes a scenario where the Geth software enters a state from which it cannot recover. Specifically, during the chain rewinding process, it searches for a state that, under certain conditions, 'will never be found'. This causes the node to get 'stuck at state rewinding'. This behavior is a direct match for the definition of CWE-835, 'Loop with Unreachable Exit Condition ('Infinite Loop')', as the rewinding process is a loop whose exit condition (finding the required state) has become unreachable. While the situation is triggered by an 'exceptional condition' (CWE-703), the actual flaw in the logic is the infinite loop itself, making CWE-835 a more specific and accurate classification. CWE-20, 'Improper Input Validation', is less fitting because the 'input' is the system's own internal state after a crash, not external data, and the direct consequence described is the loop, not just the failure to validate.",closed,"The Geth node assumes that the rewound state will always be above the state snapshot disk layer, but this assumption can be violated under certain conditions, leading to a situation where the head state is missing.","If Geth becomes stuck at 'Head state missing, repairing', it can lead to prolonged downtime of the node, preventing it from functioning properly and affecting the overall network performance.",2165860758,29156,"March 4, 2024 3:47 AM (GMT+8)","March 13, 2024 7:39 PM (GMT+8)",['type:bug'],
go-ethereum,Inconsistent tracing output for debug_traceBlockByHash.,https://github.com/ethereum/go-ethereum/issues/29114,Utilities,"#### System information

The node is running on the Sepolia network.

Geth version: `1.13.11`
CL client & version: Lighthouse
OS & Version: Linux

#### Expected behaviour

The output of calls to `debug_traceBlockByHash` for the same hash and finalized blocks should consistent.

#### Actual behaviour

First call for [0x18a918ff5840857313cfd6c8f4906d8360a6e5df281fd5671137ae9ff6665c40](https://sepolia.etherscan.io/block/5287473), when looking at transaction [0x591876205f1a7240a56be7ecce03b7e70a7e6e6a1335f05019fc36dcba92d265](https://sepolia.etherscan.io/tx/0x591876205f1a7240a56be7ecce03b7e70a7e6e6a1335f05019fc36dcba92d265) returns invalid data, saying the transaction was reverted when it wasn't:

```json
{
    ""txHash"": ""0x591876205f1a7240a56be7ecce03b7e70a7e6e6a1335f05019fc36dcba92d265"",
    ""result"": {
        ""type"": ""CALL"",
        ""from"": ""0xb224a1090cf9afda1520920423ee0594f4e125a3"",
        ""to"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
        ""value"": ""0x0"",
        ""gas"": ""0x9ba48"",
        ""gasUsed"": ""0xd4b5"",
        ""input"": ""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"",
        ""output"": ""0x08c379a00000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000001a6661696c656420746f206f627461696e20626c6f636b68617368000000000000"",
        ""calls"": [
            {
                ""type"": ""DELEGATECALL"",
                ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                ""to"": ""0xd63ec907e93c793a1f2ffd7a3f04a46a3aec74fd"",
                ""input"": ""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"",
                ""gas"": ""0x8cdf2"",
                ""value"": ""0x0"",
                ""gasUsed"": ""0xbf4"",
                ""error"": ""execution reverted""
            }
        ],
        ""error"": ""execution reverted"",
        ""txIndex"": 241
    }
}
```

Then I call `debug_traceTransaction`:

```
$ curl 'http://localhost:8545' -X POST -H ""Content-Type: application/json"" -d '{""jsonrpc"": ""2.0"",""id"":1,""method"":""debug_traceTransaction"",""params"":[""0x591876205f1a7240a56be7ecce03b7e70a7e6e6a1335f05019fc36dcba92d265""]}'
```

Subsequent calls to `debug_traceBlockByHash` are now correct:

```json
{
    ""txHash"": ""0x591876205f1a7240a56be7ecce03b7e70a7e6e6a1335f05019fc36dcba92d265"",
    ""result"": {
        ""type"": ""CALL"",
        ""from"": ""0xb224a1090cf9afda1520920423ee0594f4e125a3"",
        ""to"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
        ""value"": ""0x0"",
        ""gas"": ""0x9ba48"",
        ""gasUsed"": ""0x7f1d4"",
        ""input"": ""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"",
        ""output"": ""0x"",
        ""calls"": [
            {
                ""type"": ""DELEGATECALL"",
                ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                ""to"": ""0xd63ec907e93c793a1f2ffd7a3f04a46a3aec74fd"",
                ""input"": ""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"",
                ""gas"": ""0x8cdf2"",
                ""value"": ""0x0"",
                ""calls"": [
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x0000000000000000000000000000000000000005"",
                        ""input"": ""0x000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000020564c0a11a0f704f4fc3e8acfe0f8245f0ad1347b378fbf96e206da11a5d3630600000000000000000000000000000000000000000000000000000000000001f773eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001"",
                        ""gas"": ""0x8252e"",
                        ""gasUsed"": ""0xc8"",
                        ""output"": ""0x5b5b3d073a9c55cdd85ea2235bfe4d4804fcb916c626e0e9bc29f6173ab70b65""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x000000000000000000000000000000000000000a"",
                        ""input"": ""0x0168dab2ee92486415bacbda6e3dd6c424ad5abbad004e0072bbe5d67a929a3f5b5b3d073a9c55cdd85ea2235bfe4d4804fcb916c626e0e9bc29f6173ab70b65006da1b75642ed8a267c4b156b3b520d4dc88044d6ebe0d774ae7facaad45febabf0ec5b7413fc5c302aa02b8506f8f2141a9ceaa723ab0207d6f42b62bd7982d383a3c805f29dd7a1af59116b4f8394b2a07ba891019a047d175b1036956d4a7530e87009ff83721095e4e483671cdaace44e5132bd55acbb4e29ca3c880943"",
                        ""gas"": ""0x8235f"",
                        ""gasUsed"": ""0xc350"",
                        ""output"": ""0x000000000000000000000000000000000000000000000000000000000000100073eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x0000000000000000000000000000000000000005"",
                        ""input"": ""0x000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000020564c0a11a0f704f4fc3e8acfe0f8245f0ad1347b378fbf96e206da11a5d36306000000000000000000000000000000000000000000000000000000000000028d73eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001"",
                        ""gas"": ""0x73c3e"",
                        ""gasUsed"": ""0xc8"",
                        ""output"": ""0x66233a3febc19c74e00c852874294fe1a032055cd6e43a26efe507326576562d""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x000000000000000000000000000000000000000a"",
                        ""input"": ""0x01dce41d691a27cb0ee5346b45456751271b470ddee60641fdcfde6ad2af4dc466233a3febc19c74e00c852874294fe1a032055cd6e43a26efe507326576562d00ee858e9e2cac6cab3cf8b12d7716d7cd576ed09c6e4d8a446b1960d7bfa78ba1e8735900b6153a917ca48a609c3dc989f2cec941987e7d3cd7008241130b1206fcd54deccd3955c7d152d920275054909b441af2fc821814d20c712e9869bdf6f7d0ccb93c4540c0ca2ebf57895f113466ff302fc95d29a9346b54cb032ef0"",
                        ""gas"": ""0x73a6e"",
                        ""gasUsed"": ""0xc350"",
                        ""output"": ""0x000000000000000000000000000000000000000000000000000000000000100073eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x0000000000000000000000000000000000000005"",
                        ""input"": ""0x0000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000200931d596de2fd10f01ddd073fd5a90a976f169c76f039bb91c4775720042d43a0000000000000000000000000000000000000000000000000000000000000ef830644e72e131a029b85045b68181585d2833e84879b9709143e1f593f0000001"",
                        ""gas"": ""0x66e75"",
                        ""gasUsed"": ""0xc8"",
                        ""output"": ""0x2f4efada34d3a1db98c1eef53ef7b32dd5cd4ae3587a5c1f689257aaa74836ee""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x0000000000000000000000000000000000000005"",
                        ""input"": ""0x0000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000200931d596de2fd10f01ddd073fd5a90a976f169c76f039bb91c4775720042d43a0000000000000000000000000000000000000000000000000000000000000b1430644e72e131a029b85045b68181585d2833e84879b9709143e1f593f0000001"",
                        ""gas"": ""0x66bf4"",
                        ""gasUsed"": ""0xc8"",
                        ""output"": ""0x26861c593190929ec7ed1c6bcde1b194ccc9fce04f9135b16da4df33d7070f2f""
                    },
                    {
                        ""type"": ""STATICCALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""input"": ""0xf398789b196bb83f25adbd798fe91ecaafad22392f50acc9e1e70131391a31bc2f25fb8a015e433fef9d9bdaa06be67fcd035557db334dbc878f879f3077403f6e4e3852255c709983ef1aed2f62b9962f6f031403cf319e145863fe65765803837a81412067442f2838d3e0a0991ffd7e5f28b8dc4ccec19a051988a029f9ff1be821612563b0c09133dcf4a2e5ee456e63bbec2d2f71830b9be9837c50df0804e74ad10f8a2434705d19901aa06d3f4f5b2c62e7ab6a6d8d9e863691feccae21dbc46e2c46d6169bfdc1a54dda7ae2ca9f72a7db1d16b60bc5eeb83113412d9c82f08625a02ee774539dd1f6dd7de83160e8468560e14f125ed638dbc4c6e8b7c015cf00d28a4398c4ebcb3c3147c3d072d0944103c569a44c54f243fc12e3526f3c9c0101ed1f27c5a104f72c8c87d2a9436719dac26b976119bc4784f5829eeb5a042f4efada34d3a1db98c1eef53ef7b32dd5cd4ae3587a5c1f689257aaa74836ee26861c593190929ec7ed1c6bcde1b194ccc9fce04f9135b16da4df33d7070f2f26697cd56eee0cbfe2b50721792a4fc4dfd2dc3f3033a2ec6db7f5195dd546cd1b1f803239fa90acff381a3f8e559b78cbe61efecba710a5d2701ae71c702799"",
                        ""gas"": ""0x65ac5"",
                        ""calls"": [
                            {
                                ""type"": ""DELEGATECALL"",
                                ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                ""to"": ""0xd63ec907e93c793a1f2ffd7a3f04a46a3aec74fd"",
                                ""input"": ""0xf398789b196bb83f25adbd798fe91ecaafad22392f50acc9e1e70131391a31bc2f25fb8a015e433fef9d9bdaa06be67fcd035557db334dbc878f879f3077403f6e4e3852255c709983ef1aed2f62b9962f6f031403cf319e145863fe65765803837a81412067442f2838d3e0a0991ffd7e5f28b8dc4ccec19a051988a029f9ff1be821612563b0c09133dcf4a2e5ee456e63bbec2d2f71830b9be9837c50df0804e74ad10f8a2434705d19901aa06d3f4f5b2c62e7ab6a6d8d9e863691feccae21dbc46e2c46d6169bfdc1a54dda7ae2ca9f72a7db1d16b60bc5eeb83113412d9c82f08625a02ee774539dd1f6dd7de83160e8468560e14f125ed638dbc4c6e8b7c015cf00d28a4398c4ebcb3c3147c3d072d0944103c569a44c54f243fc12e3526f3c9c0101ed1f27c5a104f72c8c87d2a9436719dac26b976119bc4784f5829eeb5a042f4efada34d3a1db98c1eef53ef7b32dd5cd4ae3587a5c1f689257aaa74836ee26861c593190929ec7ed1c6bcde1b194ccc9fce04f9135b16da4df33d7070f2f26697cd56eee0cbfe2b50721792a4fc4dfd2dc3f3033a2ec6db7f5195dd546cd1b1f803239fa90acff381a3f8e559b78cbe61efecba710a5d2701ae71c702799"",
                                ""gas"": ""0x63f2f"",
                                ""value"": ""0x0"",
                                ""calls"": [
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x10a077041c9157dac87c494a03452e6c8990096c9a84d7639f49353b535c52652810c2f73835cf600f07c978f55fe18817c2885e3fc4ac949020107cf7ee814b00d28a4398c4ebcb3c3147c3d072d0944103c569a44c54f243fc12e3526f3c9c"",
                                        ""gas"": ""0x61ff8"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x264ef25d0264d0b12f5a130e2a06bb73a97d7d9d307afce61df922801431e7a4009537fb1e6ddfa5480e74889fc87c2d0f2db954ec82e79bf78473821a312f33""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x264ef25d0264d0b12f5a130e2a06bb73a97d7d9d307afce61df922801431e7a4009537fb1e6ddfa5480e74889fc87c2d0f2db954ec82e79bf78473821a312f33305431f2cbe819fd16a18be847911a4ace4d7c886eec337d3b002549e3cf196f0d2684d93f911f00e2d7fa8b423d6f1c74de7f04687d8d65a3f84510398e3ddc"",
                                        ""gas"": ""0x6082b"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x2a02f9d2bd81a616d61c3a0266345724c1182fc4df5834b08b3aad94093650d403408b978fc0446c29d06ab75c78576e24306f7bd66e5938090ae82a6e30fef3""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x161b96e55439a2e3fd8b33be69d5c498c178a817ced7b5ad55dfeaa629f628df037022c488f518974889d49dbd029935e6a671da3d747dca6e2a3a870926303d0101ed1f27c5a104f72c8c87d2a9436719dac26b976119bc4784f5829eeb5a04"",
                                        ""gas"": ""0x606a2"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x28e915a21b03b9d7480068dabc53c35c0ca7e154f7526680ab17678d299cbfd0273c53505ee166ffc069c4ac59ecb33c214bbfb5c46cc8582417902ed0e72bca""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x28e915a21b03b9d7480068dabc53c35c0ca7e154f7526680ab17678d299cbfd0273c53505ee166ffc069c4ac59ecb33c214bbfb5c46cc8582417902ed0e72bca2a02f9d2bd81a616d61c3a0266345724c1182fc4df5834b08b3aad94093650d403408b978fc0446c29d06ab75c78576e24306f7bd66e5938090ae82a6e30fef3"",
                                        ""gas"": ""0x5eed8"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x0daf5f59546b956721fc2ec277b1d312823bf24bdee1eabc4c76e1b85abbe44005573af8955c511a395d225fc532fb43388c457ed71a00997e52ccdb7c55eb7e""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x17f498193bc520aada875e0584b99b605321c6b96b4d01b0027001bb961fd04e00c4c7eae80ad32bd3f2e07e0f6c496053c62426761195ae7faa7388458b0a342f4efada34d3a1db98c1eef53ef7b32dd5cd4ae3587a5c1f689257aaa74836ee"",
                                        ""gas"": ""0x5ed4f"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x2d4701b3615e0005933693918d82981c99e94963787ed7b29ed5d1c87f90c43c1f66fee06a5018b589438541d351aa88d8209908f19e132b37a3f7bce5757148""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x2d4701b3615e0005933693918d82981c99e94963787ed7b29ed5d1c87f90c43c1f66fee06a5018b589438541d351aa88d8209908f19e132b37a3f7bce57571480daf5f59546b956721fc2ec277b1d312823bf24bdee1eabc4c76e1b85abbe44005573af8955c511a395d225fc532fb43388c457ed71a00997e52ccdb7c55eb7e"",
                                        ""gas"": ""0x5d585"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x29e04876e0bb883f007b86f718d7b6d48361c6718d7092e22d9353c1f232b9a90da45748666a24a2bf190a07de1fd0eed0de5d62ab28418f10fbf2fd581b750b""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x2975d86a27bf5c231b312673e80c335625d992e8200deac4f5f10c2159e7a24d094cd49be59c33deefc1d696ed21c34bae02c48d7c3c0d0027a55033b17e21ea26861c593190929ec7ed1c6bcde1b194ccc9fce04f9135b16da4df33d7070f2f"",
                                        ""gas"": ""0x5d3fc"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x02b0c0a4f84c822be3ced9e65f285eb8910c18efe2dc03731bf1b5d3c1fe96d70fefb8f3357e290cee79b00a19a2d60cc89af66a3a9a3fe8db2799c6928fc925""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x02b0c0a4f84c822be3ced9e65f285eb8910c18efe2dc03731bf1b5d3c1fe96d70fefb8f3357e290cee79b00a19a2d60cc89af66a3a9a3fe8db2799c6928fc92529e04876e0bb883f007b86f718d7b6d48361c6718d7092e22d9353c1f232b9a90da45748666a24a2bf190a07de1fd0eed0de5d62ab28418f10fbf2fd581b750b"",
                                        ""gas"": ""0x5bc32"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x200a14344e2eda2b6feb5c2b7fe22bd6a61c411632e189599e9d287be30bcbe92586d561d605b8c4b59561ae3f90b19258e420580e9b0e82199612e34bab56e5""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x09d2a4c276ee16cd46bfa0cb5f1b44d122ad6d8e0ee14a3c102053ec543dbc3d1b19e0e7e1ddcd7570e23ae762d55f7d44bc604dc7db27b154c1708d57385c0b26697cd56eee0cbfe2b50721792a4fc4dfd2dc3f3033a2ec6db7f5195dd546cd"",
                                        ""gas"": ""0x5baa9"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x0733b3ded0db598ad2ba4e5273fca842a77ed92061d1ce5fc3b591b420ca723c1d6f148a0893f3bca607c20aa77f4663de117f19ebd2fa81b8a07679503ce1b0""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x0733b3ded0db598ad2ba4e5273fca842a77ed92061d1ce5fc3b591b420ca723c1d6f148a0893f3bca607c20aa77f4663de117f19ebd2fa81b8a07679503ce1b0200a14344e2eda2b6feb5c2b7fe22bd6a61c411632e189599e9d287be30bcbe92586d561d605b8c4b59561ae3f90b19258e420580e9b0e82199612e34bab56e5"",
                                        ""gas"": ""0x5a2de"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x0c77ddf10c5f87ded1e0ba2751804755906dda2d965d55e99801307f684d0dbc24c5e6ddad417deb757884cac8aa52a99ef4836dd5fb93d4f1708245541481d4""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000007"",
                                        ""input"": ""0x1591d3b45a480146f4629f9941c392ea161b9db2757f28ff11c7527727d374eb206ad75ee40f8d6e1e0ba3888ec707b29abb5d3295d012bc6b6bd306b4db65281b1f803239fa90acff381a3f8e559b78cbe61efecba710a5d2701ae71c702799"",
                                        ""gas"": ""0x5a156"",
                                        ""gasUsed"": ""0x1770"",
                                        ""output"": ""0x0d1a351fe2917a02ccae8d38fd173105d20dc6649b2e3dc350efb45727ba6b8e09d53d0a2790fa15f5660068da99219cf5d09ee67c849a86ea0b4ab8d5205aff""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000006"",
                                        ""input"": ""0x0d1a351fe2917a02ccae8d38fd173105d20dc6649b2e3dc350efb45727ba6b8e09d53d0a2790fa15f5660068da99219cf5d09ee67c849a86ea0b4ab8d5205aff0c77ddf10c5f87ded1e0ba2751804755906dda2d965d55e99801307f684d0dbc24c5e6ddad417deb757884cac8aa52a99ef4836dd5fb93d4f1708245541481d4"",
                                        ""gas"": ""0x5898b"",
                                        ""gasUsed"": ""0x96"",
                                        ""output"": ""0x106f895a864f5cdc6e8a67aa30470d6cdea3486b6a2a8b103709fc87ce8fa2ea0029224529d9f329b53790ea36b23f4d47029b9a972856636bd7551715fb0933""
                                    },
                                    {
                                        ""type"": ""STATICCALL"",
                                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                                        ""to"": ""0x0000000000000000000000000000000000000008"",
                                        ""input"": ""0x196bb83f25adbd798fe91ecaafad22392f50acc9e1e70131391a31bc2f25fb8a2f060b32f194044f17e45f36b47e0305bc4e1cd4e0e242ee0ba94bd76a2ec4f5255c709983ef1aed2f62b9962f6f031403cf319e145863fe65765803837a81412067442f2838d3e0a0991ffd7e5f28b8dc4ccec19a051988a029f9ff1be821612563b0c09133dcf4a2e5ee456e63bbec2d2f71830b9be9837c50df0804e74ad10f8a2434705d19901aa06d3f4f5b2c62e7ab6a6d8d9e863691feccae21dbc46e10988d6c2d54f28c25a0718015e512c36da5ca9e0b5643d7af02c20f2293646323dfa0a56f85c5491fdced399eb5e13382204b2e6cfef68b4c13769bde43a98a27fc2d45e854d09eac69a6c11777153eb2699536b2580073f8e26d2350265278205ace91468165575227d56963b92cd031e404b6ff8cdff60e0acf15a0fab2670be5bac130e37ea0e1e6c55abd0817a17e7f9027d11a09f4ce4985a7f9bd714e231dd62f292b6811fcd5cdfd9a4c645ab425576bb20fe0ed18f60814d0011bfc106f895a864f5cdc6e8a67aa30470d6cdea3486b6a2a8b103709fc87ce8fa2ea0029224529d9f329b53790ea36b23f4d47029b9a972856636bd7551715fb0933198e9393920d483a7260bfb731fb5d25f1aa493335a9e71297e485b7aef312c21800deef121f1e76426a00665e5c4479674322d4f75edadd46debd5cd992f6ed090689d0585ff075ec9e99ad690c3395bc4b313370b38ef355acdadcd122975b12c85ea5db8c6deb4aab71808dcb408fe3d1e7690c43d37b4ce6cc0166fa7daa2c46d6169bfdc1a54dda7ae2ca9f72a7db1d16b60bc5eeb83113412d9c82f08625a02ee774539dd1f6dd7de83160e8468560e14f125ed638dbc4c6e8b7c015cf1c60bc71f85d3120e336087daf45a8386ef48dbedd97fc87f7978b0b35d7e4761813d77586ff1f677d79fdcdb7fe9b4cea4c466e2c908d08d0f636406ae79bc10aa84398ad8517473c42113de0ad583f67b79e07372f761f32938f94e56517972c6c441389cb49117c12d11a33d276a6e7002278ac1a18994b5d8a19cbf99ae6"",
                                        ""gas"": ""0x5865e"",
                                        ""gasUsed"": ""0x2c308"",
                                        ""output"": ""0x0000000000000000000000000000000000000000000000000000000000000001""
                                    }
                                ],
                                ""gasUsed"": ""0x3659c"",
                                ""output"": ""0x0000000000000000000000000000000000000000000000000000000000000001""
                            }
                        ],
                        ""gasUsed"": ""0x367f7"",
                        ""output"": ""0x0000000000000000000000000000000000000000000000000000000000000001""
                    },
                    {
                        ""type"": ""CALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x187712a3e229498e9e42888761ab9b92bceb46c7"",
                        ""input"": ""0x"",
                        ""gas"": ""0x8fc"",
                        ""value"": ""0x7b08cda3a5e6"",
                        ""gasUsed"": ""0x0"",
                        ""output"": ""0x""
                    },
                    {
                        ""type"": ""CALL"",
                        ""from"": ""0x804c520d3c084c805e37a35e90057ac32831f96f"",
                        ""to"": ""0x1f4b725659ad5bf380911779e27bb04798e86b56"",
                        ""input"": ""0x"",
                        ""gas"": ""0x8fc"",
                        ""value"": ""0x2f946786492817"",
                        ""gasUsed"": ""0x0"",
                        ""output"": ""0x""
                    }
                ],
                ""gasUsed"": ""0x72920"",
                ""output"": ""0x""
            }
        ],
        ""txIndex"": 241
    }
}
```

#### Steps to reproduce the behaviour

I don't know whether it's reproducible.",api: incorrect api output,CWE-665,Improper Initialization,"The bug report describes a situation where the `debug_traceBlockByHash` function provides an incorrect output on its first execution. However, after a different function (`debug_traceTransaction`) is called, subsequent calls to `debug_traceBlockByHash` yield the correct, expected output. This behavior strongly indicates that a required resource or state is not being properly prepared or initialized before the first call. The `debug_traceTransaction` call appears to perform the necessary initialization as a side effect, which corrects the state for later calls. This perfectly matches the description of CWE-665, where a resource is not initialized or is incorrectly initialized, leaving it in an unexpected state. CWE-362 (Race Condition) is not the best fit because the issue is described as a sequential series of events, not a problem of concurrent access. CWE-703 (Improper Check or Handling of Exceptional Conditions) is also less accurate because the problem is not the handling of a rare error condition, but rather the system being in an incorrect state from the start due to a lack of proper initialization.",closed,"The `debug_traceBlockByHash` function inconsistently processes transaction data, resulting in incorrect tracing outputs where certain transactions incorrectly appear to have been reverted when they were not.","This inconsistency can lead to confusion for developers and users relying on the tracing output for debugging and analysis, potentially resulting in incorrect assumptions about transaction states and behaviors, which could affect application logic and user trust.",2159202562,29114,"February 28, 2024 3:13 PM (GMT+8)","March 13, 2024 2:40 PM (GMT+8)",['type:bug'],
go-ethereum,dev mode with path enabled: panic when rewinding farther than 128 blocks.,https://github.com/ethereum/go-ethereum/issues/29103,Storage,"#### Steps to reproduce the behaviour

Start geth in dev mode with path enabled, `--datadir` omitted.  Create many blocks.  Rewind the chain farther than 128 blocks.

#### Backtrace

````
ERROR[02-27|14:41:06.774] RPC method debug_setHead crashed: runtime error: invalid memory address or nil pointer dereference
goroutine 11000 [running]:
github.com/ethereum/go-ethereum/rpc.(*callback).call.func1()
	github.com/ethereum/go-ethereum/rpc/service.go:199 +0x74
panic({0x1065ece40, 0x10744c9a0})
	runtime/panic.go:884 +0x204
github.com/ethereum/go-ethereum/core/rawdb.(*ResettableFreezer).AncientRange(0x14001eb02a0?, {0x105eff918?, 0x140006f5120?}, 0x140003a0b28?, 0x140003a0c28?, 0x1065d4140?)
	github.com/ethereum/go-ethereum/core/rawdb/freezer_resettable.go:127 +0x34
github.com/ethereum/go-ethereum/core/rawdb.ReadStateHistoryMetaList(...)
	github.com/ethereum/go-ethereum/core/rawdb/accessors_state.go:180
github.com/ethereum/go-ethereum/triedb/pathdb.checkHistories(0x0, 0x8e94f000774ec435?, 0xb89b7709dbd314c8?, 0x1400262ac58)
	github.com/ethereum/go-ethereum/triedb/pathdb/history.go:548 +0x70
github.com/ethereum/go-ethereum/triedb/pathdb.(*Database).Recoverable(0x140001ce280, {0x5f, 0x91, 0x4e, 0xb1, 0x6c, 0xef, 0xb9, 0xb5, 0x35, ...})
	github.com/ethereum/go-ethereum/triedb/pathdb/database.go:397 +0x160
github.com/ethereum/go-ethereum/triedb.(*Database).Recoverable(0x1067534c0?, {0x5f, 0x91, 0x4e, 0xb1, 0x6c, 0xef, 0xb9, 0xb5, 0x35, ...})
	github.com/ethereum/go-ethereum/triedb/database.go:286 +0x44
github.com/ethereum/go-ethereum/core.(*BlockChain).stateRecoverable(0x14000210400, {0x5f, 0x91, 0x4e, 0xb1, 0x6c, 0xef, 0xb9, 0xb5, 0x35, ...})
	github.com/ethereum/go-ethereum/core/blockchain_reader.go:331 +0x7c
github.com/ethereum/go-ethereum/core.(*BlockChain).setHeadBeyondRoot.func1({0x12f1f0398, 0x14002f3b1d0}, 0x14001a68780)
	github.com/ethereum/go-ethereum/core/blockchain.go:676 +0x908
github.com/ethereum/go-ethereum/core.(*HeaderChain).setHead(0x140004ac6c0, 0x1, 0x0, 0x1400262b298, 0x1400262b278)
	github.com/ethereum/go-ethereum/core/headerchain.go:609 +0x340
github.com/ethereum/go-ethereum/core.(*HeaderChain).SetHead(...)
	github.com/ethereum/go-ethereum/core/headerchain.go:554
github.com/ethereum/go-ethereum/core.(*BlockChain).setHeadBeyondRoot(0x14000210400, 0x1, 0x0, {0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...}, ...)
	github.com/ethereum/go-ethereum/core/blockchain.go:788 +0x280
github.com/ethereum/go-ethereum/core.(*BlockChain).SetHead(0x14000210400, 0x104f5615c?)
	github.com/ethereum/go-ethereum/core/blockchain.go:570 +0x34
github.com/ethereum/go-ethereum/eth.(*EthAPIBackend).SetHead(0x140006e8e88, 0x0?)
	github.com/ethereum/go-ethereum/eth/api_backend.go:64 +0x48
github.com/ethereum/go-ethereum/internal/ethapi.(*DebugAPI).SetHead(0x0?, 0x0?)
	github.com/ethereum/go-ethereum/internal/ethapi/api.go:2111 +0x28
reflect.Value.call({0x14000e26460?, 0x1400097c9a0?, 0x12f1317e0?}, {0x105ef45fe, 0x4}, {0x14000b6fef0, 0x2, 0x105716974?})
	reflect/value.go:586 +0x87c
reflect.Value.Call({0x14000e26460?, 0x1400097c9a0?, 0x1?}, {0x14000b6fef0?, 0x0?, 0x14000d38648?})
	reflect/value.go:370 +0x90
github.com/ethereum/go-ethereum/rpc.(*callback).call(0x14000025140, {0x106843998?, 0x14000b6fea0}, {0x14000d38620, 0xd}, {0x14001aa4618, 0x1, 0x10570f750?})
	github.com/ethereum/go-ethereum/rpc/service.go:205 +0x364
github.com/ethereum/go-ethereum/rpc.(*handler).runMethod(0x14000d38618?, {0x106843998?, 0x14000b6fea0?}, 0x14001a1b260, 0x1?, {0x14001aa4618?, 0x14002dcee38?, 0x0?})
	github.com/ethereum/go-ethereum/rpc/handler.go:565 +0x40
github.com/ethereum/go-ethereum/rpc.(*handler).handleCall(0x14000456000, 0x14001875470, 0x14001a1b260)
	github.com/ethereum/go-ethereum/rpc/handler.go:512 +0x1dc
github.com/ethereum/go-ethereum/rpc.(*handler).handleCallMsg(0x14000456000, 0x14000b6fea0?, 0x14001a1b260)
	github.com/ethereum/go-ethereum/rpc/handler.go:470 +0x1d4
github.com/ethereum/go-ethereum/rpc.(*handler).handleNonBatchCall(0x14000456000, 0x14001875470, 0x14001a1b260)
	github.com/ethereum/go-ethereum/rpc/handler.go:296 +0x174
github.com/ethereum/go-ethereum/rpc.(*handler).handleMsg.func1.1(0x106843998?)
	github.com/ethereum/go-ethereum/rpc/handler.go:269 +0x2c
github.com/ethereum/go-ethereum/rpc.(*handler).startCallProc.func1()
	github.com/ethereum/go-ethereum/rpc/handler.go:387 +0xc0
created by github.com/ethereum/go-ethereum/rpc.(*handler).startCallProc
	github.com/ethereum/go-ethereum/rpc/handler.go:383 +0x8c
````",storage: storage persistence failure,CWE-476,NULL Pointer Dereference,"The user wants me to analyze the provided bug report and select the most accurate CWE from the given list. The bug report's backtrace explicitly states the error is a 'runtime error: invalid memory address or nil pointer dereference'. This error message directly corresponds to the definition of CWE-476, which is 'The product dereferences a pointer that it expects to be valid but is NULL.' The Go language's 'nil pointer dereference' is the equivalent of a NULL pointer dereference in other languages. While CWE-754 (Improper Check for Unusual or Exceptional Conditions) could be considered a potential root cause (the 'unusual condition' being rewinding farther than 128 blocks), CWE-476 describes the specific, observable fault that causes the program to crash, as detailed in the backtrace. CWE-252 (Unchecked Return Value) is less suitable as there is no direct evidence in the report that the nil pointer resulted from an unchecked function return, even if it's a possible cause. Therefore, CWE-476 is the most precise and evident classification based on the provided information.",closed,The panic occurs due to an attempt to access a nil pointer while processing a request to rewind the blockchain further than 128 blocks. This indicates a lack of proper checks or error handling when dealing with the blockchain state.,"This bug can lead to application crashes during RPC calls, potentially disrupting the service and causing denial of service for users trying to interact with the node in dev mode. It may also lead to data inconsistency if not handled properly.",2157746174,29103,"February 27, 2024 10:50 PM (GMT+8)","February 28, 2024 8:40 PM (GMT+8)",['type:bug'],
go-ethereum,The memory preallocated for WriteBatch is always smaller than the actual size in nodebuffer,https://github.com/ethereum/go-ethereum/issues/29061,Storage,"#### System information

Geth version:  1.13
CL client & version: none
OS & Version: Windows/Linux/OSX
Commit hash : master

#### Expected behaviour

https://github.com/ethereum/go-ethereum/blob/b87b9b45331f87fb1da379c5f17a81ebc3738c6e/triedb/pathdb/nodebuffer.go#L209-L236

Pre-allocated memory to avoid re-allocated.

#### Actual behaviour

The calculated size in Nodebuffer is actually slightly smaller than the actual size, which can result in large memory re-allocate(256M+) during the batch.Put process, affecting performance.

#### Steps to reproduce the behaviour

add detailed log to reproduce

```
log.Debug(""Persisted pathdb nodes"", ""nodes"", len(b.nodes), ""pre-bytes"", common.StorageSize(b.size), ""bytes"", common.StorageSize(size), ""elapsed"", common.PrettyDuration(time.Since(start)))
```

#### Backtrace

none.
",general: general performance degradation,CWE-131,Incorrect Calculation of Buffer Size,"The bug report's central issue is that a pre-allocated buffer's size is miscalculated. The report states, 'The calculated size in Nodebuffer is actually slightly smaller than the actual size'. This directly aligns with the definition of CWE-131: 'The product does not correctly calculate the size to be used when allocating a buffer'. While the consequence is performance degradation due to re-allocation (related to resource management), the root cause is the incorrect calculation of the buffer's size, making CWE-131 the most precise fit. CWE-682 (Incorrect Calculation) is a parent category and is too general, as CWE-131 is specific to buffer size calculations. CWE-400 (Uncontrolled Resource Consumption) describes the symptom (inefficient memory re-allocation) rather than the fundamental flaw, which is the miscalculation itself.",closed,"The preallocated memory for WriteBatch is incorrectly calculated, leading to insufficient memory being allocated compared to the actual requirements during the batch.Put process.","This bug can cause significant performance degradation due to excessive memory reallocation (256M+) during operations, potentially leading to increased latency and resource usage in the application.",2150283089,29061,"February 23, 2024 2:58 AM (GMT+8)","February 28, 2024 8:23 PM (GMT+8)",['type:bug'],
go-ethereum,rpc eth_getTransactionByHash and eth_getTransactionReceipt inconsistency after reorgs,https://github.com/ethereum/go-ethereum/issues/28992,Consensus,"#### System information

Geth version: `geth version 1.13.11-stable-8f7eb9cc`
CL client & version: `beacon-chain version Prysm/v4.2.1/59b310a2216c57fcf67ea0fdec739dad07aeec8b.`
OS & Version: `Linux Ubuntu 22.04.3 LTS amd64`
Commit hash : (not develop)


Initially synced with `--syncmode snap`, switched to `--syncmode full` and `--gcmode archive` after initial sync completed. Always `--state.scheme hash` and `--db.engine pebble`.

I have an older Geth node synced the same way running version `1.12.0-stable-e501b3b0` that does not experience this issue.

#### Expected behaviour

`eth_getTransactionByHash` and `eth_getTransactionReceipt` should always return the correct data, including after a reorg.

#### Actual behaviour

Immediately & shortly after a reorg `eth_getTransactionByHash` and `eth_getTransactionReceipt` are incorrect. In some circumstances they remain incorrect forever.  `eth_getBlockByNumber` and `eth_getBlockReceipts` return the correct data even when `eth_getTransactionByHash` and `eth_getTransactionReceipt` return incorrect data.

Last week I snap synced a new Geth node on version `1.13.11-stable-8f7eb9cc`. After switching my application to use it and I started noticing the above inconsistencies. Yesterday I implemented extra checks that restart my application and rewind 10 blocks when the issue occurs and everything seemed fine after that (the correct data would be available from `eth_getTransactionReceipt` when requested after my application restarted). Moments ago I was digging deeper to understand the problem, hitting the node with lots of `eth_getBlockReceipts` requests after a reorg, and it appears to have caused the bad data to stick permanently.

For reference, Etherscan keeps a list of recent reorgs here https://etherscan.io/blocks_forked

#### Steps to reproduce the behaviour

Subscribe to new blocks and check their receipts via `eth_getBlockReceipts` to see whether the block hashes match.

For a minimal reproduction see https://github.com/NickKelly1/geth-rpc-tx-receipt-issue-reproduction.

",api: incorrect api output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes an inconsistency in data returned by RPC calls (`eth_getTransactionByHash`, `eth_getTransactionReceipt`) specifically occurring 'Immediately & shortly after a reorg'. A blockchain reorg is a complex operation involving concurrent updates to shared data structures that represent the canonical chain state. The bug's symptoms—where different API calls return conflicting information about the same underlying state, and the issue is timing-dependent—are classic indicators of a race condition. The reorg process and the RPC request handlers are the 'concurrent code sequences'. The blockchain state database and its associated caches are the 'shared resource'. The period 'immediately & shortly after a reorg' is the 'timing window' where improper synchronization allows RPC handlers to read an inconsistent, partially updated state. 

CWE-667 (Improper Locking) is a potential implementation cause for a race condition, but CWE-362 describes the observable behavior more accurately and generally without making assumptions about the specific code defect. 

CWE-666 (Operation on Resource in Wrong Phase of Lifetime) is less fitting because the issue is not about using a resource before initialization or after destruction, but rather about accessing a resource while it is in a transient, inconsistent state due to concurrent modification. The core problem is synchronization, not lifecycle phase.",closed,The inconsistency in the responses of `eth_getTransactionByHash` and `eth_getTransactionReceipt` after a blockchain reorganization is likely due to a bug introduced in the handling of transaction and receipt data during reorgs in the new Geth version.,"This bug can lead to applications receiving incorrect transaction data, which can affect user interactions, smart contract executions, and overall trust in the blockchain's data integrity. If the data remains incorrect indefinitely, it could cause significant disruptions in services relying on accurate transaction information.",2135573000,28992,"February 15, 2024 3:34 AM (GMT+8)","February 16, 2024 1:00 AM (GMT+8)",['type:bug'],
go-ethereum,Blobpool data - blocks start of geth after unclean shutdown.,https://github.com/ethereum/go-ethereum/issues/28990,Storage,"#### System information
Geth version: `1.13.11` & `1.13.12`
DB: Pebble, Scheme: Path
CL client & version: prysm@v4.2.1
OS & Version: 22.04 LTS Ubuntu server
Chain: Holesky
HW: i7-6700, 32GB RAM, SSDs

#### Desired behaviour
Geth service is able to start even if blobpool data has an issue.

#### Actual behaviour & workaround
After accidental power loss, Geth 1.13.11 or 1.13.12 is not able to start, exits with Fatal error.

```
  $ sudo journalctl -u geth.service

Feb 12 08:51:44 ethgoerli geth[765]: INFO [02-12|08:51:44.169] Loaded most recent local block           number=927,779 hash=a40c7b..6f3f27 td=1 age=1m20s
Feb 12 08:51:44 ethgoerli geth[765]: INFO [02-12|08:51:44.169] Loaded most recent local finalized block number=927,715 hash=f8c08f..095f98 td=1 age=14m8s
Feb 12 08:51:44 ethgoerli geth[765]: INFO [02-12|08:51:44.170] Loaded last snap-sync pivot marker       number=441,353
Feb 12 08:51:44 ethgoerli geth[765]: WARN [02-12|08:51:44.171] Head state missing, repairing            number=927,779 hash=a40c7b..6f3f27 snaproot=092afa..5d8676
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.311] Loaded most recent local header          number=927,779 hash=a40c7b..6f3f27 td=1 age=1m21s
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.311] Loaded most recent local block           number=925,620 hash=0836c0..a65e1a td=1 age=7h32m57s
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.311] Loaded most recent local snap block      number=927,779 hash=a40c7b..6f3f27 td=1 age=1m21s
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.311] Loaded most recent local finalized block number=927,715 hash=f8c08f..095f98 td=1 age=14m9s
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.311] Loaded last snap-sync pivot marker       number=441,353
Feb 12 08:51:45 ethgoerli geth[765]: WARN [02-12|08:51:45.316] Enabling snapshot recovery               chainhead=925,620 diskbase=926,703
Feb 12 08:51:45 ethgoerli geth[765]: WARN [02-12|08:51:45.318] Loaded snapshot journal                  diskroot=092afa..5d8676 diffs=unmatched
Feb 12 08:51:45 ethgoerli geth[765]: WARN [02-12|08:51:45.318] Snapshot is not continuous with chain    snaproot=092afa..5d8676 chainroot=46884f..af0630
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.318] Initialized transaction indexer          range=""last 2350000 blocks""
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.320] Loaded local transaction journal         transactions=0 dropped=0
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.320] Regenerated local transaction journal    transactions=0 accounts=0
Feb 12 08:51:45 ethgoerli geth[765]: INFO [02-12|08:51:45.325] Transaction pool stopped
Feb 12 08:51:45 ethgoerli geth[765]: Fatal: Failed to register the Ethereum service: EOF
Feb 12 08:51:45 ethgoerli systemd[1]: geth.service: Main process exited, code=exited, status=1/FAILURE
Feb 12 08:51:45 ethgoerli systemd[1]: geth.service: Failed with result 'exit-code'.
Feb 12 08:51:45 ethgoerli systemd[1]: geth.service: Consumed 3.740s CPU time.
Feb 12 08:51:50 ethgoerli systemd[1]: geth.service: Scheduled restart job, restart counter is at 1.
Feb 12 08:51:50 ethgoerli systemd[1]: Stopped Go Ethereum Client.
Feb 12 08:51:50 ethgoerli systemd[1]: geth.service: Consumed 3.740s CPU time.
```

Updated Geth to 1.13.12, did not change behavior.
Tried to resync Geth 1.13.12 from start, still same Fatal error.

```
  $ sudo systemctl stop geth
  $ sudo -u goeth geth --datadir /mnt/ssd-eth/goethereum removedb
	Remove 'state data'? [y/n] y
	Remove 'ancient chain'? [y/n] y
  $ sudo systemctl start geth
  $ sudo journalctl -u geth.service

Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.260] Loaded most recent local block           number=0 hash=b5f7f9..61bde4 td=1 age=4mo2w3d
Feb 12 14:55:27 ethgoerli geth[1571]: WARN [02-12|14:55:27.261] Loaded snapshot journal                  diffs=missing
Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.261] Initialized transaction indexer          range=""last 2350000 blocks""
Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.261] Resuming state snapshot generation       root=69d8c9..788783 accounts=0 slots=0 storage=0.00B dangling=0 elapsed=""59.003µs""
Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.262] Loaded local transaction journal         transactions=0 dropped=0
Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.262] Regenerated local transaction journal    transactions=0 accounts=0
Feb 12 14:55:27 ethgoerli geth[1571]: INFO [02-12|14:55:27.263] Transaction pool stopped
Feb 12 14:55:27 ethgoerli geth[1571]: Fatal: Failed to register the Ethereum service: EOF
Feb 12 14:55:27 ethgoerli systemd[1]: geth.service: Main process exited, code=exited, status=1/FAILURE
Feb 12 14:55:27 ethgoerli systemd[1]: geth.service: Failed with result 'exit-code'.
Feb 12 14:55:30 ethgoerli systemd[1]: Stopped Go Ethereum Client.
```

Removed ""LOCK"" file and ""blobpool"" directory and everything looked OK again.

```
  $ sudo -u goeth geth --datadir /mnt/ssd-eth/goethereum removedb
	Remove 'state data'? [y/n] y
	Remove 'ancient chain'? [y/n] y
  $ sudo -u goeth rm -v /mnt/ssd-eth/goethereum/geth/LOCK
  $ sudo -u goeth rm -rv /mnt/ssd-eth/goethereum/geth/blobpool/
  $ sudo systemctl start geth
  $ sudo journalctl -u geth.service

Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.692] Loaded most recent local block           number=0 hash=b5f7f9..61bde4 td=1 age=4mo2w3d
Feb 12 14:56:22 ethgoerli geth[1596]: WARN [02-12|14:56:22.692] Loaded snapshot journal                  diffs=missing
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.692] Initialized transaction indexer          range=""last 2350000 blocks""
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.692] Resuming state snapshot generation       root=69d8c9..788783 accounts=0 slots=0 storage=0.00B dangling=0 elapsed=""50.172µs""
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.692] Loaded local transaction journal         transactions=0 dropped=0
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.692] Regenerated local transaction journal    transactions=0 accounts=0
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.705] Generated state snapshot                 accounts=317 slots=31 storage=15.40KiB dangling=0 elapsed=12.675ms
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.707] Enabled snap sync                        head=0 hash=b5f7f9..61bde4
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.709] Chain post-merge, sync via beacon client
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.709] Gasprice oracle is ignoring threshold set threshold=2
Feb 12 14:56:22 ethgoerli geth[1596]: WARN [02-12|14:56:22.721] Engine API enabled                       protocol=eth
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.721] Starting peer-to-peer node               instance=Geth/v1.13.12-stable-02eb36af/linux-amd64/go1.21.6
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.830] New local node record                    seq=****** id=****** ip=127.0.0.1 udp=30304 tcp=30304
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.830] Started P2P networking                   self=enode://******
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.831] IPC endpoint opened                      url=/mnt/ssd-eth/goethereum/geth.ipc
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.831] Loaded JWT secret file                   path=/mnt/ssd-eth/******
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.832] HTTP server started                      endpoint=127.0.0.1:8545 auth=false prefix= cors= vhosts=localhost
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.832] WebSocket enabled                        url=ws://127.0.0.1:8551
Feb 12 14:56:22 ethgoerli geth[1596]: INFO [02-12|14:56:22.832] HTTP server started                      endpoint=127.0.0.1:8551 auth=true  prefix= cors=localhost vhosts=localhost
Feb 12 14:56:33 ethgoerli geth[1596]: INFO [02-12|14:56:33.589] Looking for peers                        peercount=1 tried=33 static=0
```

#### Suggestions for improvements.
* Improve Fatal log info to easier pinpoint the issue causing the exit.
* Automatically resync blobpool data at startup if it's detected as corrupt or has issues
* Add removedb function for ""blobpool data"" removal
",storage: storage persistence failure,CWE-703,Improper Check or Handling of Exceptional Conditions,"The bug report describes a scenario where the application, `geth`, enters a non-recoverable state after an 'accidental power loss' or 'unclean shutdown'. This event is a classic example of an 'exceptional condition' that is not part of the normal operational flow. The application's data files (`blobpool`) become corrupted or inconsistent as a result. Upon restart, the application fails to handle this corrupted state, leading to a fatal error (`Fatal: Failed to register the Ethereum service: EOF`) and a crash. This directly aligns with the definition of CWE-703, as the product does not properly 'handle exceptional conditions that rarely occur'. The desired behavior, 'Geth service is able to start even if blobpool data has an issue', explicitly calls for better handling of this exact type of exception. 

CWE-20 (Improper Input Validation) is less fitting. While the application is failing because it's reading corrupt data from its own storage (a form of 'input'), the fundamental weakness is not the validation logic itself, but the lack of a robust recovery mechanism for the specific exceptional event (the power loss) that caused the data to become invalid. 

CWE-665 (Improper Initialization) is also less accurate. The problem is not with the initial creation of the resource, but with the re-initialization process during startup when it encounters a corrupted state left by the unclean shutdown. The initialization fails *because* it cannot handle the exceptional condition, making CWE-703 the more precise and root-cause-oriented classification.",closed,"The Geth client fails to handle corrupted blobpool data after an unclean shutdown, leading to a fatal error during the startup process.","The inability of the Geth client to start after an unclean shutdown can disrupt the operation of Ethereum nodes, affecting transaction processing and network connectivity.",2134760547,28990,"February 14, 2024 4:46 PM (GMT+8)","February 16, 2024 11:33 PM (GMT+8)",['type:bug'],
go-ethereum,Unexpected overflow for BlobTxType,https://github.com/ethereum/go-ethereum/issues/28969,Utilities,"#### System information

Geth version: `n/a`
CL client & version: v1.12.2 / v1.13.12
OS & Version: Linux/OSX
Commit hash : (if `develop`)

#### Expected behaviour

`BlobTxType` is processed correctly.

#### Actual behaviour

Errors are reported when calling `uint256.FromBig((*big.Int)(dec.R))` as it reports an overflow. 
Also opened an issue with the uint256 library. https://github.com/holiman/uint256/issues/147

#### Steps to reproduce the behaviour

Running Orchestrate tx-listener on Sepolia.

#### Backtrace

Logging the value that would return the error.

````
INFO   [0007] (tx-listener.session.ethereum.hook): block processed  block_number=5263607 chain=4b0aed40-c2da-44b1-9396-50233910590e owner_id= tenant_id=_
'r' value overflows uint256: 0xb75685b724028d4cc66bd8ff0aa46b6e4721842ac1f7f4880563b581dcfb2ee
's' value overflows uint256: 0x4cdd5a8417fa2c49aa472b8e079e01f276120089ea0c7b27df4533193876abed
'v' value overflows uint256: 0x1
'r' value overflows uint256: 0x241bff69a5506e1a26543b97b22854ec556f822b71627a3136f245e05b98fda9
's' value overflows uint256: 0x7a8ee9210af64eee6e3a15b331ea7d491d3d983f93d52b06f97282a050a9e973
'v' value overflows uint256: 0x1
````

When submitting logs: please submit them as text and not screenshots.
",consensus: consensus liveness failure,CWE-20,Improper Input Validation,"The bug report describes an error where a function `uint256.FromBig` fails because the input `big.Int` value is too large to be represented as a `uint256`. The values that cause the overflow, `r` and `s`, are components of a transaction (`BlobTxType`), which constitutes external input to the system. The root cause of the error is that the code attempts to process this input without first verifying that it conforms to the required constraints (i.e., that the value is less than 2^256). This is a classic case of improper input validation.

- **CWE-20 (Improper Input Validation)** is the most accurate choice. The system receives data from an external source (a transaction) and fails to validate that its properties (the size of the `r` and `s` values) are correct before processing. The subsequent overflow is a direct symptom of this lack of validation.

- **CWE-190 (Integer Overflow or Wraparound)** is less suitable. While an 'overflow' occurs, CWE-190 typically describes a situation where an arithmetic calculation (like addition or multiplication) results in a value that exceeds the storage capacity, often leading to a wraparound. Here, the overflow is detected during a type conversion from an input value, and the function correctly reports an error rather than wrapping around. The weakness is not in the arithmetic itself, but in the failure to sanitize the input that leads to the failed conversion.

- **CWE-195 (Signed to Unsigned Conversion Error)** is not the best fit. The issue is about the magnitude of the number, not a misinterpretation due to its sign. The `big.Int` value is simply too large to fit in the `uint256` container, a problem that would persist even if the value was guaranteed to be positive. Therefore, the more general CWE-20 is more appropriate.",closed,"The system is attempting to process values that exceed the maximum limit of the uint256 data type, leading to overflow errors.","This bug could prevent the correct processing of transactions involving BlobTxType, potentially leading to transaction failures or incorrect behavior in the blockchain application.",2128981297,28969,"February 11, 2024 1:06 PM (GMT+8)","February 12, 2024 2:51 PM (GMT+8)",['type:bug'],
go-ethereum,Incorrect transaction receipts after reorg on Holesky,https://github.com/ethereum/go-ethereum/issues/28918,Consensus,"#### System information

Geth version: `Geth/v1.13.11-stable-8f7eb9cc/linux-amd64/go1.21.6`
CL client & version: `Lighthouse v4.6.0-1be5253`
OS & Version: Linux
Commit hash : (if `develop`)

#### Expected behaviour
Return the correct transaction receipt after reorg

#### Actual behaviour

The node returns the incorrect receipt, from the forked block, not the real block.

This only happens SOMETIMES, not always. I have multiple geth full nodes on Holesky and they frequently disagree about transaction receipt details.

#### Steps to reproduce the behaviour

This is VERY hard to reproduce and you might need multiple geth nodes to query to find it. However, it's happening rather frequently. We ask for a transaction receipt of a given transaction that might be in a fork block and even though the node has already re-orged back to the correct chan, the receipt doesn't get updated...

Ok, here's what I can see:

Take this transaction hash: `0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d`

https://holesky.etherscan.io/tx/0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d

It can be found in this block: https://holesky.etherscan.io/block/863089

But it can also be found in this block: https://holesky.etherscan.io/block/863089/f

On the ""problem node"" here's the proof:

```bash
# Get forked block by hash and grep the txhash:
curl -s -H 'Content-Type: application/json' http://localhost:8545 -d '{""jsonrpc"":""2.0"",""id"":1,""method"":""eth_getBlockByHash"",""params"":[""0x35700cb7eb316e36bba0f0d77124026cb0d0e2438f37164485705e1b535d299e"",false]}' | jq '.result.transactions[]' | grep 0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d
""0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d""

# Get the real block by hash and grep the txhash:
curl -s -H 'Content-Type: application/json' http://localhost:8545 -d '{""jsonrpc"":""2.0"",""id"":1,""method"":""eth_getBlockByHash"",""params"":[""0x60564dc65c29b542a2d9bc17cf14a613b0694cc50e8f865caf1bba450209b883"",false]}' | jq '.result.transactions[]' | grep 0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d
""0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d
```

So the node knows about both the fork and the real block and the txhash is in both, ask for the receipt:

```bash
curl -s -H 'Content-Type: application/json' http://localhost:8545 -d '{""jsonrpc"": ""2.0"", ""method"": ""eth_getTransactionReceipt"", ""params"": [""0xa40c2c133a9ebdb9324b2045ca3662fcb064643733fa1d272a951ad9603b578d""], ""id"": 1}' | jq
{
  ""jsonrpc"": ""2.0"",
  ""id"": 1,
  ""result"": {
    ""blockHash"": ""0x35700cb7eb316e36bba0f0d77124026cb0d0e2438f37164485705e1b535d299e"",
    ""blockNumber"": ""0xd2b71""
```

The node is clearly returning the receipt of the fork... but if I ask the node for the block by number, we can see, it's not on the fork...

```bash
curl -s -H 'Content-Type: application/json' http://localhost:8545 -d '{""jsonrpc"":""2.0"",""id"":1,""method"":""eth_getBlockByNumber"",""params"":[""0xd2b71"",false]}' | jq '.result.hash'
""0x60564dc65c29b542a2d9bc17cf14a613b0694cc50e8f865caf1bba450209b883""
```

Thus it is my belief that there is some bug in Geth preventing the receipt data from getting updated after the fork and returning the correct response.

Again, this does not happen on all my nodes at the same time, but it does happen somewhat randomly.

### Geth config

`--state.scheme=path`
",api: incorrect api output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a situation where a Geth node returns an incorrect transaction receipt after a blockchain re-organization (reorg). Specifically, it returns the receipt from a stale, forked block even though other parts of the node's state correctly reflect the new, canonical chain. This behavior is described as intermittent and hard to reproduce, happening 'SOMETIMES' and 'somewhat randomly'. This points to a timing-related issue. The reorg process and the API request handler (`eth_getTransactionReceipt`) are concurrent operations acting on a shared resource: the node's state database/cache. The inconsistent state (correct block by number, incorrect receipt by hash) strongly suggests that these concurrent operations are not properly synchronized. A request for a receipt is likely being processed in a timing window where the reorg has updated some parts of the state but not yet the transaction receipt index. This perfectly matches the definition of CWE-362, a race condition. CWE-416 is less likely as the issue seems to be about accessing valid but outdated data, not accessing freed memory. CWE-1300 is irrelevant as the bug is a software logic flaw, not a physical side-channel vulnerability.",closed,"The Geth client is returning transaction receipts from a forked block instead of the correct block after a reorganization, indicating a potential issue in how the state is updated post-reorg.","Incorrect transaction receipts can lead to confusion and errors in transaction validation, potentially allowing users to believe that transactions have been processed or confirmed when they have not, undermining the reliability of the blockchain.",2115503285,28918,"February 2, 2024 6:12 PM (GMT+8)","February 3, 2024 2:17 AM (GMT+8)",['type:bug'],
go-ethereum,txIndexer.report() method uses too much cpu on sepolia network,https://github.com/ethereum/go-ethereum/issues/28907,Consensus,"#### System information

Geth version: `v1.13.11`
CL client & version: prysm@v4.2.1
OS & Version: Linux

#### Steps to reproduce the behaviour

We have been running an archive node for sepolia network, the node also serves the `eth_getTransactionReceipt` calls at a rate of 150 QPS, this call serves very well until we upgrading to v1.13.11, which causes `eth_getTransactionReceipt` at a very high latency (p95 >5 seconds).

I dug a bit on the `eth_getTransactionReceipt` method and found that in v1.13.11 if the transaction is not found atm it will [trigger a progress query on the `txIndexer.txIndexProgress()`](https://github.com/ethereum/go-ethereum/blob/master/core/blockchain_reader.go#L275), the `txIndexProgress()` method then trigger the `txIndexer.report()` method and get the progress from the txIndexer mainloop through a channel. (Well I don't think it's suitable to have a channel on the path of serving a RPC call, but let's hold on that for now.)

The real cause of the high latency is inside the `txIndexer.report()`, it can trace to the deep internals of pebble and finally stop at the crc32.Update() method and Syscall6(). 

![image](https://github.com/ethereum/go-ethereum/assets/4777457/ce36c961-ddf2-436c-a25f-f0382002f8c5)

as you can see `txIndexer.report()` takes 81% of the sampled CPU time.

#### node startup options

```
geth
 --sepolia \
                  --datadir=/var/data/geth \
                  --syncmode=full \
                  --snapshot=false \
                  --cache=1024 \
                  --txlookuplimit=0 \
                  --http \
                  --http.addr=0.0.0.0 \
                  --http.port=8545 \
                  --http.vhosts=* \
                  --http.api=net,web3,eth,txpool,pre,engine,trace \
                  --ws \
                  --ws.addr=0.0.0.0 \
                  --ws.port=8546 \
                  --ws.origins=* \
                  --ws.api=net,web3,eth,txpool,engine \
                  --rpc.allow-unprotected-txs \
                  --metrics \
                  --pprof \
                  --pprof.addr=0.0.0.0 \
                  --pprof.port=9260 \
                  --allow-insecure-unlock \
                  --rpc.gascap=250000000 \
                  --authrpc.addr=0.0.0.0 \
                  --authrpc.port=8551 \
                  --authrpc.jwtsecret=/var/data/geth/jwt.hex \
                  --authrpc.vhosts=* \
                  --state.scheme=path \
                  --db.engine=pebble \
                  --history.transactions=0
```


#### Update

While things has not ended. We also run a mainnet ethereum node and also upgraded to `v1.13.11`, but the latency of the `eth_getTransactionReceipt` is just as low as before(p95 ~1ms). So I also capture a cpu profile for the mainnet node, btw the mainnet node and the sepolia roughly serve the same kinds and the same amount of RPC calls, but as we can see in mainnet cpu profile the `txIndexer.report()` only takes 0.4% of the sampled CPU time.

![image](https://github.com/ethereum/go-ethereum/assets/4777457/b8c893f1-beeb-4a2c-ba24-c6a5af46cb67)


we can see in mainnet node's pprof it doesn't run into the crc32.Update and the Syscall6 method, maybe it's quite related to pebbledb or the db hierarchy between sepolia and mainnet... ",general: general performance degradation,CWE-400,Uncontrolled Resource Consumption,"The bug report details a situation where a specific function, `txIndexer.report()`, consumes an excessive amount of CPU time (81% of the sampled time) under a high load of specific RPC calls (`eth_getTransactionReceipt`). This massive CPU usage is a clear example of a resource consumption problem. CPU time is a finite resource, and the software fails to control its usage by this function, leading to severe performance degradation (high latency). This directly matches the definition of CWE-400, 'Uncontrolled Resource Consumption', which describes a product not properly controlling the allocation of a limited resource.

CWE-703, 'Improper Check or Handling of Exceptional Conditions', is not suitable because the triggering event—a request for a transaction receipt that does not exist—is a normal and expected part of the API's operation, not a rare or exceptional condition that is improperly handled.

CWE-407, 'Inefficient Algorithmic Complexity', is a plausible but less precise fit. While the high CPU usage could be due to an inefficient algorithm, the report's primary evidence is the sheer amount of resource consumed, not an analysis of the algorithm's complexity (e.g., O(n^2) vs. O(n)). CWE-400 is a more direct and accurate classification of the observed phenomenon, which is the uncontrolled use of the CPU resource.",closed,"The `txIndexer.report()` method in Geth v1.13.11 is consuming excessive CPU resources due to inefficient handling of transaction index progress, particularly when the transaction is not found, leading to high latency in the `eth_getTransactionReceipt` calls.","The high CPU usage and resulting latency can degrade the performance of the Ethereum Sepolia network node, causing slow responses for RPC calls, which may affect user experience and application performance relying on these calls.",2111850052,28907,"February 1, 2024 8:23 AM (GMT+8)","February 6, 2024 11:07 AM (GMT+8)",['type:bug'],
go-ethereum,Transaction lookup using eth_getTransactionReceipt returns the wrong information after reorg,https://github.com/ethereum/go-ethereum/issues/28885,Consensus,"#### System information

Geth version: `Geth/v1.13.11-stable-8f7eb9cc/linux-amd64/go1.20.7`
CL client & version: `lighthouse@v4.6.0`
OS & Version: Linux

#### Expected behaviour
`eth_getTransactionReceipt` returns the right receipt information including block hash, number, e.t.c. Even when a reorg occurs on that block and the transaction is mined in another block.

#### Actual behaviour
`eth_getTransactionReceipt` sometimes returns the receipt with information from the reorg'd block. This causes our internal systems to fail. This is especially observed in the sepolia/holesky testnets since 1.13.11 is required for the upcoming hardfork.

#### Steps to reproduce the behaviour
1. Upgrade to 1.13.11 stable version along with lighthouse 4.6.0
2. Run an archival node with the settings below (although it can possibly happen in full nodes)

```
exec /app/geth \
    --networkid ""17000"" \
    --syncmode=""full"" \
    --gcmode=""archival"" \
    --snapshot=""true"" \
    --rpc.txfeecap=0 \
    --rpc.batch-request-limit 100000 \
    --rpc.batch-response-max-size 500000000 \
    --http \
    --http.addr 0.0.0.0 \
    --http.vhosts=* \
    --http.api=""engine,eth,web3,net,debug,txpool"" \
    --http.corsdomain=* \
    --authrpc.addr 0.0.0.0 \
    --authrpc.vhosts=* \
    --cache ""16384"" \
    --state.scheme hash
```

3. When a reorg occurs there's a probability that the cache for eth_getTransactionReceipt stores the wrong receipt information so any subsequent calls to get a receipt returns the wrong information. When querying the block using the hash or number, the right details are contained there

#### Backtrace
Logs that had reorg
````
# Specific transaction with observed behavior
curl -X POST -H ""Content-Type: application/json"" --data '{""method"":""eth_getTransactionReceipt"",""params"":[""0x36057fedd64685fb69ba23f9d49cbf7b1c0039659d24adaf2b60274b716ef012""],""id"":0,""jsonrpc"":""2.0""}' http://localhost:8545 | jq

# Actual Result
{
  ""jsonrpc"": ""2.0"",
  ""id"": 0,
  ""result"": {
    ""blockHash"": ""0xa0056303bb52371aa38b7996f031a9d10bc8dd1d78ce921b5047abb47334ad7a"",
    ""blockNumber"": ""0xc78e8"",
    ""contractAddress"": null,
    ""cumulativeGasUsed"": ""0x1c7bac2"",
    ""effectiveGasPrice"": ""0x3b9aca00"",
    ""from"": ""0x9146a7ece7054c39f2d27dfc45efa8fa8e1d1323"",
    ""gasUsed"": ""0xfaa5e"",
    ""logs"": [],
    ""logsBloom"": ""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
    ""status"": ""0x1"",
    ""to"": ""0x3f5dfd1522a84394390382a9801616bd530a9655"",
    ""transactionHash"": ""0x36057fedd64685fb69ba23f9d49cbf7b1c0039659d24adaf2b60274b716ef012"",
    ""transactionIndex"": ""0x2d"",
    ""type"": ""0x2""
  }
}


# Expected result
{
  ""jsonrpc"": ""2.0"",
  ""id"": 0,
  ""result"": {
    ""blockHash"": ""0x046495e9e416d899e933c21cd0539aad3d90f6888bd46007246456189c482299"",
    ""blockNumber"": ""0xc78e9"",
    ""contractAddress"": null,
    ""cumulativeGasUsed"": ""0xffe36"",
    ""effectiveGasPrice"": ""0x3b9aca00"",
    ""from"": ""0x9146a7ece7054c39f2d27dfc45efa8fa8e1d1323"",
    ""gasUsed"": ""0xfaa5e"",
    ""logs"": [],
    ""logsBloom"": ""0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"",
    ""status"": ""0x1"",
    ""to"": ""0x3f5dfd1522a84394390382a9801616bd530a9655"",
    ""transactionHash"": ""0x36057fedd64685fb69ba23f9d49cbf7b1c0039659d24adaf2b60274b716ef012"",
    ""transactionIndex"": ""0x1"",
    ""type"": ""0x2""
  }
}


# Logs from problematic deployment
For prod ethereum-0 archival holesky
ethereum-0 geth INFO [01-26|22:08:21.009] Chain head was updated                   number=817,384 hash=a00563..34ad7a root=51418b..2f5c82 elapsed=4.17309ms
ethereum-0 geth INFO [01-26|22:08:28.259] Imported new potential chain segment     number=817,384 hash=319dbf..fec640 blocks=1 txs=55 mgas=29.916 elapsed=128.272ms   mgasps=233.222 snapdiffs=1.35MiB triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:29.254] Imported new potential chain segment     number=817,385 hash=046495..482299 blocks=1 txs=33 mgas=29.944 elapsed=135.098ms   mgasps=221.645 snapdiffs=1.35MiB triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:31.895] Chain reorg detected                     number=817,383 hash=2bd818..756b40 drop=1 dropfrom=a00563..34ad7a add=2 addfrom=046495..482299
ethereum-0 geth INFO [01-26|22:08:31.904] Chain head was updated                   number=817,385 hash=046495..482299 root=c7fbc7..da6141 elapsed=9.360949ms
ethereum-0 geth INFO [01-26|22:08:38.883] Imported new potential chain segment     number=817,386 hash=6b13b0..95ed30 blocks=1 txs=23 mgas=9.466  elapsed=43.761ms    mgasps=216.302 snapdiffs=1.35MiB triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:39.176] Chain head was updated                   number=817,386 hash=6b13b0..95ed30 root=b1f284..f364cd elapsed=4.695815ms

# Logs from expected behavior
ethereum-0 geth INFO [01-26|22:07:39.776] Imported new potential chain segment     number=817,383 hash=2bd818..756b40 blocks=1    txs=0       mgas=0.000    elapsed=3.333ms     mgasps=0.000   snapdiffs=3.18MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:07:40.072] Chain head was updated                   number=817,383 hash=2bd818..756b40 root=c0724c..aab761 elapsed=""815.439µs""
ethereum-0 geth INFO [01-26|22:08:14.904] Imported new potential chain segment     number=817,384 hash=a00563..34ad7a blocks=1    txs=49      mgas=29.998   elapsed=146.869ms   mgasps=204.250 snapdiffs=3.18MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:20.822] Chain head was updated                   number=817,384 hash=a00563..34ad7a root=51418b..2f5c82 elapsed=3.650328ms
ethereum-0 geth INFO [01-26|22:08:23.798] Imported new potential chain segment     number=817,384 hash=319dbf..fec640 blocks=1    txs=55      mgas=29.916   elapsed=122.690ms   mgasps=243.832 snapdiffs=3.19MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:24.836] Imported new potential chain segment     number=817,385 hash=046495..482299 blocks=1    txs=33      mgas=29.944   elapsed=120.422ms   mgasps=248.658 snapdiffs=3.19MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:26.823] Chain reorg detected                     number=817,383 hash=2bd818..756b40 drop=1 dropfrom=a00563..34ad7a add=1 addfrom=319dbf..fec640
ethereum-0 geth INFO [01-26|22:08:26.829] Chain head was updated                   number=817,384 hash=319dbf..fec640 root=aa8a16..a2261d elapsed=6.317064ms
ethereum-0 geth INFO [01-26|22:08:27.667] Chain head was updated                   number=817,385 hash=046495..482299 root=c7fbc7..da6141 elapsed=4.855725ms
ethereum-0 geth INFO [01-26|22:08:38.878] Imported new potential chain segment     number=817,386 hash=6b13b0..95ed30 blocks=1    txs=23      mgas=9.466    elapsed=39.822ms    mgasps=237.699 snapdiffs=3.19MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:39.170] Chain head was updated                   number=817,386 hash=6b13b0..95ed30 root=b1f284..f364cd elapsed=1.247488ms
ethereum-0 geth INFO [01-26|22:08:49.142] Imported new potential chain segment     number=817,387 hash=a6dd16..dbda80 blocks=1    txs=38      mgas=28.078   elapsed=109.512ms   mgasps=256.391 snapdiffs=3.19MiB    triedirty=0.00B
ethereum-0 geth INFO [01-26|22:08:49.440] Chain head was updated                   number=817,387 hash=a6dd16..dbda80 root=b8bece..4073f3 elapsed=1.507894ms
ethereum-0 geth INFO [01-26|22:09:02.154] Regenerated local transaction journal    transactions=0 accounts=0
````

When submitting logs: please submit them as text and not screenshots.
",api: incorrect api output,CWE-362,Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'),"The bug report describes a scenario where an API call, `eth_getTransactionReceipt`, returns incorrect (stale) data. This occurs specifically after a blockchain 'reorg' event. A reorg involves one process (chain synchronization) modifying the state of the blockchain by dropping old blocks and adding new ones. Concurrently, another process (the API handler) is attempting to read this state to fulfill a user request. The report explicitly states that a cache is involved and that it can store the 'wrong receipt information' after a reorg. This points to a timing issue where the API reads from the cache before the reorg process has a chance to invalidate or update the cached entry. This is a classic race condition. 

CWE-362, 'Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')', perfectly describes this situation. The shared resource is the transaction receipt cache and the underlying blockchain state. The concurrent code sequences are the chain reorg logic and the API request handler. The lack of proper synchronization between the modification (reorg) and the read (API call) leads to the bug.

CWE-841, 'Improper Enforcement of Behavioral Workflow', is not applicable because the issue is not about a user or actor failing to perform actions in a required sequence. It's an internal state management failure due to concurrency.

CWE-462, 'Duplicate Key in Associative List (Alist)', is also incorrect as the problem is not related to duplicate keys in a data structure but rather to the value associated with a key being stale.",closed,"The caching mechanism for transaction receipts fails to update correctly during a blockchain reorganization, leading to the return of stale or incorrect data from the eth_getTransactionReceipt method.","This bug can cause internal systems that depend on accurate transaction receipt information to fail, leading to potential disruptions in services that rely on the integrity of transaction data.",2103069559,28885,"January 26, 2024 11:51 PM (GMT+8)","January 30, 2024 4:24 PM (GMT+8)",['type:bug'],